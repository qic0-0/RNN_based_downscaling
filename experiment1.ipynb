{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb20fe9d-0dbb-4caf-aa2b-8b5921383169",
   "metadata": {},
   "source": [
    "## AEP"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "8118ffd26142a9a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_aep = pd.read_csv(\"data/AEP_hourly.csv\")\n",
    "df_aep.rename(columns={'Datetime': 'ds', 'AEP_MW': 'y'}, inplace=True)\n",
    "df_aep['ds'] = pd.to_datetime(df_aep['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'AEP_results'"
   ],
   "id": "5db8d797fb6b5d60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "e20100736d301702"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import prophet_linear_adjust as prophet_based\n",
    "daily_demand = df_aep.groupby(df_aep['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_aep, date_start, date_end, daily_demand, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "8cd84b577cc13ea5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with daily, weekly, yearly seasonality",
   "id": "88e6f85b9cc64c1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand = df_aep.groupby(df_aep['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "results_prophet_dwy = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_aep, date_start, date_end, daily_demand, manual = False, daily = True, weekly = True, yearly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_dwy.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_dwy = pd.concat(results_prophet_dwy, ignore_index=True)\n",
    "\n",
    "results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)"
   ],
   "id": "55aec6877637d97a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test Simple RNN",
   "id": "23089dd82c59ca7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_simple\n",
    "train_config = RNN_simple.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_simple = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = RNN_simple.RNN_simple(latent_dim=32, activation='relu')\n",
    "    trainer = RNN_simple.RNN_train_simple(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_simple = pd.concat([results_simple, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)"
   ],
   "id": "2e3bd59d5a1cacd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6d8c4c83-0604-4c0c-8fd5-b696b180310f",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "6007d956-d042-4f55-b110-4649eb5b23d1",
   "metadata": {},
   "source": [
    "import RNN_attention\n",
    "train_config = RNN_attention.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_attention = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = RNN_attention.RNN_attention(latent_dim=32, d_model=128, nhead=4)\n",
    "    trainer = RNN_attention.RNN_train_attention(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_attention = pd.concat([results_attention, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "448d1d3a-c3c8-46e9-bad0-55eb3eb3457c",
   "metadata": {},
   "source": "### test RNN+self convolution + fourier matrix (weekly, monthly, yearly)"
  },
  {
   "cell_type": "code",
   "id": "64c5838c-0d23-48b1-b71d-2c0c79c15634",
   "metadata": {},
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=32,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier = pd.concat([results_fourier, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "34d07cb93e10a743"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k = 24*3\n",
    "x_ax = np.arange(k)\n",
    "\n",
    "plt.plot(x_ax, results_fourier['y_hat'][:k], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.plot(x_ax, results_fourier['y'][:k], marker=\"o\", linestyle=\"-\", color=\"r\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_Tplus1\")\n",
    "plt.title(\"Line plot of y_Tplus1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "417e3cb139fad504",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "547af856-e054-4279-96e4-e1e4264db04d",
   "metadata": {},
   "source": [
    "## Comed"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import model_summary as model_class\n",
    "import prophet_linear_adjust as prophet_based\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "498db8ff6ea6c4cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8da89f60-d42c-4b68-b83f-b10f930f69c1",
   "metadata": {},
   "source": [
    "df_comed = pd.read_csv(\"COMED_hourly.csv\")\n",
    "df_comed.rename(columns={'Datetime': 'ds', 'COMED_MW': 'y'}, inplace=True)\n",
    "df_comed['ds'] = pd.to_datetime(df_comed['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "out_dir = 'Comed_results'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "a72919bd420eae26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand_comed = df_comed.groupby(df_comed['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_comed, date_start, date_end, daily_demand_comed, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv(out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "68fe5f9ff5d05326",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with weekly seasonality",
   "id": "6fa4ad7e711b555b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand_comed = df_comed.groupby(df_comed['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet_w = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_comed, date_start, date_end, daily_demand_comed, manual = False, daily = True, weekly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_w.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_w = pd.concat(results_prophet_w, ignore_index=True)\n",
    "\n",
    "results_prophet_w.to_csv(out_dir + '/results_prophet_w.csv', index=False)"
   ],
   "id": "56304448d5c902b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f9ee246e-5e4c-45dc-b92d-c225f8cc6dd5",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "a9fbb12a-f16f-4437-acbf-e9ba9bdc7a2a",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con.to_csv(out_dir + '/results_aep_self_con.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "098899fc-f69c-40fd-97d5-21d4a8e72619",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + numerical weekday"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wn = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wn()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wn = pd.concat([results_aep_self_con_wn, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con_wn.to_csv(out_dir + '/results_aep_self_con_wn.csv', index=False)"
   ],
   "id": "f6b8f3248cc64895",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f21f0b6e-940d-4aba-ade0-11c129bfcf90",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + categorical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "6725e474-71bd-4c89-9874-c86e0542477d",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wc = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wc()\n",
    "    trainer = model_class.RNN_train_2(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "results_aep_self_con_wc.to_csv(out_dir + '/results_aep_self_con_wc.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5213cfe5-3065-40c2-8f0a-c36d9e0d7380",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier vector (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "57c81264-58cc-4abe-b8ae-3dcc4ecd8e02",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"vector\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w = pd.concat([results_aep_fourier_w, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w.to_csv(out_dir + '/results_aep_fourier_w.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "30cf4e2e-c31d-4a79-991a-8749f4801426",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier matrix (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee279949-a82f-452f-901e-03c15a84f6dd",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_w_matrix.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "\n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4,\n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_kw3_km6_ky10_matrix.csv', index=False)"
   ],
   "id": "946c3d2aa7d3f8be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN_based Asym",
   "id": "b23fd78f03c3bfc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_asym_feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_asy_con = pd.concat([results_aep_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_asy_con.to_csv(out_dir + '/results_aep_asy_con.csv', index=False)"
   ],
   "id": "44d660bd30d194a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "out_dir",
   "id": "264e1975114e7808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test RNN_based ARMA",
   "id": "ad6bccf216b7bf43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"cpu\"))\n",
    "results_arma_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_ARMA_Feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_arma_asy_con.to_csv(out_dir + '/results_arma_asy_con.csv', index=False)"
   ],
   "id": "7ba75a50b7a82bbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test Dirich",
   "id": "f033d8578ca1b48b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import model_dich\n",
    "\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.device = \"mps\"\n",
    "cfg.n_epochs = 90\n",
    "cfg.lr = 5e-4\n",
    "cfg.x_col = \"x\"\n",
    "cfg.y_cols = [f\"y_{i}\" for i in range(24)]\n",
    "cfg.T_hist = 32\n",
    "cfg.batch_size = 64\n",
    "cfg.test_ratio = 0.2\n",
    "cfg.kl_coeff = 1.0\n",
    "\n",
    "\n",
    "train_config = model_class.training_config(n_epochs = 3, device = torch.device(\"cpu\"))\n",
    "results_prob_dich = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_dich.DirichletComposerRNN(device=torch.device(\"cpu\"))\n",
    "    trainer = model_dich.RNN_train(model, cfg)\n",
    "    ret = trainer(df_reduced)\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': ret['Y_pred'].flatten(), 'y': ret['Y_test'].flatten()})\n",
    "\n",
    "    results_prob_dich = pd.concat([results_prob_dich, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prob_dich.to_csv(out_dir + '/results_prob_dich_90epoch.csv', index=False)"
   ],
   "id": "767da83a436cca0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "out_dir",
   "id": "23d6231718bf88a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ca0dee4-c216-4ab3-a0c6-602048f0dc4c",
   "metadata": {},
   "source": [
    "## DAYTON"
   ]
  },
  {
   "cell_type": "code",
   "id": "89b69783-5c4d-4ce5-9707-7b41ee140a4a",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import model_summary as model_class\n",
    "import prophet_linear_adjust as prophet_based\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "301ff3fe-0ffc-46c8-bd19-98d31cd4be20",
   "metadata": {},
   "source": [
    "df_dayton = pd.read_csv(\"DAYTON_hourly.csv\")\n",
    "df_dayton.rename(columns={'Datetime': 'ds', 'DAYTON_MW': 'y'}, inplace=True)\n",
    "df_dayton['ds'] = pd.to_datetime(df_dayton['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'Dayton_results'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "c2a43fda96025ca4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand_dayton = df_dayton.groupby(df_dayton['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_dayton, date_start, date_end, daily_demand_dayton, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv(out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "50bf8437d421c5e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with seasonality",
   "id": "87a4d70da45eb581"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand_dayton = df_dayton.groupby(df_dayton['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet_w = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_dayton, date_start, date_end, daily_demand_dayton, manual = False, daily = True, weekly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_w.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_w = pd.concat(results_prophet_w, ignore_index=True)\n",
    "\n",
    "results_prophet_w.to_csv(out_dir + '/results_prophet_w.csv', index=False)"
   ],
   "id": "49a41aceef093834",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "15e06fbb-b00d-4517-b3e3-b7b87c857a2b",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "9893c3dd-afac-42f1-97a0-c37c2a8f912c",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con.to_csv(out_dir + '/results_aep_self_con.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "516ef30e-8db6-402f-8734-7ad8a9fb3b61",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + numerical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a3c678a-f2ff-4500-bd32-28f713423daf",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wn = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wn()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wn = pd.concat([results_aep_self_con_wn, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con_wn.to_csv(out_dir + '/results_aep_self_con_wn.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0270a4ad-425a-48d9-8556-e4110c38d332",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + categorical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "7d71860d-6bd7-40b6-bce6-7e6f464f36d1",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wc = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wc()\n",
    "    trainer = model_class.RNN_train_2(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "results_aep_self_con_wc.to_csv(out_dir + '/results_aep_self_con_wc.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "486d9b49-266f-4d7a-adf2-50330ce2b43c",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier vector (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "bf602c0e-24fa-4fdb-9d15-ea7053c447c5",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"vector\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w = pd.concat([results_aep_fourier_w, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w.to_csv(out_dir + '/results_aep_fourier_w.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3833363e-8d81-4830-a91a-7669368eb946",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier matrix (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6bc4a3c9-4a45-4412-8ddb-702e2ef86549",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_w_matrix.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b0226858dbc63265",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "\n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4,\n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_kw3_km6_ky10_matrix.csv', index=False)"
   ],
   "id": "93729619fb65c27d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN_based asym",
   "id": "54d537e510ff3d03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_asym_feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_asy_con = pd.concat([results_aep_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_asy_con.to_csv(out_dir + '/results_aep_asy_con.csv', index=False)"
   ],
   "id": "11bc72e4cced646e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN_based ARMA",
   "id": "6a504d406fd2c7bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"cpu\"))\n",
    "results_arma_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_ARMA_Feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_arma_asy_con.to_csv(out_dir + '/results_arma_asy_con.csv', index=False)"
   ],
   "id": "e3e66e64470977a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d27cf356-2ff4-4378-b703-2f448c5feb51",
   "metadata": {},
   "source": [
    "## DEOK"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a3a7744-611e-43a6-af04-b599caa3f0f9",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import model_summary as model_class\n",
    "import prophet_linear_adjust as prophet_based\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58e77d59-04d2-4325-ba43-49365711bf25",
   "metadata": {},
   "source": [
    "df_deok = pd.read_csv(\"DEOK_hourly.csv\")\n",
    "df_deok.rename(columns={'Datetime': 'ds', 'DEOK_MW': 'y'}, inplace=True)\n",
    "df_deok['ds'] = pd.to_datetime(df_deok['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'Deok_results'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "9c511e80846b31ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand_deok = df_deok.groupby(df_deok['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_deok, date_start, date_end, daily_demand_deok, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv(out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "2851f131cd7e7d1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with weekly seasonality",
   "id": "bc68866fe05682cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand_deok = df_deok.groupby(df_deok['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "results_prophet_w = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_deok, date_start, date_end, daily_demand_deok, manual = False, daily = True, weekly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_w.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_w = pd.concat(results_prophet_w, ignore_index=True)\n",
    "\n",
    "results_prophet_w.to_csv(out_dir + '/results_prophet_w.csv', index=False)"
   ],
   "id": "237529760dfba1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c39d431-2b1f-4c1a-beb4-7419b9743eff",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "56191aed-b3f0-4310-844e-7a7cb33859c7",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con.to_csv(out_dir + '/results_aep_self_con.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3b0ad29d-c1ce-42e4-b531-c18995aee2a5",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + numerical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "d1a634a6-8595-4e14-9211-321c96e3952e",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wn = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wn()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wn = pd.concat([results_aep_self_con_wn, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con_wn.to_csv(out_dir + '/results_aep_self_con_wn.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d279f1e3-814f-4e92-a728-a69b8d9edaa7",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + categorical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f2c37ad-3a27-4288-9e33-e4fd6762084b",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wc = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wc()\n",
    "    trainer = model_class.RNN_train_2(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "results_aep_self_con_wc.to_csv(out_dir + '/results_aep_self_con_wc.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0b3f52c4-720d-43c7-bdf7-6feff3156197",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier vector (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b06fe62-65ac-4279-8eaf-af83e1993db9",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"vector\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w = pd.concat([results_aep_fourier_w, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w.to_csv(out_dir + '/results_aep_fourier_w.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9a8eb99c-9fd8-4e1f-bde8-d828c435296c",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier matrix (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "b17cb594-359d-4712-b704-71b7e293481c",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_w_matrix.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN_based asym",
   "id": "961ea56b8e152fde"
  },
  {
   "cell_type": "code",
   "id": "80b8d677-64cd-46f4-beec-91da417b3940",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_asym_feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_asy_con = pd.concat([results_aep_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_asy_con.to_csv(out_dir + '/results_aep_asy_con.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test RNN_based ARMA",
   "id": "dbbcaa33b4e564a6"
  },
  {
   "cell_type": "code",
   "id": "c7c23a4c-b0d3-487f-9550-c71b8b5d9d9a",
   "metadata": {},
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"cpu\"))\n",
    "results_arma_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_ARMA_Feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_arma_asy_con.to_csv(out_dir + '/results_arma_asy_con.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aa01b47f-ab24-4859-8e8c-c1697ed2e61a",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1664e3b4-3076-40f6-9971-fde328252947",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "446fb538-8d01-444d-b722-99e2547467c9",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f269cf35-b68b-4c0f-81dc-eb4cf3b80359",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "41807dc5-6529-47ea-857e-483dacaca4a3",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "75b79ce5-fbc3-4ea9-9c8d-804118a32c6f",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52b3181d-41c4-4e29-a7e4-622ffe9eaa62",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6266e9ec-31c0-434f-87d9-74fa9156e69e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea2f8595-bad6-4254-97d7-c473ef63525a",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4418937a-a255-464f-8efb-7c01372490d6",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
