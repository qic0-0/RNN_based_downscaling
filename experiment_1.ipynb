{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-29T20:25:56.731322Z",
     "start_time": "2025-10-29T20:25:55.735015Z"
    }
   },
   "source": "!pip install asym_helper\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not find a version that satisfies the requirement asym_helper (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for asym_helper\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## AEP",
   "id": "8ebb6fd21a9fa33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T20:28:06.389923Z",
     "start_time": "2025-10-29T20:28:06.281767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import model_summary as model_class\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "66c9ca75eaa22afa",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T20:29:27.487880Z",
     "start_time": "2025-10-29T20:29:27.370005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_aep = pd.read_csv(\"data/AEP_hourly.csv\")\n",
    "df_aep.rename(columns={'Datetime': 'ds', 'AEP_MW': 'y'}, inplace=True)\n",
    "df_aep['ds'] = pd.to_datetime(df_aep['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'new_exp_results'"
   ],
   "id": "1b61e3dbafbab4c3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test GRU model",
   "id": "7bab0ba7aff18a01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T20:30:48.288720Z",
     "start_time": "2025-10-29T20:29:29.470927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"vector\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "\n",
    "results_aep_fourier_w_matrix_gru = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier_GRU(\n",
    "        cont_dim=cont_dim,     # full feature dim per step\n",
    "        fourier_dim=F_pairs, # only used in hand-rolled branch\n",
    "        xf_mode=\"vector\",           # or \"matrix\" to match your original\n",
    "        d_model=128,\n",
    "        nhead=4,\n",
    "        H=24,\n",
    "        use_gate=True,\n",
    "        nonneg_U0=False,\n",
    "        use_gru=True,               # turn on GRU backbone (process all x together)\n",
    "    )\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix_gru = pd.concat([results_aep_fourier_w_matrix_gru, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix_gru.to_csv(out_dir + '/results_aep_fourier_gru_kw3_km6_ky10_matrix.csv', index=False)"
   ],
   "id": "a066e293e1c9a8dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Documents/GitHub/RNN_based_downscaling/model_summary.py:1484: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {ep + 1} loss: {float(loss):.4f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7645\n",
      "epoch 2 loss: 0.4159\n",
      "epoch 3 loss: 0.3810\n",
      "epoch 4 loss: 0.2755\n",
      "epoch 5 loss: 0.1947\n",
      "epoch 6 loss: 0.1579\n",
      "epoch 7 loss: 0.1267\n",
      "epoch 8 loss: 0.1151\n",
      "epoch 9 loss: 0.1068\n",
      "epoch 10 loss: 0.0954\n",
      "epoch 11 loss: 0.0772\n",
      "epoch 12 loss: 0.0794\n",
      "epoch 13 loss: 0.0705\n",
      "epoch 14 loss: 0.0748\n",
      "epoch 15 loss: 0.0687\n",
      "epoch 16 loss: 0.0692\n",
      "epoch 17 loss: 0.0643\n",
      "epoch 18 loss: 0.0607\n",
      "epoch 19 loss: 0.0621\n",
      "epoch 20 loss: 0.0529\n",
      "epoch 21 loss: 0.0527\n",
      "epoch 22 loss: 0.0566\n",
      "epoch 23 loss: 0.0597\n",
      "epoch 24 loss: 0.0520\n",
      "epoch 25 loss: 0.0485\n",
      "epoch 26 loss: 0.0506\n",
      "epoch 27 loss: 0.0450\n",
      "epoch 28 loss: 0.0392\n",
      "epoch 29 loss: 0.0382\n",
      "epoch 30 loss: 0.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_48333/131365095.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_fourier_w_matrix_gru = pd.concat([results_aep_fourier_w_matrix_gru, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 32\u001B[0m\n\u001B[1;32m     20\u001B[0m model \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mRNN_fourier_GRU(\n\u001B[1;32m     21\u001B[0m     cont_dim\u001B[38;5;241m=\u001B[39mcont_dim,     \u001B[38;5;66;03m# full feature dim per step\u001B[39;00m\n\u001B[1;32m     22\u001B[0m     fourier_dim\u001B[38;5;241m=\u001B[39mF_pairs, \u001B[38;5;66;03m# only used in hand-rolled branch\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     29\u001B[0m     use_gru\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,               \u001B[38;5;66;03m# turn on GRU backbone (process all x together)\u001B[39;00m\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     31\u001B[0m trainer \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mRNN_train_fourier(model, train_config, fourier_conf)\n\u001B[0;32m---> 32\u001B[0m forcast, true \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_reduced\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m result \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mday\u001B[39m\u001B[38;5;124m'\u001B[39m: df_reduced[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mds\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mdate\u001B[38;5;241m.\u001B[39mmax(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhour\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m24\u001B[39m)), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_hat\u001B[39m\u001B[38;5;124m'\u001B[39m: forcast, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m: true})\n\u001B[1;32m     36\u001B[0m results_aep_fourier_w_matrix_gru \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([results_aep_fourier_w_matrix_gru, result])\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/GitHub/RNN_based_downscaling/model_summary.py:1473\u001B[0m, in \u001B[0;36mRNN_train_fourier.__call__\u001B[0;34m(self, df)\u001B[0m\n\u001B[1;32m   1471\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m   1472\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m xb, yb \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[0;32m-> 1473\u001B[0m     xb, yb \u001B[38;5;241m=\u001B[39m \u001B[43mxb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m, yb\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m   1474\u001B[0m     opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m   1475\u001B[0m     o, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(xb)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import model_dich_mu_std_laa",
   "id": "d37e788de2b52520"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T20:43:07.289986Z",
     "start_time": "2025-10-29T20:43:06.581301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Cfg:\n",
    "    pass\n",
    "\n",
    "cfg = Cfg()\n",
    "cfg.device = \"mps\"            # 或 \"cuda\"/\"cpu\"\n",
    "cfg.n_epochs = 90\n",
    "cfg.lr = 5e-4\n",
    "cfg.x_col = \"x\"\n",
    "cfg.y_cols = [f\"y_{i}\" for i in range(24)]\n",
    "cfg.T_hist = 32\n",
    "cfg.batch_size = 64\n",
    "cfg.test_ratio = 0.2\n",
    "cfg.kl_coeff = 1.0            # 新版loss不使用KL, 留着也无妨\n",
    "cfg.pred_samples = 100000\n",
    "\n",
    "# ---- 结果容器 ----\n",
    "results_prob_dich = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y': []})\n",
    "\n",
    "# ---- 滑动时间窗 ----\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end   = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "while True:\n",
    "    print(i)\n",
    "    # 取一天/一段窗口的数据（按你提供的逻辑）\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "\n",
    "    # ---- 建模：K=24（份额维度），d_x=1（x是总量一列） ----\n",
    "    model = model_dich_mu_std_laa.DirichletMeanConcentration(\n",
    "        K=24,            # 24 小时\n",
    "        d_model=128,     # 可调\n",
    "        d_x=11,           # 外生/总量特征维度\n",
    "        nhead=4,\n",
    "        dropout=0.1,\n",
    "        activation=\"relu\",\n",
    "        tie_c_to_h_only=True\n",
    "    )\n",
    "\n",
    "    trainer = model_dich_mu_std_laa.RNN_train(model, cfg, train_sample = False)\n",
    "    ret = trainer(df_reduced)\n",
    "\n",
    "    # 取当天的 y_hat 与真实 y（注意转成 numpy）\n",
    "    y_hat = ret['Y_pred'].flatten().cpu().numpy()\n",
    "    y_true = ret['Y_test'].flatten().cpu().numpy()\n",
    "\n",
    "    day_val = pd.to_datetime(df_reduced['ds'].max()).date()\n",
    "    result = pd.DataFrame({\n",
    "        'day':  [day_val] * 24,\n",
    "        'hour': list(range(24)),\n",
    "        'y_hat': y_hat,\n",
    "        'y':    y_true\n",
    "    })\n",
    "\n",
    "    results_prob_dich = pd.concat([results_prob_dich, result], ignore_index=True)\n",
    "\n",
    "    # 窗口右移一天\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end   += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 3:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "# 保存结果\n",
    "results_prob_dich.to_csv(out_dir + '/model_dich_mu_std_lla_pw7.csv', index=False)\n"
   ],
   "id": "73190cb69fd135ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x39 and 15x24)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 46\u001B[0m\n\u001B[1;32m     35\u001B[0m model \u001B[38;5;241m=\u001B[39m model_dich_mu_std\u001B[38;5;241m.\u001B[39mDirichletMeanConcentration(\n\u001B[1;32m     36\u001B[0m     K\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m24\u001B[39m,            \u001B[38;5;66;03m# 24 小时\u001B[39;00m\n\u001B[1;32m     37\u001B[0m     d_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m,     \u001B[38;5;66;03m# 可调\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     42\u001B[0m     tie_c_to_h_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     43\u001B[0m )\n\u001B[1;32m     45\u001B[0m trainer \u001B[38;5;241m=\u001B[39m model_dich_mu_std\u001B[38;5;241m.\u001B[39mRNN_train(model, cfg, fourier_conf, train_sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 46\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_reduced\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# 取当天的 y_hat 与真实 y（注意转成 numpy）\u001B[39;00m\n\u001B[1;32m     49\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m ret[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY_pred\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mflatten()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[0;32m~/Documents/GitHub/RNN_based_downscaling/model_dich_mu_std.py:438\u001B[0m, in \u001B[0;36mRNN_train.__call__\u001B[0;34m(self, df)\u001B[0m\n\u001B[1;32m    435\u001B[0m x_t_raw \u001B[38;5;241m=\u001B[39m _inv_std_vec(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39msx, x_t_std)\n\u001B[1;32m    437\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad(set_to_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 438\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_hist_std\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_t\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_t_std\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx_t_raw\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_sample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m loss, logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39melbo_loss(\n\u001B[1;32m    441\u001B[0m     out,\n\u001B[1;32m    442\u001B[0m     y_t_raw\u001B[38;5;241m=\u001B[39my_t_raw,\n\u001B[1;32m    443\u001B[0m     x_t_raw\u001B[38;5;241m=\u001B[39mx_t_raw\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m x_t_raw\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m x_t_raw\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m x_t_raw,\n\u001B[1;32m    444\u001B[0m     use_dirichlet_nll\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    445\u001B[0m )\n\u001B[1;32m    447\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/GitHub/RNN_based_downscaling/model_dich_mu_std.py:204\u001B[0m, in \u001B[0;36mDirichletMeanConcentration.forward\u001B[0;34m(self, y_hist_std, x_t, total, sample)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    197\u001B[0m     y_hist_std: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    200\u001B[0m     sample: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    201\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    203\u001B[0m     h_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_history(y_hist_std)\n\u001B[0;32m--> 204\u001B[0m     alpha, pi, c \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dirichlet_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m     out: Dict[\u001B[38;5;28mstr\u001B[39m, torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malpha\u001B[39m\u001B[38;5;124m\"\u001B[39m: alpha, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpi\u001B[39m\u001B[38;5;124m\"\u001B[39m: pi, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mc\u001B[39m\u001B[38;5;124m\"\u001B[39m: c}\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m total \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/GitHub/RNN_based_downscaling/model_dich_mu_std.py:180\u001B[0m, in \u001B[0;36mDirichletMeanConcentration._dirichlet_params\u001B[0;34m(self, h_t, x_t)\u001B[0m\n\u001B[1;32m    178\u001B[0m eta \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_h(h_t)\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m x_t \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 180\u001B[0m     eta \u001B[38;5;241m=\u001B[39m eta \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW_x\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m pi \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(eta, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    183\u001B[0m c_in \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwc_h(h_t)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (64x39 and 15x24)"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
