{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb20fe9d-0dbb-4caf-aa2b-8b5921383169",
   "metadata": {},
   "source": [
    "## AEP"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "id": "8118ffd26142a9a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_aep = pd.read_csv(\"data/AEP_hourly.csv\")\n",
    "df_aep.rename(columns={'Datetime': 'ds', 'AEP_MW': 'y'}, inplace=True)\n",
    "df_aep['ds'] = pd.to_datetime(df_aep['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'AEP_results'"
   ],
   "id": "5db8d797fb6b5d60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "e20100736d301702"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import prophet_linear_adjust as prophet_based\n",
    "daily_demand = df_aep.groupby(df_aep['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_aep, date_start, date_end, daily_demand, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "8cd84b577cc13ea5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with daily, weekly, yearly seasonality",
   "id": "88e6f85b9cc64c1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand = df_aep.groupby(df_aep['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "results_prophet_dwy = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_aep, date_start, date_end, daily_demand, manual = False, daily = True, weekly = True, yearly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_dwy.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_dwy = pd.concat(results_prophet_dwy, ignore_index=True)\n",
    "\n",
    "results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)"
   ],
   "id": "55aec6877637d97a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test Simple RNN",
   "id": "23089dd82c59ca7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_simple\n",
    "train_config = RNN_simple.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_simple = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = RNN_simple.RNN_simple(latent_dim=32, activation='relu')\n",
    "    trainer = RNN_simple.RNN_train_simple(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_simple = pd.concat([results_simple, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)"
   ],
   "id": "2e3bd59d5a1cacd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6d8c4c83-0604-4c0c-8fd5-b696b180310f",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "6007d956-d042-4f55-b110-4649eb5b23d1",
   "metadata": {},
   "source": [
    "import RNN_attention\n",
    "train_config = RNN_attention.training_config(n_epochs = 5, device = torch.device(\"mps\"))\n",
    "results_attention = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = RNN_attention.RNN_attention(latent_dim=32, d_model=128, nhead=4)\n",
    "    trainer = RNN_attention.RNN_train_attention(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_attention = pd.concat([results_attention, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "448d1d3a-c3c8-46e9-bad0-55eb3eb3457c",
   "metadata": {},
   "source": "### test RNN+self convolution + fourier matrix (weekly, monthly, yearly)"
  },
  {
   "cell_type": "code",
   "id": "64c5838c-0d23-48b1-b71d-2c0c79c15634",
   "metadata": {},
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=32,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier = pd.concat([results_fourier, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test latent dim = 16",
   "id": "34d07cb93e10a743"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier_dim16 = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=16,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier_dim16 = pd.concat([results_fourier_dim16, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier_dim16.to_csv('experiment_results/' + out_dir + '/results_fourier_dim16.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier_dim16.to_csv('experiment_results/' + out_dir + '/results_fourier_dim16.csv', index=False)"
   ],
   "id": "3f2edd44d37830b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test latent dim = 64",
   "id": "88c083aa69cdedf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier_dim64 = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=64,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier_dim64 = pd.concat([results_fourier_dim64, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier_dim64.to_csv('experiment_results/' + out_dir + '/results_fourier_dim64.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier_dim64.to_csv('experiment_results/' + out_dir + '/results_fourier_dim64.csv', index=False)"
   ],
   "id": "7ffb53b90dc87bfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k = 24*3\n",
    "x_ax = np.arange(k)\n",
    "\n",
    "plt.plot(x_ax, results_fourier['y_hat'][:k], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.plot(x_ax, results_fourier['y'][:k], marker=\"o\", linestyle=\"-\", color=\"r\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_Tplus1\")\n",
    "plt.title(\"Line plot of y_Tplus1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "417e3cb139fad504",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "547af856-e054-4279-96e4-e1e4264db04d",
   "metadata": {},
   "source": [
    "## Comed"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "id": "498db8ff6ea6c4cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8da89f60-d42c-4b68-b83f-b10f930f69c1",
   "metadata": {},
   "source": [
    "df_comed = pd.read_csv(\"data/COMED_hourly.csv\")\n",
    "df_comed.rename(columns={'Datetime': 'ds', 'COMED_MW': 'y'}, inplace=True)\n",
    "df_comed['ds'] = pd.to_datetime(df_comed['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "out_dir = 'Comed_results'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "a72919bd420eae26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import prophet_linear_adjust as prophet_based\n",
    "daily_demand = df_comed.groupby(df_comed['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_comed, date_start, date_end, daily_demand,\n",
    "                                                    manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "68fe5f9ff5d05326",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with daily, weekly, yearly seasonality",
   "id": "6fa4ad7e711b555b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand = df_comed.groupby(df_comed['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet_dwy = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_comed, date_start, date_end, daily_demand,\n",
    "                                                    manual = False, daily = True, weekly = True, yearly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_dwy.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_dwy = pd.concat(results_prophet_dwy, ignore_index=True)\n",
    "\n",
    "results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)"
   ],
   "id": "56304448d5c902b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test Simple RNN",
   "id": "509002adca0832c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_simple\n",
    "train_config = RNN_simple.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_simple = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = RNN_simple.RNN_simple(latent_dim=32, activation='relu')\n",
    "    trainer = RNN_simple.RNN_train_simple(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_simple = pd.concat([results_simple, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)"
   ],
   "id": "effe295806bc78f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN+self convolution",
   "id": "27a1dc0982bea635"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_attention\n",
    "train_config = RNN_attention.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_attention = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = RNN_attention.RNN_attention(latent_dim=32, d_model=128, nhead=4)\n",
    "    trainer = RNN_attention.RNN_train_attention(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_attention = pd.concat([results_attention, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)"
   ],
   "id": "590d7ffdbc1fc715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN+self convolution + fourier matrix (weekly, monthly, yearly)",
   "id": "8eebb163ce9691e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=32,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier = pd.concat([results_fourier, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)"
   ],
   "id": "f62e32e43cb755da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test latent dim = 16",
   "id": "64fe2e1bd15d45ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier_dim16 = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=16,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier_dim16 = pd.concat([results_fourier_dim16, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier_dim16.to_csv('experiment_results/' + out_dir + '/results_fourier_dim16.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier_dim16.to_csv('experiment_results/' + out_dir + '/results_fourier_dim16.csv', index=False)"
   ],
   "id": "ed83ae36a32d08d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test latent dim = 64",
   "id": "f6420b905a40cb47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier_dim64 = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=64,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier_dim64 = pd.concat([results_fourier_dim64, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier_dim64.to_csv('experiment_results/' + out_dir + '/results_fourier_dim64.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier_dim64.to_csv('experiment_results/' + out_dir + '/results_fourier_dim64.csv', index=False)"
   ],
   "id": "40751bac5923c0c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k = 24*3\n",
    "x_ax = np.arange(k)\n",
    "\n",
    "plt.plot(x_ax, results_fourier['y_hat'][:k], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.plot(x_ax, results_fourier['y'][:k], marker=\"o\", linestyle=\"-\", color=\"r\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_Tplus1\")\n",
    "plt.title(\"Line plot of y_Tplus1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "2ca49d0e4263b5d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "60f7ddc4ade59ad5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8917e527ba006c89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3fcc4ce242732396",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ca0dee4-c216-4ab3-a0c6-602048f0dc4c",
   "metadata": {},
   "source": [
    "## DAYTON"
   ]
  },
  {
   "cell_type": "code",
   "id": "89b69783-5c4d-4ce5-9707-7b41ee140a4a",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "301ff3fe-0ffc-46c8-bd19-98d31cd4be20",
   "metadata": {},
   "source": [
    "df_dayton = pd.read_csv(\"data/DAYTON_hourly.csv\")\n",
    "df_dayton.rename(columns={'Datetime': 'ds', 'DAYTON_MW': 'y'}, inplace=True)\n",
    "df_dayton['ds'] = pd.to_datetime(df_dayton['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'Dayton_results'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "c2a43fda96025ca4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import prophet_linear_adjust as prophet_based\n",
    "daily_demand = df_dayton.groupby(df_dayton['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_dayton, date_start, date_end, daily_demand, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "50bf8437d421c5e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with daily, weekly, yearly seasonality",
   "id": "87a4d70da45eb581"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand = df_dayton.groupby(df_dayton['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet_dwy = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_dayton, date_start, date_end, daily_demand, manual = False, daily = True, weekly = True, yearly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_dwy.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_dwy = pd.concat(results_prophet_dwy, ignore_index=True)\n",
    "\n",
    "results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)"
   ],
   "id": "49a41aceef093834",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test Simple RNN",
   "id": "af89bc554626a344"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_simple\n",
    "train_config = RNN_simple.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_simple = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = RNN_simple.RNN_simple(latent_dim=32, activation='relu')\n",
    "    trainer = RNN_simple.RNN_train_simple(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_simple = pd.concat([results_simple, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)"
   ],
   "id": "4152539d3c514814",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "15e06fbb-b00d-4517-b3e3-b7b87c857a2b",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "9893c3dd-afac-42f1-97a0-c37c2a8f912c",
   "metadata": {},
   "source": [
    "import RNN_attention\n",
    "train_config = RNN_attention.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_attention = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = RNN_attention.RNN_attention(latent_dim=32, d_model=128, nhead=4)\n",
    "    trainer = RNN_attention.RNN_train_attention(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_attention = pd.concat([results_attention, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "516ef30e-8db6-402f-8734-7ad8a9fb3b61",
   "metadata": {},
   "source": "### test RNN+self convolution + fourier matrix (weekly, monthly, yearly)"
  },
  {
   "cell_type": "code",
   "id": "8a3c678a-f2ff-4500-bd32-28f713423daf",
   "metadata": {},
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=32,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier = pd.concat([results_fourier, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test latent dim = 16",
   "id": "875ddaf9f9ec4b7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier_dim16 = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=16,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier_dim16 = pd.concat([results_fourier_dim16, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier_dim16.to_csv('experiment_results/' + out_dir + '/results_fourier_dim16.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier_dim16.to_csv('experiment_results/' + out_dir + '/results_fourier_dim16.csv', index=False)"
   ],
   "id": "d7bdf67bb62180b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test latent dim = 64",
   "id": "99254f75566ade3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier_dim64 = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=64,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier_dim64 = pd.concat([results_fourier_dim64, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier_dim64.to_csv('experiment_results/' + out_dir + '/results_fourier_dim64.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier_dim64.to_csv('experiment_results/' + out_dir + '/results_fourier_dim64.csv', index=False)"
   ],
   "id": "f73ceead844a4379",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k = 24*3\n",
    "x_ax = np.arange(k)\n",
    "\n",
    "plt.plot(x_ax, results_fourier['y_hat'][:k], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.plot(x_ax, results_fourier['y'][:k], marker=\"o\", linestyle=\"-\", color=\"r\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_Tplus1\")\n",
    "plt.title(\"Line plot of y_Tplus1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "ec646840fbd3c70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d57271ba0b12f9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d27cf356-2ff4-4378-b703-2f448c5feb51",
   "metadata": {},
   "source": [
    "## DEOK"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a3a7744-611e-43a6-af04-b599caa3f0f9",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58e77d59-04d2-4325-ba43-49365711bf25",
   "metadata": {},
   "source": [
    "df_deok = pd.read_csv(\"data/DEOK_hourly.csv\")\n",
    "df_deok.rename(columns={'Datetime': 'ds', 'DEOK_MW': 'y'}, inplace=True)\n",
    "df_deok['ds'] = pd.to_datetime(df_deok['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'Deok_results'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "9c511e80846b31ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import prophet_linear_adjust as prophet_based\n",
    "daily_demand = df_deok.groupby(df_deok['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_deok, date_start, date_end, daily_demand, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv('experiment_results/' + out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "2851f131cd7e7d1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with daily, weekly, yearly seasonality",
   "id": "bc68866fe05682cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "daily_demand = df_deok.groupby(df_deok['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "results_prophet_dwy = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_deok, date_start, date_end, daily_demand, manual = False, daily = True, weekly = True, yearly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_dwy.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_dwy = pd.concat(results_prophet_dwy, ignore_index=True)\n",
    "\n",
    "results_prophet_dwy.to_csv('experiment_results/' + out_dir + '/results_prophet_dwy.csv', index=False)"
   ],
   "id": "237529760dfba1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test Simple RNN",
   "id": "2373d4aaf210c5ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_simple\n",
    "train_config = RNN_simple.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_simple = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = RNN_simple.RNN_simple(latent_dim=32, activation='relu')\n",
    "    trainer = RNN_simple.RNN_train_simple(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_simple = pd.concat([results_simple, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_simple.to_csv('experiment_results/' + out_dir + '/results_simple.csv', index=False)"
   ],
   "id": "798e118757ea893e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c39d431-2b1f-4c1a-beb4-7419b9743eff",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "56191aed-b3f0-4310-844e-7a7cb33859c7",
   "metadata": {},
   "source": [
    "import RNN_attention\n",
    "train_config = RNN_attention.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_attention = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = RNN_attention.RNN_attention(latent_dim=32, d_model=128, nhead=4)\n",
    "    trainer = RNN_attention.RNN_train_attention(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_attention = pd.concat([results_attention, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_attention.to_csv('experiment_results/' + out_dir + '/results_attention.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3b0ad29d-c1ce-42e4-b531-c18995aee2a5",
   "metadata": {},
   "source": "### test RNN+self convolution + fourier matrix (weekly, monthly, yearly)"
  },
  {
   "cell_type": "code",
   "id": "d1a634a6-8595-4e14-9211-321c96e3952e",
   "metadata": {},
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=32,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier = pd.concat([results_fourier, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier.to_csv('experiment_results/' + out_dir + '/results_fourier.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test latent dim = 16",
   "id": "47bb95a0c73622cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier_dim16 = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=16,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier_dim16 = pd.concat([results_fourier_dim16, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier_dim16.to_csv('experiment_results/' + out_dir + '/results_fourier_dim16.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier_dim16.to_csv('experiment_results/' + out_dir + '/results_fourier_dim16.csv', index=False)"
   ],
   "id": "632cd040f5c355e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test latent dim = 64",
   "id": "53a42be6b6c3db21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import RNN_fourier_RNN\n",
    "\n",
    "train_config = RNN_fourier_RNN.training_config(n_epochs=30, device=torch.device(\"mps\"))\n",
    "fourier_conf = RNN_fourier_RNN.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "\n",
    "# Calculate dimensions correctly\n",
    "K_total = fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly\n",
    "F_per_hour = 2 * K_total  # sin/cos pairs per hour\n",
    "\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_per_hour\n",
    "    fourier_dim = F_per_hour\n",
    "else:  # matrix mode\n",
    "    cont_dim = 1 + 24 * F_per_hour  # Each hour gets F_per_hour features\n",
    "    fourier_dim = F_per_hour\n",
    "\n",
    "results_fourier_dim64 = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = RNN_fourier_RNN.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim, xf_mode=\"matrix\",\n",
    "                                               d_model=128,latent_dim=64,nhead=4)\n",
    "    trainer = RNN_fourier_RNN.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_fourier_dim64 = pd.concat([results_fourier_dim64, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i % 5 == 0:\n",
    "        results_fourier_dim64.to_csv('experiment_results/' + out_dir + '/results_fourier_dim64.csv', index=False)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_fourier_dim64.to_csv('experiment_results/' + out_dir + '/results_fourier_dim64.csv', index=False)"
   ],
   "id": "4d7926c33c8b4ba2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k = 24*3\n",
    "x_ax = np.arange(k)\n",
    "\n",
    "plt.plot(x_ax, results_fourier['y_hat'][:k], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.plot(x_ax, results_fourier['y'][:k], marker=\"o\", linestyle=\"-\", color=\"r\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_Tplus1\")\n",
    "plt.title(\"Line plot of y_Tplus1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "d75dcbb35ee70fb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f269cf35-b68b-4c0f-81dc-eb4cf3b80359",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
