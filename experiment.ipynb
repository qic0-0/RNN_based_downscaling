{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb20fe9d-0dbb-4caf-aa2b-8b5921383169",
   "metadata": {},
   "source": [
    "## AEP"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T03:59:45.410233Z",
     "start_time": "2025-10-17T03:59:43.271476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import model_summary as model_class\n",
    "import prophet_linear_adjust as prophet_based\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "8118ffd26142a9a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T03:59:45.488526Z",
     "start_time": "2025-10-17T03:59:45.418263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_aep = pd.read_csv(\"AEP_hourly.csv\")\n",
    "df_aep.rename(columns={'Datetime': 'ds', 'AEP_MW': 'y'}, inplace=True)\n",
    "df_aep['ds'] = pd.to_datetime(df_aep['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'AEP_results'"
   ],
   "id": "5db8d797fb6b5d60",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "e20100736d301702"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T17:28:56.739651Z",
     "start_time": "2025-10-03T17:19:10.966444Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:19:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:19:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:19:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:19:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:19:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:19:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:19:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:19:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:19:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:19:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:19:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:20:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:20:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:20:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:20:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:20:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:20:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:20:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:20:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:20:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:20:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:20:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:20:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:20:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:20:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:21:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:21:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:21:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:21:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:21:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:21:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:21:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:21:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:21:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:21:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:21:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:21:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:21:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:21:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:21:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:21:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:22:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:22:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:22:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:22:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:22:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:22:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:22:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:22:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:22:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:22:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:22:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:22:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:23:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:23:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:23:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:23:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:23:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:23:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:23:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:23:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:23:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:23:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:23:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:23:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:23:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:23:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:24:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:24:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:24:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:24:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:24:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:24:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:24:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:24:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:24:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:24:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:24:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:24:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:24:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:24:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:25:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:25:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:25:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:25:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:25:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:25:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:25:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:25:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:25:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:25:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:25:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:25:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:25:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:25:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:25:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:25:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:26:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:26:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:26:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:26:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:26:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:26:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:26:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:26:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:26:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:26:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:26:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:26:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:26:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:26:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:26:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:26:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:27:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:27:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:27:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:27:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:27:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:27:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:27:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:27:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:27:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:27:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:27:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:27:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:27:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:27:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:28:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:28:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:28:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:28:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:28:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:28:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:28:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:28:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:28:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:28:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:28:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:28:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:28:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "daily_demand_aep = df_aep.groupby(df_aep['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_aep, date_start, date_end, daily_demand_aep, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv(out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "8cd84b577cc13ea5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with seasonality",
   "id": "f0494a6fb6476dfc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T17:44:08.461309Z",
     "start_time": "2025-10-03T17:32:36.194219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_demand_aep = df_aep.groupby(df_aep['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "results_prophet_w = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_aep, date_start, date_end, daily_demand_aep, manual = False, daily = True, weekly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_w.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_w = pd.concat(results_prophet_w, ignore_index=True)\n",
    "\n",
    "results_prophet_w.to_csv(out_dir + '/results_prophet_w.csv', index=False)"
   ],
   "id": "8861991aaa3fe3d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:32:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:32:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:32:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:32:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:32:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:33:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:33:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:33:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:33:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:33:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:34:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:34:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:34:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:34:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:34:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:34:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:36:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:36:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:36:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:36:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:36:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:36:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:36:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:36:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:36:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:36:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:36:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:37:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:37:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:37:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:37:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:37:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:37:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:37:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:37:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:37:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:37:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:37:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:38:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:38:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:38:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:38:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:38:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:38:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:38:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:38:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:38:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:38:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:38:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:38:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:39:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:39:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:39:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:39:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:39:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:39:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:39:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:40:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:40:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:40:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:40:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:40:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:40:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:40:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:40:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:40:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:40:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:40:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:40:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:41:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:41:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:41:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:41:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:41:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:41:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:41:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:42:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:42:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:42:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:42:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:42:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:42:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:42:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:42:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:42:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:42:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:42:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:42:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:42:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:43:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:43:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:43:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:43:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:43:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:43:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:43:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:43:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:43:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:43:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:43:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:44:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:44:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:44:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with weekly, yearly",
   "id": "88e6f85b9cc64c1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T17:07:04.841987Z",
     "start_time": "2025-10-10T16:55:40.952466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_demand_aep = df_aep.groupby(df_aep['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "results_prophet_w = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_aep, date_start, date_end, daily_demand_aep, manual = False, daily = True, weekly = True, yearly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_w.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_w = pd.concat(results_prophet_w, ignore_index=True)\n",
    "\n",
    "results_prophet_w.to_csv(out_dir + '/results_prophet_wy.csv', index=False)"
   ],
   "id": "55aec6877637d97a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:55:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:55:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:55:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:55:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:55:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:56:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:56:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:56:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:56:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:56:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:56:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:56:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:56:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:56:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:56:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:56:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:56:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:56:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:57:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:57:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:57:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:57:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:57:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:58:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:58:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:58:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:58:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:58:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:58:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:58:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:58:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:58:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:58:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:59:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:00:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:00:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:00:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:00:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-10-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:00:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:00:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:00:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:00:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:01:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:01:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:01:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:01:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:01:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:01:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:01:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:02:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:02:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:02:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:02:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:02:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:02:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:02:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:02:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:02:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:02:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:02:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:02:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:02:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:02:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:03:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:03:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:03:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:03:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:03:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:03:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:03:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:03:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:03:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:03:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:03:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:03:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:04:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:04:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:04:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:04:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:04:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:05:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:05:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:05:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:05:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:05:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:05:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:05:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:05:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:05:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:05:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:05:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:06:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:06:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:06:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:06:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:06:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2008-12-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:07:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "6d8c4c83-0604-4c0c-8fd5-b696b180310f",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "6007d956-d042-4f55-b110-4649eb5b23d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:22:52.085010Z",
     "start_time": "2025-10-15T21:18:26.566156Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con.to_csv(out_dir + '/results_aep_self_con.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:1081: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {epoch+1} loss:\", float(loss))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.74363774061203\n",
      "epoch 2 loss: 0.42372915148735046\n",
      "epoch 3 loss: 0.34425923228263855\n",
      "epoch 4 loss: 0.29446545243263245\n",
      "epoch 5 loss: 0.19785860180854797\n",
      "epoch 6 loss: 0.20438528060913086\n",
      "epoch 7 loss: 0.1875699907541275\n",
      "epoch 8 loss: 0.19233396649360657\n",
      "epoch 9 loss: 0.21584638953208923\n",
      "epoch 10 loss: 0.17910407483577728\n",
      "epoch 11 loss: 0.19281527400016785\n",
      "epoch 12 loss: 0.20178668200969696\n",
      "epoch 13 loss: 0.1655149757862091\n",
      "epoch 14 loss: 0.20754076540470123\n",
      "epoch 15 loss: 0.1967955231666565\n",
      "epoch 16 loss: 0.16582460701465607\n",
      "epoch 17 loss: 0.17262797057628632\n",
      "epoch 18 loss: 0.16111493110656738\n",
      "epoch 19 loss: 0.1905333250761032\n",
      "epoch 20 loss: 0.17482037842273712\n",
      "epoch 21 loss: 0.1752234399318695\n",
      "epoch 22 loss: 0.18278919160366058\n",
      "epoch 23 loss: 0.1224280297756195\n",
      "epoch 24 loss: 0.1408056616783142\n",
      "epoch 25 loss: 0.14818690717220306\n",
      "epoch 26 loss: 0.14746227860450745\n",
      "epoch 27 loss: 0.13546980917453766\n",
      "epoch 28 loss: 0.24548032879829407\n",
      "epoch 29 loss: 0.15961913764476776\n",
      "epoch 30 loss: 0.14242297410964966\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_15728/1001191365.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7818735837936401\n",
      "epoch 2 loss: 0.8209155797958374\n",
      "epoch 3 loss: 0.501896858215332\n",
      "epoch 4 loss: 0.2610316276550293\n",
      "epoch 5 loss: 0.22551284730434418\n",
      "epoch 6 loss: 0.1767885833978653\n",
      "epoch 7 loss: 0.19145676493644714\n",
      "epoch 8 loss: 0.2291010469198227\n",
      "epoch 9 loss: 0.16091540455818176\n",
      "epoch 10 loss: 0.1813545972108841\n",
      "epoch 11 loss: 0.1714954525232315\n",
      "epoch 12 loss: 0.17892420291900635\n",
      "epoch 13 loss: 0.170654296875\n",
      "epoch 14 loss: 0.249619722366333\n",
      "epoch 15 loss: 0.1584932506084442\n",
      "epoch 16 loss: 0.17885731160640717\n",
      "epoch 17 loss: 0.13654948770999908\n",
      "epoch 18 loss: 0.15105800330638885\n",
      "epoch 19 loss: 0.15069051086902618\n",
      "epoch 20 loss: 0.15569670498371124\n",
      "epoch 21 loss: 0.1633756309747696\n",
      "epoch 22 loss: 0.1713956594467163\n",
      "epoch 23 loss: 0.13184484839439392\n",
      "epoch 24 loss: 0.1753690093755722\n",
      "epoch 25 loss: 0.17290779948234558\n",
      "epoch 26 loss: 0.10598540306091309\n",
      "epoch 27 loss: 0.13724064826965332\n",
      "epoch 28 loss: 0.12485364079475403\n",
      "epoch 29 loss: 0.15892080962657928\n",
      "epoch 30 loss: 0.1416337490081787\n",
      "3\n",
      "epoch 1 loss: 0.6964138150215149\n",
      "epoch 2 loss: 0.6943733096122742\n",
      "epoch 3 loss: 0.5245945453643799\n",
      "epoch 4 loss: 0.26809749007225037\n",
      "epoch 5 loss: 0.20300810039043427\n",
      "epoch 6 loss: 0.20083163678646088\n",
      "epoch 7 loss: 0.20717595517635345\n",
      "epoch 8 loss: 0.18625669181346893\n",
      "epoch 9 loss: 0.17664986848831177\n",
      "epoch 10 loss: 0.19949768483638763\n",
      "epoch 11 loss: 0.15447187423706055\n",
      "epoch 12 loss: 0.19614244997501373\n",
      "epoch 13 loss: 0.1864900439977646\n",
      "epoch 14 loss: 0.17551538348197937\n",
      "epoch 15 loss: 0.20669811964035034\n",
      "epoch 16 loss: 0.20492036640644073\n",
      "epoch 17 loss: 0.16898159682750702\n",
      "epoch 18 loss: 0.17430250346660614\n",
      "epoch 19 loss: 0.17461144924163818\n",
      "epoch 20 loss: 0.2335527092218399\n",
      "epoch 21 loss: 0.13353100419044495\n",
      "epoch 22 loss: 0.1338534653186798\n",
      "epoch 23 loss: 0.15445038676261902\n",
      "epoch 24 loss: 0.1465228646993637\n",
      "epoch 25 loss: 0.15437287092208862\n",
      "epoch 26 loss: 0.13491837680339813\n",
      "epoch 27 loss: 0.1819169968366623\n",
      "epoch 28 loss: 0.1469026356935501\n",
      "epoch 29 loss: 0.13598814606666565\n",
      "epoch 30 loss: 0.1214866116642952\n",
      "4\n",
      "epoch 1 loss: 0.8009876608848572\n",
      "epoch 2 loss: 0.7235419154167175\n",
      "epoch 3 loss: 0.38342559337615967\n",
      "epoch 4 loss: 0.23847176134586334\n",
      "epoch 5 loss: 0.22336213290691376\n",
      "epoch 6 loss: 0.18614408373832703\n",
      "epoch 7 loss: 0.20748060941696167\n",
      "epoch 8 loss: 0.18636387586593628\n",
      "epoch 9 loss: 0.18475931882858276\n",
      "epoch 10 loss: 0.21289671957492828\n",
      "epoch 11 loss: 0.17785455286502838\n",
      "epoch 12 loss: 0.17671802639961243\n",
      "epoch 13 loss: 0.21530942618846893\n",
      "epoch 14 loss: 0.1965985894203186\n",
      "epoch 15 loss: 0.14225028455257416\n",
      "epoch 16 loss: 0.14691351354122162\n",
      "epoch 17 loss: 0.1557861566543579\n",
      "epoch 18 loss: 0.15262599289417267\n",
      "epoch 19 loss: 0.11192915588617325\n",
      "epoch 20 loss: 0.1372067928314209\n",
      "epoch 21 loss: 0.10524166375398636\n",
      "epoch 22 loss: 0.12295404076576233\n",
      "epoch 23 loss: 0.1529095619916916\n",
      "epoch 24 loss: 0.14571166038513184\n",
      "epoch 25 loss: 0.14927604794502258\n",
      "epoch 26 loss: 0.12292559444904327\n",
      "epoch 27 loss: 0.12117573618888855\n",
      "epoch 28 loss: 0.13329261541366577\n",
      "epoch 29 loss: 0.13071773946285248\n",
      "epoch 30 loss: 0.11279922723770142\n",
      "5\n",
      "epoch 1 loss: 0.8663314580917358\n",
      "epoch 2 loss: 0.5237702131271362\n",
      "epoch 3 loss: 0.28368258476257324\n",
      "epoch 4 loss: 0.23850561678409576\n",
      "epoch 5 loss: 0.22485056519508362\n",
      "epoch 6 loss: 0.21703985333442688\n",
      "epoch 7 loss: 0.1974824070930481\n",
      "epoch 8 loss: 0.22563081979751587\n",
      "epoch 9 loss: 0.21121378242969513\n",
      "epoch 10 loss: 0.1922219693660736\n",
      "epoch 11 loss: 0.22050167620182037\n",
      "epoch 12 loss: 0.17873737215995789\n",
      "epoch 13 loss: 0.16796906292438507\n",
      "epoch 14 loss: 0.1830407828092575\n",
      "epoch 15 loss: 0.1779002696275711\n",
      "epoch 16 loss: 0.22161222994327545\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m model \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mRNN_FeatureAttention()\n\u001B[1;32m     12\u001B[0m trainer \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mRNN_train_1(model, train_config)\n\u001B[0;32m---> 13\u001B[0m forcast, true \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_reduced\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m result \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mday\u001B[39m\u001B[38;5;124m'\u001B[39m: df_reduced[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mds\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mdate\u001B[38;5;241m.\u001B[39mmax(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhour\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m24\u001B[39m)), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_hat\u001B[39m\u001B[38;5;124m'\u001B[39m: forcast, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m: true})\n\u001B[1;32m     17\u001B[0m results_aep_self_con \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([results_aep_self_con, result])\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Desktop/Downscaling/work_summary_9_26/model_summary.py:1076\u001B[0m, in \u001B[0;36mRNN_train_1.__call__\u001B[0;34m(self, df)\u001B[0m\n\u001B[1;32m   1074\u001B[0m yb \u001B[38;5;241m=\u001B[39m yb\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_config\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   1075\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m-> 1076\u001B[0m o, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1077\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmse_loss(o, yb)\n\u001B[1;32m   1078\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1773\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1782\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1783\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/Downscaling/work_summary_9_26/model_summary.py:127\u001B[0m, in \u001B[0;36mRNN_FeatureAttention.forward\u001B[0;34m(self, x, z0)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(T):\n\u001B[1;32m    126\u001B[0m     x_t \u001B[38;5;241m=\u001B[39m x[:, t, :]\n\u001B[0;32m--> 127\u001B[0m     z_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact(z_t \u001B[38;5;241m@\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m+\u001B[39m x_t \u001B[38;5;241m@\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mU\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mb\u001B[49m)\n\u001B[1;32m    128\u001B[0m     z_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_feature_attend(z_t)\n\u001B[1;32m    129\u001B[0m     Z\u001B[38;5;241m.\u001B[39mappend(z_t)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1949\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1944\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[1;32m   1946\u001B[0m \u001B[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001B[39;00m\n\u001B[1;32m   1947\u001B[0m \u001B[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001B[39;00m\n\u001B[1;32m   1948\u001B[0m \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001B[39;00m\n\u001B[0;32m-> 1949\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[Tensor, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModule\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m   1950\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m:\n\u001B[1;32m   1951\u001B[0m         _parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:22:57.273887Z",
     "start_time": "2025-10-15T21:22:57.081035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k = 24*3\n",
    "x_ax = np.arange(len(results_aep_self_con['y'][:k]))\n",
    "\n",
    "plt.plot(x_ax, results_aep_self_con['y_hat'][:k], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.plot(x_ax, results_aep_self_con['y'][:k], marker=\"o\", linestyle=\"-\", color=\"r\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_Tplus1\")\n",
    "plt.title(\"Line plot of y_Tplus1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "27a5e4ae04297fc8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "6a4e7924-6f76-4f6f-b754-db199ec89734",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + numerical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f2b1022-93f4-4141-9f5b-fd9dec4150ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T09:00:18.060115Z",
     "start_time": "2025-10-03T07:58:50.233335Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wn = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wn()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wn = pd.concat([results_aep_self_con_wn, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con_wn.to_csv(out_dir + '/results_aep_self_con_wn.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1 loss: 0.6716395020484924\n",
      "epoch 2 loss: 0.4556232988834381\n",
      "epoch 3 loss: 0.3228101134300232\n",
      "epoch 4 loss: 0.2447081208229065\n",
      "epoch 5 loss: 0.17460261285305023\n",
      "epoch 6 loss: 0.1978360116481781\n",
      "epoch 7 loss: 0.21279363334178925\n",
      "epoch 8 loss: 0.18435551226139069\n",
      "epoch 9 loss: 0.19015228748321533\n",
      "epoch 10 loss: 0.1872287541627884\n",
      "epoch 11 loss: 0.1599700003862381\n",
      "epoch 12 loss: 0.15799812972545624\n",
      "epoch 13 loss: 0.191727876663208\n",
      "epoch 14 loss: 0.20354795455932617\n",
      "epoch 15 loss: 0.16044828295707703\n",
      "epoch 16 loss: 0.15399082005023956\n",
      "epoch 17 loss: 0.13161246478557587\n",
      "epoch 18 loss: 0.11924848705530167\n",
      "epoch 19 loss: 0.17580987513065338\n",
      "epoch 20 loss: 0.15082377195358276\n",
      "epoch 21 loss: 0.1377718150615692\n",
      "epoch 22 loss: 0.12725551426410675\n",
      "epoch 23 loss: 0.09108277410268784\n",
      "epoch 24 loss: 0.12582790851593018\n",
      "epoch 25 loss: 0.11517995595932007\n",
      "epoch 26 loss: 0.10474909096956253\n",
      "epoch 27 loss: 0.12175706028938293\n",
      "epoch 28 loss: 0.10018753260374069\n",
      "epoch 29 loss: 0.10974211245775223\n",
      "epoch 30 loss: 0.10611942410469055\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_60650/1946476654.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_self_con_wn = pd.concat([results_aep_self_con_wn, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7393772006034851\n",
      "epoch 2 loss: 0.9175370931625366\n",
      "epoch 3 loss: 0.38082191348075867\n",
      "epoch 4 loss: 0.2910465598106384\n",
      "epoch 5 loss: 0.22382289171218872\n",
      "epoch 6 loss: 0.17806650698184967\n",
      "epoch 7 loss: 0.18607467412948608\n",
      "epoch 8 loss: 0.1945217251777649\n",
      "epoch 9 loss: 0.1652352213859558\n",
      "epoch 10 loss: 0.1673697680234909\n",
      "epoch 11 loss: 0.22524112462997437\n",
      "epoch 12 loss: 0.18695706129074097\n",
      "epoch 13 loss: 0.17789317667484283\n",
      "epoch 14 loss: 0.190596804022789\n",
      "epoch 15 loss: 0.2010572999715805\n",
      "epoch 16 loss: 0.172170951962471\n",
      "epoch 17 loss: 0.19858890771865845\n",
      "epoch 18 loss: 0.16897009313106537\n",
      "epoch 19 loss: 0.13492648303508759\n",
      "epoch 20 loss: 0.13549479842185974\n",
      "epoch 21 loss: 0.1534690409898758\n",
      "epoch 22 loss: 0.14554980397224426\n",
      "epoch 23 loss: 0.1283101588487625\n",
      "epoch 24 loss: 0.13737930357456207\n",
      "epoch 25 loss: 0.16324825584888458\n",
      "epoch 26 loss: 0.14227043092250824\n",
      "epoch 27 loss: 0.10533501207828522\n",
      "epoch 28 loss: 0.10596948862075806\n",
      "epoch 29 loss: 0.1287045031785965\n",
      "epoch 30 loss: 0.12068945914506912\n",
      "3\n",
      "epoch 1 loss: 0.761958658695221\n",
      "epoch 2 loss: 0.7879165410995483\n",
      "epoch 3 loss: 0.4011869430541992\n",
      "epoch 4 loss: 0.2503548562526703\n",
      "epoch 5 loss: 0.1778479814529419\n",
      "epoch 6 loss: 0.16516976058483124\n",
      "epoch 7 loss: 0.21974977850914001\n",
      "epoch 8 loss: 0.20585337281227112\n",
      "epoch 9 loss: 0.16306360065937042\n",
      "epoch 10 loss: 0.2758665084838867\n",
      "epoch 11 loss: 0.1875002533197403\n",
      "epoch 12 loss: 0.21411055326461792\n",
      "epoch 13 loss: 0.14504937827587128\n",
      "epoch 14 loss: 0.16779960691928864\n",
      "epoch 15 loss: 0.17241764068603516\n",
      "epoch 16 loss: 0.18087105453014374\n",
      "epoch 17 loss: 0.13755695521831512\n",
      "epoch 18 loss: 0.16924603283405304\n",
      "epoch 19 loss: 0.15121567249298096\n",
      "epoch 20 loss: 0.12879961729049683\n",
      "epoch 21 loss: 0.1417580395936966\n",
      "epoch 22 loss: 0.11871535331010818\n",
      "epoch 23 loss: 0.13716928660869598\n",
      "epoch 24 loss: 0.11003851890563965\n",
      "epoch 25 loss: 0.12308404594659805\n",
      "epoch 26 loss: 0.10440746694803238\n",
      "epoch 27 loss: 0.17380337417125702\n",
      "epoch 28 loss: 0.14066827297210693\n",
      "epoch 29 loss: 0.10380547493696213\n",
      "epoch 30 loss: 0.17676140367984772\n",
      "4\n",
      "epoch 1 loss: 0.7472791075706482\n",
      "epoch 2 loss: 0.4964192509651184\n",
      "epoch 3 loss: 0.3200575113296509\n",
      "epoch 4 loss: 0.3001847267150879\n",
      "epoch 5 loss: 0.25216853618621826\n",
      "epoch 6 loss: 0.24273841083049774\n",
      "epoch 7 loss: 0.20824280381202698\n",
      "epoch 8 loss: 0.19771365821361542\n",
      "epoch 9 loss: 0.18917755782604218\n",
      "epoch 10 loss: 0.19162431359291077\n",
      "epoch 11 loss: 0.19237874448299408\n",
      "epoch 12 loss: 0.23621799051761627\n",
      "epoch 13 loss: 0.1679774671792984\n",
      "epoch 14 loss: 0.17334279417991638\n",
      "epoch 15 loss: 0.15256521105766296\n",
      "epoch 16 loss: 0.14164522290229797\n",
      "epoch 17 loss: 0.14542901515960693\n",
      "epoch 18 loss: 0.160304456949234\n",
      "epoch 19 loss: 0.11637312173843384\n",
      "epoch 20 loss: 0.12084269523620605\n",
      "epoch 21 loss: 0.1928606480360031\n",
      "epoch 22 loss: 0.1076735109090805\n",
      "epoch 23 loss: 0.12824806571006775\n",
      "epoch 24 loss: 0.11607102304697037\n",
      "epoch 25 loss: 0.09674371778964996\n",
      "epoch 26 loss: 0.12060976028442383\n",
      "epoch 27 loss: 0.14807778596878052\n",
      "epoch 28 loss: 0.10556642711162567\n",
      "epoch 29 loss: 0.10829558223485947\n",
      "epoch 30 loss: 0.10712168365716934\n",
      "5\n",
      "epoch 1 loss: 0.8859660029411316\n",
      "epoch 2 loss: 0.6125146150588989\n",
      "epoch 3 loss: 0.4341906011104584\n",
      "epoch 4 loss: 0.2522786855697632\n",
      "epoch 5 loss: 0.22133348882198334\n",
      "epoch 6 loss: 0.22473996877670288\n",
      "epoch 7 loss: 0.2381688803434372\n",
      "epoch 8 loss: 0.17304860055446625\n",
      "epoch 9 loss: 0.20546330511569977\n",
      "epoch 10 loss: 0.21975401043891907\n",
      "epoch 11 loss: 0.24404820799827576\n",
      "epoch 12 loss: 0.15206432342529297\n",
      "epoch 13 loss: 0.2048189491033554\n",
      "epoch 14 loss: 0.23958149552345276\n",
      "epoch 15 loss: 0.16397050023078918\n",
      "epoch 16 loss: 0.18709295988082886\n",
      "epoch 17 loss: 0.18565917015075684\n",
      "epoch 18 loss: 0.20709820091724396\n",
      "epoch 19 loss: 0.19079157710075378\n",
      "epoch 20 loss: 0.16568778455257416\n",
      "epoch 21 loss: 0.11762069910764694\n",
      "epoch 22 loss: 0.16883021593093872\n",
      "epoch 23 loss: 0.1910705417394638\n",
      "epoch 24 loss: 0.1347210556268692\n",
      "epoch 25 loss: 0.14091604948043823\n",
      "epoch 26 loss: 0.17700617015361786\n",
      "epoch 27 loss: 0.15221107006072998\n",
      "epoch 28 loss: 0.21414853632450104\n",
      "epoch 29 loss: 0.1403902918100357\n",
      "epoch 30 loss: 0.12650185823440552\n",
      "6\n",
      "epoch 1 loss: 0.7134597301483154\n",
      "epoch 2 loss: 0.4009675085544586\n",
      "epoch 3 loss: 0.342239111661911\n",
      "epoch 4 loss: 0.2699397802352905\n",
      "epoch 5 loss: 0.22907426953315735\n",
      "epoch 6 loss: 0.20449449121952057\n",
      "epoch 7 loss: 0.2560356557369232\n",
      "epoch 8 loss: 0.21961310505867004\n",
      "epoch 9 loss: 0.23192524909973145\n",
      "epoch 10 loss: 0.21989808976650238\n",
      "epoch 11 loss: 0.19735433161258698\n",
      "epoch 12 loss: 0.1943875551223755\n",
      "epoch 13 loss: 0.16907048225402832\n",
      "epoch 14 loss: 0.22980424761772156\n",
      "epoch 15 loss: 0.18232403695583344\n",
      "epoch 16 loss: 0.1617235541343689\n",
      "epoch 17 loss: 0.19846227765083313\n",
      "epoch 18 loss: 0.18886010348796844\n",
      "epoch 19 loss: 0.18497033417224884\n",
      "epoch 20 loss: 0.12991487979888916\n",
      "epoch 21 loss: 0.1728065013885498\n",
      "epoch 22 loss: 0.17038887739181519\n",
      "epoch 23 loss: 0.16794314980506897\n",
      "epoch 24 loss: 0.18877048790454865\n",
      "epoch 25 loss: 0.16053369641304016\n",
      "epoch 26 loss: 0.15195247530937195\n",
      "epoch 27 loss: 0.12998424470424652\n",
      "epoch 28 loss: 0.13454098999500275\n",
      "epoch 29 loss: 0.12920352816581726\n",
      "epoch 30 loss: 0.16288158297538757\n",
      "7\n",
      "epoch 1 loss: 0.9595392942428589\n",
      "epoch 2 loss: 0.5193713903427124\n",
      "epoch 3 loss: 0.36654457449913025\n",
      "epoch 4 loss: 0.2684045732021332\n",
      "epoch 5 loss: 0.1579318344593048\n",
      "epoch 6 loss: 0.2328438013792038\n",
      "epoch 7 loss: 0.21758022904396057\n",
      "epoch 8 loss: 0.24051284790039062\n",
      "epoch 9 loss: 0.15597805380821228\n",
      "epoch 10 loss: 0.17408105731010437\n",
      "epoch 11 loss: 0.17630057036876678\n",
      "epoch 12 loss: 0.1954461932182312\n",
      "epoch 13 loss: 0.21952427923679352\n",
      "epoch 14 loss: 0.1928873062133789\n",
      "epoch 15 loss: 0.21281574666500092\n",
      "epoch 16 loss: 0.17320942878723145\n",
      "epoch 17 loss: 0.18628282845020294\n",
      "epoch 18 loss: 0.15918166935443878\n",
      "epoch 19 loss: 0.1680092066526413\n",
      "epoch 20 loss: 0.1861228197813034\n",
      "epoch 21 loss: 0.2568832337856293\n",
      "epoch 22 loss: 0.22655142843723297\n",
      "epoch 23 loss: 0.16585810482501984\n",
      "epoch 24 loss: 0.17354130744934082\n",
      "epoch 25 loss: 0.11127061396837234\n",
      "epoch 26 loss: 0.14526799321174622\n",
      "epoch 27 loss: 0.15375706553459167\n",
      "epoch 28 loss: 0.13129107654094696\n",
      "epoch 29 loss: 0.11062467098236084\n",
      "epoch 30 loss: 0.12725993990898132\n",
      "8\n",
      "epoch 1 loss: 0.9169450998306274\n",
      "epoch 2 loss: 0.5657327175140381\n",
      "epoch 3 loss: 0.3139980435371399\n",
      "epoch 4 loss: 0.26392191648483276\n",
      "epoch 5 loss: 0.2351812720298767\n",
      "epoch 6 loss: 0.18922244012355804\n",
      "epoch 7 loss: 0.20680895447731018\n",
      "epoch 8 loss: 0.18493281304836273\n",
      "epoch 9 loss: 0.21028032898902893\n",
      "epoch 10 loss: 0.18657401204109192\n",
      "epoch 11 loss: 0.19339323043823242\n",
      "epoch 12 loss: 0.14186057448387146\n",
      "epoch 13 loss: 0.20659971237182617\n",
      "epoch 14 loss: 0.15281106531620026\n",
      "epoch 15 loss: 0.14311353862285614\n",
      "epoch 16 loss: 0.15524135529994965\n",
      "epoch 17 loss: 0.17352795600891113\n",
      "epoch 18 loss: 0.16545459628105164\n",
      "epoch 19 loss: 0.150406613945961\n",
      "epoch 20 loss: 0.15832753479480743\n",
      "epoch 21 loss: 0.18202655017375946\n",
      "epoch 22 loss: 0.16245825588703156\n",
      "epoch 23 loss: 0.14821204543113708\n",
      "epoch 24 loss: 0.1262221783399582\n",
      "epoch 25 loss: 0.12450579553842545\n",
      "epoch 26 loss: 0.12617430090904236\n",
      "epoch 27 loss: 0.12811093032360077\n",
      "epoch 28 loss: 0.12255281955003738\n",
      "epoch 29 loss: 0.10269386321306229\n",
      "epoch 30 loss: 0.11981267482042313\n",
      "9\n",
      "epoch 1 loss: 1.0324819087982178\n",
      "epoch 2 loss: 0.8101317882537842\n",
      "epoch 3 loss: 0.6807480454444885\n",
      "epoch 4 loss: 0.2893197536468506\n",
      "epoch 5 loss: 0.21347719430923462\n",
      "epoch 6 loss: 0.19385039806365967\n",
      "epoch 7 loss: 0.18102701008319855\n",
      "epoch 8 loss: 0.1916215419769287\n",
      "epoch 9 loss: 0.16185830533504486\n",
      "epoch 10 loss: 0.19155430793762207\n",
      "epoch 11 loss: 0.19079427421092987\n",
      "epoch 12 loss: 0.1495339572429657\n",
      "epoch 13 loss: 0.19358302652835846\n",
      "epoch 14 loss: 0.17991231381893158\n",
      "epoch 15 loss: 0.139629065990448\n",
      "epoch 16 loss: 0.16733956336975098\n",
      "epoch 17 loss: 0.2071884572505951\n",
      "epoch 18 loss: 0.18829046189785004\n",
      "epoch 19 loss: 0.14545324444770813\n",
      "epoch 20 loss: 0.1467624455690384\n",
      "epoch 21 loss: 0.12471847981214523\n",
      "epoch 22 loss: 0.15108893811702728\n",
      "epoch 23 loss: 0.11831944435834885\n",
      "epoch 24 loss: 0.1666950136423111\n",
      "epoch 25 loss: 0.15365377068519592\n",
      "epoch 26 loss: 0.13496153056621552\n",
      "epoch 27 loss: 0.1228424459695816\n",
      "epoch 28 loss: 0.12081556022167206\n",
      "epoch 29 loss: 0.09529893845319748\n",
      "epoch 30 loss: 0.11147341132164001\n",
      "10\n",
      "epoch 1 loss: 0.9082984924316406\n",
      "epoch 2 loss: 0.5614483952522278\n",
      "epoch 3 loss: 0.3724592626094818\n",
      "epoch 4 loss: 0.33427080512046814\n",
      "epoch 5 loss: 0.23233409225940704\n",
      "epoch 6 loss: 0.18372738361358643\n",
      "epoch 7 loss: 0.22091001272201538\n",
      "epoch 8 loss: 0.18237493932247162\n",
      "epoch 9 loss: 0.21643061935901642\n",
      "epoch 10 loss: 0.19905763864517212\n",
      "epoch 11 loss: 0.1727096140384674\n",
      "epoch 12 loss: 0.18280243873596191\n",
      "epoch 13 loss: 0.17246802151203156\n",
      "epoch 14 loss: 0.23711709678173065\n",
      "epoch 15 loss: 0.18824045360088348\n",
      "epoch 16 loss: 0.16485372185707092\n",
      "epoch 17 loss: 0.16254514455795288\n",
      "epoch 18 loss: 0.16908033192157745\n",
      "epoch 19 loss: 0.16193652153015137\n",
      "epoch 20 loss: 0.17974546551704407\n",
      "epoch 21 loss: 0.18196983635425568\n",
      "epoch 22 loss: 0.1492978185415268\n",
      "epoch 23 loss: 0.15807966887950897\n",
      "epoch 24 loss: 0.15845251083374023\n",
      "epoch 25 loss: 0.1415976732969284\n",
      "epoch 26 loss: 0.13355110585689545\n",
      "epoch 27 loss: 0.12772512435913086\n",
      "epoch 28 loss: 0.12952499091625214\n",
      "epoch 29 loss: 0.13216915726661682\n",
      "epoch 30 loss: 0.12517651915550232\n",
      "11\n",
      "epoch 1 loss: 0.645398736000061\n",
      "epoch 2 loss: 0.6694521903991699\n",
      "epoch 3 loss: 0.8368666768074036\n",
      "epoch 4 loss: 0.47745364904403687\n",
      "epoch 5 loss: 0.18660840392112732\n",
      "epoch 6 loss: 0.2115100622177124\n",
      "epoch 7 loss: 0.17628709971904755\n",
      "epoch 8 loss: 0.2296355962753296\n",
      "epoch 9 loss: 0.21236129105091095\n",
      "epoch 10 loss: 0.14207829535007477\n",
      "epoch 11 loss: 0.2329457849264145\n",
      "epoch 12 loss: 0.2073434740304947\n",
      "epoch 13 loss: 0.23422078788280487\n",
      "epoch 14 loss: 0.19693408906459808\n",
      "epoch 15 loss: 0.18315662443637848\n",
      "epoch 16 loss: 0.2393638789653778\n",
      "epoch 17 loss: 0.1851804405450821\n",
      "epoch 18 loss: 0.1676524132490158\n",
      "epoch 19 loss: 0.16884934902191162\n",
      "epoch 20 loss: 0.18595632910728455\n",
      "epoch 21 loss: 0.19557060301303864\n",
      "epoch 22 loss: 0.18635232746601105\n",
      "epoch 23 loss: 0.1683783233165741\n",
      "epoch 24 loss: 0.1576976627111435\n",
      "epoch 25 loss: 0.19726893305778503\n",
      "epoch 26 loss: 0.16716021299362183\n",
      "epoch 27 loss: 0.16821296513080597\n",
      "epoch 28 loss: 0.1454099714756012\n",
      "epoch 29 loss: 0.12394556403160095\n",
      "epoch 30 loss: 0.17108654975891113\n",
      "12\n",
      "epoch 1 loss: 0.9551176428794861\n",
      "epoch 2 loss: 0.47856369614601135\n",
      "epoch 3 loss: 0.23881608247756958\n",
      "epoch 4 loss: 0.21901746094226837\n",
      "epoch 5 loss: 0.1745433658361435\n",
      "epoch 6 loss: 0.20724427700042725\n",
      "epoch 7 loss: 0.24902495741844177\n",
      "epoch 8 loss: 0.21798214316368103\n",
      "epoch 9 loss: 0.19492964446544647\n",
      "epoch 10 loss: 0.18699346482753754\n",
      "epoch 11 loss: 0.20290502905845642\n",
      "epoch 12 loss: 0.17895634472370148\n",
      "epoch 13 loss: 0.20494642853736877\n",
      "epoch 14 loss: 0.17028845846652985\n",
      "epoch 15 loss: 0.18693219125270844\n",
      "epoch 16 loss: 0.18449263274669647\n",
      "epoch 17 loss: 0.20015208423137665\n",
      "epoch 18 loss: 0.20114323496818542\n",
      "epoch 19 loss: 0.3330319821834564\n",
      "epoch 20 loss: 0.17076539993286133\n",
      "epoch 21 loss: 0.17171557247638702\n",
      "epoch 22 loss: 0.13546700775623322\n",
      "epoch 23 loss: 0.1653493344783783\n",
      "epoch 24 loss: 0.1605997085571289\n",
      "epoch 25 loss: 0.13715733587741852\n",
      "epoch 26 loss: 0.13615766167640686\n",
      "epoch 27 loss: 0.1477171629667282\n",
      "epoch 28 loss: 0.1422942727804184\n",
      "epoch 29 loss: 0.10990680009126663\n",
      "epoch 30 loss: 0.12246552854776382\n",
      "13\n",
      "epoch 1 loss: 0.7493603825569153\n",
      "epoch 2 loss: 0.5550010800361633\n",
      "epoch 3 loss: 0.33006229996681213\n",
      "epoch 4 loss: 0.23862767219543457\n",
      "epoch 5 loss: 0.18153789639472961\n",
      "epoch 6 loss: 0.16027972102165222\n",
      "epoch 7 loss: 0.20774337649345398\n",
      "epoch 8 loss: 0.22797387838363647\n",
      "epoch 9 loss: 0.1968599408864975\n",
      "epoch 10 loss: 0.16199515759944916\n",
      "epoch 11 loss: 0.17446264624595642\n",
      "epoch 12 loss: 0.17386725544929504\n",
      "epoch 13 loss: 0.20488053560256958\n",
      "epoch 14 loss: 0.18900097906589508\n",
      "epoch 15 loss: 0.16055746376514435\n",
      "epoch 16 loss: 0.17275629937648773\n",
      "epoch 17 loss: 0.20086149871349335\n",
      "epoch 18 loss: 0.2197355329990387\n",
      "epoch 19 loss: 0.16299527883529663\n",
      "epoch 20 loss: 0.15289761126041412\n",
      "epoch 21 loss: 0.13935713469982147\n",
      "epoch 22 loss: 0.1234210804104805\n",
      "epoch 23 loss: 0.1409519463777542\n",
      "epoch 24 loss: 0.12541508674621582\n",
      "epoch 25 loss: 0.11685416102409363\n",
      "epoch 26 loss: 0.1472071409225464\n",
      "epoch 27 loss: 0.08937686681747437\n",
      "epoch 28 loss: 0.11315013468265533\n",
      "epoch 29 loss: 0.15819087624549866\n",
      "epoch 30 loss: 0.11972212791442871\n",
      "14\n",
      "epoch 1 loss: 0.6621175408363342\n",
      "epoch 2 loss: 1.0608397722244263\n",
      "epoch 3 loss: 0.6141518950462341\n",
      "epoch 4 loss: 0.3256472051143646\n",
      "epoch 5 loss: 0.23351119458675385\n",
      "epoch 6 loss: 0.18556487560272217\n",
      "epoch 7 loss: 0.1938992440700531\n",
      "epoch 8 loss: 0.2084704041481018\n",
      "epoch 9 loss: 0.18418601155281067\n",
      "epoch 10 loss: 0.18038935959339142\n",
      "epoch 11 loss: 0.18579073250293732\n",
      "epoch 12 loss: 0.21405775845050812\n",
      "epoch 13 loss: 0.16416342556476593\n",
      "epoch 14 loss: 0.15657076239585876\n",
      "epoch 15 loss: 0.18307729065418243\n",
      "epoch 16 loss: 0.17131873965263367\n",
      "epoch 17 loss: 0.18849419057369232\n",
      "epoch 18 loss: 0.19517390429973602\n",
      "epoch 19 loss: 0.23499839007854462\n",
      "epoch 20 loss: 0.2514922618865967\n",
      "epoch 21 loss: 0.1551358997821808\n",
      "epoch 22 loss: 0.12482967972755432\n",
      "epoch 23 loss: 0.1685335487127304\n",
      "epoch 24 loss: 0.14726239442825317\n",
      "epoch 25 loss: 0.17463655769824982\n",
      "epoch 26 loss: 0.1323215514421463\n",
      "epoch 27 loss: 0.14656953513622284\n",
      "epoch 28 loss: 0.12291944772005081\n",
      "epoch 29 loss: 0.13704323768615723\n",
      "epoch 30 loss: 0.13982358574867249\n",
      "15\n",
      "epoch 1 loss: 0.6636347770690918\n",
      "epoch 2 loss: 0.5902243256568909\n",
      "epoch 3 loss: 0.41900813579559326\n",
      "epoch 4 loss: 0.2822858393192291\n",
      "epoch 5 loss: 0.1667906939983368\n",
      "epoch 6 loss: 0.21626806259155273\n",
      "epoch 7 loss: 0.1977570652961731\n",
      "epoch 8 loss: 0.22104167938232422\n",
      "epoch 9 loss: 0.16153071820735931\n",
      "epoch 10 loss: 0.20666256546974182\n",
      "epoch 11 loss: 0.16766151785850525\n",
      "epoch 12 loss: 0.1611611247062683\n",
      "epoch 13 loss: 0.20857274532318115\n",
      "epoch 14 loss: 0.21139024198055267\n",
      "epoch 15 loss: 0.20394083857536316\n",
      "epoch 16 loss: 0.17271900177001953\n",
      "epoch 17 loss: 0.1551135927438736\n",
      "epoch 18 loss: 0.17725452780723572\n",
      "epoch 19 loss: 0.14134837687015533\n",
      "epoch 20 loss: 0.1850578337907791\n",
      "epoch 21 loss: 0.11981622874736786\n",
      "epoch 22 loss: 0.14547517895698547\n",
      "epoch 23 loss: 0.1335788518190384\n",
      "epoch 24 loss: 0.14208881556987762\n",
      "epoch 25 loss: 0.1593521684408188\n",
      "epoch 26 loss: 0.13997776806354523\n",
      "epoch 27 loss: 0.12685386836528778\n",
      "epoch 28 loss: 0.09077487140893936\n",
      "epoch 29 loss: 0.12131708860397339\n",
      "epoch 30 loss: 0.1315145343542099\n",
      "16\n",
      "epoch 1 loss: 0.8009912967681885\n",
      "epoch 2 loss: 0.5443623661994934\n",
      "epoch 3 loss: 0.2963715195655823\n",
      "epoch 4 loss: 0.26126015186309814\n",
      "epoch 5 loss: 0.24680308997631073\n",
      "epoch 6 loss: 0.1771899163722992\n",
      "epoch 7 loss: 0.17871718108654022\n",
      "epoch 8 loss: 0.21133394539356232\n",
      "epoch 9 loss: 0.1798458844423294\n",
      "epoch 10 loss: 0.2023136019706726\n",
      "epoch 11 loss: 0.1478099375963211\n",
      "epoch 12 loss: 0.18545541167259216\n",
      "epoch 13 loss: 0.1900501400232315\n",
      "epoch 14 loss: 0.21530555188655853\n",
      "epoch 15 loss: 0.17443038523197174\n",
      "epoch 16 loss: 0.14492440223693848\n",
      "epoch 17 loss: 0.1464073359966278\n",
      "epoch 18 loss: 0.17007195949554443\n",
      "epoch 19 loss: 0.15330451726913452\n",
      "epoch 20 loss: 0.18826662003993988\n",
      "epoch 21 loss: 0.15657727420330048\n",
      "epoch 22 loss: 0.1561248004436493\n",
      "epoch 23 loss: 0.14196504652500153\n",
      "epoch 24 loss: 0.1424899399280548\n",
      "epoch 25 loss: 0.1623649150133133\n",
      "epoch 26 loss: 0.14254337549209595\n",
      "epoch 27 loss: 0.14233623445034027\n",
      "epoch 28 loss: 0.1505730301141739\n",
      "epoch 29 loss: 0.11008749902248383\n",
      "epoch 30 loss: 0.09714485704898834\n",
      "17\n",
      "epoch 1 loss: 1.0746628046035767\n",
      "epoch 2 loss: 0.6201217174530029\n",
      "epoch 3 loss: 0.5628657341003418\n",
      "epoch 4 loss: 0.4567228853702545\n",
      "epoch 5 loss: 0.34908297657966614\n",
      "epoch 6 loss: 0.24035391211509705\n",
      "epoch 7 loss: 0.2128283530473709\n",
      "epoch 8 loss: 0.18008054792881012\n",
      "epoch 9 loss: 0.20912720263004303\n",
      "epoch 10 loss: 0.19179239869117737\n",
      "epoch 11 loss: 0.17669633030891418\n",
      "epoch 12 loss: 0.1731761246919632\n",
      "epoch 13 loss: 0.19449177384376526\n",
      "epoch 14 loss: 0.20670534670352936\n",
      "epoch 15 loss: 0.18640321493148804\n",
      "epoch 16 loss: 0.17359444499015808\n",
      "epoch 17 loss: 0.20822674036026\n",
      "epoch 18 loss: 0.1693086177110672\n",
      "epoch 19 loss: 0.17761525511741638\n",
      "epoch 20 loss: 0.18396428227424622\n",
      "epoch 21 loss: 0.16352172195911407\n",
      "epoch 22 loss: 0.1341855525970459\n",
      "epoch 23 loss: 0.12278851121664047\n",
      "epoch 24 loss: 0.18627870082855225\n",
      "epoch 25 loss: 0.13825774192810059\n",
      "epoch 26 loss: 0.16267865896224976\n",
      "epoch 27 loss: 0.1190367266535759\n",
      "epoch 28 loss: 0.12090584635734558\n",
      "epoch 29 loss: 0.11617764085531235\n",
      "epoch 30 loss: 0.12969765067100525\n",
      "18\n",
      "epoch 1 loss: 0.8462989926338196\n",
      "epoch 2 loss: 0.5642172694206238\n",
      "epoch 3 loss: 0.6122653484344482\n",
      "epoch 4 loss: 0.3750418722629547\n",
      "epoch 5 loss: 0.19575561583042145\n",
      "epoch 6 loss: 0.20762377977371216\n",
      "epoch 7 loss: 0.176285982131958\n",
      "epoch 8 loss: 0.20677581429481506\n",
      "epoch 9 loss: 0.16835348308086395\n",
      "epoch 10 loss: 0.17709873616695404\n",
      "epoch 11 loss: 0.18854421377182007\n",
      "epoch 12 loss: 0.17292520403862\n",
      "epoch 13 loss: 0.1842343807220459\n",
      "epoch 14 loss: 0.17000752687454224\n",
      "epoch 15 loss: 0.1914491057395935\n",
      "epoch 16 loss: 0.20269443094730377\n",
      "epoch 17 loss: 0.21366670727729797\n",
      "epoch 18 loss: 0.18912413716316223\n",
      "epoch 19 loss: 0.20529724657535553\n",
      "epoch 20 loss: 0.19273048639297485\n",
      "epoch 21 loss: 0.18617364764213562\n",
      "epoch 22 loss: 0.18148165941238403\n",
      "epoch 23 loss: 0.15297311544418335\n",
      "epoch 24 loss: 0.1680772453546524\n",
      "epoch 25 loss: 0.15503431856632233\n",
      "epoch 26 loss: 0.20005007088184357\n",
      "epoch 27 loss: 0.13028863072395325\n",
      "epoch 28 loss: 0.13550704717636108\n",
      "epoch 29 loss: 0.1142084151506424\n",
      "epoch 30 loss: 0.177501380443573\n",
      "19\n",
      "epoch 1 loss: 0.7882989048957825\n",
      "epoch 2 loss: 0.7580317258834839\n",
      "epoch 3 loss: 0.35890230536460876\n",
      "epoch 4 loss: 0.26933327317237854\n",
      "epoch 5 loss: 0.19508221745491028\n",
      "epoch 6 loss: 0.17852750420570374\n",
      "epoch 7 loss: 0.18721356987953186\n",
      "epoch 8 loss: 0.23113736510276794\n",
      "epoch 9 loss: 0.2209857851266861\n",
      "epoch 10 loss: 0.2304227203130722\n",
      "epoch 11 loss: 0.2111203521490097\n",
      "epoch 12 loss: 0.17549622058868408\n",
      "epoch 13 loss: 0.20962564647197723\n",
      "epoch 14 loss: 0.18268604576587677\n",
      "epoch 15 loss: 0.16422487795352936\n",
      "epoch 16 loss: 0.20036499202251434\n",
      "epoch 17 loss: 0.22404958307743073\n",
      "epoch 18 loss: 0.22786054015159607\n",
      "epoch 19 loss: 0.1730646938085556\n",
      "epoch 20 loss: 0.22928118705749512\n",
      "epoch 21 loss: 0.2389221042394638\n",
      "epoch 22 loss: 0.1548250913619995\n",
      "epoch 23 loss: 0.14291180670261383\n",
      "epoch 24 loss: 0.1929042935371399\n",
      "epoch 25 loss: 0.2032281458377838\n",
      "epoch 26 loss: 0.15773478150367737\n",
      "epoch 27 loss: 0.1672663688659668\n",
      "epoch 28 loss: 0.12517331540584564\n",
      "epoch 29 loss: 0.13655436038970947\n",
      "epoch 30 loss: 0.17495083808898926\n",
      "20\n",
      "epoch 1 loss: 0.9335809946060181\n",
      "epoch 2 loss: 0.7208962440490723\n",
      "epoch 3 loss: 0.7432913780212402\n",
      "epoch 4 loss: 0.6742481589317322\n",
      "epoch 5 loss: 0.3929325044155121\n",
      "epoch 6 loss: 0.29866108298301697\n",
      "epoch 7 loss: 0.2520276606082916\n",
      "epoch 8 loss: 0.23901604115962982\n",
      "epoch 9 loss: 0.21670189499855042\n",
      "epoch 10 loss: 0.1839045286178589\n",
      "epoch 11 loss: 0.22081784904003143\n",
      "epoch 12 loss: 0.2066553384065628\n",
      "epoch 13 loss: 0.1761188954114914\n",
      "epoch 14 loss: 0.1805480271577835\n",
      "epoch 15 loss: 0.23002982139587402\n",
      "epoch 16 loss: 0.19218476116657257\n",
      "epoch 17 loss: 0.20194463431835175\n",
      "epoch 18 loss: 0.21633775532245636\n",
      "epoch 19 loss: 0.19027180969715118\n",
      "epoch 20 loss: 0.18007658421993256\n",
      "epoch 21 loss: 0.15846897661685944\n",
      "epoch 22 loss: 0.20535679161548615\n",
      "epoch 23 loss: 0.18723364174365997\n",
      "epoch 24 loss: 0.1978471428155899\n",
      "epoch 25 loss: 0.15767207741737366\n",
      "epoch 26 loss: 0.1729651242494583\n",
      "epoch 27 loss: 0.16542378067970276\n",
      "epoch 28 loss: 0.15710203349590302\n",
      "epoch 29 loss: 0.15333907306194305\n",
      "epoch 30 loss: 0.15786175429821014\n",
      "21\n",
      "epoch 1 loss: 0.8980844020843506\n",
      "epoch 2 loss: 0.6159257292747498\n",
      "epoch 3 loss: 0.39612877368927\n",
      "epoch 4 loss: 0.26353758573532104\n",
      "epoch 5 loss: 0.21554572880268097\n",
      "epoch 6 loss: 0.20155039429664612\n",
      "epoch 7 loss: 0.16381391882896423\n",
      "epoch 8 loss: 0.19705072045326233\n",
      "epoch 9 loss: 0.22811201214790344\n",
      "epoch 10 loss: 0.1660493016242981\n",
      "epoch 11 loss: 0.19607320427894592\n",
      "epoch 12 loss: 0.16284452378749847\n",
      "epoch 13 loss: 0.17834948003292084\n",
      "epoch 14 loss: 0.22525712847709656\n",
      "epoch 15 loss: 0.20387770235538483\n",
      "epoch 16 loss: 0.1795208752155304\n",
      "epoch 17 loss: 0.15258148312568665\n",
      "epoch 18 loss: 0.1569461077451706\n",
      "epoch 19 loss: 0.14910008013248444\n",
      "epoch 20 loss: 0.1590714156627655\n",
      "epoch 21 loss: 0.1480465531349182\n",
      "epoch 22 loss: 0.13288918137550354\n",
      "epoch 23 loss: 0.14588020741939545\n",
      "epoch 24 loss: 0.13275454938411713\n",
      "epoch 25 loss: 0.167787104845047\n",
      "epoch 26 loss: 0.122380830347538\n",
      "epoch 27 loss: 0.09859637916088104\n",
      "epoch 28 loss: 0.10352727025747299\n",
      "epoch 29 loss: 0.12709662318229675\n",
      "epoch 30 loss: 0.10285870730876923\n",
      "22\n",
      "epoch 1 loss: 0.9821243286132812\n",
      "epoch 2 loss: 0.4645370841026306\n",
      "epoch 3 loss: 0.34790295362472534\n",
      "epoch 4 loss: 0.18607056140899658\n",
      "epoch 5 loss: 0.2581349015235901\n",
      "epoch 6 loss: 0.22062720358371735\n",
      "epoch 7 loss: 0.21326947212219238\n",
      "epoch 8 loss: 0.21649494767189026\n",
      "epoch 9 loss: 0.18916195631027222\n",
      "epoch 10 loss: 0.16737034916877747\n",
      "epoch 11 loss: 0.19063769280910492\n",
      "epoch 12 loss: 0.14565566182136536\n",
      "epoch 13 loss: 0.1443364918231964\n",
      "epoch 14 loss: 0.20522978901863098\n",
      "epoch 15 loss: 0.15767543017864227\n",
      "epoch 16 loss: 0.19518786668777466\n",
      "epoch 17 loss: 0.20030975341796875\n",
      "epoch 18 loss: 0.20104938745498657\n",
      "epoch 19 loss: 0.15785901248455048\n",
      "epoch 20 loss: 0.19627173244953156\n",
      "epoch 21 loss: 0.19644755125045776\n",
      "epoch 22 loss: 0.1671120524406433\n",
      "epoch 23 loss: 0.2599649429321289\n",
      "epoch 24 loss: 0.1454835683107376\n",
      "epoch 25 loss: 0.11797474324703217\n",
      "epoch 26 loss: 0.1497381329536438\n",
      "epoch 27 loss: 0.1364060491323471\n",
      "epoch 28 loss: 0.14318686723709106\n",
      "epoch 29 loss: 0.12252362072467804\n",
      "epoch 30 loss: 0.11812794953584671\n",
      "23\n",
      "epoch 1 loss: 0.6443738341331482\n",
      "epoch 2 loss: 0.7427165508270264\n",
      "epoch 3 loss: 0.46754276752471924\n",
      "epoch 4 loss: 0.2344832569360733\n",
      "epoch 5 loss: 0.19559817016124725\n",
      "epoch 6 loss: 0.18984676897525787\n",
      "epoch 7 loss: 0.2015487551689148\n",
      "epoch 8 loss: 0.18634220957756042\n",
      "epoch 9 loss: 0.153256356716156\n",
      "epoch 10 loss: 0.21048228442668915\n",
      "epoch 11 loss: 0.22587257623672485\n",
      "epoch 12 loss: 0.2302025556564331\n",
      "epoch 13 loss: 0.15535174310207367\n",
      "epoch 14 loss: 0.2047664076089859\n",
      "epoch 15 loss: 0.15775063633918762\n",
      "epoch 16 loss: 0.18011875450611115\n",
      "epoch 17 loss: 0.17070437967777252\n",
      "epoch 18 loss: 0.19177792966365814\n",
      "epoch 19 loss: 0.18758448958396912\n",
      "epoch 20 loss: 0.16519753634929657\n",
      "epoch 21 loss: 0.15627169609069824\n",
      "epoch 22 loss: 0.13960035145282745\n",
      "epoch 23 loss: 0.14451909065246582\n",
      "epoch 24 loss: 0.1290806233882904\n",
      "epoch 25 loss: 0.15448352694511414\n",
      "epoch 26 loss: 0.12448888272047043\n",
      "epoch 27 loss: 0.13061688840389252\n",
      "epoch 28 loss: 0.10609062761068344\n",
      "epoch 29 loss: 0.1085086390376091\n",
      "epoch 30 loss: 0.11083052307367325\n",
      "24\n",
      "epoch 1 loss: 0.950802743434906\n",
      "epoch 2 loss: 0.5156131386756897\n",
      "epoch 3 loss: 0.33686819672584534\n",
      "epoch 4 loss: 0.22224827110767365\n",
      "epoch 5 loss: 0.2486022710800171\n",
      "epoch 6 loss: 0.19835461676120758\n",
      "epoch 7 loss: 0.21796299517154694\n",
      "epoch 8 loss: 0.1963777393102646\n",
      "epoch 9 loss: 0.1746712625026703\n",
      "epoch 10 loss: 0.181421160697937\n",
      "epoch 11 loss: 0.1772555559873581\n",
      "epoch 12 loss: 0.1783449649810791\n",
      "epoch 13 loss: 0.18908511102199554\n",
      "epoch 14 loss: 0.16680282354354858\n",
      "epoch 15 loss: 0.16928768157958984\n",
      "epoch 16 loss: 0.14266595244407654\n",
      "epoch 17 loss: 0.17971929907798767\n",
      "epoch 18 loss: 0.13126052916049957\n",
      "epoch 19 loss: 0.14014893770217896\n",
      "epoch 20 loss: 0.12861697375774384\n",
      "epoch 21 loss: 0.14110344648361206\n",
      "epoch 22 loss: 0.10984082520008087\n",
      "epoch 23 loss: 0.12972798943519592\n",
      "epoch 24 loss: 0.15607938170433044\n",
      "epoch 25 loss: 0.10014764964580536\n",
      "epoch 26 loss: 0.13899318873882294\n",
      "epoch 27 loss: 0.10744648426771164\n",
      "epoch 28 loss: 0.12635450065135956\n",
      "epoch 29 loss: 0.13587582111358643\n",
      "epoch 30 loss: 0.15917448699474335\n",
      "25\n",
      "epoch 1 loss: 0.9437257647514343\n",
      "epoch 2 loss: 0.6077296733856201\n",
      "epoch 3 loss: 0.37366095185279846\n",
      "epoch 4 loss: 0.3131706118583679\n",
      "epoch 5 loss: 0.2651882767677307\n",
      "epoch 6 loss: 0.20430798828601837\n",
      "epoch 7 loss: 0.17002718150615692\n",
      "epoch 8 loss: 0.16220207512378693\n",
      "epoch 9 loss: 0.18833966553211212\n",
      "epoch 10 loss: 0.19549600780010223\n",
      "epoch 11 loss: 0.21909962594509125\n",
      "epoch 12 loss: 0.18784824013710022\n",
      "epoch 13 loss: 0.16153796017169952\n",
      "epoch 14 loss: 0.1619480699300766\n",
      "epoch 15 loss: 0.19748246669769287\n",
      "epoch 16 loss: 0.1692921221256256\n",
      "epoch 17 loss: 0.1856449544429779\n",
      "epoch 18 loss: 0.1755511611700058\n",
      "epoch 19 loss: 0.16095639765262604\n",
      "epoch 20 loss: 0.13708025217056274\n",
      "epoch 21 loss: 0.1855330616235733\n",
      "epoch 22 loss: 0.11723588407039642\n",
      "epoch 23 loss: 0.15190666913986206\n",
      "epoch 24 loss: 0.11799141019582748\n",
      "epoch 25 loss: 0.1657889038324356\n",
      "epoch 26 loss: 0.12744830548763275\n",
      "epoch 27 loss: 0.09639915078878403\n",
      "epoch 28 loss: 0.12883314490318298\n",
      "epoch 29 loss: 0.10977138578891754\n",
      "epoch 30 loss: 0.1033073365688324\n",
      "26\n",
      "epoch 1 loss: 0.8065545558929443\n",
      "epoch 2 loss: 0.48723915219306946\n",
      "epoch 3 loss: 0.31302130222320557\n",
      "epoch 4 loss: 0.2119927853345871\n",
      "epoch 5 loss: 0.21593143045902252\n",
      "epoch 6 loss: 0.19980758428573608\n",
      "epoch 7 loss: 0.19718556106090546\n",
      "epoch 8 loss: 0.23436063528060913\n",
      "epoch 9 loss: 0.19292505085468292\n",
      "epoch 10 loss: 0.2205573320388794\n",
      "epoch 11 loss: 0.16050581634044647\n",
      "epoch 12 loss: 0.17129047214984894\n",
      "epoch 13 loss: 0.1490996927022934\n",
      "epoch 14 loss: 0.1932756006717682\n",
      "epoch 15 loss: 0.19606786966323853\n",
      "epoch 16 loss: 0.18614040315151215\n",
      "epoch 17 loss: 0.1887436956167221\n",
      "epoch 18 loss: 0.16922153532505035\n",
      "epoch 19 loss: 0.1648462563753128\n",
      "epoch 20 loss: 0.19909660518169403\n",
      "epoch 21 loss: 0.18761326372623444\n",
      "epoch 22 loss: 0.15942196547985077\n",
      "epoch 23 loss: 0.19567665457725525\n",
      "epoch 24 loss: 0.1780393272638321\n",
      "epoch 25 loss: 0.16852092742919922\n",
      "epoch 26 loss: 0.1289638727903366\n",
      "epoch 27 loss: 0.13535833358764648\n",
      "epoch 28 loss: 0.1332913637161255\n",
      "epoch 29 loss: 0.14433437585830688\n",
      "epoch 30 loss: 0.1394675225019455\n",
      "27\n",
      "epoch 1 loss: 0.705626368522644\n",
      "epoch 2 loss: 0.4120682179927826\n",
      "epoch 3 loss: 0.33142635226249695\n",
      "epoch 4 loss: 0.22545059025287628\n",
      "epoch 5 loss: 0.20137019455432892\n",
      "epoch 6 loss: 0.2082076221704483\n",
      "epoch 7 loss: 0.20933246612548828\n",
      "epoch 8 loss: 0.19172511994838715\n",
      "epoch 9 loss: 0.17159196734428406\n",
      "epoch 10 loss: 0.20680932700634003\n",
      "epoch 11 loss: 0.17617236077785492\n",
      "epoch 12 loss: 0.2027013897895813\n",
      "epoch 13 loss: 0.17037515342235565\n",
      "epoch 14 loss: 0.167898029088974\n",
      "epoch 15 loss: 0.16699177026748657\n",
      "epoch 16 loss: 0.1849568784236908\n",
      "epoch 17 loss: 0.17912358045578003\n",
      "epoch 18 loss: 0.16915936768054962\n",
      "epoch 19 loss: 0.14429906010627747\n",
      "epoch 20 loss: 0.11793725937604904\n",
      "epoch 21 loss: 0.15567021071910858\n",
      "epoch 22 loss: 0.1268492341041565\n",
      "epoch 23 loss: 0.14602090418338776\n",
      "epoch 24 loss: 0.150575652718544\n",
      "epoch 25 loss: 0.16472820937633514\n",
      "epoch 26 loss: 0.13428370654582977\n",
      "epoch 27 loss: 0.13893821835517883\n",
      "epoch 28 loss: 0.12654078006744385\n",
      "epoch 29 loss: 0.09310220181941986\n",
      "epoch 30 loss: 0.09941857308149338\n",
      "28\n",
      "epoch 1 loss: 1.0139905214309692\n",
      "epoch 2 loss: 0.6573824286460876\n",
      "epoch 3 loss: 0.7214996218681335\n",
      "epoch 4 loss: 0.37123367190361023\n",
      "epoch 5 loss: 0.19514836370944977\n",
      "epoch 6 loss: 0.19265609979629517\n",
      "epoch 7 loss: 0.22047603130340576\n",
      "epoch 8 loss: 0.19147467613220215\n",
      "epoch 9 loss: 0.14847178757190704\n",
      "epoch 10 loss: 0.19965608417987823\n",
      "epoch 11 loss: 0.2333751618862152\n",
      "epoch 12 loss: 0.18525879085063934\n",
      "epoch 13 loss: 0.1538124829530716\n",
      "epoch 14 loss: 0.16357411444187164\n",
      "epoch 15 loss: 0.15907882153987885\n",
      "epoch 16 loss: 0.15681606531143188\n",
      "epoch 17 loss: 0.13114191591739655\n",
      "epoch 18 loss: 0.13228973746299744\n",
      "epoch 19 loss: 0.15149720013141632\n",
      "epoch 20 loss: 0.14391490817070007\n",
      "epoch 21 loss: 0.1238107979297638\n",
      "epoch 22 loss: 0.12190153449773788\n",
      "epoch 23 loss: 0.13585606217384338\n",
      "epoch 24 loss: 0.12905871868133545\n",
      "epoch 25 loss: 0.1203712671995163\n",
      "epoch 26 loss: 0.09696286171674728\n",
      "epoch 27 loss: 0.14613769948482513\n",
      "epoch 28 loss: 0.13894009590148926\n",
      "epoch 29 loss: 0.10804864764213562\n",
      "epoch 30 loss: 0.10461971908807755\n",
      "29\n",
      "epoch 1 loss: 0.8906463980674744\n",
      "epoch 2 loss: 0.6082184910774231\n",
      "epoch 3 loss: 0.34475621581077576\n",
      "epoch 4 loss: 0.21058885753154755\n",
      "epoch 5 loss: 0.19522012770175934\n",
      "epoch 6 loss: 0.17179149389266968\n",
      "epoch 7 loss: 0.2025822401046753\n",
      "epoch 8 loss: 0.22983084619045258\n",
      "epoch 9 loss: 0.19143646955490112\n",
      "epoch 10 loss: 0.19660629332065582\n",
      "epoch 11 loss: 0.1843711882829666\n",
      "epoch 12 loss: 0.19188161194324493\n",
      "epoch 13 loss: 0.21271561086177826\n",
      "epoch 14 loss: 0.17557212710380554\n",
      "epoch 15 loss: 0.19141525030136108\n",
      "epoch 16 loss: 0.1787601113319397\n",
      "epoch 17 loss: 0.1519601047039032\n",
      "epoch 18 loss: 0.17217028141021729\n",
      "epoch 19 loss: 0.13723911345005035\n",
      "epoch 20 loss: 0.14828695356845856\n",
      "epoch 21 loss: 0.14245550334453583\n",
      "epoch 22 loss: 0.18798701465129852\n",
      "epoch 23 loss: 0.132181778550148\n",
      "epoch 24 loss: 0.1467425674200058\n",
      "epoch 25 loss: 0.11562834680080414\n",
      "epoch 26 loss: 0.15534529089927673\n",
      "epoch 27 loss: 0.16029590368270874\n",
      "epoch 28 loss: 0.14140771329402924\n",
      "epoch 29 loss: 0.12611328065395355\n",
      "epoch 30 loss: 0.12306026369333267\n",
      "30\n",
      "epoch 1 loss: 0.9796856641769409\n",
      "epoch 2 loss: 0.5165802836418152\n",
      "epoch 3 loss: 0.29812121391296387\n",
      "epoch 4 loss: 0.22022303938865662\n",
      "epoch 5 loss: 0.19194070994853973\n",
      "epoch 6 loss: 0.18658772110939026\n",
      "epoch 7 loss: 0.2258390486240387\n",
      "epoch 8 loss: 0.20652832090854645\n",
      "epoch 9 loss: 0.1580319106578827\n",
      "epoch 10 loss: 0.171341672539711\n",
      "epoch 11 loss: 0.19282099604606628\n",
      "epoch 12 loss: 0.17818652093410492\n",
      "epoch 13 loss: 0.19203992187976837\n",
      "epoch 14 loss: 0.15347658097743988\n",
      "epoch 15 loss: 0.2090793401002884\n",
      "epoch 16 loss: 0.1784915179014206\n",
      "epoch 17 loss: 0.1935005933046341\n",
      "epoch 18 loss: 0.1313825398683548\n",
      "epoch 19 loss: 0.1568184643983841\n",
      "epoch 20 loss: 0.14026273787021637\n",
      "epoch 21 loss: 0.1818460077047348\n",
      "epoch 22 loss: 0.2601911425590515\n",
      "epoch 23 loss: 0.2323479950428009\n",
      "epoch 24 loss: 0.15729454159736633\n",
      "epoch 25 loss: 0.15452980995178223\n",
      "epoch 26 loss: 0.15395447611808777\n",
      "epoch 27 loss: 0.17421257495880127\n",
      "epoch 28 loss: 0.1690356582403183\n",
      "epoch 29 loss: 0.1270851343870163\n",
      "epoch 30 loss: 0.14920969307422638\n",
      "31\n",
      "epoch 1 loss: 1.0338565111160278\n",
      "epoch 2 loss: 0.5460330843925476\n",
      "epoch 3 loss: 0.3769441843032837\n",
      "epoch 4 loss: 0.2854395806789398\n",
      "epoch 5 loss: 0.2753415107727051\n",
      "epoch 6 loss: 0.20156903564929962\n",
      "epoch 7 loss: 0.2375747114419937\n",
      "epoch 8 loss: 0.22730988264083862\n",
      "epoch 9 loss: 0.19552646577358246\n",
      "epoch 10 loss: 0.21518224477767944\n",
      "epoch 11 loss: 0.21379877626895905\n",
      "epoch 12 loss: 0.19916817545890808\n",
      "epoch 13 loss: 0.19928094744682312\n",
      "epoch 14 loss: 0.17613254487514496\n",
      "epoch 15 loss: 0.19163066148757935\n",
      "epoch 16 loss: 0.14699473977088928\n",
      "epoch 17 loss: 0.17687907814979553\n",
      "epoch 18 loss: 0.19526101648807526\n",
      "epoch 19 loss: 0.17679283022880554\n",
      "epoch 20 loss: 0.2093764841556549\n",
      "epoch 21 loss: 0.15138593316078186\n",
      "epoch 22 loss: 0.14377461373806\n",
      "epoch 23 loss: 0.16679862141609192\n",
      "epoch 24 loss: 0.14906054735183716\n",
      "epoch 25 loss: 0.16298101842403412\n",
      "epoch 26 loss: 0.17803995311260223\n",
      "epoch 27 loss: 0.2146163135766983\n",
      "epoch 28 loss: 0.18213728070259094\n",
      "epoch 29 loss: 0.1411062628030777\n",
      "epoch 30 loss: 0.1926460862159729\n",
      "32\n",
      "epoch 1 loss: 0.8382158875465393\n",
      "epoch 2 loss: 0.8788995146751404\n",
      "epoch 3 loss: 0.7504062056541443\n",
      "epoch 4 loss: 0.40332186222076416\n",
      "epoch 5 loss: 0.30834466218948364\n",
      "epoch 6 loss: 0.2142559438943863\n",
      "epoch 7 loss: 0.2176237404346466\n",
      "epoch 8 loss: 0.23182973265647888\n",
      "epoch 9 loss: 0.17918886244297028\n",
      "epoch 10 loss: 0.167746439576149\n",
      "epoch 11 loss: 0.18390750885009766\n",
      "epoch 12 loss: 0.204983651638031\n",
      "epoch 13 loss: 0.15798576176166534\n",
      "epoch 14 loss: 0.19101138412952423\n",
      "epoch 15 loss: 0.20341046154499054\n",
      "epoch 16 loss: 0.15038585662841797\n",
      "epoch 17 loss: 0.14505068957805634\n",
      "epoch 18 loss: 0.17564301192760468\n",
      "epoch 19 loss: 0.14348211884498596\n",
      "epoch 20 loss: 0.1431240439414978\n",
      "epoch 21 loss: 0.12281836569309235\n",
      "epoch 22 loss: 0.11071351170539856\n",
      "epoch 23 loss: 0.15051095187664032\n",
      "epoch 24 loss: 0.12164046615362167\n",
      "epoch 25 loss: 0.2490473985671997\n",
      "epoch 26 loss: 0.13164155185222626\n",
      "epoch 27 loss: 0.13933782279491425\n",
      "epoch 28 loss: 0.122266985476017\n",
      "epoch 29 loss: 0.12388357520103455\n",
      "epoch 30 loss: 0.13167303800582886\n",
      "33\n",
      "epoch 1 loss: 0.8647578358650208\n",
      "epoch 2 loss: 0.642816960811615\n",
      "epoch 3 loss: 0.4735199511051178\n",
      "epoch 4 loss: 0.3783677816390991\n",
      "epoch 5 loss: 0.2259121984243393\n",
      "epoch 6 loss: 0.21398769319057465\n",
      "epoch 7 loss: 0.16528838872909546\n",
      "epoch 8 loss: 0.17844291031360626\n",
      "epoch 9 loss: 0.13735906779766083\n",
      "epoch 10 loss: 0.14710211753845215\n",
      "epoch 11 loss: 0.18904833495616913\n",
      "epoch 12 loss: 0.15307195484638214\n",
      "epoch 13 loss: 0.17265348136425018\n",
      "epoch 14 loss: 0.14421242475509644\n",
      "epoch 15 loss: 0.18622931838035583\n",
      "epoch 16 loss: 0.2207837998867035\n",
      "epoch 17 loss: 0.19997279345989227\n",
      "epoch 18 loss: 0.21730361878871918\n",
      "epoch 19 loss: 0.24789811670780182\n",
      "epoch 20 loss: 0.19145256280899048\n",
      "epoch 21 loss: 0.17414379119873047\n",
      "epoch 22 loss: 0.16112904250621796\n",
      "epoch 23 loss: 0.17250627279281616\n",
      "epoch 24 loss: 0.15759329497814178\n",
      "epoch 25 loss: 0.1194051206111908\n",
      "epoch 26 loss: 0.11962663382291794\n",
      "epoch 27 loss: 0.13211263716220856\n",
      "epoch 28 loss: 0.1513986885547638\n",
      "epoch 29 loss: 0.19710083305835724\n",
      "epoch 30 loss: 0.13106046617031097\n",
      "34\n",
      "epoch 1 loss: 0.858372688293457\n",
      "epoch 2 loss: 0.5615196228027344\n",
      "epoch 3 loss: 0.6089498400688171\n",
      "epoch 4 loss: 0.3041197955608368\n",
      "epoch 5 loss: 0.27545201778411865\n",
      "epoch 6 loss: 0.2171020358800888\n",
      "epoch 7 loss: 0.1973423808813095\n",
      "epoch 8 loss: 0.19659225642681122\n",
      "epoch 9 loss: 0.1924058496952057\n",
      "epoch 10 loss: 0.21453943848609924\n",
      "epoch 11 loss: 0.17088370025157928\n",
      "epoch 12 loss: 0.20017191767692566\n",
      "epoch 13 loss: 0.17823854088783264\n",
      "epoch 14 loss: 0.1853175014257431\n",
      "epoch 15 loss: 0.17059093713760376\n",
      "epoch 16 loss: 0.17537106573581696\n",
      "epoch 17 loss: 0.17367973923683167\n",
      "epoch 18 loss: 0.16424323618412018\n",
      "epoch 19 loss: 0.1599985808134079\n",
      "epoch 20 loss: 0.16160227358341217\n",
      "epoch 21 loss: 0.18076260387897491\n",
      "epoch 22 loss: 0.16934263706207275\n",
      "epoch 23 loss: 0.16738535463809967\n",
      "epoch 24 loss: 0.20700949430465698\n",
      "epoch 25 loss: 0.14380957186222076\n",
      "epoch 26 loss: 0.1562482714653015\n",
      "epoch 27 loss: 0.11785534769296646\n",
      "epoch 28 loss: 0.10183697938919067\n",
      "epoch 29 loss: 0.1263916939496994\n",
      "epoch 30 loss: 0.10518638044595718\n",
      "35\n",
      "epoch 1 loss: 0.9561669826507568\n",
      "epoch 2 loss: 0.6445158123970032\n",
      "epoch 3 loss: 0.48606377840042114\n",
      "epoch 4 loss: 0.2882949113845825\n",
      "epoch 5 loss: 0.21641933917999268\n",
      "epoch 6 loss: 0.18852581083774567\n",
      "epoch 7 loss: 0.19206108152866364\n",
      "epoch 8 loss: 0.24977289140224457\n",
      "epoch 9 loss: 0.13691475987434387\n",
      "epoch 10 loss: 0.2317356914281845\n",
      "epoch 11 loss: 0.16002947092056274\n",
      "epoch 12 loss: 0.2335290014743805\n",
      "epoch 13 loss: 0.19216600060462952\n",
      "epoch 14 loss: 0.20982708036899567\n",
      "epoch 15 loss: 0.1722215712070465\n",
      "epoch 16 loss: 0.22141939401626587\n",
      "epoch 17 loss: 0.19250985980033875\n",
      "epoch 18 loss: 0.17816391587257385\n",
      "epoch 19 loss: 0.16122564673423767\n",
      "epoch 20 loss: 0.16036373376846313\n",
      "epoch 21 loss: 0.17086568474769592\n",
      "epoch 22 loss: 0.1685710847377777\n",
      "epoch 23 loss: 0.16923707723617554\n",
      "epoch 24 loss: 0.17445121705532074\n",
      "epoch 25 loss: 0.16272065043449402\n",
      "epoch 26 loss: 0.1353321671485901\n",
      "epoch 27 loss: 0.1348554939031601\n",
      "epoch 28 loss: 0.14384739100933075\n",
      "epoch 29 loss: 0.11197938770055771\n",
      "epoch 30 loss: 0.11022820323705673\n",
      "36\n",
      "epoch 1 loss: 0.9359480142593384\n",
      "epoch 2 loss: 0.5692324042320251\n",
      "epoch 3 loss: 0.40455514192581177\n",
      "epoch 4 loss: 0.2244029939174652\n",
      "epoch 5 loss: 0.1956312358379364\n",
      "epoch 6 loss: 0.1906178593635559\n",
      "epoch 7 loss: 0.22161751985549927\n",
      "epoch 8 loss: 0.22587217390537262\n",
      "epoch 9 loss: 0.19765710830688477\n",
      "epoch 10 loss: 0.16925768554210663\n",
      "epoch 11 loss: 0.15737831592559814\n",
      "epoch 12 loss: 0.18140175938606262\n",
      "epoch 13 loss: 0.18259204924106598\n",
      "epoch 14 loss: 0.24627305567264557\n",
      "epoch 15 loss: 0.1834050863981247\n",
      "epoch 16 loss: 0.15390406548976898\n",
      "epoch 17 loss: 0.19990907609462738\n",
      "epoch 18 loss: 0.1600019931793213\n",
      "epoch 19 loss: 0.15973873436450958\n",
      "epoch 20 loss: 0.15730129182338715\n",
      "epoch 21 loss: 0.15273982286453247\n",
      "epoch 22 loss: 0.13687670230865479\n",
      "epoch 23 loss: 0.1486901193857193\n",
      "epoch 24 loss: 0.14435440301895142\n",
      "epoch 25 loss: 0.11372862011194229\n",
      "epoch 26 loss: 0.10915641486644745\n",
      "epoch 27 loss: 0.1160864531993866\n",
      "epoch 28 loss: 0.13907866179943085\n",
      "epoch 29 loss: 0.11643736064434052\n",
      "epoch 30 loss: 0.1215801015496254\n",
      "37\n",
      "epoch 1 loss: 0.7109969854354858\n",
      "epoch 2 loss: 0.49491170048713684\n",
      "epoch 3 loss: 0.29959794878959656\n",
      "epoch 4 loss: 0.18699507415294647\n",
      "epoch 5 loss: 0.2085651010274887\n",
      "epoch 6 loss: 0.2132146656513214\n",
      "epoch 7 loss: 0.18365368247032166\n",
      "epoch 8 loss: 0.18847626447677612\n",
      "epoch 9 loss: 0.18829476833343506\n",
      "epoch 10 loss: 0.1719474047422409\n",
      "epoch 11 loss: 0.1574035882949829\n",
      "epoch 12 loss: 0.1892063170671463\n",
      "epoch 13 loss: 0.16245685517787933\n",
      "epoch 14 loss: 0.13965003192424774\n",
      "epoch 15 loss: 0.14683012664318085\n",
      "epoch 16 loss: 0.17702174186706543\n",
      "epoch 17 loss: 0.18342745304107666\n",
      "epoch 18 loss: 0.1525680273771286\n",
      "epoch 19 loss: 0.1564711034297943\n",
      "epoch 20 loss: 0.16985252499580383\n",
      "epoch 21 loss: 0.1435755491256714\n",
      "epoch 22 loss: 0.14869244396686554\n",
      "epoch 23 loss: 0.17184121906757355\n",
      "epoch 24 loss: 0.14887773990631104\n",
      "epoch 25 loss: 0.12341826409101486\n",
      "epoch 26 loss: 0.15277862548828125\n",
      "epoch 27 loss: 0.12495364993810654\n",
      "epoch 28 loss: 0.1471259444952011\n",
      "epoch 29 loss: 0.11266530305147171\n",
      "epoch 30 loss: 0.09039707481861115\n",
      "38\n",
      "epoch 1 loss: 0.8664848208427429\n",
      "epoch 2 loss: 0.8532174229621887\n",
      "epoch 3 loss: 0.5688874125480652\n",
      "epoch 4 loss: 0.3358924686908722\n",
      "epoch 5 loss: 0.19247904419898987\n",
      "epoch 6 loss: 0.2050458937883377\n",
      "epoch 7 loss: 0.22015492618083954\n",
      "epoch 8 loss: 0.197580024600029\n",
      "epoch 9 loss: 0.2213222235441208\n",
      "epoch 10 loss: 0.20884761214256287\n",
      "epoch 11 loss: 0.15787775814533234\n",
      "epoch 12 loss: 0.18505512177944183\n",
      "epoch 13 loss: 0.19835685193538666\n",
      "epoch 14 loss: 0.14793138206005096\n",
      "epoch 15 loss: 0.21815091371536255\n",
      "epoch 16 loss: 0.17217189073562622\n",
      "epoch 17 loss: 0.2699124217033386\n",
      "epoch 18 loss: 0.17117543518543243\n",
      "epoch 19 loss: 0.20526506006717682\n",
      "epoch 20 loss: 0.15586887300014496\n",
      "epoch 21 loss: 0.15185803174972534\n",
      "epoch 22 loss: 0.14190512895584106\n",
      "epoch 23 loss: 0.13266515731811523\n",
      "epoch 24 loss: 0.13636572659015656\n",
      "epoch 25 loss: 0.15992358326911926\n",
      "epoch 26 loss: 0.1387145072221756\n",
      "epoch 27 loss: 0.13693459331989288\n",
      "epoch 28 loss: 0.12471920996904373\n",
      "epoch 29 loss: 0.11271785944700241\n",
      "epoch 30 loss: 0.12536738812923431\n",
      "39\n",
      "epoch 1 loss: 0.865534245967865\n",
      "epoch 2 loss: 0.592622697353363\n",
      "epoch 3 loss: 0.34509873390197754\n",
      "epoch 4 loss: 0.22676591575145721\n",
      "epoch 5 loss: 0.24142986536026\n",
      "epoch 6 loss: 0.1937207132577896\n",
      "epoch 7 loss: 0.18475578725337982\n",
      "epoch 8 loss: 0.17011570930480957\n",
      "epoch 9 loss: 0.20650121569633484\n",
      "epoch 10 loss: 0.20848307013511658\n",
      "epoch 11 loss: 0.19835391640663147\n",
      "epoch 12 loss: 0.2010316401720047\n",
      "epoch 13 loss: 0.20565997064113617\n",
      "epoch 14 loss: 0.18262489140033722\n",
      "epoch 15 loss: 0.16567793488502502\n",
      "epoch 16 loss: 0.16859988868236542\n",
      "epoch 17 loss: 0.16616159677505493\n",
      "epoch 18 loss: 0.18066716194152832\n",
      "epoch 19 loss: 0.18618641793727875\n",
      "epoch 20 loss: 0.210866779088974\n",
      "epoch 21 loss: 0.18242408335208893\n",
      "epoch 22 loss: 0.13674791157245636\n",
      "epoch 23 loss: 0.1605108380317688\n",
      "epoch 24 loss: 0.18270039558410645\n",
      "epoch 25 loss: 0.1619512140750885\n",
      "epoch 26 loss: 0.17804041504859924\n",
      "epoch 27 loss: 0.16006602346897125\n",
      "epoch 28 loss: 0.15978026390075684\n",
      "epoch 29 loss: 0.13516661524772644\n",
      "epoch 30 loss: 0.13317115604877472\n",
      "40\n",
      "epoch 1 loss: 0.8667615056037903\n",
      "epoch 2 loss: 0.6474254727363586\n",
      "epoch 3 loss: 0.4999385178089142\n",
      "epoch 4 loss: 0.2895509898662567\n",
      "epoch 5 loss: 0.23729193210601807\n",
      "epoch 6 loss: 0.1871509850025177\n",
      "epoch 7 loss: 0.1788715273141861\n",
      "epoch 8 loss: 0.22941802442073822\n",
      "epoch 9 loss: 0.19822297990322113\n",
      "epoch 10 loss: 0.17242033779621124\n",
      "epoch 11 loss: 0.20047596096992493\n",
      "epoch 12 loss: 0.1892668604850769\n",
      "epoch 13 loss: 0.20264889299869537\n",
      "epoch 14 loss: 0.1852322667837143\n",
      "epoch 15 loss: 0.15751539170742035\n",
      "epoch 16 loss: 0.17754866182804108\n",
      "epoch 17 loss: 0.177639901638031\n",
      "epoch 18 loss: 0.13964895904064178\n",
      "epoch 19 loss: 0.1583111584186554\n",
      "epoch 20 loss: 0.1757759302854538\n",
      "epoch 21 loss: 0.1342514306306839\n",
      "epoch 22 loss: 0.17218272387981415\n",
      "epoch 23 loss: 0.15069672465324402\n",
      "epoch 24 loss: 0.12741480767726898\n",
      "epoch 25 loss: 0.1279444694519043\n",
      "epoch 26 loss: 0.10271260142326355\n",
      "epoch 27 loss: 0.10398432612419128\n",
      "epoch 28 loss: 0.10912614315748215\n",
      "epoch 29 loss: 0.13711239397525787\n",
      "epoch 30 loss: 0.11009935289621353\n",
      "41\n",
      "epoch 1 loss: 0.7736138701438904\n",
      "epoch 2 loss: 0.8643423914909363\n",
      "epoch 3 loss: 0.6480336785316467\n",
      "epoch 4 loss: 0.26025843620300293\n",
      "epoch 5 loss: 0.22818796336650848\n",
      "epoch 6 loss: 0.21465590596199036\n",
      "epoch 7 loss: 0.21157954633235931\n",
      "epoch 8 loss: 0.23820385336875916\n",
      "epoch 9 loss: 0.18493777513504028\n",
      "epoch 10 loss: 0.15287509560585022\n",
      "epoch 11 loss: 0.19414843618869781\n",
      "epoch 12 loss: 0.18459434807300568\n",
      "epoch 13 loss: 0.19613270461559296\n",
      "epoch 14 loss: 0.19569545984268188\n",
      "epoch 15 loss: 0.18843330442905426\n",
      "epoch 16 loss: 0.1670694351196289\n",
      "epoch 17 loss: 0.12786433100700378\n",
      "epoch 18 loss: 0.17806760966777802\n",
      "epoch 19 loss: 0.20326997339725494\n",
      "epoch 20 loss: 0.17117910087108612\n",
      "epoch 21 loss: 0.17729520797729492\n",
      "epoch 22 loss: 0.1292545050382614\n",
      "epoch 23 loss: 0.12511368095874786\n",
      "epoch 24 loss: 0.18405486643314362\n",
      "epoch 25 loss: 0.1320243924856186\n",
      "epoch 26 loss: 0.1638369858264923\n",
      "epoch 27 loss: 0.17881788313388824\n",
      "epoch 28 loss: 0.14521031081676483\n",
      "epoch 29 loss: 0.14656497538089752\n",
      "epoch 30 loss: 0.14790043234825134\n",
      "42\n",
      "epoch 1 loss: 0.8293998837471008\n",
      "epoch 2 loss: 0.5271989703178406\n",
      "epoch 3 loss: 0.4221753478050232\n",
      "epoch 4 loss: 0.2728804349899292\n",
      "epoch 5 loss: 0.2331639677286148\n",
      "epoch 6 loss: 0.17332732677459717\n",
      "epoch 7 loss: 0.2085760235786438\n",
      "epoch 8 loss: 0.17804792523384094\n",
      "epoch 9 loss: 0.18707090616226196\n",
      "epoch 10 loss: 0.20604395866394043\n",
      "epoch 11 loss: 0.1693601757287979\n",
      "epoch 12 loss: 0.18222063779830933\n",
      "epoch 13 loss: 0.18101611733436584\n",
      "epoch 14 loss: 0.21290384232997894\n",
      "epoch 15 loss: 0.1875142604112625\n",
      "epoch 16 loss: 0.19673548638820648\n",
      "epoch 17 loss: 0.16778065264225006\n",
      "epoch 18 loss: 0.1611916720867157\n",
      "epoch 19 loss: 0.14713257551193237\n",
      "epoch 20 loss: 0.13552722334861755\n",
      "epoch 21 loss: 0.15927521884441376\n",
      "epoch 22 loss: 0.18163788318634033\n",
      "epoch 23 loss: 0.16415199637413025\n",
      "epoch 24 loss: 0.11101491749286652\n",
      "epoch 25 loss: 0.1480318009853363\n",
      "epoch 26 loss: 0.1289883404970169\n",
      "epoch 27 loss: 0.1390816867351532\n",
      "epoch 28 loss: 0.11848999559879303\n",
      "epoch 29 loss: 0.11761142313480377\n",
      "epoch 30 loss: 0.11956881731748581\n",
      "43\n",
      "epoch 1 loss: 0.8060888051986694\n",
      "epoch 2 loss: 0.7411251664161682\n",
      "epoch 3 loss: 0.8494983911514282\n",
      "epoch 4 loss: 0.6147049069404602\n",
      "epoch 5 loss: 0.27506348490715027\n",
      "epoch 6 loss: 0.22090820968151093\n",
      "epoch 7 loss: 0.20711222290992737\n",
      "epoch 8 loss: 0.20293106138706207\n",
      "epoch 9 loss: 0.18586410582065582\n",
      "epoch 10 loss: 0.1854414939880371\n",
      "epoch 11 loss: 0.20370030403137207\n",
      "epoch 12 loss: 0.22616608440876007\n",
      "epoch 13 loss: 0.20743702352046967\n",
      "epoch 14 loss: 0.15432003140449524\n",
      "epoch 15 loss: 0.19394370913505554\n",
      "epoch 16 loss: 0.11998435854911804\n",
      "epoch 17 loss: 0.2666008770465851\n",
      "epoch 18 loss: 0.17012497782707214\n",
      "epoch 19 loss: 0.16878928244113922\n",
      "epoch 20 loss: 0.1670336127281189\n",
      "epoch 21 loss: 0.13766859471797943\n",
      "epoch 22 loss: 0.17511393129825592\n",
      "epoch 23 loss: 0.13186511397361755\n",
      "epoch 24 loss: 0.15531016886234283\n",
      "epoch 25 loss: 0.11462750285863876\n",
      "epoch 26 loss: 0.13938480615615845\n",
      "epoch 27 loss: 0.12268213927745819\n",
      "epoch 28 loss: 0.14515794813632965\n",
      "epoch 29 loss: 0.15070420503616333\n",
      "epoch 30 loss: 0.11445918679237366\n",
      "44\n",
      "epoch 1 loss: 0.6994957327842712\n",
      "epoch 2 loss: 0.43036019802093506\n",
      "epoch 3 loss: 0.3226858675479889\n",
      "epoch 4 loss: 0.2741846740245819\n",
      "epoch 5 loss: 0.23902761936187744\n",
      "epoch 6 loss: 0.21807390451431274\n",
      "epoch 7 loss: 0.23324501514434814\n",
      "epoch 8 loss: 0.19441093504428864\n",
      "epoch 9 loss: 0.20177379250526428\n",
      "epoch 10 loss: 0.21951577067375183\n",
      "epoch 11 loss: 0.21944564580917358\n",
      "epoch 12 loss: 0.20559187233448029\n",
      "epoch 13 loss: 0.20038703083992004\n",
      "epoch 14 loss: 0.16970820724964142\n",
      "epoch 15 loss: 0.20636451244354248\n",
      "epoch 16 loss: 0.17970894277095795\n",
      "epoch 17 loss: 0.21451488137245178\n",
      "epoch 18 loss: 0.15973655879497528\n",
      "epoch 19 loss: 0.209677591919899\n",
      "epoch 20 loss: 0.15482543408870697\n",
      "epoch 21 loss: 0.20724476873874664\n",
      "epoch 22 loss: 0.1566370129585266\n",
      "epoch 23 loss: 0.14068229496479034\n",
      "epoch 24 loss: 0.1586785763502121\n",
      "epoch 25 loss: 0.13575518131256104\n",
      "epoch 26 loss: 0.18879127502441406\n",
      "epoch 27 loss: 0.18189892172813416\n",
      "epoch 28 loss: 0.14141812920570374\n",
      "epoch 29 loss: 0.14454308152198792\n",
      "epoch 30 loss: 0.1304354965686798\n",
      "45\n",
      "epoch 1 loss: 0.8911322355270386\n",
      "epoch 2 loss: 0.49836036562919617\n",
      "epoch 3 loss: 0.3611691892147064\n",
      "epoch 4 loss: 0.26943784952163696\n",
      "epoch 5 loss: 0.19661256670951843\n",
      "epoch 6 loss: 0.18986672163009644\n",
      "epoch 7 loss: 0.18158729374408722\n",
      "epoch 8 loss: 0.11013749241828918\n",
      "epoch 9 loss: 0.19069130718708038\n",
      "epoch 10 loss: 0.20216570794582367\n",
      "epoch 11 loss: 0.1794576197862625\n",
      "epoch 12 loss: 0.25428664684295654\n",
      "epoch 13 loss: 0.18964186310768127\n",
      "epoch 14 loss: 0.1600043922662735\n",
      "epoch 15 loss: 0.16254223883152008\n",
      "epoch 16 loss: 0.19016335904598236\n",
      "epoch 17 loss: 0.19524866342544556\n",
      "epoch 18 loss: 0.16598659753799438\n",
      "epoch 19 loss: 0.19129446148872375\n",
      "epoch 20 loss: 0.20533941686153412\n",
      "epoch 21 loss: 0.1263289600610733\n",
      "epoch 22 loss: 0.15587951242923737\n",
      "epoch 23 loss: 0.13075146079063416\n",
      "epoch 24 loss: 0.155302956700325\n",
      "epoch 25 loss: 0.1392492800951004\n",
      "epoch 26 loss: 0.13210588693618774\n",
      "epoch 27 loss: 0.13981543481349945\n",
      "epoch 28 loss: 0.10308945924043655\n",
      "epoch 29 loss: 0.1376916766166687\n",
      "epoch 30 loss: 0.13559405505657196\n",
      "46\n",
      "epoch 1 loss: 0.8881104588508606\n",
      "epoch 2 loss: 1.0452381372451782\n",
      "epoch 3 loss: 0.5440923571586609\n",
      "epoch 4 loss: 0.33242684602737427\n",
      "epoch 5 loss: 0.20739716291427612\n",
      "epoch 6 loss: 0.1821926087141037\n",
      "epoch 7 loss: 0.20730283856391907\n",
      "epoch 8 loss: 0.22277390956878662\n",
      "epoch 9 loss: 0.19482456147670746\n",
      "epoch 10 loss: 0.1995142102241516\n",
      "epoch 11 loss: 0.1697913408279419\n",
      "epoch 12 loss: 0.19755421578884125\n",
      "epoch 13 loss: 0.2151116281747818\n",
      "epoch 14 loss: 0.16824078559875488\n",
      "epoch 15 loss: 0.20531553030014038\n",
      "epoch 16 loss: 0.19727668166160583\n",
      "epoch 17 loss: 0.1953851878643036\n",
      "epoch 18 loss: 0.1596926748752594\n",
      "epoch 19 loss: 0.22252322733402252\n",
      "epoch 20 loss: 0.1417309045791626\n",
      "epoch 21 loss: 0.16000251471996307\n",
      "epoch 22 loss: 0.13267594575881958\n",
      "epoch 23 loss: 0.1583189070224762\n",
      "epoch 24 loss: 0.15736588835716248\n",
      "epoch 25 loss: 0.15514321625232697\n",
      "epoch 26 loss: 0.13776655495166779\n",
      "epoch 27 loss: 0.1679048240184784\n",
      "epoch 28 loss: 0.17293301224708557\n",
      "epoch 29 loss: 0.1771814078092575\n",
      "epoch 30 loss: 0.161225363612175\n",
      "47\n",
      "epoch 1 loss: 0.8079879283905029\n",
      "epoch 2 loss: 0.6620791554450989\n",
      "epoch 3 loss: 0.6639518737792969\n",
      "epoch 4 loss: 0.47782814502716064\n",
      "epoch 5 loss: 0.3890012204647064\n",
      "epoch 6 loss: 0.2310444861650467\n",
      "epoch 7 loss: 0.2331044226884842\n",
      "epoch 8 loss: 0.18232324719429016\n",
      "epoch 9 loss: 0.22350908815860748\n",
      "epoch 10 loss: 0.17431478202342987\n",
      "epoch 11 loss: 0.1690172553062439\n",
      "epoch 12 loss: 0.19538085162639618\n",
      "epoch 13 loss: 0.171007439494133\n",
      "epoch 14 loss: 0.21273329854011536\n",
      "epoch 15 loss: 0.17595885694026947\n",
      "epoch 16 loss: 0.17328961193561554\n",
      "epoch 17 loss: 0.11663243174552917\n",
      "epoch 18 loss: 0.15793371200561523\n",
      "epoch 19 loss: 0.14644618332386017\n",
      "epoch 20 loss: 0.1345129758119583\n",
      "epoch 21 loss: 0.13377176225185394\n",
      "epoch 22 loss: 0.10302267223596573\n",
      "epoch 23 loss: 0.11425510793924332\n",
      "epoch 24 loss: 0.13097542524337769\n",
      "epoch 25 loss: 0.1700337529182434\n",
      "epoch 26 loss: 0.17813222110271454\n",
      "epoch 27 loss: 0.11294647306203842\n",
      "epoch 28 loss: 0.1470664143562317\n",
      "epoch 29 loss: 0.1366676539182663\n",
      "epoch 30 loss: 0.13249294459819794\n",
      "48\n",
      "epoch 1 loss: 0.9576265215873718\n",
      "epoch 2 loss: 0.5526990294456482\n",
      "epoch 3 loss: 0.34114962816238403\n",
      "epoch 4 loss: 0.25765109062194824\n",
      "epoch 5 loss: 0.23928166925907135\n",
      "epoch 6 loss: 0.2305331975221634\n",
      "epoch 7 loss: 0.22501128911972046\n",
      "epoch 8 loss: 0.21072524785995483\n",
      "epoch 9 loss: 0.17822130024433136\n",
      "epoch 10 loss: 0.19161754846572876\n",
      "epoch 11 loss: 0.1798904836177826\n",
      "epoch 12 loss: 0.18485070765018463\n",
      "epoch 13 loss: 0.16470125317573547\n",
      "epoch 14 loss: 0.18390759825706482\n",
      "epoch 15 loss: 0.1569642424583435\n",
      "epoch 16 loss: 0.1512196958065033\n",
      "epoch 17 loss: 0.1616603136062622\n",
      "epoch 18 loss: 0.16230617463588715\n",
      "epoch 19 loss: 0.20250801742076874\n",
      "epoch 20 loss: 0.13542048633098602\n",
      "epoch 21 loss: 0.13819514214992523\n",
      "epoch 22 loss: 0.1229795441031456\n",
      "epoch 23 loss: 0.14772669970989227\n",
      "epoch 24 loss: 0.16192473471164703\n",
      "epoch 25 loss: 0.11439406126737595\n",
      "epoch 26 loss: 0.11172541230916977\n",
      "epoch 27 loss: 0.12923409044742584\n",
      "epoch 28 loss: 0.14182616770267487\n",
      "epoch 29 loss: 0.1211184486746788\n",
      "epoch 30 loss: 0.11976766586303711\n",
      "49\n",
      "epoch 1 loss: 0.8379625082015991\n",
      "epoch 2 loss: 0.6635864973068237\n",
      "epoch 3 loss: 0.3103073537349701\n",
      "epoch 4 loss: 0.20612236857414246\n",
      "epoch 5 loss: 0.2106003761291504\n",
      "epoch 6 loss: 0.16531667113304138\n",
      "epoch 7 loss: 0.18044570088386536\n",
      "epoch 8 loss: 0.19324342906475067\n",
      "epoch 9 loss: 0.20527377724647522\n",
      "epoch 10 loss: 0.14702048897743225\n",
      "epoch 11 loss: 0.19026148319244385\n",
      "epoch 12 loss: 0.20112274587154388\n",
      "epoch 13 loss: 0.17618001997470856\n",
      "epoch 14 loss: 0.15503615140914917\n",
      "epoch 15 loss: 0.1451398879289627\n",
      "epoch 16 loss: 0.15549632906913757\n",
      "epoch 17 loss: 0.17967770993709564\n",
      "epoch 18 loss: 0.13909253478050232\n",
      "epoch 19 loss: 0.13924765586853027\n",
      "epoch 20 loss: 0.12659713625907898\n",
      "epoch 21 loss: 0.11742063611745834\n",
      "epoch 22 loss: 0.14608915150165558\n",
      "epoch 23 loss: 0.13754960894584656\n",
      "epoch 24 loss: 0.1298578977584839\n",
      "epoch 25 loss: 0.157969668507576\n",
      "epoch 26 loss: 0.10181568562984467\n",
      "epoch 27 loss: 0.12480312585830688\n",
      "epoch 28 loss: 0.14559109508991241\n",
      "epoch 29 loss: 0.10121321678161621\n",
      "epoch 30 loss: 0.15580105781555176\n",
      "50\n",
      "epoch 1 loss: 1.044193148612976\n",
      "epoch 2 loss: 0.5242686867713928\n",
      "epoch 3 loss: 0.7949420809745789\n",
      "epoch 4 loss: 0.43730753660202026\n",
      "epoch 5 loss: 0.2679668068885803\n",
      "epoch 6 loss: 0.21784551441669464\n",
      "epoch 7 loss: 0.21455803513526917\n",
      "epoch 8 loss: 0.19094204902648926\n",
      "epoch 9 loss: 0.21703410148620605\n",
      "epoch 10 loss: 0.17717067897319794\n",
      "epoch 11 loss: 0.18871235847473145\n",
      "epoch 12 loss: 0.1394760012626648\n",
      "epoch 13 loss: 0.1715053766965866\n",
      "epoch 14 loss: 0.2102598249912262\n",
      "epoch 15 loss: 0.1719638556241989\n",
      "epoch 16 loss: 0.19936257600784302\n",
      "epoch 17 loss: 0.16258041560649872\n",
      "epoch 18 loss: 0.22621051967144012\n",
      "epoch 19 loss: 0.18948142230510712\n",
      "epoch 20 loss: 0.17890609800815582\n",
      "epoch 21 loss: 0.20153570175170898\n",
      "epoch 22 loss: 0.14963169395923615\n",
      "epoch 23 loss: 0.1802355796098709\n",
      "epoch 24 loss: 0.15475206077098846\n",
      "epoch 25 loss: 0.1522020697593689\n",
      "epoch 26 loss: 0.1587645411491394\n",
      "epoch 27 loss: 0.33543023467063904\n",
      "epoch 28 loss: 0.13315510749816895\n",
      "epoch 29 loss: 0.11873213201761246\n",
      "epoch 30 loss: 0.13298916816711426\n",
      "51\n",
      "epoch 1 loss: 0.9853506088256836\n",
      "epoch 2 loss: 0.4830670654773712\n",
      "epoch 3 loss: 0.28282520174980164\n",
      "epoch 4 loss: 0.2621845006942749\n",
      "epoch 5 loss: 0.1910526603460312\n",
      "epoch 6 loss: 0.3165591359138489\n",
      "epoch 7 loss: 0.1802978664636612\n",
      "epoch 8 loss: 0.19063438475131989\n",
      "epoch 9 loss: 0.19352644681930542\n",
      "epoch 10 loss: 0.18387511372566223\n",
      "epoch 11 loss: 0.19573906064033508\n",
      "epoch 12 loss: 0.18494266271591187\n",
      "epoch 13 loss: 0.19934962689876556\n",
      "epoch 14 loss: 0.16889145970344543\n",
      "epoch 15 loss: 0.15889988839626312\n",
      "epoch 16 loss: 0.20829874277114868\n",
      "epoch 17 loss: 0.1471966952085495\n",
      "epoch 18 loss: 0.1763250231742859\n",
      "epoch 19 loss: 0.14564131200313568\n",
      "epoch 20 loss: 0.1694752424955368\n",
      "epoch 21 loss: 0.18865174055099487\n",
      "epoch 22 loss: 0.11375240236520767\n",
      "epoch 23 loss: 0.171678364276886\n",
      "epoch 24 loss: 0.12108929455280304\n",
      "epoch 25 loss: 0.1430702656507492\n",
      "epoch 26 loss: 0.1315111666917801\n",
      "epoch 27 loss: 0.13348399102687836\n",
      "epoch 28 loss: 0.1328304409980774\n",
      "epoch 29 loss: 0.10411088913679123\n",
      "epoch 30 loss: 0.11342506110668182\n",
      "52\n",
      "epoch 1 loss: 0.7063688039779663\n",
      "epoch 2 loss: 0.5902518033981323\n",
      "epoch 3 loss: 0.3168608844280243\n",
      "epoch 4 loss: 0.20723995566368103\n",
      "epoch 5 loss: 0.1649983823299408\n",
      "epoch 6 loss: 0.23852525651454926\n",
      "epoch 7 loss: 0.21631860733032227\n",
      "epoch 8 loss: 0.15544314682483673\n",
      "epoch 9 loss: 0.17095531523227692\n",
      "epoch 10 loss: 0.22140155732631683\n",
      "epoch 11 loss: 0.17592619359493256\n",
      "epoch 12 loss: 0.20066383481025696\n",
      "epoch 13 loss: 0.1992613524198532\n",
      "epoch 14 loss: 0.18766102194786072\n",
      "epoch 15 loss: 0.19845670461654663\n",
      "epoch 16 loss: 0.17265236377716064\n",
      "epoch 17 loss: 0.18890312314033508\n",
      "epoch 18 loss: 0.12362395226955414\n",
      "epoch 19 loss: 0.1662614345550537\n",
      "epoch 20 loss: 0.15742148458957672\n",
      "epoch 21 loss: 0.1735922247171402\n",
      "epoch 22 loss: 0.14868810772895813\n",
      "epoch 23 loss: 0.143116757273674\n",
      "epoch 24 loss: 0.15153010189533234\n",
      "epoch 25 loss: 0.14833632111549377\n",
      "epoch 26 loss: 0.1795067936182022\n",
      "epoch 27 loss: 0.1905936598777771\n",
      "epoch 28 loss: 0.12211278080940247\n",
      "epoch 29 loss: 0.1600160300731659\n",
      "epoch 30 loss: 0.14794553816318512\n",
      "53\n",
      "epoch 1 loss: 0.7127392292022705\n",
      "epoch 2 loss: 0.6231638193130493\n",
      "epoch 3 loss: 0.41462746262550354\n",
      "epoch 4 loss: 0.24634477496147156\n",
      "epoch 5 loss: 0.19845466315746307\n",
      "epoch 6 loss: 0.21930094063282013\n",
      "epoch 7 loss: 0.21880538761615753\n",
      "epoch 8 loss: 0.19872604310512543\n",
      "epoch 9 loss: 0.16388073563575745\n",
      "epoch 10 loss: 0.1870999038219452\n",
      "epoch 11 loss: 0.16331495344638824\n",
      "epoch 12 loss: 0.2010881006717682\n",
      "epoch 13 loss: 0.17725129425525665\n",
      "epoch 14 loss: 0.1807902455329895\n",
      "epoch 15 loss: 0.21018975973129272\n",
      "epoch 16 loss: 0.1597042828798294\n",
      "epoch 17 loss: 0.17078052461147308\n",
      "epoch 18 loss: 0.1944223940372467\n",
      "epoch 19 loss: 0.18020649254322052\n",
      "epoch 20 loss: 0.1879865676164627\n",
      "epoch 21 loss: 0.13362741470336914\n",
      "epoch 22 loss: 0.14611490070819855\n",
      "epoch 23 loss: 0.1342737078666687\n",
      "epoch 24 loss: 0.16281403601169586\n",
      "epoch 25 loss: 0.11106682568788528\n",
      "epoch 26 loss: 0.13203373551368713\n",
      "epoch 27 loss: 0.15686514973640442\n",
      "epoch 28 loss: 0.11926805973052979\n",
      "epoch 29 loss: 0.12622976303100586\n",
      "epoch 30 loss: 0.1455143392086029\n",
      "54\n",
      "epoch 1 loss: 0.9959810376167297\n",
      "epoch 2 loss: 0.6188517808914185\n",
      "epoch 3 loss: 0.7238253951072693\n",
      "epoch 4 loss: 0.37712764739990234\n",
      "epoch 5 loss: 0.2563106119632721\n",
      "epoch 6 loss: 0.207359179854393\n",
      "epoch 7 loss: 0.16165857017040253\n",
      "epoch 8 loss: 0.20323695242404938\n",
      "epoch 9 loss: 0.16568158566951752\n",
      "epoch 10 loss: 0.19999919831752777\n",
      "epoch 11 loss: 0.17529304325580597\n",
      "epoch 12 loss: 0.19040457904338837\n",
      "epoch 13 loss: 0.19138185679912567\n",
      "epoch 14 loss: 0.2478799670934677\n",
      "epoch 15 loss: 0.17036233842372894\n",
      "epoch 16 loss: 0.18171368539333344\n",
      "epoch 17 loss: 0.13275153934955597\n",
      "epoch 18 loss: 0.18734751641750336\n",
      "epoch 19 loss: 0.1394750028848648\n",
      "epoch 20 loss: 0.12702645361423492\n",
      "epoch 21 loss: 0.14734818041324615\n",
      "epoch 22 loss: 0.1362820267677307\n",
      "epoch 23 loss: 0.13198216259479523\n",
      "epoch 24 loss: 0.148231640458107\n",
      "epoch 25 loss: 0.14428094029426575\n",
      "epoch 26 loss: 0.09778641164302826\n",
      "epoch 27 loss: 0.12706832587718964\n",
      "epoch 28 loss: 0.13352800905704498\n",
      "epoch 29 loss: 0.16628466546535492\n",
      "epoch 30 loss: 0.11750771105289459\n",
      "55\n",
      "epoch 1 loss: 1.0197062492370605\n",
      "epoch 2 loss: 0.8197731971740723\n",
      "epoch 3 loss: 0.6476226449012756\n",
      "epoch 4 loss: 0.3978593349456787\n",
      "epoch 5 loss: 0.2099546194076538\n",
      "epoch 6 loss: 0.20023488998413086\n",
      "epoch 7 loss: 0.1945970505475998\n",
      "epoch 8 loss: 0.19163468480110168\n",
      "epoch 9 loss: 0.1888357251882553\n",
      "epoch 10 loss: 0.26467442512512207\n",
      "epoch 11 loss: 0.1316281110048294\n",
      "epoch 12 loss: 0.20043601095676422\n",
      "epoch 13 loss: 0.1475350558757782\n",
      "epoch 14 loss: 0.18077585101127625\n",
      "epoch 15 loss: 0.1464068740606308\n",
      "epoch 16 loss: 0.16985546052455902\n",
      "epoch 17 loss: 0.15738150477409363\n",
      "epoch 18 loss: 0.16005492210388184\n",
      "epoch 19 loss: 0.1808740198612213\n",
      "epoch 20 loss: 0.14143796265125275\n",
      "epoch 21 loss: 0.13073818385601044\n",
      "epoch 22 loss: 0.15100586414337158\n",
      "epoch 23 loss: 0.1340722143650055\n",
      "epoch 24 loss: 0.13101518154144287\n",
      "epoch 25 loss: 0.14750485122203827\n",
      "epoch 26 loss: 0.10780999064445496\n",
      "epoch 27 loss: 0.128152996301651\n",
      "epoch 28 loss: 0.09012226015329361\n",
      "epoch 29 loss: 0.14608263969421387\n",
      "epoch 30 loss: 0.13215504586696625\n",
      "56\n",
      "epoch 1 loss: 0.7671672701835632\n",
      "epoch 2 loss: 0.5097429156303406\n",
      "epoch 3 loss: 0.2812914252281189\n",
      "epoch 4 loss: 0.2157772332429886\n",
      "epoch 5 loss: 0.2167074829339981\n",
      "epoch 6 loss: 0.18057003617286682\n",
      "epoch 7 loss: 0.16157257556915283\n",
      "epoch 8 loss: 0.19597932696342468\n",
      "epoch 9 loss: 0.14852537214756012\n",
      "epoch 10 loss: 0.1823730319738388\n",
      "epoch 11 loss: 0.1666230410337448\n",
      "epoch 12 loss: 0.1943541169166565\n",
      "epoch 13 loss: 0.16828720271587372\n",
      "epoch 14 loss: 0.18853653967380524\n",
      "epoch 15 loss: 0.16496986150741577\n",
      "epoch 16 loss: 0.16576792299747467\n",
      "epoch 17 loss: 0.130239337682724\n",
      "epoch 18 loss: 0.11587641388177872\n",
      "epoch 19 loss: 0.23563075065612793\n",
      "epoch 20 loss: 0.16124577820301056\n",
      "epoch 21 loss: 0.16008014976978302\n",
      "epoch 22 loss: 0.11131411790847778\n",
      "epoch 23 loss: 0.11105778813362122\n",
      "epoch 24 loss: 0.15490761399269104\n",
      "epoch 25 loss: 0.13336434960365295\n",
      "epoch 26 loss: 0.13292597234249115\n",
      "epoch 27 loss: 0.09580705314874649\n",
      "epoch 28 loss: 0.16876336932182312\n",
      "epoch 29 loss: 0.11408959329128265\n",
      "epoch 30 loss: 0.12798795104026794\n",
      "57\n",
      "epoch 1 loss: 0.8142209053039551\n",
      "epoch 2 loss: 0.8370819687843323\n",
      "epoch 3 loss: 0.5634310841560364\n",
      "epoch 4 loss: 0.39438396692276\n",
      "epoch 5 loss: 0.23238123953342438\n",
      "epoch 6 loss: 0.23720520734786987\n",
      "epoch 7 loss: 0.20159445703029633\n",
      "epoch 8 loss: 0.14625243842601776\n",
      "epoch 9 loss: 0.2082681655883789\n",
      "epoch 10 loss: 0.1891583651304245\n",
      "epoch 11 loss: 0.1773272305727005\n",
      "epoch 12 loss: 0.204420804977417\n",
      "epoch 13 loss: 0.15145520865917206\n",
      "epoch 14 loss: 0.19603730738162994\n",
      "epoch 15 loss: 0.1839357167482376\n",
      "epoch 16 loss: 0.20461225509643555\n",
      "epoch 17 loss: 0.1401495486497879\n",
      "epoch 18 loss: 0.15030482411384583\n",
      "epoch 19 loss: 0.1156737208366394\n",
      "epoch 20 loss: 0.13008342683315277\n",
      "epoch 21 loss: 0.11492007970809937\n",
      "epoch 22 loss: 0.15489013493061066\n",
      "epoch 23 loss: 0.12804631888866425\n",
      "epoch 24 loss: 0.13438548147678375\n",
      "epoch 25 loss: 0.1209476962685585\n",
      "epoch 26 loss: 0.13393567502498627\n",
      "epoch 27 loss: 0.12584367394447327\n",
      "epoch 28 loss: 0.12385768443346024\n",
      "epoch 29 loss: 0.12164894491434097\n",
      "epoch 30 loss: 0.13262903690338135\n",
      "58\n",
      "epoch 1 loss: 0.7550362944602966\n",
      "epoch 2 loss: 0.8479039669036865\n",
      "epoch 3 loss: 0.6503844857215881\n",
      "epoch 4 loss: 0.33004871010780334\n",
      "epoch 5 loss: 0.2154385894536972\n",
      "epoch 6 loss: 0.22322648763656616\n",
      "epoch 7 loss: 0.17106665670871735\n",
      "epoch 8 loss: 0.16726969182491302\n",
      "epoch 9 loss: 0.24473808705806732\n",
      "epoch 10 loss: 0.21404626965522766\n",
      "epoch 11 loss: 0.18330182135105133\n",
      "epoch 12 loss: 0.1848183274269104\n",
      "epoch 13 loss: 0.20605112612247467\n",
      "epoch 14 loss: 0.19703027606010437\n",
      "epoch 15 loss: 0.16591264307498932\n",
      "epoch 16 loss: 0.22264687716960907\n",
      "epoch 17 loss: 0.1477840691804886\n",
      "epoch 18 loss: 0.18658877909183502\n",
      "epoch 19 loss: 0.1813489943742752\n",
      "epoch 20 loss: 0.1355322301387787\n",
      "epoch 21 loss: 0.14413876831531525\n",
      "epoch 22 loss: 0.14683595299720764\n",
      "epoch 23 loss: 0.18674711883068085\n",
      "epoch 24 loss: 0.19432416558265686\n",
      "epoch 25 loss: 0.1080162525177002\n",
      "epoch 26 loss: 0.12098478525876999\n",
      "epoch 27 loss: 0.12598639726638794\n",
      "epoch 28 loss: 0.1414998471736908\n",
      "epoch 29 loss: 0.12374570220708847\n",
      "epoch 30 loss: 0.13680486381053925\n",
      "59\n",
      "epoch 1 loss: 0.8883044719696045\n",
      "epoch 2 loss: 0.8615938425064087\n",
      "epoch 3 loss: 0.4129507541656494\n",
      "epoch 4 loss: 0.27044928073883057\n",
      "epoch 5 loss: 0.1950514316558838\n",
      "epoch 6 loss: 0.18032383918762207\n",
      "epoch 7 loss: 0.19718356430530548\n",
      "epoch 8 loss: 0.20634159445762634\n",
      "epoch 9 loss: 0.16987262666225433\n",
      "epoch 10 loss: 0.20179225504398346\n",
      "epoch 11 loss: 0.19129246473312378\n",
      "epoch 12 loss: 0.16813695430755615\n",
      "epoch 13 loss: 0.23632937669754028\n",
      "epoch 14 loss: 0.15917730331420898\n",
      "epoch 15 loss: 0.17397627234458923\n",
      "epoch 16 loss: 0.1430143564939499\n",
      "epoch 17 loss: 0.18067476153373718\n",
      "epoch 18 loss: 0.12849126756191254\n",
      "epoch 19 loss: 0.1514260470867157\n",
      "epoch 20 loss: 0.11751297861337662\n",
      "epoch 21 loss: 0.13718199729919434\n",
      "epoch 22 loss: 0.1415056586265564\n",
      "epoch 23 loss: 0.1910696178674698\n",
      "epoch 24 loss: 0.0955747738480568\n",
      "epoch 25 loss: 0.14053450524806976\n",
      "epoch 26 loss: 0.102137990295887\n",
      "epoch 27 loss: 0.11960869282484055\n",
      "epoch 28 loss: 0.10334635525941849\n",
      "epoch 29 loss: 0.1270948201417923\n",
      "epoch 30 loss: 0.14736177027225494\n",
      "60\n",
      "epoch 1 loss: 0.8483846187591553\n",
      "epoch 2 loss: 0.6192342638969421\n",
      "epoch 3 loss: 0.46564289927482605\n",
      "epoch 4 loss: 0.34314289689064026\n",
      "epoch 5 loss: 0.21183890104293823\n",
      "epoch 6 loss: 0.21029458940029144\n",
      "epoch 7 loss: 0.18131482601165771\n",
      "epoch 8 loss: 0.18356166779994965\n",
      "epoch 9 loss: 0.22254909574985504\n",
      "epoch 10 loss: 0.22319157421588898\n",
      "epoch 11 loss: 0.22228169441223145\n",
      "epoch 12 loss: 0.19933098554611206\n",
      "epoch 13 loss: 0.14153729379177094\n",
      "epoch 14 loss: 0.16676534712314606\n",
      "epoch 15 loss: 0.18254856765270233\n",
      "epoch 16 loss: 0.16083410382270813\n",
      "epoch 17 loss: 0.17668145895004272\n",
      "epoch 18 loss: 0.18385255336761475\n",
      "epoch 19 loss: 0.16990090906620026\n",
      "epoch 20 loss: 0.1387273520231247\n",
      "epoch 21 loss: 0.16387349367141724\n",
      "epoch 22 loss: 0.1510525345802307\n",
      "epoch 23 loss: 0.18108884990215302\n",
      "epoch 24 loss: 0.17481113970279694\n",
      "epoch 25 loss: 0.13391727209091187\n",
      "epoch 26 loss: 0.13859540224075317\n",
      "epoch 27 loss: 0.12164076417684555\n",
      "epoch 28 loss: 0.13962304592132568\n",
      "epoch 29 loss: 0.1495189070701599\n",
      "epoch 30 loss: 0.09275804460048676\n",
      "61\n",
      "epoch 1 loss: 0.6248221397399902\n",
      "epoch 2 loss: 0.7332707047462463\n",
      "epoch 3 loss: 0.9008095860481262\n",
      "epoch 4 loss: 0.31489497423171997\n",
      "epoch 5 loss: 0.21275292336940765\n",
      "epoch 6 loss: 0.1737954467535019\n",
      "epoch 7 loss: 0.22413061559200287\n",
      "epoch 8 loss: 0.22535663843154907\n",
      "epoch 9 loss: 0.17845049500465393\n",
      "epoch 10 loss: 0.19119088351726532\n",
      "epoch 11 loss: 0.17133687436580658\n",
      "epoch 12 loss: 0.2058495283126831\n",
      "epoch 13 loss: 0.22299334406852722\n",
      "epoch 14 loss: 0.1841241866350174\n",
      "epoch 15 loss: 0.16869497299194336\n",
      "epoch 16 loss: 0.15424798429012299\n",
      "epoch 17 loss: 0.16272413730621338\n",
      "epoch 18 loss: 0.1684180498123169\n",
      "epoch 19 loss: 0.1661001443862915\n",
      "epoch 20 loss: 0.21493901312351227\n",
      "epoch 21 loss: 0.16692225635051727\n",
      "epoch 22 loss: 0.18857720494270325\n",
      "epoch 23 loss: 0.12380611896514893\n",
      "epoch 24 loss: 0.15290433168411255\n",
      "epoch 25 loss: 0.14946496486663818\n",
      "epoch 26 loss: 0.18163031339645386\n",
      "epoch 27 loss: 0.16737273335456848\n",
      "epoch 28 loss: 0.18036194145679474\n",
      "epoch 29 loss: 0.1581987738609314\n",
      "epoch 30 loss: 0.16078288853168488\n",
      "62\n",
      "epoch 1 loss: 0.7856957912445068\n",
      "epoch 2 loss: 0.619160532951355\n",
      "epoch 3 loss: 0.306694358587265\n",
      "epoch 4 loss: 0.21658466756343842\n",
      "epoch 5 loss: 0.18553532660007477\n",
      "epoch 6 loss: 0.22562430799007416\n",
      "epoch 7 loss: 0.1797555387020111\n",
      "epoch 8 loss: 0.20609703660011292\n",
      "epoch 9 loss: 0.18482299149036407\n",
      "epoch 10 loss: 0.204646036028862\n",
      "epoch 11 loss: 0.16681352257728577\n",
      "epoch 12 loss: 0.16146141290664673\n",
      "epoch 13 loss: 0.19194968044757843\n",
      "epoch 14 loss: 0.18317484855651855\n",
      "epoch 15 loss: 0.16943027079105377\n",
      "epoch 16 loss: 0.18726319074630737\n",
      "epoch 17 loss: 0.21019382774829865\n",
      "epoch 18 loss: 0.18710249662399292\n",
      "epoch 19 loss: 0.14482228457927704\n",
      "epoch 20 loss: 0.13863904774188995\n",
      "epoch 21 loss: 0.20503252744674683\n",
      "epoch 22 loss: 0.14755679666996002\n",
      "epoch 23 loss: 0.12630511820316315\n",
      "epoch 24 loss: 0.16846981644630432\n",
      "epoch 25 loss: 0.13211163878440857\n",
      "epoch 26 loss: 0.14444118738174438\n",
      "epoch 27 loss: 0.19154033064842224\n",
      "epoch 28 loss: 0.1376226246356964\n",
      "epoch 29 loss: 0.11409599334001541\n",
      "epoch 30 loss: 0.12819814682006836\n",
      "63\n",
      "epoch 1 loss: 0.7931223511695862\n",
      "epoch 2 loss: 0.5510326027870178\n",
      "epoch 3 loss: 0.29505881667137146\n",
      "epoch 4 loss: 0.20418471097946167\n",
      "epoch 5 loss: 0.20518113672733307\n",
      "epoch 6 loss: 0.19345638155937195\n",
      "epoch 7 loss: 0.1403367519378662\n",
      "epoch 8 loss: 0.16035929322242737\n",
      "epoch 9 loss: 0.20767472684383392\n",
      "epoch 10 loss: 0.1754387468099594\n",
      "epoch 11 loss: 0.16621701419353485\n",
      "epoch 12 loss: 0.17927956581115723\n",
      "epoch 13 loss: 0.1896667331457138\n",
      "epoch 14 loss: 0.17354901134967804\n",
      "epoch 15 loss: 0.15009653568267822\n",
      "epoch 16 loss: 0.15951025485992432\n",
      "epoch 17 loss: 0.1487249732017517\n",
      "epoch 18 loss: 0.13761812448501587\n",
      "epoch 19 loss: 0.1575656533241272\n",
      "epoch 20 loss: 0.138885959982872\n",
      "epoch 21 loss: 0.1918121725320816\n",
      "epoch 22 loss: 0.15816348791122437\n",
      "epoch 23 loss: 0.1399172842502594\n",
      "epoch 24 loss: 0.18950845301151276\n",
      "epoch 25 loss: 0.13768291473388672\n",
      "epoch 26 loss: 0.11735318601131439\n",
      "epoch 27 loss: 0.12859070301055908\n",
      "epoch 28 loss: 0.13936874270439148\n",
      "epoch 29 loss: 0.1470174938440323\n",
      "epoch 30 loss: 0.12784595787525177\n",
      "64\n",
      "epoch 1 loss: 0.7898876070976257\n",
      "epoch 2 loss: 0.48646801710128784\n",
      "epoch 3 loss: 0.3520815074443817\n",
      "epoch 4 loss: 0.2286195605993271\n",
      "epoch 5 loss: 0.21100914478302002\n",
      "epoch 6 loss: 0.15947669744491577\n",
      "epoch 7 loss: 0.18421803414821625\n",
      "epoch 8 loss: 0.20405180752277374\n",
      "epoch 9 loss: 0.1675226092338562\n",
      "epoch 10 loss: 0.175558403134346\n",
      "epoch 11 loss: 0.24326565861701965\n",
      "epoch 12 loss: 0.1541430801153183\n",
      "epoch 13 loss: 0.1463020294904709\n",
      "epoch 14 loss: 0.16546617448329926\n",
      "epoch 15 loss: 0.17661763727664948\n",
      "epoch 16 loss: 0.16425620019435883\n",
      "epoch 17 loss: 0.1510605365037918\n",
      "epoch 18 loss: 0.18540389835834503\n",
      "epoch 19 loss: 0.18388940393924713\n",
      "epoch 20 loss: 0.15436966717243195\n",
      "epoch 21 loss: 0.1492287963628769\n",
      "epoch 22 loss: 0.14836454391479492\n",
      "epoch 23 loss: 0.19004561007022858\n",
      "epoch 24 loss: 0.15781272947788239\n",
      "epoch 25 loss: 0.12830425798892975\n",
      "epoch 26 loss: 0.18148505687713623\n",
      "epoch 27 loss: 0.13555441796779633\n",
      "epoch 28 loss: 0.14269593358039856\n",
      "epoch 29 loss: 0.1543334275484085\n",
      "epoch 30 loss: 0.12038755416870117\n",
      "65\n",
      "epoch 1 loss: 0.681538462638855\n",
      "epoch 2 loss: 0.6076919436454773\n",
      "epoch 3 loss: 0.5901979804039001\n",
      "epoch 4 loss: 0.3876146078109741\n",
      "epoch 5 loss: 0.22948455810546875\n",
      "epoch 6 loss: 0.19314932823181152\n",
      "epoch 7 loss: 0.15516528487205505\n",
      "epoch 8 loss: 0.2104189097881317\n",
      "epoch 9 loss: 0.15561330318450928\n",
      "epoch 10 loss: 0.23095464706420898\n",
      "epoch 11 loss: 0.20777708292007446\n",
      "epoch 12 loss: 0.20539157092571259\n",
      "epoch 13 loss: 0.20458638668060303\n",
      "epoch 14 loss: 0.277899831533432\n",
      "epoch 15 loss: 0.19095607101917267\n",
      "epoch 16 loss: 0.198696568608284\n",
      "epoch 17 loss: 0.14908795058727264\n",
      "epoch 18 loss: 0.17492739856243134\n",
      "epoch 19 loss: 0.15623348951339722\n",
      "epoch 20 loss: 0.1552906185388565\n",
      "epoch 21 loss: 0.14635500311851501\n",
      "epoch 22 loss: 0.13645188510417938\n",
      "epoch 23 loss: 0.13323603570461273\n",
      "epoch 24 loss: 0.15894438326358795\n",
      "epoch 25 loss: 0.14857597649097443\n",
      "epoch 26 loss: 0.17415879666805267\n",
      "epoch 27 loss: 0.13246652483940125\n",
      "epoch 28 loss: 0.11599206924438477\n",
      "epoch 29 loss: 0.1389903426170349\n",
      "epoch 30 loss: 0.12168930470943451\n",
      "66\n",
      "epoch 1 loss: 0.9551821351051331\n",
      "epoch 2 loss: 0.8892044425010681\n",
      "epoch 3 loss: 0.49178546667099\n",
      "epoch 4 loss: 0.31501108407974243\n",
      "epoch 5 loss: 0.2087145894765854\n",
      "epoch 6 loss: 0.19620215892791748\n",
      "epoch 7 loss: 0.18289582431316376\n",
      "epoch 8 loss: 0.1764773577451706\n",
      "epoch 9 loss: 0.20293472707271576\n",
      "epoch 10 loss: 0.1941775232553482\n",
      "epoch 11 loss: 0.19258850812911987\n",
      "epoch 12 loss: 0.1907590925693512\n",
      "epoch 13 loss: 0.18446898460388184\n",
      "epoch 14 loss: 0.15292119979858398\n",
      "epoch 15 loss: 0.13947689533233643\n",
      "epoch 16 loss: 0.18081071972846985\n",
      "epoch 17 loss: 0.15940001606941223\n",
      "epoch 18 loss: 0.14482004940509796\n",
      "epoch 19 loss: 0.1446816325187683\n",
      "epoch 20 loss: 0.12537533044815063\n",
      "epoch 21 loss: 0.17337234318256378\n",
      "epoch 22 loss: 0.1179930567741394\n",
      "epoch 23 loss: 0.13814784586429596\n",
      "epoch 24 loss: 0.13564921915531158\n",
      "epoch 25 loss: 0.17182426154613495\n",
      "epoch 26 loss: 0.127488374710083\n",
      "epoch 27 loss: 0.14520561695098877\n",
      "epoch 28 loss: 0.13581494987010956\n",
      "epoch 29 loss: 0.11905302852392197\n",
      "epoch 30 loss: 0.12477418780326843\n",
      "67\n",
      "epoch 1 loss: 0.9080848693847656\n",
      "epoch 2 loss: 0.6890153288841248\n",
      "epoch 3 loss: 0.31834325194358826\n",
      "epoch 4 loss: 0.19223251938819885\n",
      "epoch 5 loss: 0.20216526091098785\n",
      "epoch 6 loss: 0.23355555534362793\n",
      "epoch 7 loss: 0.26566964387893677\n",
      "epoch 8 loss: 0.24321839213371277\n",
      "epoch 9 loss: 0.19704210758209229\n",
      "epoch 10 loss: 0.1875530481338501\n",
      "epoch 11 loss: 0.20974530279636383\n",
      "epoch 12 loss: 0.19171704351902008\n",
      "epoch 13 loss: 0.1431606560945511\n",
      "epoch 14 loss: 0.20185153186321259\n",
      "epoch 15 loss: 0.19307029247283936\n",
      "epoch 16 loss: 0.21062885224819183\n",
      "epoch 17 loss: 0.18589961528778076\n",
      "epoch 18 loss: 0.1412629634141922\n",
      "epoch 19 loss: 0.15369226038455963\n",
      "epoch 20 loss: 0.14505553245544434\n",
      "epoch 21 loss: 0.17567360401153564\n",
      "epoch 22 loss: 0.126664936542511\n",
      "epoch 23 loss: 0.16289427876472473\n",
      "epoch 24 loss: 0.1646776795387268\n",
      "epoch 25 loss: 0.1594395637512207\n",
      "epoch 26 loss: 0.13826066255569458\n",
      "epoch 27 loss: 0.11235044151544571\n",
      "epoch 28 loss: 0.13971753418445587\n",
      "epoch 29 loss: 0.1463719755411148\n",
      "epoch 30 loss: 0.11001746356487274\n",
      "68\n",
      "epoch 1 loss: 0.834324061870575\n",
      "epoch 2 loss: 0.6009622812271118\n",
      "epoch 3 loss: 0.3310045301914215\n",
      "epoch 4 loss: 0.1973642259836197\n",
      "epoch 5 loss: 0.23325084149837494\n",
      "epoch 6 loss: 0.20401060581207275\n",
      "epoch 7 loss: 0.21974068880081177\n",
      "epoch 8 loss: 0.17233386635780334\n",
      "epoch 9 loss: 0.17922066152095795\n",
      "epoch 10 loss: 0.2019270807504654\n",
      "epoch 11 loss: 0.1759205311536789\n",
      "epoch 12 loss: 0.20880673825740814\n",
      "epoch 13 loss: 0.12535148859024048\n",
      "epoch 14 loss: 0.1731870174407959\n",
      "epoch 15 loss: 0.15747235715389252\n",
      "epoch 16 loss: 0.18356092274188995\n",
      "epoch 17 loss: 0.17783474922180176\n",
      "epoch 18 loss: 0.18722976744174957\n",
      "epoch 19 loss: 0.1907775104045868\n",
      "epoch 20 loss: 0.15904028713703156\n",
      "epoch 21 loss: 0.13052472472190857\n",
      "epoch 22 loss: 0.12879423797130585\n",
      "epoch 23 loss: 0.15836496651172638\n",
      "epoch 24 loss: 0.13040213286876678\n",
      "epoch 25 loss: 0.14226581156253815\n",
      "epoch 26 loss: 0.1270821988582611\n",
      "epoch 27 loss: 0.14131341874599457\n",
      "epoch 28 loss: 0.1026860848069191\n",
      "epoch 29 loss: 0.11834048479795456\n",
      "epoch 30 loss: 0.14146703481674194\n",
      "69\n",
      "epoch 1 loss: 0.9487014412879944\n",
      "epoch 2 loss: 0.502838134765625\n",
      "epoch 3 loss: 0.3337782621383667\n",
      "epoch 4 loss: 0.19953598082065582\n",
      "epoch 5 loss: 0.20351968705654144\n",
      "epoch 6 loss: 0.23149512708187103\n",
      "epoch 7 loss: 0.2547113001346588\n",
      "epoch 8 loss: 0.21185633540153503\n",
      "epoch 9 loss: 0.19605441391468048\n",
      "epoch 10 loss: 0.18396450579166412\n",
      "epoch 11 loss: 0.2636396586894989\n",
      "epoch 12 loss: 0.20223203301429749\n",
      "epoch 13 loss: 0.15667930245399475\n",
      "epoch 14 loss: 0.15701916813850403\n",
      "epoch 15 loss: 0.16884832084178925\n",
      "epoch 16 loss: 0.18095256388187408\n",
      "epoch 17 loss: 0.17514543235301971\n",
      "epoch 18 loss: 0.16805143654346466\n",
      "epoch 19 loss: 0.16208095848560333\n",
      "epoch 20 loss: 0.15489035844802856\n",
      "epoch 21 loss: 0.1588452309370041\n",
      "epoch 22 loss: 0.13079312443733215\n",
      "epoch 23 loss: 0.16109700500965118\n",
      "epoch 24 loss: 0.13703946769237518\n",
      "epoch 25 loss: 0.23632138967514038\n",
      "epoch 26 loss: 0.11666367948055267\n",
      "epoch 27 loss: 0.12517888844013214\n",
      "epoch 28 loss: 0.11812344193458557\n",
      "epoch 29 loss: 0.12547630071640015\n",
      "epoch 30 loss: 0.12957651913166046\n",
      "70\n",
      "epoch 1 loss: 0.7550697326660156\n",
      "epoch 2 loss: 0.5054606795310974\n",
      "epoch 3 loss: 0.2542228698730469\n",
      "epoch 4 loss: 0.2283397763967514\n",
      "epoch 5 loss: 0.24452318251132965\n",
      "epoch 6 loss: 0.22057604789733887\n",
      "epoch 7 loss: 0.22397953271865845\n",
      "epoch 8 loss: 0.1721085160970688\n",
      "epoch 9 loss: 0.18154776096343994\n",
      "epoch 10 loss: 0.24357348680496216\n",
      "epoch 11 loss: 0.1743226796388626\n",
      "epoch 12 loss: 0.19520917534828186\n",
      "epoch 13 loss: 0.18268410861492157\n",
      "epoch 14 loss: 0.16040201485157013\n",
      "epoch 15 loss: 0.177340567111969\n",
      "epoch 16 loss: 0.14884436130523682\n",
      "epoch 17 loss: 0.1842668652534485\n",
      "epoch 18 loss: 0.17058910429477692\n",
      "epoch 19 loss: 0.1750323325395584\n",
      "epoch 20 loss: 0.21061816811561584\n",
      "epoch 21 loss: 0.18137754499912262\n",
      "epoch 22 loss: 0.16128699481487274\n",
      "epoch 23 loss: 0.1546369194984436\n",
      "epoch 24 loss: 0.17509548366069794\n",
      "epoch 25 loss: 0.1515951156616211\n",
      "epoch 26 loss: 0.19330596923828125\n",
      "epoch 27 loss: 0.1264563649892807\n",
      "epoch 28 loss: 0.13307400047779083\n",
      "epoch 29 loss: 0.19436988234519958\n",
      "epoch 30 loss: 0.1407749056816101\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "4bfdc96a-cacc-430f-9a85-5d287c8ff45f",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + categorical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "25ff7b72-e9cb-40af-81a5-b353fdef34f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:02:54.570641Z",
     "start_time": "2025-10-03T09:00:18.137750Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wc = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wc()\n",
    "    trainer = model_class.RNN_train_2(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "results_aep_self_con_wc.to_csv(out_dir + '/results_aep_self_con_wc.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1 loss: 0.7715416550636292\n",
      "epoch 2 loss: 0.5838039517402649\n",
      "epoch 3 loss: 0.3343912363052368\n",
      "epoch 4 loss: 0.25005215406417847\n",
      "epoch 5 loss: 0.18683649599552155\n",
      "epoch 6 loss: 0.1840142458677292\n",
      "epoch 7 loss: 0.21400894224643707\n",
      "epoch 8 loss: 0.21237602829933167\n",
      "epoch 9 loss: 0.1788121610879898\n",
      "epoch 10 loss: 0.25528252124786377\n",
      "epoch 11 loss: 0.19917680323123932\n",
      "epoch 12 loss: 0.21658053994178772\n",
      "epoch 13 loss: 0.17399148643016815\n",
      "epoch 14 loss: 0.21722447872161865\n",
      "epoch 15 loss: 0.16168159246444702\n",
      "epoch 16 loss: 0.13318531215190887\n",
      "epoch 17 loss: 0.17825062572956085\n",
      "epoch 18 loss: 0.16237463057041168\n",
      "epoch 19 loss: 0.1590723693370819\n",
      "epoch 20 loss: 0.19821049273014069\n",
      "epoch 21 loss: 0.11100352555513382\n",
      "epoch 22 loss: 0.1284191906452179\n",
      "epoch 23 loss: 0.13947127759456635\n",
      "epoch 24 loss: 0.1531929075717926\n",
      "epoch 25 loss: 0.10600049793720245\n",
      "epoch 26 loss: 0.10837643593549728\n",
      "epoch 27 loss: 0.1164146363735199\n",
      "epoch 28 loss: 0.11140160262584686\n",
      "epoch 29 loss: 0.10288127511739731\n",
      "epoch 30 loss: 0.1236979067325592\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_60650/2051541769.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7697824835777283\n",
      "epoch 2 loss: 1.0466982126235962\n",
      "epoch 3 loss: 0.40084514021873474\n",
      "epoch 4 loss: 0.2554231584072113\n",
      "epoch 5 loss: 0.16607436537742615\n",
      "epoch 6 loss: 0.2078515738248825\n",
      "epoch 7 loss: 0.1666652113199234\n",
      "epoch 8 loss: 0.1542893797159195\n",
      "epoch 9 loss: 0.16349489986896515\n",
      "epoch 10 loss: 0.1704801619052887\n",
      "epoch 11 loss: 0.18191124498844147\n",
      "epoch 12 loss: 0.1990099847316742\n",
      "epoch 13 loss: 0.20048309862613678\n",
      "epoch 14 loss: 0.18564225733280182\n",
      "epoch 15 loss: 0.181046724319458\n",
      "epoch 16 loss: 0.14806458353996277\n",
      "epoch 17 loss: 0.12445133924484253\n",
      "epoch 18 loss: 0.12904436886310577\n",
      "epoch 19 loss: 0.13692370057106018\n",
      "epoch 20 loss: 0.13509468734264374\n",
      "epoch 21 loss: 0.1378697007894516\n",
      "epoch 22 loss: 0.12657654285430908\n",
      "epoch 23 loss: 0.1211991086602211\n",
      "epoch 24 loss: 0.11649903655052185\n",
      "epoch 25 loss: 0.10674810409545898\n",
      "epoch 26 loss: 0.11812275648117065\n",
      "epoch 27 loss: 0.12566879391670227\n",
      "epoch 28 loss: 0.09194234013557434\n",
      "epoch 29 loss: 0.14972829818725586\n",
      "epoch 30 loss: 0.11813120543956757\n",
      "3\n",
      "epoch 1 loss: 0.7919052839279175\n",
      "epoch 2 loss: 0.5559009909629822\n",
      "epoch 3 loss: 0.2798078656196594\n",
      "epoch 4 loss: 0.2392655909061432\n",
      "epoch 5 loss: 0.20580162107944489\n",
      "epoch 6 loss: 0.21482950448989868\n",
      "epoch 7 loss: 0.23071949183940887\n",
      "epoch 8 loss: 0.14825855195522308\n",
      "epoch 9 loss: 0.1481795758008957\n",
      "epoch 10 loss: 0.14076067507266998\n",
      "epoch 11 loss: 0.17986859381198883\n",
      "epoch 12 loss: 0.17761488258838654\n",
      "epoch 13 loss: 0.16298753023147583\n",
      "epoch 14 loss: 0.18997745215892792\n",
      "epoch 15 loss: 0.190247043967247\n",
      "epoch 16 loss: 0.19008858501911163\n",
      "epoch 17 loss: 0.16991694271564484\n",
      "epoch 18 loss: 0.15614886581897736\n",
      "epoch 19 loss: 0.16326378285884857\n",
      "epoch 20 loss: 0.1537207067012787\n",
      "epoch 21 loss: 0.1444721817970276\n",
      "epoch 22 loss: 0.16681405901908875\n",
      "epoch 23 loss: 0.16012205183506012\n",
      "epoch 24 loss: 0.13260488212108612\n",
      "epoch 25 loss: 0.17999914288520813\n",
      "epoch 26 loss: 0.13528867065906525\n",
      "epoch 27 loss: 0.09780855476856232\n",
      "epoch 28 loss: 0.13826416432857513\n",
      "epoch 29 loss: 0.1206168457865715\n",
      "epoch 30 loss: 0.1086626723408699\n",
      "4\n",
      "epoch 1 loss: 0.765221118927002\n",
      "epoch 2 loss: 0.7295488119125366\n",
      "epoch 3 loss: 0.32308223843574524\n",
      "epoch 4 loss: 0.24199049174785614\n",
      "epoch 5 loss: 0.19218003749847412\n",
      "epoch 6 loss: 0.25478029251098633\n",
      "epoch 7 loss: 0.1932845115661621\n",
      "epoch 8 loss: 0.20339025557041168\n",
      "epoch 9 loss: 0.20834428071975708\n",
      "epoch 10 loss: 0.14614306390285492\n",
      "epoch 11 loss: 0.15543603897094727\n",
      "epoch 12 loss: 0.1751129925251007\n",
      "epoch 13 loss: 0.1754007786512375\n",
      "epoch 14 loss: 0.20557259023189545\n",
      "epoch 15 loss: 0.1866697371006012\n",
      "epoch 16 loss: 0.1834460198879242\n",
      "epoch 17 loss: 0.1692437380552292\n",
      "epoch 18 loss: 0.23363783955574036\n",
      "epoch 19 loss: 0.16015410423278809\n",
      "epoch 20 loss: 0.18471461534500122\n",
      "epoch 21 loss: 0.1755371391773224\n",
      "epoch 22 loss: 0.19466498494148254\n",
      "epoch 23 loss: 0.1523691564798355\n",
      "epoch 24 loss: 0.1372368335723877\n",
      "epoch 25 loss: 0.16936150193214417\n",
      "epoch 26 loss: 0.14608414471149445\n",
      "epoch 27 loss: 0.15634748339653015\n",
      "epoch 28 loss: 0.13893918693065643\n",
      "epoch 29 loss: 0.1596674919128418\n",
      "epoch 30 loss: 0.13441245257854462\n",
      "5\n",
      "epoch 1 loss: 0.7527793049812317\n",
      "epoch 2 loss: 0.4908119738101959\n",
      "epoch 3 loss: 0.33991673588752747\n",
      "epoch 4 loss: 0.29531967639923096\n",
      "epoch 5 loss: 0.21178588271141052\n",
      "epoch 6 loss: 0.2154938280582428\n",
      "epoch 7 loss: 0.22472526133060455\n",
      "epoch 8 loss: 0.23623880743980408\n",
      "epoch 9 loss: 0.19907647371292114\n",
      "epoch 10 loss: 0.21181155741214752\n",
      "epoch 11 loss: 0.1714124083518982\n",
      "epoch 12 loss: 0.1894446462392807\n",
      "epoch 13 loss: 0.16576214134693146\n",
      "epoch 14 loss: 0.18251562118530273\n",
      "epoch 15 loss: 0.22407247126102448\n",
      "epoch 16 loss: 0.1344394087791443\n",
      "epoch 17 loss: 0.14058268070220947\n",
      "epoch 18 loss: 0.16179436445236206\n",
      "epoch 19 loss: 0.10605426132678986\n",
      "epoch 20 loss: 0.21645167469978333\n",
      "epoch 21 loss: 0.13715820014476776\n",
      "epoch 22 loss: 0.1118200272321701\n",
      "epoch 23 loss: 0.11869204044342041\n",
      "epoch 24 loss: 0.21262606978416443\n",
      "epoch 25 loss: 0.14278052747249603\n",
      "epoch 26 loss: 0.17264606058597565\n",
      "epoch 27 loss: 0.13160760700702667\n",
      "epoch 28 loss: 0.1198735237121582\n",
      "epoch 29 loss: 0.11646721512079239\n",
      "epoch 30 loss: 0.12054699659347534\n",
      "6\n",
      "epoch 1 loss: 0.8128051161766052\n",
      "epoch 2 loss: 0.5088593363761902\n",
      "epoch 3 loss: 0.35639622807502747\n",
      "epoch 4 loss: 0.2571876347064972\n",
      "epoch 5 loss: 0.21221083402633667\n",
      "epoch 6 loss: 0.2269153743982315\n",
      "epoch 7 loss: 0.16404397785663605\n",
      "epoch 8 loss: 0.18666142225265503\n",
      "epoch 9 loss: 0.22736366093158722\n",
      "epoch 10 loss: 0.17134499549865723\n",
      "epoch 11 loss: 0.1812719851732254\n",
      "epoch 12 loss: 0.18179009854793549\n",
      "epoch 13 loss: 0.20569448173046112\n",
      "epoch 14 loss: 0.174232617020607\n",
      "epoch 15 loss: 0.1847539097070694\n",
      "epoch 16 loss: 0.17075294256210327\n",
      "epoch 17 loss: 0.17036229372024536\n",
      "epoch 18 loss: 0.1561710238456726\n",
      "epoch 19 loss: 0.14967061579227448\n",
      "epoch 20 loss: 0.1288430243730545\n",
      "epoch 21 loss: 0.15629790723323822\n",
      "epoch 22 loss: 0.15706390142440796\n",
      "epoch 23 loss: 0.17035721242427826\n",
      "epoch 24 loss: 0.12092461436986923\n",
      "epoch 25 loss: 0.13301368057727814\n",
      "epoch 26 loss: 0.12904874980449677\n",
      "epoch 27 loss: 0.10877299308776855\n",
      "epoch 28 loss: 0.1323605328798294\n",
      "epoch 29 loss: 0.14007091522216797\n",
      "epoch 30 loss: 0.11316338181495667\n",
      "7\n",
      "epoch 1 loss: 1.0007816553115845\n",
      "epoch 2 loss: 0.9455446004867554\n",
      "epoch 3 loss: 0.5395619869232178\n",
      "epoch 4 loss: 0.3051069974899292\n",
      "epoch 5 loss: 0.23126283288002014\n",
      "epoch 6 loss: 0.2364071011543274\n",
      "epoch 7 loss: 0.19700132310390472\n",
      "epoch 8 loss: 0.19150368869304657\n",
      "epoch 9 loss: 0.2245878279209137\n",
      "epoch 10 loss: 0.24328069388866425\n",
      "epoch 11 loss: 0.15891775488853455\n",
      "epoch 12 loss: 0.18132644891738892\n",
      "epoch 13 loss: 0.1736627221107483\n",
      "epoch 14 loss: 0.12117920815944672\n",
      "epoch 15 loss: 0.2078825682401657\n",
      "epoch 16 loss: 0.17028510570526123\n",
      "epoch 17 loss: 0.1979934275150299\n",
      "epoch 18 loss: 0.15963198244571686\n",
      "epoch 19 loss: 0.17341682314872742\n",
      "epoch 20 loss: 0.17969273030757904\n",
      "epoch 21 loss: 0.13120150566101074\n",
      "epoch 22 loss: 0.1380593478679657\n",
      "epoch 23 loss: 0.14935532212257385\n",
      "epoch 24 loss: 0.12399109452962875\n",
      "epoch 25 loss: 0.12166135758161545\n",
      "epoch 26 loss: 0.09289403259754181\n",
      "epoch 27 loss: 0.13223569095134735\n",
      "epoch 28 loss: 0.10150793194770813\n",
      "epoch 29 loss: 0.12162920832633972\n",
      "epoch 30 loss: 0.11331692337989807\n",
      "8\n",
      "epoch 1 loss: 0.9680284857749939\n",
      "epoch 2 loss: 0.6059476137161255\n",
      "epoch 3 loss: 0.4782203435897827\n",
      "epoch 4 loss: 0.28720203042030334\n",
      "epoch 5 loss: 0.2715546786785126\n",
      "epoch 6 loss: 0.2144727110862732\n",
      "epoch 7 loss: 0.20604638755321503\n",
      "epoch 8 loss: 0.23042550683021545\n",
      "epoch 9 loss: 0.16767723858356476\n",
      "epoch 10 loss: 0.1666913777589798\n",
      "epoch 11 loss: 0.16841644048690796\n",
      "epoch 12 loss: 0.18345730006694794\n",
      "epoch 13 loss: 0.23347324132919312\n",
      "epoch 14 loss: 0.25278615951538086\n",
      "epoch 15 loss: 0.24095633625984192\n",
      "epoch 16 loss: 0.17203432321548462\n",
      "epoch 17 loss: 0.1596234142780304\n",
      "epoch 18 loss: 0.14168323576450348\n",
      "epoch 19 loss: 0.17655174434185028\n",
      "epoch 20 loss: 0.1789645552635193\n",
      "epoch 21 loss: 0.15267369151115417\n",
      "epoch 22 loss: 0.15369829535484314\n",
      "epoch 23 loss: 0.13045503199100494\n",
      "epoch 24 loss: 0.13655999302864075\n",
      "epoch 25 loss: 0.14596858620643616\n",
      "epoch 26 loss: 0.15626639127731323\n",
      "epoch 27 loss: 0.13325272500514984\n",
      "epoch 28 loss: 0.09317008405923843\n",
      "epoch 29 loss: 0.14531545341014862\n",
      "epoch 30 loss: 0.09982789307832718\n",
      "9\n",
      "epoch 1 loss: 0.8277053236961365\n",
      "epoch 2 loss: 0.591779351234436\n",
      "epoch 3 loss: 0.3887052536010742\n",
      "epoch 4 loss: 0.24626249074935913\n",
      "epoch 5 loss: 0.19198648631572723\n",
      "epoch 6 loss: 0.15096640586853027\n",
      "epoch 7 loss: 0.18309827148914337\n",
      "epoch 8 loss: 0.19153441488742828\n",
      "epoch 9 loss: 0.156781867146492\n",
      "epoch 10 loss: 0.23336748778820038\n",
      "epoch 11 loss: 0.1756049245595932\n",
      "epoch 12 loss: 0.20972135663032532\n",
      "epoch 13 loss: 0.16012686491012573\n",
      "epoch 14 loss: 0.17000214755535126\n",
      "epoch 15 loss: 0.1453864872455597\n",
      "epoch 16 loss: 0.18841944634914398\n",
      "epoch 17 loss: 0.13863608241081238\n",
      "epoch 18 loss: 0.13600069284439087\n",
      "epoch 19 loss: 0.163554847240448\n",
      "epoch 20 loss: 0.08936411887407303\n",
      "epoch 21 loss: 0.15778931975364685\n",
      "epoch 22 loss: 0.1569153368473053\n",
      "epoch 23 loss: 0.11591017246246338\n",
      "epoch 24 loss: 0.12397642433643341\n",
      "epoch 25 loss: 0.11151713877916336\n",
      "epoch 26 loss: 0.1066899523139\n",
      "epoch 27 loss: 0.10953976958990097\n",
      "epoch 28 loss: 0.09476540982723236\n",
      "epoch 29 loss: 0.10971065610647202\n",
      "epoch 30 loss: 0.18496330082416534\n",
      "10\n",
      "epoch 1 loss: 0.6296061873435974\n",
      "epoch 2 loss: 0.5603200793266296\n",
      "epoch 3 loss: 0.40522533655166626\n",
      "epoch 4 loss: 0.2673271596431732\n",
      "epoch 5 loss: 0.1992841213941574\n",
      "epoch 6 loss: 0.18493454158306122\n",
      "epoch 7 loss: 0.16514216363430023\n",
      "epoch 8 loss: 0.19962544739246368\n",
      "epoch 9 loss: 0.1820286214351654\n",
      "epoch 10 loss: 0.19373206794261932\n",
      "epoch 11 loss: 0.17085953056812286\n",
      "epoch 12 loss: 0.16094763576984406\n",
      "epoch 13 loss: 0.2161707580089569\n",
      "epoch 14 loss: 0.19298960268497467\n",
      "epoch 15 loss: 0.16417749226093292\n",
      "epoch 16 loss: 0.15313607454299927\n",
      "epoch 17 loss: 0.21550153195858002\n",
      "epoch 18 loss: 0.1458740085363388\n",
      "epoch 19 loss: 0.13458940386772156\n",
      "epoch 20 loss: 0.11826103925704956\n",
      "epoch 21 loss: 0.14695274829864502\n",
      "epoch 22 loss: 0.13989906013011932\n",
      "epoch 23 loss: 0.13422255218029022\n",
      "epoch 24 loss: 0.12392441928386688\n",
      "epoch 25 loss: 0.12113776803016663\n",
      "epoch 26 loss: 0.14488904178142548\n",
      "epoch 27 loss: 0.11790928244590759\n",
      "epoch 28 loss: 0.11458245664834976\n",
      "epoch 29 loss: 0.16602341830730438\n",
      "epoch 30 loss: 0.11132905632257462\n",
      "11\n",
      "epoch 1 loss: 0.6993072032928467\n",
      "epoch 2 loss: 0.750347375869751\n",
      "epoch 3 loss: 0.40697479248046875\n",
      "epoch 4 loss: 0.28740713000297546\n",
      "epoch 5 loss: 0.22144190967082977\n",
      "epoch 6 loss: 0.18183420598506927\n",
      "epoch 7 loss: 0.19310835003852844\n",
      "epoch 8 loss: 0.19978687167167664\n",
      "epoch 9 loss: 0.17718495428562164\n",
      "epoch 10 loss: 0.19262510538101196\n",
      "epoch 11 loss: 0.2076277881860733\n",
      "epoch 12 loss: 0.1920536756515503\n",
      "epoch 13 loss: 0.18148770928382874\n",
      "epoch 14 loss: 0.22638118267059326\n",
      "epoch 15 loss: 0.24517665803432465\n",
      "epoch 16 loss: 0.2213592231273651\n",
      "epoch 17 loss: 0.15537483990192413\n",
      "epoch 18 loss: 0.133916974067688\n",
      "epoch 19 loss: 0.1787191778421402\n",
      "epoch 20 loss: 0.15472325682640076\n",
      "epoch 21 loss: 0.1535446047782898\n",
      "epoch 22 loss: 0.13958270847797394\n",
      "epoch 23 loss: 0.20742428302764893\n",
      "epoch 24 loss: 0.10946615040302277\n",
      "epoch 25 loss: 0.15744976699352264\n",
      "epoch 26 loss: 0.16703484952449799\n",
      "epoch 27 loss: 0.14268425107002258\n",
      "epoch 28 loss: 0.10775133222341537\n",
      "epoch 29 loss: 0.13576216995716095\n",
      "epoch 30 loss: 0.13086670637130737\n",
      "12\n",
      "epoch 1 loss: 0.8721261620521545\n",
      "epoch 2 loss: 0.6861916780471802\n",
      "epoch 3 loss: 0.4221748113632202\n",
      "epoch 4 loss: 0.2180931568145752\n",
      "epoch 5 loss: 0.23489536345005035\n",
      "epoch 6 loss: 0.25039201974868774\n",
      "epoch 7 loss: 0.1977013796567917\n",
      "epoch 8 loss: 0.1871005892753601\n",
      "epoch 9 loss: 0.17002660036087036\n",
      "epoch 10 loss: 0.1838240921497345\n",
      "epoch 11 loss: 0.2107478678226471\n",
      "epoch 12 loss: 0.19797971844673157\n",
      "epoch 13 loss: 0.14470204710960388\n",
      "epoch 14 loss: 0.22258687019348145\n",
      "epoch 15 loss: 0.1420428603887558\n",
      "epoch 16 loss: 0.20129872858524323\n",
      "epoch 17 loss: 0.14505906403064728\n",
      "epoch 18 loss: 0.178523451089859\n",
      "epoch 19 loss: 0.1746419221162796\n",
      "epoch 20 loss: 0.20898282527923584\n",
      "epoch 21 loss: 0.1581159085035324\n",
      "epoch 22 loss: 0.13186109066009521\n",
      "epoch 23 loss: 0.14467132091522217\n",
      "epoch 24 loss: 0.12968987226486206\n",
      "epoch 25 loss: 0.1501961499452591\n",
      "epoch 26 loss: 0.12038974463939667\n",
      "epoch 27 loss: 0.11507409065961838\n",
      "epoch 28 loss: 0.14171209931373596\n",
      "epoch 29 loss: 0.128609299659729\n",
      "epoch 30 loss: 0.10985186696052551\n",
      "13\n",
      "epoch 1 loss: 0.7360007166862488\n",
      "epoch 2 loss: 0.7479988932609558\n",
      "epoch 3 loss: 0.44078677892684937\n",
      "epoch 4 loss: 0.2472001165151596\n",
      "epoch 5 loss: 0.20410753786563873\n",
      "epoch 6 loss: 0.20258480310440063\n",
      "epoch 7 loss: 0.22925154864788055\n",
      "epoch 8 loss: 0.17633818089962006\n",
      "epoch 9 loss: 0.16831010580062866\n",
      "epoch 10 loss: 0.18458102643489838\n",
      "epoch 11 loss: 0.17715534567832947\n",
      "epoch 12 loss: 0.24336044490337372\n",
      "epoch 13 loss: 0.1407259702682495\n",
      "epoch 14 loss: 0.19016343355178833\n",
      "epoch 15 loss: 0.1464572548866272\n",
      "epoch 16 loss: 0.16863839328289032\n",
      "epoch 17 loss: 0.172607883810997\n",
      "epoch 18 loss: 0.13602067530155182\n",
      "epoch 19 loss: 0.12561649084091187\n",
      "epoch 20 loss: 0.11733978986740112\n",
      "epoch 21 loss: 0.11530221998691559\n",
      "epoch 22 loss: 0.11903035640716553\n",
      "epoch 23 loss: 0.16008873283863068\n",
      "epoch 24 loss: 0.09904040396213531\n",
      "epoch 25 loss: 0.11505872756242752\n",
      "epoch 26 loss: 0.11310948431491852\n",
      "epoch 27 loss: 0.10098847001791\n",
      "epoch 28 loss: 0.0988960713148117\n",
      "epoch 29 loss: 0.10311616212129593\n",
      "epoch 30 loss: 0.08667901903390884\n",
      "14\n",
      "epoch 1 loss: 0.8979426026344299\n",
      "epoch 2 loss: 0.9399335980415344\n",
      "epoch 3 loss: 0.5444139838218689\n",
      "epoch 4 loss: 0.24714037775993347\n",
      "epoch 5 loss: 0.2013462483882904\n",
      "epoch 6 loss: 0.22700251638889313\n",
      "epoch 7 loss: 0.21610863506793976\n",
      "epoch 8 loss: 0.18767906725406647\n",
      "epoch 9 loss: 0.2022392302751541\n",
      "epoch 10 loss: 0.17072694003582\n",
      "epoch 11 loss: 0.19407925009727478\n",
      "epoch 12 loss: 0.17338763177394867\n",
      "epoch 13 loss: 0.18123143911361694\n",
      "epoch 14 loss: 0.16051863133907318\n",
      "epoch 15 loss: 0.19541087746620178\n",
      "epoch 16 loss: 0.162701815366745\n",
      "epoch 17 loss: 0.15276195108890533\n",
      "epoch 18 loss: 0.15978588163852692\n",
      "epoch 19 loss: 0.13229119777679443\n",
      "epoch 20 loss: 0.13772693276405334\n",
      "epoch 21 loss: 0.09797375649213791\n",
      "epoch 22 loss: 0.12845151126384735\n",
      "epoch 23 loss: 0.10257738083600998\n",
      "epoch 24 loss: 0.13585200905799866\n",
      "epoch 25 loss: 0.11461904644966125\n",
      "epoch 26 loss: 0.10272471606731415\n",
      "epoch 27 loss: 0.14657659828662872\n",
      "epoch 28 loss: 0.12217281758785248\n",
      "epoch 29 loss: 0.11513906717300415\n",
      "epoch 30 loss: 0.1406306028366089\n",
      "15\n",
      "epoch 1 loss: 0.6634772419929504\n",
      "epoch 2 loss: 0.45352107286453247\n",
      "epoch 3 loss: 0.28100812435150146\n",
      "epoch 4 loss: 0.2653715908527374\n",
      "epoch 5 loss: 0.18633081018924713\n",
      "epoch 6 loss: 0.19895438849925995\n",
      "epoch 7 loss: 0.22125251591205597\n",
      "epoch 8 loss: 0.22058479487895966\n",
      "epoch 9 loss: 0.1693088412284851\n",
      "epoch 10 loss: 0.1996861696243286\n",
      "epoch 11 loss: 0.18614664673805237\n",
      "epoch 12 loss: 0.17049163579940796\n",
      "epoch 13 loss: 0.1560673862695694\n",
      "epoch 14 loss: 0.17400018870830536\n",
      "epoch 15 loss: 0.15726138651371002\n",
      "epoch 16 loss: 0.20229275524616241\n",
      "epoch 17 loss: 0.18551842868328094\n",
      "epoch 18 loss: 0.2515052258968353\n",
      "epoch 19 loss: 0.1952270120382309\n",
      "epoch 20 loss: 0.15314775705337524\n",
      "epoch 21 loss: 0.21218279004096985\n",
      "epoch 22 loss: 0.14845745265483856\n",
      "epoch 23 loss: 0.1372029036283493\n",
      "epoch 24 loss: 0.16945990920066833\n",
      "epoch 25 loss: 0.11322980374097824\n",
      "epoch 26 loss: 0.15479853749275208\n",
      "epoch 27 loss: 0.13358689844608307\n",
      "epoch 28 loss: 0.1234959289431572\n",
      "epoch 29 loss: 0.15912453830242157\n",
      "epoch 30 loss: 0.16496743261814117\n",
      "16\n",
      "epoch 1 loss: 0.8803467154502869\n",
      "epoch 2 loss: 0.7193241715431213\n",
      "epoch 3 loss: 0.7754942178726196\n",
      "epoch 4 loss: 0.46800824999809265\n",
      "epoch 5 loss: 0.26534581184387207\n",
      "epoch 6 loss: 0.2803804576396942\n",
      "epoch 7 loss: 0.18068084120750427\n",
      "epoch 8 loss: 0.1676676720380783\n",
      "epoch 9 loss: 0.19693070650100708\n",
      "epoch 10 loss: 0.17204025387763977\n",
      "epoch 11 loss: 0.14921674132347107\n",
      "epoch 12 loss: 0.20413032174110413\n",
      "epoch 13 loss: 0.16647009551525116\n",
      "epoch 14 loss: 0.18702980875968933\n",
      "epoch 15 loss: 0.15110105276107788\n",
      "epoch 16 loss: 0.1845967173576355\n",
      "epoch 17 loss: 0.18542006611824036\n",
      "epoch 18 loss: 0.18332070112228394\n",
      "epoch 19 loss: 0.15779028832912445\n",
      "epoch 20 loss: 0.14794643223285675\n",
      "epoch 21 loss: 0.184743732213974\n",
      "epoch 22 loss: 0.17315776646137238\n",
      "epoch 23 loss: 0.19892771542072296\n",
      "epoch 24 loss: 0.1818147450685501\n",
      "epoch 25 loss: 0.14951202273368835\n",
      "epoch 26 loss: 0.17268899083137512\n",
      "epoch 27 loss: 0.18002133071422577\n",
      "epoch 28 loss: 0.16242486238479614\n",
      "epoch 29 loss: 0.1339380294084549\n",
      "epoch 30 loss: 0.1334424912929535\n",
      "17\n",
      "epoch 1 loss: 0.9093430042266846\n",
      "epoch 2 loss: 0.5697585940361023\n",
      "epoch 3 loss: 0.4119068682193756\n",
      "epoch 4 loss: 0.2388557493686676\n",
      "epoch 5 loss: 0.21769697964191437\n",
      "epoch 6 loss: 0.20199955999851227\n",
      "epoch 7 loss: 0.17222850024700165\n",
      "epoch 8 loss: 0.20141233503818512\n",
      "epoch 9 loss: 0.1993212252855301\n",
      "epoch 10 loss: 0.1987278014421463\n",
      "epoch 11 loss: 0.1659257709980011\n",
      "epoch 12 loss: 0.1806163191795349\n",
      "epoch 13 loss: 0.16564582288265228\n",
      "epoch 14 loss: 0.19987207651138306\n",
      "epoch 15 loss: 0.19579696655273438\n",
      "epoch 16 loss: 0.1636544018983841\n",
      "epoch 17 loss: 0.1707804799079895\n",
      "epoch 18 loss: 0.1889123022556305\n",
      "epoch 19 loss: 0.17803972959518433\n",
      "epoch 20 loss: 0.19923673570156097\n",
      "epoch 21 loss: 0.1551651507616043\n",
      "epoch 22 loss: 0.14257916808128357\n",
      "epoch 23 loss: 0.13930125534534454\n",
      "epoch 24 loss: 0.17629565298557281\n",
      "epoch 25 loss: 0.15660393238067627\n",
      "epoch 26 loss: 0.12683039903640747\n",
      "epoch 27 loss: 0.11452127248048782\n",
      "epoch 28 loss: 0.12716881930828094\n",
      "epoch 29 loss: 0.13087204098701477\n",
      "epoch 30 loss: 0.14520792663097382\n",
      "18\n",
      "epoch 1 loss: 0.9118533730506897\n",
      "epoch 2 loss: 0.6799190640449524\n",
      "epoch 3 loss: 0.8271002769470215\n",
      "epoch 4 loss: 0.636225163936615\n",
      "epoch 5 loss: 0.295567125082016\n",
      "epoch 6 loss: 0.23671044409275055\n",
      "epoch 7 loss: 0.21927402913570404\n",
      "epoch 8 loss: 0.18698212504386902\n",
      "epoch 9 loss: 0.2040460705757141\n",
      "epoch 10 loss: 0.22053764760494232\n",
      "epoch 11 loss: 0.18634307384490967\n",
      "epoch 12 loss: 0.22327959537506104\n",
      "epoch 13 loss: 0.19389604032039642\n",
      "epoch 14 loss: 0.20804131031036377\n",
      "epoch 15 loss: 0.1931246668100357\n",
      "epoch 16 loss: 0.21321450173854828\n",
      "epoch 17 loss: 0.16672159731388092\n",
      "epoch 18 loss: 0.19903987646102905\n",
      "epoch 19 loss: 0.1613900065422058\n",
      "epoch 20 loss: 0.14577209949493408\n",
      "epoch 21 loss: 0.18387359380722046\n",
      "epoch 22 loss: 0.19421546161174774\n",
      "epoch 23 loss: 0.14640003442764282\n",
      "epoch 24 loss: 0.13945600390434265\n",
      "epoch 25 loss: 0.2023029923439026\n",
      "epoch 26 loss: 0.16390541195869446\n",
      "epoch 27 loss: 0.11772385239601135\n",
      "epoch 28 loss: 0.1583726406097412\n",
      "epoch 29 loss: 0.12849974632263184\n",
      "epoch 30 loss: 0.10987283289432526\n",
      "19\n",
      "epoch 1 loss: 0.8148210048675537\n",
      "epoch 2 loss: 0.6676405072212219\n",
      "epoch 3 loss: 0.39763039350509644\n",
      "epoch 4 loss: 0.28169184923171997\n",
      "epoch 5 loss: 0.23371289670467377\n",
      "epoch 6 loss: 0.23433968424797058\n",
      "epoch 7 loss: 0.19781185686588287\n",
      "epoch 8 loss: 0.1810271441936493\n",
      "epoch 9 loss: 0.20601148903369904\n",
      "epoch 10 loss: 0.21095848083496094\n",
      "epoch 11 loss: 0.15831634402275085\n",
      "epoch 12 loss: 0.17751264572143555\n",
      "epoch 13 loss: 0.19492322206497192\n",
      "epoch 14 loss: 0.18131890892982483\n",
      "epoch 15 loss: 0.22677528858184814\n",
      "epoch 16 loss: 0.17800386250019073\n",
      "epoch 17 loss: 0.18753518164157867\n",
      "epoch 18 loss: 0.1874794214963913\n",
      "epoch 19 loss: 0.2067125290632248\n",
      "epoch 20 loss: 0.17209959030151367\n",
      "epoch 21 loss: 0.20873235166072845\n",
      "epoch 22 loss: 0.1898384988307953\n",
      "epoch 23 loss: 0.20085619390010834\n",
      "epoch 24 loss: 0.1947893649339676\n",
      "epoch 25 loss: 0.15569865703582764\n",
      "epoch 26 loss: 0.15248626470565796\n",
      "epoch 27 loss: 0.13368292152881622\n",
      "epoch 28 loss: 0.16621588170528412\n",
      "epoch 29 loss: 0.17846430838108063\n",
      "epoch 30 loss: 0.1421782374382019\n",
      "20\n",
      "epoch 1 loss: 0.7891700863838196\n",
      "epoch 2 loss: 0.5109056234359741\n",
      "epoch 3 loss: 0.32504311203956604\n",
      "epoch 4 loss: 0.2406725287437439\n",
      "epoch 5 loss: 0.1993415355682373\n",
      "epoch 6 loss: 0.21038788557052612\n",
      "epoch 7 loss: 0.1618405431509018\n",
      "epoch 8 loss: 0.21551848948001862\n",
      "epoch 9 loss: 0.14700838923454285\n",
      "epoch 10 loss: 0.17083203792572021\n",
      "epoch 11 loss: 0.17600378394126892\n",
      "epoch 12 loss: 0.2106987088918686\n",
      "epoch 13 loss: 0.17212416231632233\n",
      "epoch 14 loss: 0.21540628373622894\n",
      "epoch 15 loss: 0.16039559245109558\n",
      "epoch 16 loss: 0.16221065819263458\n",
      "epoch 17 loss: 0.17729374766349792\n",
      "epoch 18 loss: 0.1737987995147705\n",
      "epoch 19 loss: 0.1739417016506195\n",
      "epoch 20 loss: 0.14377768337726593\n",
      "epoch 21 loss: 0.14405390620231628\n",
      "epoch 22 loss: 0.14080166816711426\n",
      "epoch 23 loss: 0.1363983303308487\n",
      "epoch 24 loss: 0.18010291457176208\n",
      "epoch 25 loss: 0.14044150710105896\n",
      "epoch 26 loss: 0.12175000458955765\n",
      "epoch 27 loss: 0.14800803363323212\n",
      "epoch 28 loss: 0.1363585740327835\n",
      "epoch 29 loss: 0.09713511168956757\n",
      "epoch 30 loss: 0.09786911308765411\n",
      "21\n",
      "epoch 1 loss: 0.7315469980239868\n",
      "epoch 2 loss: 0.5744761824607849\n",
      "epoch 3 loss: 0.35886746644973755\n",
      "epoch 4 loss: 0.24547289311885834\n",
      "epoch 5 loss: 0.21084783971309662\n",
      "epoch 6 loss: 0.18474453687667847\n",
      "epoch 7 loss: 0.2316400110721588\n",
      "epoch 8 loss: 0.1875300109386444\n",
      "epoch 9 loss: 0.18272383511066437\n",
      "epoch 10 loss: 0.20643240213394165\n",
      "epoch 11 loss: 0.1771809458732605\n",
      "epoch 12 loss: 0.1715954840183258\n",
      "epoch 13 loss: 0.16088971495628357\n",
      "epoch 14 loss: 0.22064025700092316\n",
      "epoch 15 loss: 0.14321482181549072\n",
      "epoch 16 loss: 0.20237745344638824\n",
      "epoch 17 loss: 0.12991957366466522\n",
      "epoch 18 loss: 0.19091859459877014\n",
      "epoch 19 loss: 0.20617857575416565\n",
      "epoch 20 loss: 0.15001264214515686\n",
      "epoch 21 loss: 0.16268068552017212\n",
      "epoch 22 loss: 0.19046065211296082\n",
      "epoch 23 loss: 0.1668618768453598\n",
      "epoch 24 loss: 0.16258883476257324\n",
      "epoch 25 loss: 0.11782431602478027\n",
      "epoch 26 loss: 0.10774281620979309\n",
      "epoch 27 loss: 0.14019887149333954\n",
      "epoch 28 loss: 0.1467379331588745\n",
      "epoch 29 loss: 0.15528319776058197\n",
      "epoch 30 loss: 0.14397257566452026\n",
      "22\n",
      "epoch 1 loss: 0.6703531742095947\n",
      "epoch 2 loss: 0.7214047312736511\n",
      "epoch 3 loss: 0.5154951810836792\n",
      "epoch 4 loss: 0.256615549325943\n",
      "epoch 5 loss: 0.22348548471927643\n",
      "epoch 6 loss: 0.20064528286457062\n",
      "epoch 7 loss: 0.2557706832885742\n",
      "epoch 8 loss: 0.2005724310874939\n",
      "epoch 9 loss: 0.1911654770374298\n",
      "epoch 10 loss: 0.1798856258392334\n",
      "epoch 11 loss: 0.19822068512439728\n",
      "epoch 12 loss: 0.16330747306346893\n",
      "epoch 13 loss: 0.17907021939754486\n",
      "epoch 14 loss: 0.18333621323108673\n",
      "epoch 15 loss: 0.17238649725914001\n",
      "epoch 16 loss: 0.1923729032278061\n",
      "epoch 17 loss: 0.22150780260562897\n",
      "epoch 18 loss: 0.16895657777786255\n",
      "epoch 19 loss: 0.17763449251651764\n",
      "epoch 20 loss: 0.16619457304477692\n",
      "epoch 21 loss: 0.1713288128376007\n",
      "epoch 22 loss: 0.184787780046463\n",
      "epoch 23 loss: 0.21952416002750397\n",
      "epoch 24 loss: 0.22688183188438416\n",
      "epoch 25 loss: 0.16378237307071686\n",
      "epoch 26 loss: 0.1893494576215744\n",
      "epoch 27 loss: 0.1398444026708603\n",
      "epoch 28 loss: 0.1728239506483078\n",
      "epoch 29 loss: 0.2048276662826538\n",
      "epoch 30 loss: 0.15658050775527954\n",
      "23\n",
      "epoch 1 loss: 0.780812680721283\n",
      "epoch 2 loss: 0.5959789156913757\n",
      "epoch 3 loss: 0.2771988809108734\n",
      "epoch 4 loss: 0.2279558777809143\n",
      "epoch 5 loss: 0.1964961439371109\n",
      "epoch 6 loss: 0.1782822459936142\n",
      "epoch 7 loss: 0.1931135207414627\n",
      "epoch 8 loss: 0.23007731139659882\n",
      "epoch 9 loss: 0.16696125268936157\n",
      "epoch 10 loss: 0.1673857867717743\n",
      "epoch 11 loss: 0.17933033406734467\n",
      "epoch 12 loss: 0.1724887490272522\n",
      "epoch 13 loss: 0.1763167679309845\n",
      "epoch 14 loss: 0.15190532803535461\n",
      "epoch 15 loss: 0.11712603271007538\n",
      "epoch 16 loss: 0.1286601424217224\n",
      "epoch 17 loss: 0.16210079193115234\n",
      "epoch 18 loss: 0.13727326691150665\n",
      "epoch 19 loss: 0.17662431299686432\n",
      "epoch 20 loss: 0.13155828416347504\n",
      "epoch 21 loss: 0.19938652217388153\n",
      "epoch 22 loss: 0.14590966701507568\n",
      "epoch 23 loss: 0.12223517894744873\n",
      "epoch 24 loss: 0.1496804654598236\n",
      "epoch 25 loss: 0.14475934207439423\n",
      "epoch 26 loss: 0.1254141926765442\n",
      "epoch 27 loss: 0.17651359736919403\n",
      "epoch 28 loss: 0.10141918063163757\n",
      "epoch 29 loss: 0.1039927527308464\n",
      "epoch 30 loss: 0.11215177178382874\n",
      "24\n",
      "epoch 1 loss: 1.001517653465271\n",
      "epoch 2 loss: 1.0313769578933716\n",
      "epoch 3 loss: 0.5352692604064941\n",
      "epoch 4 loss: 0.3102349638938904\n",
      "epoch 5 loss: 0.23608417809009552\n",
      "epoch 6 loss: 0.21174141764640808\n",
      "epoch 7 loss: 0.23248283565044403\n",
      "epoch 8 loss: 0.18214403092861176\n",
      "epoch 9 loss: 0.1617887169122696\n",
      "epoch 10 loss: 0.19960853457450867\n",
      "epoch 11 loss: 0.1806442141532898\n",
      "epoch 12 loss: 0.16580452024936676\n",
      "epoch 13 loss: 0.1692115217447281\n",
      "epoch 14 loss: 0.1707042157649994\n",
      "epoch 15 loss: 0.16047409176826477\n",
      "epoch 16 loss: 0.1872926503419876\n",
      "epoch 17 loss: 0.10128071904182434\n",
      "epoch 18 loss: 0.11670196056365967\n",
      "epoch 19 loss: 0.10408508777618408\n",
      "epoch 20 loss: 0.13381510972976685\n",
      "epoch 21 loss: 0.13113661110401154\n",
      "epoch 22 loss: 0.1329849809408188\n",
      "epoch 23 loss: 0.1108749732375145\n",
      "epoch 24 loss: 0.1288229376077652\n",
      "epoch 25 loss: 0.11725059151649475\n",
      "epoch 26 loss: 0.10614357888698578\n",
      "epoch 27 loss: 0.12319657951593399\n",
      "epoch 28 loss: 0.10534953325986862\n",
      "epoch 29 loss: 0.1397377997636795\n",
      "epoch 30 loss: 0.11182035505771637\n",
      "25\n",
      "epoch 1 loss: 0.7858855724334717\n",
      "epoch 2 loss: 0.45329874753952026\n",
      "epoch 3 loss: 0.31704282760620117\n",
      "epoch 4 loss: 0.2816351652145386\n",
      "epoch 5 loss: 0.23055844008922577\n",
      "epoch 6 loss: 0.231197789311409\n",
      "epoch 7 loss: 0.17877142131328583\n",
      "epoch 8 loss: 0.18082904815673828\n",
      "epoch 9 loss: 0.2369389683008194\n",
      "epoch 10 loss: 0.2045937329530716\n",
      "epoch 11 loss: 0.21149541437625885\n",
      "epoch 12 loss: 0.16628898680210114\n",
      "epoch 13 loss: 0.21676872670650482\n",
      "epoch 14 loss: 0.2074662148952484\n",
      "epoch 15 loss: 0.20153439044952393\n",
      "epoch 16 loss: 0.16145604848861694\n",
      "epoch 17 loss: 0.16614730656147003\n",
      "epoch 18 loss: 0.1730765551328659\n",
      "epoch 19 loss: 0.14455148577690125\n",
      "epoch 20 loss: 0.14471209049224854\n",
      "epoch 21 loss: 0.1485886126756668\n",
      "epoch 22 loss: 0.16612708568572998\n",
      "epoch 23 loss: 0.17937979102134705\n",
      "epoch 24 loss: 0.1373518407344818\n",
      "epoch 25 loss: 0.16104090213775635\n",
      "epoch 26 loss: 0.11617918312549591\n",
      "epoch 27 loss: 0.13651765882968903\n",
      "epoch 28 loss: 0.1192956194281578\n",
      "epoch 29 loss: 0.09317256510257721\n",
      "epoch 30 loss: 0.10059655457735062\n",
      "26\n",
      "epoch 1 loss: 0.8228632211685181\n",
      "epoch 2 loss: 0.9944050908088684\n",
      "epoch 3 loss: 0.6194307208061218\n",
      "epoch 4 loss: 0.29090043902397156\n",
      "epoch 5 loss: 0.21033409237861633\n",
      "epoch 6 loss: 0.24768877029418945\n",
      "epoch 7 loss: 0.19329823553562164\n",
      "epoch 8 loss: 0.17208407819271088\n",
      "epoch 9 loss: 0.1628638356924057\n",
      "epoch 10 loss: 0.20862750709056854\n",
      "epoch 11 loss: 0.20965422689914703\n",
      "epoch 12 loss: 0.18399697542190552\n",
      "epoch 13 loss: 0.18948480486869812\n",
      "epoch 14 loss: 0.17192642390727997\n",
      "epoch 15 loss: 0.24297714233398438\n",
      "epoch 16 loss: 0.16374722123146057\n",
      "epoch 17 loss: 0.1511247754096985\n",
      "epoch 18 loss: 0.14393018186092377\n",
      "epoch 19 loss: 0.1692684143781662\n",
      "epoch 20 loss: 0.12320180237293243\n",
      "epoch 21 loss: 0.1468495875597\n",
      "epoch 22 loss: 0.16342352330684662\n",
      "epoch 23 loss: 0.14956119656562805\n",
      "epoch 24 loss: 0.1355876624584198\n",
      "epoch 25 loss: 0.11366034299135208\n",
      "epoch 26 loss: 0.14212453365325928\n",
      "epoch 27 loss: 0.14027884602546692\n",
      "epoch 28 loss: 0.14257551729679108\n",
      "epoch 29 loss: 0.16149567067623138\n",
      "epoch 30 loss: 0.1282588392496109\n",
      "27\n",
      "epoch 1 loss: 0.7503695487976074\n",
      "epoch 2 loss: 0.6557784080505371\n",
      "epoch 3 loss: 0.8556155562400818\n",
      "epoch 4 loss: 0.8768832683563232\n",
      "epoch 5 loss: 0.44447630643844604\n",
      "epoch 6 loss: 0.2729189097881317\n",
      "epoch 7 loss: 0.19151544570922852\n",
      "epoch 8 loss: 0.21404124796390533\n",
      "epoch 9 loss: 0.19991344213485718\n",
      "epoch 10 loss: 0.17727622389793396\n",
      "epoch 11 loss: 0.19296187162399292\n",
      "epoch 12 loss: 0.21671225130558014\n",
      "epoch 13 loss: 0.175560861825943\n",
      "epoch 14 loss: 0.19538193941116333\n",
      "epoch 15 loss: 0.18407541513442993\n",
      "epoch 16 loss: 0.19449792802333832\n",
      "epoch 17 loss: 0.1653289496898651\n",
      "epoch 18 loss: 0.1598692387342453\n",
      "epoch 19 loss: 0.21090371906757355\n",
      "epoch 20 loss: 0.1287343055009842\n",
      "epoch 21 loss: 0.14402516186237335\n",
      "epoch 22 loss: 0.16179561614990234\n",
      "epoch 23 loss: 0.15383121371269226\n",
      "epoch 24 loss: 0.12353435903787613\n",
      "epoch 25 loss: 0.1406019628047943\n",
      "epoch 26 loss: 0.15670962631702423\n",
      "epoch 27 loss: 0.13849025964736938\n",
      "epoch 28 loss: 0.13104118406772614\n",
      "epoch 29 loss: 0.13928253948688507\n",
      "epoch 30 loss: 0.14019277691841125\n",
      "28\n",
      "epoch 1 loss: 0.6925694942474365\n",
      "epoch 2 loss: 0.44223666191101074\n",
      "epoch 3 loss: 0.2392728477716446\n",
      "epoch 4 loss: 0.2229613959789276\n",
      "epoch 5 loss: 0.18482503294944763\n",
      "epoch 6 loss: 0.18934057652950287\n",
      "epoch 7 loss: 0.145951047539711\n",
      "epoch 8 loss: 0.20775103569030762\n",
      "epoch 9 loss: 0.2040368616580963\n",
      "epoch 10 loss: 0.20070365071296692\n",
      "epoch 11 loss: 0.15000635385513306\n",
      "epoch 12 loss: 0.24039988219738007\n",
      "epoch 13 loss: 0.16110026836395264\n",
      "epoch 14 loss: 0.18255391716957092\n",
      "epoch 15 loss: 0.20392672717571259\n",
      "epoch 16 loss: 0.1626998335123062\n",
      "epoch 17 loss: 0.1656540334224701\n",
      "epoch 18 loss: 0.21558567881584167\n",
      "epoch 19 loss: 0.14547888934612274\n",
      "epoch 20 loss: 0.16120000183582306\n",
      "epoch 21 loss: 0.17072540521621704\n",
      "epoch 22 loss: 0.14952372014522552\n",
      "epoch 23 loss: 0.1399046927690506\n",
      "epoch 24 loss: 0.13457795977592468\n",
      "epoch 25 loss: 0.1474754810333252\n",
      "epoch 26 loss: 0.12272049486637115\n",
      "epoch 27 loss: 0.14042143523693085\n",
      "epoch 28 loss: 0.1821407526731491\n",
      "epoch 29 loss: 0.13352704048156738\n",
      "epoch 30 loss: 0.1184457540512085\n",
      "29\n",
      "epoch 1 loss: 0.7840253114700317\n",
      "epoch 2 loss: 0.6580690145492554\n",
      "epoch 3 loss: 0.3015095591545105\n",
      "epoch 4 loss: 0.18135565519332886\n",
      "epoch 5 loss: 0.19496917724609375\n",
      "epoch 6 loss: 0.1349189430475235\n",
      "epoch 7 loss: 0.1982695609331131\n",
      "epoch 8 loss: 0.18171517550945282\n",
      "epoch 9 loss: 0.18025323748588562\n",
      "epoch 10 loss: 0.19656209647655487\n",
      "epoch 11 loss: 0.21289069950580597\n",
      "epoch 12 loss: 0.21956346929073334\n",
      "epoch 13 loss: 0.1715751588344574\n",
      "epoch 14 loss: 0.15088480710983276\n",
      "epoch 15 loss: 0.12493128329515457\n",
      "epoch 16 loss: 0.14951585233211517\n",
      "epoch 17 loss: 0.1426924169063568\n",
      "epoch 18 loss: 0.17911505699157715\n",
      "epoch 19 loss: 0.14857426285743713\n",
      "epoch 20 loss: 0.14836663007736206\n",
      "epoch 21 loss: 0.24872972071170807\n",
      "epoch 22 loss: 0.12401323020458221\n",
      "epoch 23 loss: 0.13820987939834595\n",
      "epoch 24 loss: 0.10798095911741257\n",
      "epoch 25 loss: 0.12719067931175232\n",
      "epoch 26 loss: 0.11004506051540375\n",
      "epoch 27 loss: 0.12409283220767975\n",
      "epoch 28 loss: 0.11076954752206802\n",
      "epoch 29 loss: 0.0947607234120369\n",
      "epoch 30 loss: 0.124516062438488\n",
      "30\n",
      "epoch 1 loss: 0.7918523550033569\n",
      "epoch 2 loss: 0.5576728582382202\n",
      "epoch 3 loss: 0.4787163734436035\n",
      "epoch 4 loss: 0.2780582010746002\n",
      "epoch 5 loss: 0.22651411592960358\n",
      "epoch 6 loss: 0.1886969804763794\n",
      "epoch 7 loss: 0.17728273570537567\n",
      "epoch 8 loss: 0.203884556889534\n",
      "epoch 9 loss: 0.16531839966773987\n",
      "epoch 10 loss: 0.20190340280532837\n",
      "epoch 11 loss: 0.16132189333438873\n",
      "epoch 12 loss: 0.17187504470348358\n",
      "epoch 13 loss: 0.18136370182037354\n",
      "epoch 14 loss: 0.20131629705429077\n",
      "epoch 15 loss: 0.1664242148399353\n",
      "epoch 16 loss: 0.1851590871810913\n",
      "epoch 17 loss: 0.16700424253940582\n",
      "epoch 18 loss: 0.18042726814746857\n",
      "epoch 19 loss: 0.15328674018383026\n",
      "epoch 20 loss: 0.1672966480255127\n",
      "epoch 21 loss: 0.12811249494552612\n",
      "epoch 22 loss: 0.13722282648086548\n",
      "epoch 23 loss: 0.12956295907497406\n",
      "epoch 24 loss: 0.11127551645040512\n",
      "epoch 25 loss: 0.11602656543254852\n",
      "epoch 26 loss: 0.10229086875915527\n",
      "epoch 27 loss: 0.10614977031946182\n",
      "epoch 28 loss: 0.12021948397159576\n",
      "epoch 29 loss: 0.12374365329742432\n",
      "epoch 30 loss: 0.14005061984062195\n",
      "31\n",
      "epoch 1 loss: 0.8083627820014954\n",
      "epoch 2 loss: 1.1275240182876587\n",
      "epoch 3 loss: 0.9640666842460632\n",
      "epoch 4 loss: 0.4114939570426941\n",
      "epoch 5 loss: 0.25925108790397644\n",
      "epoch 6 loss: 0.20699231326580048\n",
      "epoch 7 loss: 0.19788758456707\n",
      "epoch 8 loss: 0.22509817779064178\n",
      "epoch 9 loss: 0.17496715486049652\n",
      "epoch 10 loss: 0.20177531242370605\n",
      "epoch 11 loss: 0.21558795869350433\n",
      "epoch 12 loss: 0.19970589876174927\n",
      "epoch 13 loss: 0.17952848970890045\n",
      "epoch 14 loss: 0.17128819227218628\n",
      "epoch 15 loss: 0.22304058074951172\n",
      "epoch 16 loss: 0.18633471429347992\n",
      "epoch 17 loss: 0.19905324280261993\n",
      "epoch 18 loss: 0.16861271858215332\n",
      "epoch 19 loss: 0.15097828209400177\n",
      "epoch 20 loss: 0.14913126826286316\n",
      "epoch 21 loss: 0.16549308598041534\n",
      "epoch 22 loss: 0.2237159162759781\n",
      "epoch 23 loss: 0.12925294041633606\n",
      "epoch 24 loss: 0.1492069810628891\n",
      "epoch 25 loss: 0.1364642083644867\n",
      "epoch 26 loss: 0.18682728707790375\n",
      "epoch 27 loss: 0.14657007157802582\n",
      "epoch 28 loss: 0.1444028913974762\n",
      "epoch 29 loss: 0.15636274218559265\n",
      "epoch 30 loss: 0.14859232306480408\n",
      "32\n",
      "epoch 1 loss: 0.9526758193969727\n",
      "epoch 2 loss: 0.7604222893714905\n",
      "epoch 3 loss: 0.4048435389995575\n",
      "epoch 4 loss: 0.28796109557151794\n",
      "epoch 5 loss: 0.23758505284786224\n",
      "epoch 6 loss: 0.23576799035072327\n",
      "epoch 7 loss: 0.17441785335540771\n",
      "epoch 8 loss: 0.20909537374973297\n",
      "epoch 9 loss: 0.19214478135108948\n",
      "epoch 10 loss: 0.19988428056240082\n",
      "epoch 11 loss: 0.16694600880146027\n",
      "epoch 12 loss: 0.17130497097969055\n",
      "epoch 13 loss: 0.22467781603336334\n",
      "epoch 14 loss: 0.2353101670742035\n",
      "epoch 15 loss: 0.1731574386358261\n",
      "epoch 16 loss: 0.13727861642837524\n",
      "epoch 17 loss: 0.17252188920974731\n",
      "epoch 18 loss: 0.16505426168441772\n",
      "epoch 19 loss: 0.18465258181095123\n",
      "epoch 20 loss: 0.19702109694480896\n",
      "epoch 21 loss: 0.15841785073280334\n",
      "epoch 22 loss: 0.12621822953224182\n",
      "epoch 23 loss: 0.16484355926513672\n",
      "epoch 24 loss: 0.1350090354681015\n",
      "epoch 25 loss: 0.15019649267196655\n",
      "epoch 26 loss: 0.1266561597585678\n",
      "epoch 27 loss: 0.13767585158348083\n",
      "epoch 28 loss: 0.11622016876935959\n",
      "epoch 29 loss: 0.11114563792943954\n",
      "epoch 30 loss: 0.1338673084974289\n",
      "33\n",
      "epoch 1 loss: 0.8633355498313904\n",
      "epoch 2 loss: 0.5310015678405762\n",
      "epoch 3 loss: 0.3800123631954193\n",
      "epoch 4 loss: 0.23100391030311584\n",
      "epoch 5 loss: 0.22968974709510803\n",
      "epoch 6 loss: 0.19163887202739716\n",
      "epoch 7 loss: 0.23318974673748016\n",
      "epoch 8 loss: 0.1644224375486374\n",
      "epoch 9 loss: 0.18365542590618134\n",
      "epoch 10 loss: 0.18553794920444489\n",
      "epoch 11 loss: 0.1952952891588211\n",
      "epoch 12 loss: 0.17040011286735535\n",
      "epoch 13 loss: 0.16796398162841797\n",
      "epoch 14 loss: 0.1465255171060562\n",
      "epoch 15 loss: 0.16893048584461212\n",
      "epoch 16 loss: 0.14355145394802094\n",
      "epoch 17 loss: 0.1122218444943428\n",
      "epoch 18 loss: 0.11734815686941147\n",
      "epoch 19 loss: 0.170293390750885\n",
      "epoch 20 loss: 0.13114449381828308\n",
      "epoch 21 loss: 0.1144377589225769\n",
      "epoch 22 loss: 0.10950395464897156\n",
      "epoch 23 loss: 0.11316058039665222\n",
      "epoch 24 loss: 0.14759422838687897\n",
      "epoch 25 loss: 0.10183829814195633\n",
      "epoch 26 loss: 0.10549050569534302\n",
      "epoch 27 loss: 0.11323854327201843\n",
      "epoch 28 loss: 0.1275252103805542\n",
      "epoch 29 loss: 0.16732163727283478\n",
      "epoch 30 loss: 0.11736378818750381\n",
      "34\n",
      "epoch 1 loss: 0.9099329710006714\n",
      "epoch 2 loss: 0.6854923963546753\n",
      "epoch 3 loss: 0.3279823064804077\n",
      "epoch 4 loss: 0.2545689344406128\n",
      "epoch 5 loss: 0.21345975995063782\n",
      "epoch 6 loss: 0.21145255863666534\n",
      "epoch 7 loss: 0.19747573137283325\n",
      "epoch 8 loss: 0.2036585807800293\n",
      "epoch 9 loss: 0.1692497432231903\n",
      "epoch 10 loss: 0.21181419491767883\n",
      "epoch 11 loss: 0.22967389225959778\n",
      "epoch 12 loss: 0.17691682279109955\n",
      "epoch 13 loss: 0.19331811368465424\n",
      "epoch 14 loss: 0.20664513111114502\n",
      "epoch 15 loss: 0.16330093145370483\n",
      "epoch 16 loss: 0.14626003801822662\n",
      "epoch 17 loss: 0.14767105877399445\n",
      "epoch 18 loss: 0.19216245412826538\n",
      "epoch 19 loss: 0.13868629932403564\n",
      "epoch 20 loss: 0.2109663486480713\n",
      "epoch 21 loss: 0.1882941722869873\n",
      "epoch 22 loss: 0.14465190470218658\n",
      "epoch 23 loss: 0.13390910625457764\n",
      "epoch 24 loss: 0.15276597440242767\n",
      "epoch 25 loss: 0.14060384035110474\n",
      "epoch 26 loss: 0.1539067029953003\n",
      "epoch 27 loss: 0.11834651976823807\n",
      "epoch 28 loss: 0.12764355540275574\n",
      "epoch 29 loss: 0.11008157581090927\n",
      "epoch 30 loss: 0.10929660499095917\n",
      "35\n",
      "epoch 1 loss: 0.8241315484046936\n",
      "epoch 2 loss: 0.5175703167915344\n",
      "epoch 3 loss: 0.35887008905410767\n",
      "epoch 4 loss: 0.2515811324119568\n",
      "epoch 5 loss: 0.24715222418308258\n",
      "epoch 6 loss: 0.24910646677017212\n",
      "epoch 7 loss: 0.24892257153987885\n",
      "epoch 8 loss: 0.21552181243896484\n",
      "epoch 9 loss: 0.20900754630565643\n",
      "epoch 10 loss: 0.24679923057556152\n",
      "epoch 11 loss: 0.18869507312774658\n",
      "epoch 12 loss: 0.20269137620925903\n",
      "epoch 13 loss: 0.18528147041797638\n",
      "epoch 14 loss: 0.15561392903327942\n",
      "epoch 15 loss: 0.18957750499248505\n",
      "epoch 16 loss: 0.17551855742931366\n",
      "epoch 17 loss: 0.17203092575073242\n",
      "epoch 18 loss: 0.18690210580825806\n",
      "epoch 19 loss: 0.1901656836271286\n",
      "epoch 20 loss: 0.19859835505485535\n",
      "epoch 21 loss: 0.19871269166469574\n",
      "epoch 22 loss: 0.1544436663389206\n",
      "epoch 23 loss: 0.19676075875759125\n",
      "epoch 24 loss: 0.19041666388511658\n",
      "epoch 25 loss: 0.170948326587677\n",
      "epoch 26 loss: 0.1719292402267456\n",
      "epoch 27 loss: 0.1549641489982605\n",
      "epoch 28 loss: 0.16022858023643494\n",
      "epoch 29 loss: 0.14801029860973358\n",
      "epoch 30 loss: 0.14196260273456573\n",
      "36\n",
      "epoch 1 loss: 0.963762640953064\n",
      "epoch 2 loss: 0.7037447690963745\n",
      "epoch 3 loss: 0.3753736615180969\n",
      "epoch 4 loss: 0.26745104789733887\n",
      "epoch 5 loss: 0.27706560492515564\n",
      "epoch 6 loss: 0.26471057534217834\n",
      "epoch 7 loss: 0.23202520608901978\n",
      "epoch 8 loss: 0.1627275049686432\n",
      "epoch 9 loss: 0.19897735118865967\n",
      "epoch 10 loss: 0.19374506175518036\n",
      "epoch 11 loss: 0.15261805057525635\n",
      "epoch 12 loss: 0.19864585995674133\n",
      "epoch 13 loss: 0.21019446849822998\n",
      "epoch 14 loss: 0.19088885188102722\n",
      "epoch 15 loss: 0.19137042760849\n",
      "epoch 16 loss: 0.17450539767742157\n",
      "epoch 17 loss: 0.13779838383197784\n",
      "epoch 18 loss: 0.1901693493127823\n",
      "epoch 19 loss: 0.1573208123445511\n",
      "epoch 20 loss: 0.18776214122772217\n",
      "epoch 21 loss: 0.1558081954717636\n",
      "epoch 22 loss: 0.12467357516288757\n",
      "epoch 23 loss: 0.15430501103401184\n",
      "epoch 24 loss: 0.1749258190393448\n",
      "epoch 25 loss: 0.158966526389122\n",
      "epoch 26 loss: 0.13355915248394012\n",
      "epoch 27 loss: 0.11466385424137115\n",
      "epoch 28 loss: 0.12325580418109894\n",
      "epoch 29 loss: 0.2103615403175354\n",
      "epoch 30 loss: 0.12927725911140442\n",
      "37\n",
      "epoch 1 loss: 0.714221179485321\n",
      "epoch 2 loss: 0.823523759841919\n",
      "epoch 3 loss: 0.513353168964386\n",
      "epoch 4 loss: 0.32897061109542847\n",
      "epoch 5 loss: 0.21044965088367462\n",
      "epoch 6 loss: 0.17697638273239136\n",
      "epoch 7 loss: 0.19163523614406586\n",
      "epoch 8 loss: 0.20408278703689575\n",
      "epoch 9 loss: 0.2266550362110138\n",
      "epoch 10 loss: 0.16693636775016785\n",
      "epoch 11 loss: 0.17693544924259186\n",
      "epoch 12 loss: 0.1970381736755371\n",
      "epoch 13 loss: 0.1903771311044693\n",
      "epoch 14 loss: 0.2067583054304123\n",
      "epoch 15 loss: 0.14239011704921722\n",
      "epoch 16 loss: 0.258952260017395\n",
      "epoch 17 loss: 0.17956607043743134\n",
      "epoch 18 loss: 0.12522464990615845\n",
      "epoch 19 loss: 0.13167911767959595\n",
      "epoch 20 loss: 0.13200591504573822\n",
      "epoch 21 loss: 0.11558040231466293\n",
      "epoch 22 loss: 0.1056119054555893\n",
      "epoch 23 loss: 0.12566708028316498\n",
      "epoch 24 loss: 0.12053876370191574\n",
      "epoch 25 loss: 0.11475518345832825\n",
      "epoch 26 loss: 0.11467524617910385\n",
      "epoch 27 loss: 0.1450541764497757\n",
      "epoch 28 loss: 0.09183286875486374\n",
      "epoch 29 loss: 0.10413961857557297\n",
      "epoch 30 loss: 0.10321979969739914\n",
      "38\n",
      "epoch 1 loss: 0.8480466604232788\n",
      "epoch 2 loss: 0.7515355944633484\n",
      "epoch 3 loss: 0.9135771989822388\n",
      "epoch 4 loss: 0.6405791640281677\n",
      "epoch 5 loss: 0.38052213191986084\n",
      "epoch 6 loss: 0.2618281841278076\n",
      "epoch 7 loss: 0.17190474271774292\n",
      "epoch 8 loss: 0.21237102150917053\n",
      "epoch 9 loss: 0.16911648213863373\n",
      "epoch 10 loss: 0.19265976548194885\n",
      "epoch 11 loss: 0.2040475457906723\n",
      "epoch 12 loss: 0.18029041588306427\n",
      "epoch 13 loss: 0.2001393437385559\n",
      "epoch 14 loss: 0.15599390864372253\n",
      "epoch 15 loss: 0.1787630170583725\n",
      "epoch 16 loss: 0.1658947914838791\n",
      "epoch 17 loss: 0.18252421915531158\n",
      "epoch 18 loss: 0.14365653693675995\n",
      "epoch 19 loss: 0.21032318472862244\n",
      "epoch 20 loss: 0.1365208923816681\n",
      "epoch 21 loss: 0.20705993473529816\n",
      "epoch 22 loss: 0.14081677794456482\n",
      "epoch 23 loss: 0.11563878506422043\n",
      "epoch 24 loss: 0.13515758514404297\n",
      "epoch 25 loss: 0.12896728515625\n",
      "epoch 26 loss: 0.14883631467819214\n",
      "epoch 27 loss: 0.13875703513622284\n",
      "epoch 28 loss: 0.11161414533853531\n",
      "epoch 29 loss: 0.14360201358795166\n",
      "epoch 30 loss: 0.12277037650346756\n",
      "39\n",
      "epoch 1 loss: 0.79604172706604\n",
      "epoch 2 loss: 0.4495128393173218\n",
      "epoch 3 loss: 0.2410491555929184\n",
      "epoch 4 loss: 0.2656717002391815\n",
      "epoch 5 loss: 0.21279184520244598\n",
      "epoch 6 loss: 0.19237969815731049\n",
      "epoch 7 loss: 0.19343143701553345\n",
      "epoch 8 loss: 0.1431943029165268\n",
      "epoch 9 loss: 0.22506487369537354\n",
      "epoch 10 loss: 0.2335025668144226\n",
      "epoch 11 loss: 0.17623308300971985\n",
      "epoch 12 loss: 0.17424750328063965\n",
      "epoch 13 loss: 0.17494814097881317\n",
      "epoch 14 loss: 0.21950922906398773\n",
      "epoch 15 loss: 0.2207501381635666\n",
      "epoch 16 loss: 0.17142139375209808\n",
      "epoch 17 loss: 0.17866955697536469\n",
      "epoch 18 loss: 0.16577984392642975\n",
      "epoch 19 loss: 0.18635529279708862\n",
      "epoch 20 loss: 0.16488727927207947\n",
      "epoch 21 loss: 0.1427297443151474\n",
      "epoch 22 loss: 0.14713217318058014\n",
      "epoch 23 loss: 0.1660851538181305\n",
      "epoch 24 loss: 0.14810776710510254\n",
      "epoch 25 loss: 0.15065225958824158\n",
      "epoch 26 loss: 0.14271125197410583\n",
      "epoch 27 loss: 0.13542436063289642\n",
      "epoch 28 loss: 0.1269729882478714\n",
      "epoch 29 loss: 0.13222146034240723\n",
      "epoch 30 loss: 0.09611630439758301\n",
      "40\n",
      "epoch 1 loss: 0.7652638554573059\n",
      "epoch 2 loss: 0.5284917950630188\n",
      "epoch 3 loss: 0.2667767107486725\n",
      "epoch 4 loss: 0.2617347836494446\n",
      "epoch 5 loss: 0.17993991076946259\n",
      "epoch 6 loss: 0.17241112887859344\n",
      "epoch 7 loss: 0.19347840547561646\n",
      "epoch 8 loss: 0.16055428981781006\n",
      "epoch 9 loss: 0.19613249599933624\n",
      "epoch 10 loss: 0.16861578822135925\n",
      "epoch 11 loss: 0.19932742416858673\n",
      "epoch 12 loss: 0.18863357603549957\n",
      "epoch 13 loss: 0.17870543897151947\n",
      "epoch 14 loss: 0.18681107461452484\n",
      "epoch 15 loss: 0.1898450255393982\n",
      "epoch 16 loss: 0.1711692363023758\n",
      "epoch 17 loss: 0.1644078642129898\n",
      "epoch 18 loss: 0.16788345575332642\n",
      "epoch 19 loss: 0.16219376027584076\n",
      "epoch 20 loss: 0.10473881661891937\n",
      "epoch 21 loss: 0.127065509557724\n",
      "epoch 22 loss: 0.17526346445083618\n",
      "epoch 23 loss: 0.1681821197271347\n",
      "epoch 24 loss: 0.11260662227869034\n",
      "epoch 25 loss: 0.15234185755252838\n",
      "epoch 26 loss: 0.11575044691562653\n",
      "epoch 27 loss: 0.1304090917110443\n",
      "epoch 28 loss: 0.12983611226081848\n",
      "epoch 29 loss: 0.17555119097232819\n",
      "epoch 30 loss: 0.12195388227701187\n",
      "41\n",
      "epoch 1 loss: 0.8455954194068909\n",
      "epoch 2 loss: 0.5857577919960022\n",
      "epoch 3 loss: 0.351085364818573\n",
      "epoch 4 loss: 0.26011234521865845\n",
      "epoch 5 loss: 0.21098335087299347\n",
      "epoch 6 loss: 0.22284583747386932\n",
      "epoch 7 loss: 0.1495373696088791\n",
      "epoch 8 loss: 0.19935055077075958\n",
      "epoch 9 loss: 0.1599396914243698\n",
      "epoch 10 loss: 0.17756347358226776\n",
      "epoch 11 loss: 0.15989364683628082\n",
      "epoch 12 loss: 0.15893295407295227\n",
      "epoch 13 loss: 0.1810375154018402\n",
      "epoch 14 loss: 0.1350645124912262\n",
      "epoch 15 loss: 0.15019884705543518\n",
      "epoch 16 loss: 0.15453451871871948\n",
      "epoch 17 loss: 0.1427682340145111\n",
      "epoch 18 loss: 0.15907391905784607\n",
      "epoch 19 loss: 0.1339000016450882\n",
      "epoch 20 loss: 0.16219624876976013\n",
      "epoch 21 loss: 0.1271241158246994\n",
      "epoch 22 loss: 0.16286899149417877\n",
      "epoch 23 loss: 0.1324348896741867\n",
      "epoch 24 loss: 0.11924189329147339\n",
      "epoch 25 loss: 0.12615561485290527\n",
      "epoch 26 loss: 0.0987342894077301\n",
      "epoch 27 loss: 0.12118294090032578\n",
      "epoch 28 loss: 0.09702561795711517\n",
      "epoch 29 loss: 0.11330976337194443\n",
      "epoch 30 loss: 0.11183952540159225\n",
      "42\n",
      "epoch 1 loss: 0.8847464323043823\n",
      "epoch 2 loss: 0.7044166922569275\n",
      "epoch 3 loss: 0.3935340642929077\n",
      "epoch 4 loss: 0.2259264588356018\n",
      "epoch 5 loss: 0.2428114414215088\n",
      "epoch 6 loss: 0.22340621054172516\n",
      "epoch 7 loss: 0.18666252493858337\n",
      "epoch 8 loss: 0.183824822306633\n",
      "epoch 9 loss: 0.18883536756038666\n",
      "epoch 10 loss: 0.20903751254081726\n",
      "epoch 11 loss: 0.1636711210012436\n",
      "epoch 12 loss: 0.16847404837608337\n",
      "epoch 13 loss: 0.16153375804424286\n",
      "epoch 14 loss: 0.1832309365272522\n",
      "epoch 15 loss: 0.15924052894115448\n",
      "epoch 16 loss: 0.16923034191131592\n",
      "epoch 17 loss: 0.21597987413406372\n",
      "epoch 18 loss: 0.2041388899087906\n",
      "epoch 19 loss: 0.1437416523694992\n",
      "epoch 20 loss: 0.17661292850971222\n",
      "epoch 21 loss: 0.17292463779449463\n",
      "epoch 22 loss: 0.16142815351486206\n",
      "epoch 23 loss: 0.13775856792926788\n",
      "epoch 24 loss: 0.14624978601932526\n",
      "epoch 25 loss: 0.12364774197340012\n",
      "epoch 26 loss: 0.13910557329654694\n",
      "epoch 27 loss: 0.1419113278388977\n",
      "epoch 28 loss: 0.19247467815876007\n",
      "epoch 29 loss: 0.1325375735759735\n",
      "epoch 30 loss: 0.13383306562900543\n",
      "43\n",
      "epoch 1 loss: 0.6903066635131836\n",
      "epoch 2 loss: 0.7884690165519714\n",
      "epoch 3 loss: 0.8329739570617676\n",
      "epoch 4 loss: 0.38650065660476685\n",
      "epoch 5 loss: 0.24597424268722534\n",
      "epoch 6 loss: 0.2044685333967209\n",
      "epoch 7 loss: 0.236467644572258\n",
      "epoch 8 loss: 0.2018071562051773\n",
      "epoch 9 loss: 0.18976221978664398\n",
      "epoch 10 loss: 0.20981398224830627\n",
      "epoch 11 loss: 0.17829732596874237\n",
      "epoch 12 loss: 0.18940483033657074\n",
      "epoch 13 loss: 0.2107067108154297\n",
      "epoch 14 loss: 0.17563877999782562\n",
      "epoch 15 loss: 0.21458393335342407\n",
      "epoch 16 loss: 0.146812304854393\n",
      "epoch 17 loss: 0.1845225840806961\n",
      "epoch 18 loss: 0.16447493433952332\n",
      "epoch 19 loss: 0.16504736244678497\n",
      "epoch 20 loss: 0.18716561794281006\n",
      "epoch 21 loss: 0.2402147650718689\n",
      "epoch 22 loss: 0.11590934544801712\n",
      "epoch 23 loss: 0.1556406319141388\n",
      "epoch 24 loss: 0.1793670803308487\n",
      "epoch 25 loss: 0.214853897690773\n",
      "epoch 26 loss: 0.15520910918712616\n",
      "epoch 27 loss: 0.17682567238807678\n",
      "epoch 28 loss: 0.14969998598098755\n",
      "epoch 29 loss: 0.13066478073596954\n",
      "epoch 30 loss: 0.11744902282953262\n",
      "44\n",
      "epoch 1 loss: 0.7799778580665588\n",
      "epoch 2 loss: 0.5361077785491943\n",
      "epoch 3 loss: 0.28297901153564453\n",
      "epoch 4 loss: 0.23470722138881683\n",
      "epoch 5 loss: 0.24572186172008514\n",
      "epoch 6 loss: 0.1763046383857727\n",
      "epoch 7 loss: 0.23601950705051422\n",
      "epoch 8 loss: 0.18728166818618774\n",
      "epoch 9 loss: 0.1908925175666809\n",
      "epoch 10 loss: 0.18750736117362976\n",
      "epoch 11 loss: 0.20020964741706848\n",
      "epoch 12 loss: 0.20659615099430084\n",
      "epoch 13 loss: 0.19830264151096344\n",
      "epoch 14 loss: 0.14525733888149261\n",
      "epoch 15 loss: 0.2308330237865448\n",
      "epoch 16 loss: 0.153715118765831\n",
      "epoch 17 loss: 0.21826493740081787\n",
      "epoch 18 loss: 0.15722863376140594\n",
      "epoch 19 loss: 0.17159748077392578\n",
      "epoch 20 loss: 0.12256165593862534\n",
      "epoch 21 loss: 0.13503199815750122\n",
      "epoch 22 loss: 0.15262362360954285\n",
      "epoch 23 loss: 0.13143949210643768\n",
      "epoch 24 loss: 0.12335822731256485\n",
      "epoch 25 loss: 0.14245182275772095\n",
      "epoch 26 loss: 0.14579831063747406\n",
      "epoch 27 loss: 0.12996946275234222\n",
      "epoch 28 loss: 0.11782510578632355\n",
      "epoch 29 loss: 0.12242472171783447\n",
      "epoch 30 loss: 0.11602171510457993\n",
      "45\n",
      "epoch 1 loss: 0.9509959816932678\n",
      "epoch 2 loss: 0.7437732815742493\n",
      "epoch 3 loss: 0.7997205853462219\n",
      "epoch 4 loss: 0.3646635115146637\n",
      "epoch 5 loss: 0.1989334523677826\n",
      "epoch 6 loss: 0.18951144814491272\n",
      "epoch 7 loss: 0.17696426808834076\n",
      "epoch 8 loss: 0.271425724029541\n",
      "epoch 9 loss: 0.19308458268642426\n",
      "epoch 10 loss: 0.1779904067516327\n",
      "epoch 11 loss: 0.18915057182312012\n",
      "epoch 12 loss: 0.15466506779193878\n",
      "epoch 13 loss: 0.17355099320411682\n",
      "epoch 14 loss: 0.23260514438152313\n",
      "epoch 15 loss: 0.20170629024505615\n",
      "epoch 16 loss: 0.1571926772594452\n",
      "epoch 17 loss: 0.19580724835395813\n",
      "epoch 18 loss: 0.15150104463100433\n",
      "epoch 19 loss: 0.16137659549713135\n",
      "epoch 20 loss: 0.18640388548374176\n",
      "epoch 21 loss: 0.18665491044521332\n",
      "epoch 22 loss: 0.16272549331188202\n",
      "epoch 23 loss: 0.1394091248512268\n",
      "epoch 24 loss: 0.18533514440059662\n",
      "epoch 25 loss: 0.22555264830589294\n",
      "epoch 26 loss: 0.1862531155347824\n",
      "epoch 27 loss: 0.17524592578411102\n",
      "epoch 28 loss: 0.16149543225765228\n",
      "epoch 29 loss: 0.16362203657627106\n",
      "epoch 30 loss: 0.14786511659622192\n",
      "46\n",
      "epoch 1 loss: 0.7968806028366089\n",
      "epoch 2 loss: 0.5075982809066772\n",
      "epoch 3 loss: 0.2874639332294464\n",
      "epoch 4 loss: 0.20823965966701508\n",
      "epoch 5 loss: 0.20572352409362793\n",
      "epoch 6 loss: 0.16382616758346558\n",
      "epoch 7 loss: 0.2123577892780304\n",
      "epoch 8 loss: 0.19100770354270935\n",
      "epoch 9 loss: 0.17531125247478485\n",
      "epoch 10 loss: 0.17230410873889923\n",
      "epoch 11 loss: 0.17123952507972717\n",
      "epoch 12 loss: 0.16063091158866882\n",
      "epoch 13 loss: 0.20712335407733917\n",
      "epoch 14 loss: 0.189520925283432\n",
      "epoch 15 loss: 0.16575317084789276\n",
      "epoch 16 loss: 0.15235330164432526\n",
      "epoch 17 loss: 0.21303550899028778\n",
      "epoch 18 loss: 0.15491101145744324\n",
      "epoch 19 loss: 0.14921745657920837\n",
      "epoch 20 loss: 0.1415584534406662\n",
      "epoch 21 loss: 0.17176152765750885\n",
      "epoch 22 loss: 0.11473698168992996\n",
      "epoch 23 loss: 0.21674306690692902\n",
      "epoch 24 loss: 0.16246920824050903\n",
      "epoch 25 loss: 0.10796616971492767\n",
      "epoch 26 loss: 0.11943952739238739\n",
      "epoch 27 loss: 0.13749176263809204\n",
      "epoch 28 loss: 0.14330558478832245\n",
      "epoch 29 loss: 0.13371939957141876\n",
      "epoch 30 loss: 0.11752322316169739\n",
      "47\n",
      "epoch 1 loss: 0.8212275505065918\n",
      "epoch 2 loss: 0.8188639879226685\n",
      "epoch 3 loss: 0.633452832698822\n",
      "epoch 4 loss: 0.4469054043292999\n",
      "epoch 5 loss: 0.23146799206733704\n",
      "epoch 6 loss: 0.20029468834400177\n",
      "epoch 7 loss: 0.21827514469623566\n",
      "epoch 8 loss: 0.19953244924545288\n",
      "epoch 9 loss: 0.1936083883047104\n",
      "epoch 10 loss: 0.2001003623008728\n",
      "epoch 11 loss: 0.16610737144947052\n",
      "epoch 12 loss: 0.18059222400188446\n",
      "epoch 13 loss: 0.18859164416790009\n",
      "epoch 14 loss: 0.1725122183561325\n",
      "epoch 15 loss: 0.16286267340183258\n",
      "epoch 16 loss: 0.1737755537033081\n",
      "epoch 17 loss: 0.13412876427173615\n",
      "epoch 18 loss: 0.1421738713979721\n",
      "epoch 19 loss: 0.1507471203804016\n",
      "epoch 20 loss: 0.1368889957666397\n",
      "epoch 21 loss: 0.20254553854465485\n",
      "epoch 22 loss: 0.1377052515745163\n",
      "epoch 23 loss: 0.1484491229057312\n",
      "epoch 24 loss: 0.1538091003894806\n",
      "epoch 25 loss: 0.11328474432229996\n",
      "epoch 26 loss: 0.15928611159324646\n",
      "epoch 27 loss: 0.10900690406560898\n",
      "epoch 28 loss: 0.15041543543338776\n",
      "epoch 29 loss: 0.1257568597793579\n",
      "epoch 30 loss: 0.1296427845954895\n",
      "48\n",
      "epoch 1 loss: 0.8504165410995483\n",
      "epoch 2 loss: 0.4513859450817108\n",
      "epoch 3 loss: 0.4433212876319885\n",
      "epoch 4 loss: 0.21597972512245178\n",
      "epoch 5 loss: 0.20259009301662445\n",
      "epoch 6 loss: 0.2145848125219345\n",
      "epoch 7 loss: 0.18468770384788513\n",
      "epoch 8 loss: 0.1791694015264511\n",
      "epoch 9 loss: 0.20869994163513184\n",
      "epoch 10 loss: 0.1704261302947998\n",
      "epoch 11 loss: 0.2236713171005249\n",
      "epoch 12 loss: 0.1693870723247528\n",
      "epoch 13 loss: 0.21771441400051117\n",
      "epoch 14 loss: 0.16922640800476074\n",
      "epoch 15 loss: 0.20432382822036743\n",
      "epoch 16 loss: 0.16978470981121063\n",
      "epoch 17 loss: 0.16057178378105164\n",
      "epoch 18 loss: 0.18572627007961273\n",
      "epoch 19 loss: 0.15159007906913757\n",
      "epoch 20 loss: 0.15245020389556885\n",
      "epoch 21 loss: 0.12005127221345901\n",
      "epoch 22 loss: 0.13703125715255737\n",
      "epoch 23 loss: 0.18084816634655\n",
      "epoch 24 loss: 0.1510062962770462\n",
      "epoch 25 loss: 0.14603519439697266\n",
      "epoch 26 loss: 0.14018680155277252\n",
      "epoch 27 loss: 0.12051202356815338\n",
      "epoch 28 loss: 0.1053377166390419\n",
      "epoch 29 loss: 0.15146216750144958\n",
      "epoch 30 loss: 0.13285747170448303\n",
      "49\n",
      "epoch 1 loss: 0.6379371285438538\n",
      "epoch 2 loss: 0.6110213994979858\n",
      "epoch 3 loss: 0.40052059292793274\n",
      "epoch 4 loss: 0.24008333683013916\n",
      "epoch 5 loss: 0.19417183101177216\n",
      "epoch 6 loss: 0.2024136632680893\n",
      "epoch 7 loss: 0.23430918157100677\n",
      "epoch 8 loss: 0.2297082096338272\n",
      "epoch 9 loss: 0.24750494956970215\n",
      "epoch 10 loss: 0.2247178703546524\n",
      "epoch 11 loss: 0.1533011943101883\n",
      "epoch 12 loss: 0.15766452252864838\n",
      "epoch 13 loss: 0.21361705660820007\n",
      "epoch 14 loss: 0.18967220187187195\n",
      "epoch 15 loss: 0.180808886885643\n",
      "epoch 16 loss: 0.17552746832370758\n",
      "epoch 17 loss: 0.18604004383087158\n",
      "epoch 18 loss: 0.1975817084312439\n",
      "epoch 19 loss: 0.19165751338005066\n",
      "epoch 20 loss: 0.21170522272586823\n",
      "epoch 21 loss: 0.1494283825159073\n",
      "epoch 22 loss: 0.17772890627384186\n",
      "epoch 23 loss: 0.20674875378608704\n",
      "epoch 24 loss: 0.1406773030757904\n",
      "epoch 25 loss: 0.15027426183223724\n",
      "epoch 26 loss: 0.1921643614768982\n",
      "epoch 27 loss: 0.17613644897937775\n",
      "epoch 28 loss: 0.15136976540088654\n",
      "epoch 29 loss: 0.1236066147685051\n",
      "epoch 30 loss: 0.1893591582775116\n",
      "50\n",
      "epoch 1 loss: 0.9193328022956848\n",
      "epoch 2 loss: 0.6578887701034546\n",
      "epoch 3 loss: 0.39516958594322205\n",
      "epoch 4 loss: 0.20924393832683563\n",
      "epoch 5 loss: 0.1495099514722824\n",
      "epoch 6 loss: 0.15687565505504608\n",
      "epoch 7 loss: 0.2547681927680969\n",
      "epoch 8 loss: 0.1622578352689743\n",
      "epoch 9 loss: 0.2010364681482315\n",
      "epoch 10 loss: 0.187012180685997\n",
      "epoch 11 loss: 0.17965826392173767\n",
      "epoch 12 loss: 0.14961779117584229\n",
      "epoch 13 loss: 0.2035849541425705\n",
      "epoch 14 loss: 0.16785195469856262\n",
      "epoch 15 loss: 0.2283584475517273\n",
      "epoch 16 loss: 0.1643003225326538\n",
      "epoch 17 loss: 0.17658835649490356\n",
      "epoch 18 loss: 0.16172829270362854\n",
      "epoch 19 loss: 0.22271543741226196\n",
      "epoch 20 loss: 0.1565404236316681\n",
      "epoch 21 loss: 0.16757094860076904\n",
      "epoch 22 loss: 0.17342112958431244\n",
      "epoch 23 loss: 0.14708192646503448\n",
      "epoch 24 loss: 0.16424307227134705\n",
      "epoch 25 loss: 0.18818899989128113\n",
      "epoch 26 loss: 0.10536203533411026\n",
      "epoch 27 loss: 0.10760319977998734\n",
      "epoch 28 loss: 0.1264062523841858\n",
      "epoch 29 loss: 0.10224545747041702\n",
      "epoch 30 loss: 0.1263560950756073\n",
      "51\n",
      "epoch 1 loss: 0.8862364292144775\n",
      "epoch 2 loss: 0.6867479681968689\n",
      "epoch 3 loss: 0.40505820512771606\n",
      "epoch 4 loss: 0.2343895435333252\n",
      "epoch 5 loss: 0.2249087244272232\n",
      "epoch 6 loss: 0.20857474207878113\n",
      "epoch 7 loss: 0.21083155274391174\n",
      "epoch 8 loss: 0.2694300413131714\n",
      "epoch 9 loss: 0.17187242209911346\n",
      "epoch 10 loss: 0.18788404762744904\n",
      "epoch 11 loss: 0.21609564125537872\n",
      "epoch 12 loss: 0.17516212165355682\n",
      "epoch 13 loss: 0.17975687980651855\n",
      "epoch 14 loss: 0.18935485184192657\n",
      "epoch 15 loss: 0.16231468319892883\n",
      "epoch 16 loss: 0.20325902104377747\n",
      "epoch 17 loss: 0.18337805569171906\n",
      "epoch 18 loss: 0.18139642477035522\n",
      "epoch 19 loss: 0.17489036917686462\n",
      "epoch 20 loss: 0.21603251993656158\n",
      "epoch 21 loss: 0.1487937867641449\n",
      "epoch 22 loss: 0.14137031137943268\n",
      "epoch 23 loss: 0.15440812706947327\n",
      "epoch 24 loss: 0.20869465172290802\n",
      "epoch 25 loss: 0.1906859129667282\n",
      "epoch 26 loss: 0.15770116448402405\n",
      "epoch 27 loss: 0.16825780272483826\n",
      "epoch 28 loss: 0.17226263880729675\n",
      "epoch 29 loss: 0.16501620411872864\n",
      "epoch 30 loss: 0.18026801943778992\n",
      "52\n",
      "epoch 1 loss: 0.9024679064750671\n",
      "epoch 2 loss: 0.4548514187335968\n",
      "epoch 3 loss: 0.36710256338119507\n",
      "epoch 4 loss: 0.24957910180091858\n",
      "epoch 5 loss: 0.21112897992134094\n",
      "epoch 6 loss: 0.16531966626644135\n",
      "epoch 7 loss: 0.1758207231760025\n",
      "epoch 8 loss: 0.18801559507846832\n",
      "epoch 9 loss: 0.22355376183986664\n",
      "epoch 10 loss: 0.18613651394844055\n",
      "epoch 11 loss: 0.1771669238805771\n",
      "epoch 12 loss: 0.18288889527320862\n",
      "epoch 13 loss: 0.16151317954063416\n",
      "epoch 14 loss: 0.1876288801431656\n",
      "epoch 15 loss: 0.15843473374843597\n",
      "epoch 16 loss: 0.20437774062156677\n",
      "epoch 17 loss: 0.18662841618061066\n",
      "epoch 18 loss: 0.13865874707698822\n",
      "epoch 19 loss: 0.1335548609495163\n",
      "epoch 20 loss: 0.11378650367259979\n",
      "epoch 21 loss: 0.13434582948684692\n",
      "epoch 22 loss: 0.11655861884355545\n",
      "epoch 23 loss: 0.13149011135101318\n",
      "epoch 24 loss: 0.1359679251909256\n",
      "epoch 25 loss: 0.11132045835256577\n",
      "epoch 26 loss: 0.13463205099105835\n",
      "epoch 27 loss: 0.12156691402196884\n",
      "epoch 28 loss: 0.1810155063867569\n",
      "epoch 29 loss: 0.1541614681482315\n",
      "epoch 30 loss: 0.136684849858284\n",
      "53\n",
      "epoch 1 loss: 1.000480055809021\n",
      "epoch 2 loss: 0.3901796042919159\n",
      "epoch 3 loss: 0.2490973323583603\n",
      "epoch 4 loss: 0.22684748470783234\n",
      "epoch 5 loss: 0.19445021450519562\n",
      "epoch 6 loss: 0.19356992840766907\n",
      "epoch 7 loss: 0.2106562703847885\n",
      "epoch 8 loss: 0.1855870932340622\n",
      "epoch 9 loss: 0.21340413391590118\n",
      "epoch 10 loss: 0.2028064876794815\n",
      "epoch 11 loss: 0.1740519255399704\n",
      "epoch 12 loss: 0.2288494110107422\n",
      "epoch 13 loss: 0.1919289082288742\n",
      "epoch 14 loss: 0.16982148587703705\n",
      "epoch 15 loss: 0.1750020980834961\n",
      "epoch 16 loss: 0.20237624645233154\n",
      "epoch 17 loss: 0.15724430978298187\n",
      "epoch 18 loss: 0.1276230663061142\n",
      "epoch 19 loss: 0.12916907668113708\n",
      "epoch 20 loss: 0.15547043085098267\n",
      "epoch 21 loss: 0.13779854774475098\n",
      "epoch 22 loss: 0.14887608587741852\n",
      "epoch 23 loss: 0.14721804857254028\n",
      "epoch 24 loss: 0.1296032965183258\n",
      "epoch 25 loss: 0.1374281346797943\n",
      "epoch 26 loss: 0.1288410723209381\n",
      "epoch 27 loss: 0.1265244334936142\n",
      "epoch 28 loss: 0.12444889545440674\n",
      "epoch 29 loss: 0.14131616055965424\n",
      "epoch 30 loss: 0.11975206434726715\n",
      "54\n",
      "epoch 1 loss: 0.8681657910346985\n",
      "epoch 2 loss: 0.7012827396392822\n",
      "epoch 3 loss: 0.6793200373649597\n",
      "epoch 4 loss: 0.4302736818790436\n",
      "epoch 5 loss: 0.24503125250339508\n",
      "epoch 6 loss: 0.18640492856502533\n",
      "epoch 7 loss: 0.22277837991714478\n",
      "epoch 8 loss: 0.19129495322704315\n",
      "epoch 9 loss: 0.19137446582317352\n",
      "epoch 10 loss: 0.15744410455226898\n",
      "epoch 11 loss: 0.25377777218818665\n",
      "epoch 12 loss: 0.17653203010559082\n",
      "epoch 13 loss: 0.21330606937408447\n",
      "epoch 14 loss: 0.15829138457775116\n",
      "epoch 15 loss: 0.23494061827659607\n",
      "epoch 16 loss: 0.20824888348579407\n",
      "epoch 17 loss: 0.20659099519252777\n",
      "epoch 18 loss: 0.1803886443376541\n",
      "epoch 19 loss: 0.17833198606967926\n",
      "epoch 20 loss: 0.1543373465538025\n",
      "epoch 21 loss: 0.13677629828453064\n",
      "epoch 22 loss: 0.13227635622024536\n",
      "epoch 23 loss: 0.1417449563741684\n",
      "epoch 24 loss: 0.20171411335468292\n",
      "epoch 25 loss: 0.11669524013996124\n",
      "epoch 26 loss: 0.187729611992836\n",
      "epoch 27 loss: 0.11241866648197174\n",
      "epoch 28 loss: 0.12183348089456558\n",
      "epoch 29 loss: 0.10783284902572632\n",
      "epoch 30 loss: 0.15216153860092163\n",
      "55\n",
      "epoch 1 loss: 0.7603802680969238\n",
      "epoch 2 loss: 0.5793349742889404\n",
      "epoch 3 loss: 0.43982788920402527\n",
      "epoch 4 loss: 0.24420155584812164\n",
      "epoch 5 loss: 0.22189418971538544\n",
      "epoch 6 loss: 0.1516173779964447\n",
      "epoch 7 loss: 0.18693016469478607\n",
      "epoch 8 loss: 0.1971864402294159\n",
      "epoch 9 loss: 0.19096438586711884\n",
      "epoch 10 loss: 0.2006448656320572\n",
      "epoch 11 loss: 0.23387698829174042\n",
      "epoch 12 loss: 0.19170111417770386\n",
      "epoch 13 loss: 0.17545859515666962\n",
      "epoch 14 loss: 0.19280573725700378\n",
      "epoch 15 loss: 0.17660602927207947\n",
      "epoch 16 loss: 0.1647489219903946\n",
      "epoch 17 loss: 0.15128782391548157\n",
      "epoch 18 loss: 0.13600647449493408\n",
      "epoch 19 loss: 0.20139208436012268\n",
      "epoch 20 loss: 0.15132372081279755\n",
      "epoch 21 loss: 0.12247011810541153\n",
      "epoch 22 loss: 0.16523338854312897\n",
      "epoch 23 loss: 0.1301579624414444\n",
      "epoch 24 loss: 0.13094167411327362\n",
      "epoch 25 loss: 0.13427190482616425\n",
      "epoch 26 loss: 0.10151800513267517\n",
      "epoch 27 loss: 0.1374397724866867\n",
      "epoch 28 loss: 0.11803735792636871\n",
      "epoch 29 loss: 0.1225058063864708\n",
      "epoch 30 loss: 0.1401761770248413\n",
      "56\n",
      "epoch 1 loss: 0.9563775062561035\n",
      "epoch 2 loss: 0.8555666208267212\n",
      "epoch 3 loss: 0.5541706085205078\n",
      "epoch 4 loss: 0.32877230644226074\n",
      "epoch 5 loss: 0.2439304143190384\n",
      "epoch 6 loss: 0.21521064639091492\n",
      "epoch 7 loss: 0.20234224200248718\n",
      "epoch 8 loss: 0.18752628564834595\n",
      "epoch 9 loss: 0.21381776034832\n",
      "epoch 10 loss: 0.16087660193443298\n",
      "epoch 11 loss: 0.17550313472747803\n",
      "epoch 12 loss: 0.16553302109241486\n",
      "epoch 13 loss: 0.20613349974155426\n",
      "epoch 14 loss: 0.21177299320697784\n",
      "epoch 15 loss: 0.21401990950107574\n",
      "epoch 16 loss: 0.16300442814826965\n",
      "epoch 17 loss: 0.18735530972480774\n",
      "epoch 18 loss: 0.2223113477230072\n",
      "epoch 19 loss: 0.21297375857830048\n",
      "epoch 20 loss: 0.20959432423114777\n",
      "epoch 21 loss: 0.18929030001163483\n",
      "epoch 22 loss: 0.18673403561115265\n",
      "epoch 23 loss: 0.20234163105487823\n",
      "epoch 24 loss: 0.1802464872598648\n",
      "epoch 25 loss: 0.14853079617023468\n",
      "epoch 26 loss: 0.1597977876663208\n",
      "epoch 27 loss: 0.14916381239891052\n",
      "epoch 28 loss: 0.11665476858615875\n",
      "epoch 29 loss: 0.15180227160453796\n",
      "epoch 30 loss: 0.1308005005121231\n",
      "57\n",
      "epoch 1 loss: 0.791422426700592\n",
      "epoch 2 loss: 0.5099207758903503\n",
      "epoch 3 loss: 0.5085529088973999\n",
      "epoch 4 loss: 0.2811008393764496\n",
      "epoch 5 loss: 0.21649639308452606\n",
      "epoch 6 loss: 0.23942779004573822\n",
      "epoch 7 loss: 0.1836835741996765\n",
      "epoch 8 loss: 0.20534943044185638\n",
      "epoch 9 loss: 0.15386345982551575\n",
      "epoch 10 loss: 0.17293593287467957\n",
      "epoch 11 loss: 0.15921206772327423\n",
      "epoch 12 loss: 0.1920197606086731\n",
      "epoch 13 loss: 0.15366427600383759\n",
      "epoch 14 loss: 0.14756835997104645\n",
      "epoch 15 loss: 0.1529148668050766\n",
      "epoch 16 loss: 0.1628735065460205\n",
      "epoch 17 loss: 0.16553156077861786\n",
      "epoch 18 loss: 0.14606022834777832\n",
      "epoch 19 loss: 0.18316490948200226\n",
      "epoch 20 loss: 0.14552602171897888\n",
      "epoch 21 loss: 0.16750922799110413\n",
      "epoch 22 loss: 0.14325222373008728\n",
      "epoch 23 loss: 0.10612620413303375\n",
      "epoch 24 loss: 0.16009704768657684\n",
      "epoch 25 loss: 0.12278828769922256\n",
      "epoch 26 loss: 0.16975748538970947\n",
      "epoch 27 loss: 0.10249108821153641\n",
      "epoch 28 loss: 0.10972712188959122\n",
      "epoch 29 loss: 0.11944545805454254\n",
      "epoch 30 loss: 0.12757998704910278\n",
      "58\n",
      "epoch 1 loss: 0.7114875912666321\n",
      "epoch 2 loss: 0.617093563079834\n",
      "epoch 3 loss: 0.3616793751716614\n",
      "epoch 4 loss: 0.26141369342803955\n",
      "epoch 5 loss: 0.16894561052322388\n",
      "epoch 6 loss: 0.17260976135730743\n",
      "epoch 7 loss: 0.17413517832756042\n",
      "epoch 8 loss: 0.17548973858356476\n",
      "epoch 9 loss: 0.20093435049057007\n",
      "epoch 10 loss: 0.2003900706768036\n",
      "epoch 11 loss: 0.1818000078201294\n",
      "epoch 12 loss: 0.1943945288658142\n",
      "epoch 13 loss: 0.1744023561477661\n",
      "epoch 14 loss: 0.22724390029907227\n",
      "epoch 15 loss: 0.18093855679035187\n",
      "epoch 16 loss: 0.14758293330669403\n",
      "epoch 17 loss: 0.14243566989898682\n",
      "epoch 18 loss: 0.18619441986083984\n",
      "epoch 19 loss: 0.14739252626895905\n",
      "epoch 20 loss: 0.1435461938381195\n",
      "epoch 21 loss: 0.19778849184513092\n",
      "epoch 22 loss: 0.1287137269973755\n",
      "epoch 23 loss: 0.15358838438987732\n",
      "epoch 24 loss: 0.11793781816959381\n",
      "epoch 25 loss: 0.1512473076581955\n",
      "epoch 26 loss: 0.14770910143852234\n",
      "epoch 27 loss: 0.12388875335454941\n",
      "epoch 28 loss: 0.11182770878076553\n",
      "epoch 29 loss: 0.12517936527729034\n",
      "epoch 30 loss: 0.09572724997997284\n",
      "59\n",
      "epoch 1 loss: 0.9280484318733215\n",
      "epoch 2 loss: 0.4191576838493347\n",
      "epoch 3 loss: 0.32447561621665955\n",
      "epoch 4 loss: 0.22819311916828156\n",
      "epoch 5 loss: 0.20573997497558594\n",
      "epoch 6 loss: 0.21291491389274597\n",
      "epoch 7 loss: 0.17030726373195648\n",
      "epoch 8 loss: 0.20129923522472382\n",
      "epoch 9 loss: 0.17408153414726257\n",
      "epoch 10 loss: 0.21982091665267944\n",
      "epoch 11 loss: 0.1754276156425476\n",
      "epoch 12 loss: 0.1771843135356903\n",
      "epoch 13 loss: 0.15798664093017578\n",
      "epoch 14 loss: 0.21431425213813782\n",
      "epoch 15 loss: 0.15738825500011444\n",
      "epoch 16 loss: 0.1656682789325714\n",
      "epoch 17 loss: 0.1679893136024475\n",
      "epoch 18 loss: 0.15256772935390472\n",
      "epoch 19 loss: 0.14851415157318115\n",
      "epoch 20 loss: 0.11898510903120041\n",
      "epoch 21 loss: 0.1717885136604309\n",
      "epoch 22 loss: 0.137380912899971\n",
      "epoch 23 loss: 0.14605985581874847\n",
      "epoch 24 loss: 0.11785874515771866\n",
      "epoch 25 loss: 0.1928538978099823\n",
      "epoch 26 loss: 0.11012439429759979\n",
      "epoch 27 loss: 0.13230721652507782\n",
      "epoch 28 loss: 0.10615798830986023\n",
      "epoch 29 loss: 0.11329392343759537\n",
      "epoch 30 loss: 0.14192597568035126\n",
      "60\n",
      "epoch 1 loss: 0.7820135951042175\n",
      "epoch 2 loss: 0.5964316129684448\n",
      "epoch 3 loss: 0.3620072305202484\n",
      "epoch 4 loss: 0.2590494453907013\n",
      "epoch 5 loss: 0.19589687883853912\n",
      "epoch 6 loss: 0.18544219434261322\n",
      "epoch 7 loss: 0.212117999792099\n",
      "epoch 8 loss: 0.16135893762111664\n",
      "epoch 9 loss: 0.18385560810565948\n",
      "epoch 10 loss: 0.15590311586856842\n",
      "epoch 11 loss: 0.15691016614437103\n",
      "epoch 12 loss: 0.2228889912366867\n",
      "epoch 13 loss: 0.21437276899814606\n",
      "epoch 14 loss: 0.21644316613674164\n",
      "epoch 15 loss: 0.1543475091457367\n",
      "epoch 16 loss: 0.1657494455575943\n",
      "epoch 17 loss: 0.13677845895290375\n",
      "epoch 18 loss: 0.16081920266151428\n",
      "epoch 19 loss: 0.15394999086856842\n",
      "epoch 20 loss: 0.1643991321325302\n",
      "epoch 21 loss: 0.12370295077562332\n",
      "epoch 22 loss: 0.13486887514591217\n",
      "epoch 23 loss: 0.10497000813484192\n",
      "epoch 24 loss: 0.11357000470161438\n",
      "epoch 25 loss: 0.1250375658273697\n",
      "epoch 26 loss: 0.1170724406838417\n",
      "epoch 27 loss: 0.15914854407310486\n",
      "epoch 28 loss: 0.12278135120868683\n",
      "epoch 29 loss: 0.11656820774078369\n",
      "epoch 30 loss: 0.12371845543384552\n",
      "61\n",
      "epoch 1 loss: 0.8140249848365784\n",
      "epoch 2 loss: 0.767410933971405\n",
      "epoch 3 loss: 0.6291409730911255\n",
      "epoch 4 loss: 0.37660500407218933\n",
      "epoch 5 loss: 0.2539472281932831\n",
      "epoch 6 loss: 0.22063620388507843\n",
      "epoch 7 loss: 0.22183501720428467\n",
      "epoch 8 loss: 0.18871206045150757\n",
      "epoch 9 loss: 0.21491971611976624\n",
      "epoch 10 loss: 0.1603105664253235\n",
      "epoch 11 loss: 0.22365184128284454\n",
      "epoch 12 loss: 0.1776948720216751\n",
      "epoch 13 loss: 0.1930544227361679\n",
      "epoch 14 loss: 0.14447468519210815\n",
      "epoch 15 loss: 0.182424396276474\n",
      "epoch 16 loss: 0.1351006180047989\n",
      "epoch 17 loss: 0.15668828785419464\n",
      "epoch 18 loss: 0.15332505106925964\n",
      "epoch 19 loss: 0.14408078789710999\n",
      "epoch 20 loss: 0.1884467750787735\n",
      "epoch 21 loss: 0.17319199442863464\n",
      "epoch 22 loss: 0.132252499461174\n",
      "epoch 23 loss: 0.22013668715953827\n",
      "epoch 24 loss: 0.1337227076292038\n",
      "epoch 25 loss: 0.14704330265522003\n",
      "epoch 26 loss: 0.19247479736804962\n",
      "epoch 27 loss: 0.12834776937961578\n",
      "epoch 28 loss: 0.1310417205095291\n",
      "epoch 29 loss: 0.136202871799469\n",
      "epoch 30 loss: 0.10959259420633316\n",
      "62\n",
      "epoch 1 loss: 0.803965151309967\n",
      "epoch 2 loss: 0.8624642491340637\n",
      "epoch 3 loss: 0.6998040676116943\n",
      "epoch 4 loss: 1.0738160610198975\n",
      "epoch 5 loss: 0.8112248778343201\n",
      "epoch 6 loss: 0.3528366982936859\n",
      "epoch 7 loss: 0.2265654355287552\n",
      "epoch 8 loss: 0.18604345619678497\n",
      "epoch 9 loss: 0.1901199370622635\n",
      "epoch 10 loss: 0.21238689124584198\n",
      "epoch 11 loss: 0.1812070608139038\n",
      "epoch 12 loss: 0.1585482805967331\n",
      "epoch 13 loss: 0.18870927393436432\n",
      "epoch 14 loss: 0.19634108245372772\n",
      "epoch 15 loss: 0.18461698293685913\n",
      "epoch 16 loss: 0.18706928193569183\n",
      "epoch 17 loss: 0.14229366183280945\n",
      "epoch 18 loss: 0.17315439879894257\n",
      "epoch 19 loss: 0.17037123441696167\n",
      "epoch 20 loss: 0.18504250049591064\n",
      "epoch 21 loss: 0.16152359545230865\n",
      "epoch 22 loss: 0.1553162932395935\n",
      "epoch 23 loss: 0.16094432771205902\n",
      "epoch 24 loss: 0.1898505687713623\n",
      "epoch 25 loss: 0.19546152651309967\n",
      "epoch 26 loss: 0.13184881210327148\n",
      "epoch 27 loss: 0.16655725240707397\n",
      "epoch 28 loss: 0.1893707513809204\n",
      "epoch 29 loss: 0.12059958279132843\n",
      "epoch 30 loss: 0.134473979473114\n",
      "63\n",
      "epoch 1 loss: 0.9444753527641296\n",
      "epoch 2 loss: 0.5314775109291077\n",
      "epoch 3 loss: 0.36966413259506226\n",
      "epoch 4 loss: 0.24346420168876648\n",
      "epoch 5 loss: 0.19620664417743683\n",
      "epoch 6 loss: 0.20120367407798767\n",
      "epoch 7 loss: 0.22141198813915253\n",
      "epoch 8 loss: 0.24387452006340027\n",
      "epoch 9 loss: 0.19411836564540863\n",
      "epoch 10 loss: 0.21199500560760498\n",
      "epoch 11 loss: 0.2110101282596588\n",
      "epoch 12 loss: 0.18827231228351593\n",
      "epoch 13 loss: 0.17557458579540253\n",
      "epoch 14 loss: 0.1763097494840622\n",
      "epoch 15 loss: 0.1802184134721756\n",
      "epoch 16 loss: 0.14860109984874725\n",
      "epoch 17 loss: 0.17237386107444763\n",
      "epoch 18 loss: 0.24642819166183472\n",
      "epoch 19 loss: 0.19156377017498016\n",
      "epoch 20 loss: 0.17707186937332153\n",
      "epoch 21 loss: 0.14557461440563202\n",
      "epoch 22 loss: 0.17290547490119934\n",
      "epoch 23 loss: 0.12258321791887283\n",
      "epoch 24 loss: 0.1425032913684845\n",
      "epoch 25 loss: 0.11950886994600296\n",
      "epoch 26 loss: 0.14035044610500336\n",
      "epoch 27 loss: 0.1464422345161438\n",
      "epoch 28 loss: 0.10844153165817261\n",
      "epoch 29 loss: 0.12247048318386078\n",
      "epoch 30 loss: 0.12104623764753342\n",
      "64\n",
      "epoch 1 loss: 0.7223623991012573\n",
      "epoch 2 loss: 0.8421118259429932\n",
      "epoch 3 loss: 0.5954326391220093\n",
      "epoch 4 loss: 0.3204136788845062\n",
      "epoch 5 loss: 0.25416481494903564\n",
      "epoch 6 loss: 0.23572853207588196\n",
      "epoch 7 loss: 0.18220454454421997\n",
      "epoch 8 loss: 0.18916240334510803\n",
      "epoch 9 loss: 0.1801500767469406\n",
      "epoch 10 loss: 0.19175560772418976\n",
      "epoch 11 loss: 0.18926399946212769\n",
      "epoch 12 loss: 0.1195315346121788\n",
      "epoch 13 loss: 0.1782134622335434\n",
      "epoch 14 loss: 0.13484422862529755\n",
      "epoch 15 loss: 0.15422068536281586\n",
      "epoch 16 loss: 0.2284734547138214\n",
      "epoch 17 loss: 0.1782035380601883\n",
      "epoch 18 loss: 0.17336413264274597\n",
      "epoch 19 loss: 0.16173984110355377\n",
      "epoch 20 loss: 0.12919004261493683\n",
      "epoch 21 loss: 0.1439020037651062\n",
      "epoch 22 loss: 0.13748085498809814\n",
      "epoch 23 loss: 0.12683771550655365\n",
      "epoch 24 loss: 0.1467909812927246\n",
      "epoch 25 loss: 0.1384904980659485\n",
      "epoch 26 loss: 0.14323359727859497\n",
      "epoch 27 loss: 0.14136120676994324\n",
      "epoch 28 loss: 0.11090662330389023\n",
      "epoch 29 loss: 0.11336617916822433\n",
      "epoch 30 loss: 0.11827688664197922\n",
      "65\n",
      "epoch 1 loss: 0.7780259847640991\n",
      "epoch 2 loss: 0.6146630644798279\n",
      "epoch 3 loss: 0.5090684294700623\n",
      "epoch 4 loss: 0.2989429235458374\n",
      "epoch 5 loss: 0.2308225780725479\n",
      "epoch 6 loss: 0.21665269136428833\n",
      "epoch 7 loss: 0.21885445713996887\n",
      "epoch 8 loss: 0.1674329787492752\n",
      "epoch 9 loss: 0.22509117424488068\n",
      "epoch 10 loss: 0.18402168154716492\n",
      "epoch 11 loss: 0.24305735528469086\n",
      "epoch 12 loss: 0.1623619943857193\n",
      "epoch 13 loss: 0.2039901316165924\n",
      "epoch 14 loss: 0.17130395770072937\n",
      "epoch 15 loss: 0.21648555994033813\n",
      "epoch 16 loss: 0.2105611264705658\n",
      "epoch 17 loss: 0.20327097177505493\n",
      "epoch 18 loss: 0.15511386096477509\n",
      "epoch 19 loss: 0.16681066155433655\n",
      "epoch 20 loss: 0.14130255579948425\n",
      "epoch 21 loss: 0.10102386027574539\n",
      "epoch 22 loss: 0.11441170424222946\n",
      "epoch 23 loss: 0.1678604632616043\n",
      "epoch 24 loss: 0.18347834050655365\n",
      "epoch 25 loss: 0.11743664741516113\n",
      "epoch 26 loss: 0.14012837409973145\n",
      "epoch 27 loss: 0.18654599785804749\n",
      "epoch 28 loss: 0.12312326580286026\n",
      "epoch 29 loss: 0.10670769214630127\n",
      "epoch 30 loss: 0.10970588773488998\n",
      "66\n",
      "epoch 1 loss: 0.6852192282676697\n",
      "epoch 2 loss: 0.4714755117893219\n",
      "epoch 3 loss: 0.3130096197128296\n",
      "epoch 4 loss: 0.17505085468292236\n",
      "epoch 5 loss: 0.24787235260009766\n",
      "epoch 6 loss: 0.2061207890510559\n",
      "epoch 7 loss: 0.1905464380979538\n",
      "epoch 8 loss: 0.20444151759147644\n",
      "epoch 9 loss: 0.16168001294136047\n",
      "epoch 10 loss: 0.20132841169834137\n",
      "epoch 11 loss: 0.15601567924022675\n",
      "epoch 12 loss: 0.22212764620780945\n",
      "epoch 13 loss: 0.17945341765880585\n",
      "epoch 14 loss: 0.16149967908859253\n",
      "epoch 15 loss: 0.18244844675064087\n",
      "epoch 16 loss: 0.16906185448169708\n",
      "epoch 17 loss: 0.1985270380973816\n",
      "epoch 18 loss: 0.11588609218597412\n",
      "epoch 19 loss: 0.1790604442358017\n",
      "epoch 20 loss: 0.12759968638420105\n",
      "epoch 21 loss: 0.15171918272972107\n",
      "epoch 22 loss: 0.16740942001342773\n",
      "epoch 23 loss: 0.18120163679122925\n",
      "epoch 24 loss: 0.15729478001594543\n",
      "epoch 25 loss: 0.15288527309894562\n",
      "epoch 26 loss: 0.14248959720134735\n",
      "epoch 27 loss: 0.10214055329561234\n",
      "epoch 28 loss: 0.1332298219203949\n",
      "epoch 29 loss: 0.12736248970031738\n",
      "epoch 30 loss: 0.12445070594549179\n",
      "67\n",
      "epoch 1 loss: 0.7034225463867188\n",
      "epoch 2 loss: 0.645052969455719\n",
      "epoch 3 loss: 0.506533145904541\n",
      "epoch 4 loss: 0.33788201212882996\n",
      "epoch 5 loss: 0.22705376148223877\n",
      "epoch 6 loss: 0.18190574645996094\n",
      "epoch 7 loss: 0.19442565739154816\n",
      "epoch 8 loss: 0.17446942627429962\n",
      "epoch 9 loss: 0.23446638882160187\n",
      "epoch 10 loss: 0.1961367279291153\n",
      "epoch 11 loss: 0.17232947051525116\n",
      "epoch 12 loss: 0.18789732456207275\n",
      "epoch 13 loss: 0.1864682137966156\n",
      "epoch 14 loss: 0.1805756688117981\n",
      "epoch 15 loss: 0.14755195379257202\n",
      "epoch 16 loss: 0.1855156123638153\n",
      "epoch 17 loss: 0.17769354581832886\n",
      "epoch 18 loss: 0.1403466761112213\n",
      "epoch 19 loss: 0.1726425141096115\n",
      "epoch 20 loss: 0.1315813660621643\n",
      "epoch 21 loss: 0.2338164746761322\n",
      "epoch 22 loss: 0.21202069520950317\n",
      "epoch 23 loss: 0.12540510296821594\n",
      "epoch 24 loss: 0.13628217577934265\n",
      "epoch 25 loss: 0.09913163632154465\n",
      "epoch 26 loss: 0.13583672046661377\n",
      "epoch 27 loss: 0.15721765160560608\n",
      "epoch 28 loss: 0.14270217716693878\n",
      "epoch 29 loss: 0.15441671013832092\n",
      "epoch 30 loss: 0.1579062044620514\n",
      "68\n",
      "epoch 1 loss: 0.6897737383842468\n",
      "epoch 2 loss: 0.5077227354049683\n",
      "epoch 3 loss: 0.34736618399620056\n",
      "epoch 4 loss: 0.25669950246810913\n",
      "epoch 5 loss: 0.19572970271110535\n",
      "epoch 6 loss: 0.16025656461715698\n",
      "epoch 7 loss: 0.23613637685775757\n",
      "epoch 8 loss: 0.17219151556491852\n",
      "epoch 9 loss: 0.21442702412605286\n",
      "epoch 10 loss: 0.1907758116722107\n",
      "epoch 11 loss: 0.18175065517425537\n",
      "epoch 12 loss: 0.15524880588054657\n",
      "epoch 13 loss: 0.18817029893398285\n",
      "epoch 14 loss: 0.14575791358947754\n",
      "epoch 15 loss: 0.15485401451587677\n",
      "epoch 16 loss: 0.16281646490097046\n",
      "epoch 17 loss: 0.1666671335697174\n",
      "epoch 18 loss: 0.16174344718456268\n",
      "epoch 19 loss: 0.12790729105472565\n",
      "epoch 20 loss: 0.1304311454296112\n",
      "epoch 21 loss: 0.16791126132011414\n",
      "epoch 22 loss: 0.14075028896331787\n",
      "epoch 23 loss: 0.10170771926641464\n",
      "epoch 24 loss: 0.10166233777999878\n",
      "epoch 25 loss: 0.16774971783161163\n",
      "epoch 26 loss: 0.12412161380052567\n",
      "epoch 27 loss: 0.10385952889919281\n",
      "epoch 28 loss: 0.11579190939664841\n",
      "epoch 29 loss: 0.10634791105985641\n",
      "epoch 30 loss: 0.09113375842571259\n",
      "69\n",
      "epoch 1 loss: 0.9049349427223206\n",
      "epoch 2 loss: 0.5983429551124573\n",
      "epoch 3 loss: 0.30901429057121277\n",
      "epoch 4 loss: 0.1969752460718155\n",
      "epoch 5 loss: 0.19358044862747192\n",
      "epoch 6 loss: 0.16484728455543518\n",
      "epoch 7 loss: 0.19768887758255005\n",
      "epoch 8 loss: 0.2326914668083191\n",
      "epoch 9 loss: 0.21293574571609497\n",
      "epoch 10 loss: 0.1804475486278534\n",
      "epoch 11 loss: 0.1481565237045288\n",
      "epoch 12 loss: 0.23385697603225708\n",
      "epoch 13 loss: 0.18601897358894348\n",
      "epoch 14 loss: 0.19345460832118988\n",
      "epoch 15 loss: 0.22776643931865692\n",
      "epoch 16 loss: 0.1849261224269867\n",
      "epoch 17 loss: 0.13359126448631287\n",
      "epoch 18 loss: 0.1401928961277008\n",
      "epoch 19 loss: 0.11669498682022095\n",
      "epoch 20 loss: 0.15107600390911102\n",
      "epoch 21 loss: 0.126042440533638\n",
      "epoch 22 loss: 0.10202536731958389\n",
      "epoch 23 loss: 0.15938644111156464\n",
      "epoch 24 loss: 0.1609102338552475\n",
      "epoch 25 loss: 0.11301104724407196\n",
      "epoch 26 loss: 0.10516972094774246\n",
      "epoch 27 loss: 0.10684069991111755\n",
      "epoch 28 loss: 0.13131944835186005\n",
      "epoch 29 loss: 0.10192867368459702\n",
      "epoch 30 loss: 0.13198508322238922\n",
      "70\n",
      "epoch 1 loss: 0.7986161708831787\n",
      "epoch 2 loss: 0.47011828422546387\n",
      "epoch 3 loss: 0.2535361349582672\n",
      "epoch 4 loss: 0.24144308269023895\n",
      "epoch 5 loss: 0.21090951561927795\n",
      "epoch 6 loss: 0.17454279959201813\n",
      "epoch 7 loss: 0.189109668135643\n",
      "epoch 8 loss: 0.1997765302658081\n",
      "epoch 9 loss: 0.18886330723762512\n",
      "epoch 10 loss: 0.18337242305278778\n",
      "epoch 11 loss: 0.19225972890853882\n",
      "epoch 12 loss: 0.1422935426235199\n",
      "epoch 13 loss: 0.19284845888614655\n",
      "epoch 14 loss: 0.15455961227416992\n",
      "epoch 15 loss: 0.18167689442634583\n",
      "epoch 16 loss: 0.16264700889587402\n",
      "epoch 17 loss: 0.1174224317073822\n",
      "epoch 18 loss: 0.09738370031118393\n",
      "epoch 19 loss: 0.139114111661911\n",
      "epoch 20 loss: 0.12028125673532486\n",
      "epoch 21 loss: 0.15611006319522858\n",
      "epoch 22 loss: 0.14997120201587677\n",
      "epoch 23 loss: 0.11450804024934769\n",
      "epoch 24 loss: 0.12500888109207153\n",
      "epoch 25 loss: 0.14802490174770355\n",
      "epoch 26 loss: 0.14648762345314026\n",
      "epoch 27 loss: 0.10384125262498856\n",
      "epoch 28 loss: 0.12632140517234802\n",
      "epoch 29 loss: 0.11486704647541046\n",
      "epoch 30 loss: 0.14572617411613464\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b930b84e-bb96-4717-9434-5da760d66549",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier vector (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad224e3d-ca07-48ab-9bae-d4582c22712b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:32:33.355346Z",
     "start_time": "2025-10-06T20:32:30.037883Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"vector\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w = pd.concat([results_aep_fourier_w, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w.to_csv(out_dir + '/results_aep_fourier_w.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([64, 32, 7])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 25\u001B[0m\n\u001B[1;32m     20\u001B[0m model \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mRNN_fourier(cont_dim\u001B[38;5;241m=\u001B[39mcont_dim, fourier_dim\u001B[38;5;241m=\u001B[39mfourier_dim,\n\u001B[1;32m     21\u001B[0m                                 xf_mode\u001B[38;5;241m=\u001B[39mfourier_conf\u001B[38;5;241m.\u001B[39mmode, d_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, nhead\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, \n\u001B[1;32m     22\u001B[0m                                 activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m\"\u001B[39m, learn_z0\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m,\n\u001B[1;32m     23\u001B[0m                                 H\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m24\u001B[39m, use_gate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, nonneg_U0\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     24\u001B[0m trainer \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mRNN_train_fourier(model, train_config, fourier_conf)\n\u001B[0;32m---> 25\u001B[0m forcast, true \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_reduced\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m result \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mday\u001B[39m\u001B[38;5;124m'\u001B[39m: df_reduced[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mds\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mdate\u001B[38;5;241m.\u001B[39mmax(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhour\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m24\u001B[39m)), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_hat\u001B[39m\u001B[38;5;124m'\u001B[39m: forcast, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m: true})\n\u001B[1;32m     29\u001B[0m results_aep_fourier_w \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([results_aep_fourier_w, result])\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Desktop/Downscaling/work_summary_9_26/model_summary.py:1138\u001B[0m, in \u001B[0;36mRNN_train_fourier.__call__\u001B[0;34m(self, df)\u001B[0m\n\u001B[1;32m   1136\u001B[0m o, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(xb)\n\u001B[1;32m   1137\u001B[0m data_loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmse_loss(o, yb)\n\u001B[0;32m-> 1138\u001B[0m prior_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreg_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlambda0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlambda0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m   1139\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mlambdaf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlambdaf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m   1140\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mharmonic_orders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mharmonic_orders\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1141\u001B[0m loss \u001B[38;5;241m=\u001B[39m data_loss \u001B[38;5;241m+\u001B[39m prior_loss\n\u001B[1;32m   1142\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/Desktop/Downscaling/work_summary_9_26/model_summary.py:678\u001B[0m, in \u001B[0;36mRNN_fourier.reg_loss\u001B[0;34m(self, lambda0, lambdaf, harmonic_orders)\u001B[0m\n\u001B[1;32m    677\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreg_loss\u001B[39m(\u001B[38;5;28mself\u001B[39m, lambda0\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m, lambdaf\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m, harmonic_orders\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 678\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    679\u001B[0m     U0 \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftplus(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mU0_raw) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnonneg_U0 \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mU0_raw\n\u001B[1;32m    680\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m lambda0 \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "448d1d3a-c3c8-46e9-bad0-55eb3eb3457c",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier matrix (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "64c5838c-0d23-48b1-b71d-2c0c79c15634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T23:07:14.965610Z",
     "start_time": "2025-10-05T23:07:14.962094Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"cpu\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "\n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4,\n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_w_matrix.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "kw3_km6_ky10",
   "id": "2905a936a0711568"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:48:21.964479Z",
     "start_time": "2025-10-10T15:41:04.100176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "\n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4,\n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_kw3_km6_ky10_matrix.csv', index=False)"
   ],
   "id": "cbba4ba7c9ca40ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:1149: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {ep+1} loss: {float(loss):.4f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6578\n",
      "epoch 2 loss: 0.4387\n",
      "epoch 3 loss: 0.4501\n",
      "epoch 4 loss: 0.3607\n",
      "epoch 5 loss: 0.2821\n",
      "epoch 6 loss: 0.1383\n",
      "epoch 7 loss: 0.0829\n",
      "epoch 8 loss: 0.0621\n",
      "epoch 9 loss: 0.0533\n",
      "epoch 10 loss: 0.0461\n",
      "epoch 11 loss: 0.0446\n",
      "epoch 12 loss: 0.0463\n",
      "epoch 13 loss: 0.0415\n",
      "epoch 14 loss: 0.0433\n",
      "epoch 15 loss: 0.0393\n",
      "epoch 16 loss: 0.0388\n",
      "epoch 17 loss: 0.0445\n",
      "epoch 18 loss: 0.0359\n",
      "epoch 19 loss: 0.0336\n",
      "epoch 20 loss: 0.0331\n",
      "epoch 21 loss: 0.0368\n",
      "epoch 22 loss: 0.0345\n",
      "epoch 23 loss: 0.0350\n",
      "epoch 24 loss: 0.0302\n",
      "epoch 25 loss: 0.0315\n",
      "epoch 26 loss: 0.0332\n",
      "epoch 27 loss: 0.0299\n",
      "epoch 28 loss: 0.0289\n",
      "epoch 29 loss: 0.0291\n",
      "epoch 30 loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_32889/3588380963.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "epoch 1 loss: 1.0749\n",
      "epoch 2 loss: 0.5910\n",
      "epoch 3 loss: 0.4176\n",
      "epoch 4 loss: 0.2644\n",
      "epoch 5 loss: 0.1274\n",
      "epoch 6 loss: 0.0627\n",
      "epoch 7 loss: 0.0616\n",
      "epoch 8 loss: 0.0527\n",
      "epoch 9 loss: 0.0587\n",
      "epoch 10 loss: 0.0507\n",
      "epoch 11 loss: 0.0521\n",
      "epoch 12 loss: 0.0429\n",
      "epoch 13 loss: 0.0446\n",
      "epoch 14 loss: 0.0436\n",
      "epoch 15 loss: 0.0439\n",
      "epoch 16 loss: 0.0465\n",
      "epoch 17 loss: 0.0384\n",
      "epoch 18 loss: 0.0383\n",
      "epoch 19 loss: 0.0394\n",
      "epoch 20 loss: 0.0410\n",
      "epoch 21 loss: 0.0387\n",
      "epoch 22 loss: 0.0318\n",
      "epoch 23 loss: 0.0386\n",
      "epoch 24 loss: 0.0353\n",
      "epoch 25 loss: 0.0381\n",
      "epoch 26 loss: 0.0345\n",
      "epoch 27 loss: 0.0378\n",
      "epoch 28 loss: 0.0371\n",
      "epoch 29 loss: 0.0347\n",
      "epoch 30 loss: 0.0336\n",
      "3\n",
      "epoch 1 loss: 0.7932\n",
      "epoch 2 loss: 0.5328\n",
      "epoch 3 loss: 0.3649\n",
      "epoch 4 loss: 0.1772\n",
      "epoch 5 loss: 0.0929\n",
      "epoch 6 loss: 0.0734\n",
      "epoch 7 loss: 0.0603\n",
      "epoch 8 loss: 0.0609\n",
      "epoch 9 loss: 0.0548\n",
      "epoch 10 loss: 0.0458\n",
      "epoch 11 loss: 0.0448\n",
      "epoch 12 loss: 0.0413\n",
      "epoch 13 loss: 0.0424\n",
      "epoch 14 loss: 0.0417\n",
      "epoch 15 loss: 0.0362\n",
      "epoch 16 loss: 0.0404\n",
      "epoch 17 loss: 0.0393\n",
      "epoch 18 loss: 0.0342\n",
      "epoch 19 loss: 0.0379\n",
      "epoch 20 loss: 0.0377\n",
      "epoch 21 loss: 0.0381\n",
      "epoch 22 loss: 0.0337\n",
      "epoch 23 loss: 0.0343\n",
      "epoch 24 loss: 0.0314\n",
      "epoch 25 loss: 0.0345\n",
      "epoch 26 loss: 0.0323\n",
      "epoch 27 loss: 0.0319\n",
      "epoch 28 loss: 0.0334\n",
      "epoch 29 loss: 0.0331\n",
      "epoch 30 loss: 0.0322\n",
      "4\n",
      "epoch 1 loss: 1.0533\n",
      "epoch 2 loss: 0.6345\n",
      "epoch 3 loss: 0.4091\n",
      "epoch 4 loss: 0.4102\n",
      "epoch 5 loss: 0.4449\n",
      "epoch 6 loss: 0.2170\n",
      "epoch 7 loss: 0.1151\n",
      "epoch 8 loss: 0.0767\n",
      "epoch 9 loss: 0.0693\n",
      "epoch 10 loss: 0.0608\n",
      "epoch 11 loss: 0.0606\n",
      "epoch 12 loss: 0.0575\n",
      "epoch 13 loss: 0.0583\n",
      "epoch 14 loss: 0.0527\n",
      "epoch 15 loss: 0.0487\n",
      "epoch 16 loss: 0.0485\n",
      "epoch 17 loss: 0.0450\n",
      "epoch 18 loss: 0.0452\n",
      "epoch 19 loss: 0.0439\n",
      "epoch 20 loss: 0.0419\n",
      "epoch 21 loss: 0.0390\n",
      "epoch 22 loss: 0.0440\n",
      "epoch 23 loss: 0.0464\n",
      "epoch 24 loss: 0.0513\n",
      "epoch 25 loss: 0.0378\n",
      "epoch 26 loss: 0.0431\n",
      "epoch 27 loss: 0.0440\n",
      "epoch 28 loss: 0.0378\n",
      "epoch 29 loss: 0.0404\n",
      "epoch 30 loss: 0.0334\n",
      "5\n",
      "epoch 1 loss: 0.6532\n",
      "epoch 2 loss: 0.5892\n",
      "epoch 3 loss: 0.5812\n",
      "epoch 4 loss: 0.3045\n",
      "epoch 5 loss: 0.2263\n",
      "epoch 6 loss: 0.1250\n",
      "epoch 7 loss: 0.0862\n",
      "epoch 8 loss: 0.0721\n",
      "epoch 9 loss: 0.0696\n",
      "epoch 10 loss: 0.0532\n",
      "epoch 11 loss: 0.0501\n",
      "epoch 12 loss: 0.0439\n",
      "epoch 13 loss: 0.0398\n",
      "epoch 14 loss: 0.0416\n",
      "epoch 15 loss: 0.0426\n",
      "epoch 16 loss: 0.0391\n",
      "epoch 17 loss: 0.0361\n",
      "epoch 18 loss: 0.0324\n",
      "epoch 19 loss: 0.0322\n",
      "epoch 20 loss: 0.0312\n",
      "epoch 21 loss: 0.0347\n",
      "epoch 22 loss: 0.0344\n",
      "epoch 23 loss: 0.0346\n",
      "epoch 24 loss: 0.0352\n",
      "epoch 25 loss: 0.0298\n",
      "epoch 26 loss: 0.0322\n",
      "epoch 27 loss: 0.0325\n",
      "epoch 28 loss: 0.0334\n",
      "epoch 29 loss: 0.0277\n",
      "epoch 30 loss: 0.0316\n",
      "6\n",
      "epoch 1 loss: 0.7195\n",
      "epoch 2 loss: 0.5386\n",
      "epoch 3 loss: 0.4251\n",
      "epoch 4 loss: 0.2229\n",
      "epoch 5 loss: 0.1312\n",
      "epoch 6 loss: 0.0780\n",
      "epoch 7 loss: 0.0713\n",
      "epoch 8 loss: 0.0613\n",
      "epoch 9 loss: 0.0576\n",
      "epoch 10 loss: 0.0516\n",
      "epoch 11 loss: 0.0463\n",
      "epoch 12 loss: 0.0439\n",
      "epoch 13 loss: 0.0447\n",
      "epoch 14 loss: 0.0414\n",
      "epoch 15 loss: 0.0399\n",
      "epoch 16 loss: 0.0398\n",
      "epoch 17 loss: 0.0372\n",
      "epoch 18 loss: 0.0388\n",
      "epoch 19 loss: 0.0363\n",
      "epoch 20 loss: 0.0348\n",
      "epoch 21 loss: 0.0363\n",
      "epoch 22 loss: 0.0352\n",
      "epoch 23 loss: 0.0352\n",
      "epoch 24 loss: 0.0324\n",
      "epoch 25 loss: 0.0323\n",
      "epoch 26 loss: 0.0402\n",
      "epoch 27 loss: 0.0332\n",
      "epoch 28 loss: 0.0337\n",
      "epoch 29 loss: 0.0337\n",
      "epoch 30 loss: 0.0290\n",
      "7\n",
      "epoch 1 loss: 0.7316\n",
      "epoch 2 loss: 0.4576\n",
      "epoch 3 loss: 0.9382\n",
      "epoch 4 loss: 0.3846\n",
      "epoch 5 loss: 0.2837\n",
      "epoch 6 loss: 0.1377\n",
      "epoch 7 loss: 0.0774\n",
      "epoch 8 loss: 0.0654\n",
      "epoch 9 loss: 0.0541\n",
      "epoch 10 loss: 0.0477\n",
      "epoch 11 loss: 0.0439\n",
      "epoch 12 loss: 0.0444\n",
      "epoch 13 loss: 0.0405\n",
      "epoch 14 loss: 0.0412\n",
      "epoch 15 loss: 0.0445\n",
      "epoch 16 loss: 0.0402\n",
      "epoch 17 loss: 0.0390\n",
      "epoch 18 loss: 0.0374\n",
      "epoch 19 loss: 0.0372\n",
      "epoch 20 loss: 0.0304\n",
      "epoch 21 loss: 0.0365\n",
      "epoch 22 loss: 0.0369\n",
      "epoch 23 loss: 0.0323\n",
      "epoch 24 loss: 0.0348\n",
      "epoch 25 loss: 0.0329\n",
      "epoch 26 loss: 0.0319\n",
      "epoch 27 loss: 0.0342\n",
      "epoch 28 loss: 0.0324\n",
      "epoch 29 loss: 0.0300\n",
      "epoch 30 loss: 0.0323\n",
      "8\n",
      "epoch 1 loss: 0.7010\n",
      "epoch 2 loss: 0.5615\n",
      "epoch 3 loss: 0.4200\n",
      "epoch 4 loss: 0.4746\n",
      "epoch 5 loss: 0.3842\n",
      "epoch 6 loss: 0.4957\n",
      "epoch 7 loss: 0.2447\n",
      "epoch 8 loss: 0.1439\n",
      "epoch 9 loss: 0.0806\n",
      "epoch 10 loss: 0.0662\n",
      "epoch 11 loss: 0.0615\n",
      "epoch 12 loss: 0.0537\n",
      "epoch 13 loss: 0.0460\n",
      "epoch 14 loss: 0.0451\n",
      "epoch 15 loss: 0.0438\n",
      "epoch 16 loss: 0.0476\n",
      "epoch 17 loss: 0.0414\n",
      "epoch 18 loss: 0.0460\n",
      "epoch 19 loss: 0.0439\n",
      "epoch 20 loss: 0.0418\n",
      "epoch 21 loss: 0.0390\n",
      "epoch 22 loss: 0.0414\n",
      "epoch 23 loss: 0.0338\n",
      "epoch 24 loss: 0.0343\n",
      "epoch 25 loss: 0.0386\n",
      "epoch 26 loss: 0.0322\n",
      "epoch 27 loss: 0.0359\n",
      "epoch 28 loss: 0.0394\n",
      "epoch 29 loss: 0.0330\n",
      "epoch 30 loss: 0.0318\n",
      "9\n",
      "epoch 1 loss: 0.7999\n",
      "epoch 2 loss: 0.4536\n",
      "epoch 3 loss: 0.4922\n",
      "epoch 4 loss: 0.2283\n",
      "epoch 5 loss: 0.1266\n",
      "epoch 6 loss: 0.0821\n",
      "epoch 7 loss: 0.0834\n",
      "epoch 8 loss: 0.0676\n",
      "epoch 9 loss: 0.0563\n",
      "epoch 10 loss: 0.0591\n",
      "epoch 11 loss: 0.0439\n",
      "epoch 12 loss: 0.0495\n",
      "epoch 13 loss: 0.0425\n",
      "epoch 14 loss: 0.0419\n",
      "epoch 15 loss: 0.0451\n",
      "epoch 16 loss: 0.0442\n",
      "epoch 17 loss: 0.0408\n",
      "epoch 18 loss: 0.0407\n",
      "epoch 19 loss: 0.0398\n",
      "epoch 20 loss: 0.0365\n",
      "epoch 21 loss: 0.0365\n",
      "epoch 22 loss: 0.0360\n",
      "epoch 23 loss: 0.0384\n",
      "epoch 24 loss: 0.0299\n",
      "epoch 25 loss: 0.0360\n",
      "epoch 26 loss: 0.0370\n",
      "epoch 27 loss: 0.0324\n",
      "epoch 28 loss: 0.0312\n",
      "epoch 29 loss: 0.0314\n",
      "epoch 30 loss: 0.0337\n",
      "10\n",
      "epoch 1 loss: 0.7794\n",
      "epoch 2 loss: 0.5210\n",
      "epoch 3 loss: 0.4495\n",
      "epoch 4 loss: 0.2553\n",
      "epoch 5 loss: 0.1187\n",
      "epoch 6 loss: 0.1013\n",
      "epoch 7 loss: 0.0746\n",
      "epoch 8 loss: 0.0619\n",
      "epoch 9 loss: 0.0619\n",
      "epoch 10 loss: 0.0527\n",
      "epoch 11 loss: 0.0581\n",
      "epoch 12 loss: 0.0678\n",
      "epoch 13 loss: 0.0485\n",
      "epoch 14 loss: 0.0503\n",
      "epoch 15 loss: 0.0476\n",
      "epoch 16 loss: 0.0467\n",
      "epoch 17 loss: 0.0428\n",
      "epoch 18 loss: 0.0420\n",
      "epoch 19 loss: 0.0381\n",
      "epoch 20 loss: 0.0408\n",
      "epoch 21 loss: 0.0438\n",
      "epoch 22 loss: 0.0393\n",
      "epoch 23 loss: 0.0354\n",
      "epoch 24 loss: 0.0371\n",
      "epoch 25 loss: 0.0352\n",
      "epoch 26 loss: 0.0365\n",
      "epoch 27 loss: 0.0345\n",
      "epoch 28 loss: 0.0381\n",
      "epoch 29 loss: 0.0357\n",
      "epoch 30 loss: 0.0339\n",
      "11\n",
      "epoch 1 loss: 1.0911\n",
      "epoch 2 loss: 0.6424\n",
      "epoch 3 loss: 0.4592\n",
      "epoch 4 loss: 0.4557\n",
      "epoch 5 loss: 0.3180\n",
      "epoch 6 loss: 0.1330\n",
      "epoch 7 loss: 0.0864\n",
      "epoch 8 loss: 0.0636\n",
      "epoch 9 loss: 0.0562\n",
      "epoch 10 loss: 0.0572\n",
      "epoch 11 loss: 0.0482\n",
      "epoch 12 loss: 0.0484\n",
      "epoch 13 loss: 0.0446\n",
      "epoch 14 loss: 0.0414\n",
      "epoch 15 loss: 0.0443\n",
      "epoch 16 loss: 0.0377\n",
      "epoch 17 loss: 0.0387\n",
      "epoch 18 loss: 0.0455\n",
      "epoch 19 loss: 0.0407\n",
      "epoch 20 loss: 0.0411\n",
      "epoch 21 loss: 0.0417\n",
      "epoch 22 loss: 0.0355\n",
      "epoch 23 loss: 0.0377\n",
      "epoch 24 loss: 0.0378\n",
      "epoch 25 loss: 0.0360\n",
      "epoch 26 loss: 0.0407\n",
      "epoch 27 loss: 0.0362\n",
      "epoch 28 loss: 0.0326\n",
      "epoch 29 loss: 0.0358\n",
      "epoch 30 loss: 0.0317\n",
      "12\n",
      "epoch 1 loss: 0.7171\n",
      "epoch 2 loss: 0.6972\n",
      "epoch 3 loss: 0.5181\n",
      "epoch 4 loss: 0.5019\n",
      "epoch 5 loss: 0.3926\n",
      "epoch 6 loss: 0.3135\n",
      "epoch 7 loss: 0.1477\n",
      "epoch 8 loss: 0.0904\n",
      "epoch 9 loss: 0.0567\n",
      "epoch 10 loss: 0.0593\n",
      "epoch 11 loss: 0.0499\n",
      "epoch 12 loss: 0.0462\n",
      "epoch 13 loss: 0.0460\n",
      "epoch 14 loss: 0.0443\n",
      "epoch 15 loss: 0.0444\n",
      "epoch 16 loss: 0.0432\n",
      "epoch 17 loss: 0.0398\n",
      "epoch 18 loss: 0.0444\n",
      "epoch 19 loss: 0.0385\n",
      "epoch 20 loss: 0.0449\n",
      "epoch 21 loss: 0.0401\n",
      "epoch 22 loss: 0.0372\n",
      "epoch 23 loss: 0.0310\n",
      "epoch 24 loss: 0.0367\n",
      "epoch 25 loss: 0.0352\n",
      "epoch 26 loss: 0.0322\n",
      "epoch 27 loss: 0.0348\n",
      "epoch 28 loss: 0.0338\n",
      "epoch 29 loss: 0.0329\n",
      "epoch 30 loss: 0.0344\n",
      "13\n",
      "epoch 1 loss: 0.8363\n",
      "epoch 2 loss: 0.4348\n",
      "epoch 3 loss: 0.4611\n",
      "epoch 4 loss: 0.3909\n",
      "epoch 5 loss: 0.2893\n",
      "epoch 6 loss: 0.1425\n",
      "epoch 7 loss: 0.1023\n",
      "epoch 8 loss: 0.0826\n",
      "epoch 9 loss: 0.0611\n",
      "epoch 10 loss: 0.0544\n",
      "epoch 11 loss: 0.0470\n",
      "epoch 12 loss: 0.0484\n",
      "epoch 13 loss: 0.0470\n",
      "epoch 14 loss: 0.0509\n",
      "epoch 15 loss: 0.0546\n",
      "epoch 16 loss: 0.0543\n",
      "epoch 17 loss: 0.0574\n",
      "epoch 18 loss: 0.0419\n",
      "epoch 19 loss: 0.0404\n",
      "epoch 20 loss: 0.0379\n",
      "epoch 21 loss: 0.0406\n",
      "epoch 22 loss: 0.0429\n",
      "epoch 23 loss: 0.0431\n",
      "epoch 24 loss: 0.0368\n",
      "epoch 25 loss: 0.0359\n",
      "epoch 26 loss: 0.0392\n",
      "epoch 27 loss: 0.0345\n",
      "epoch 28 loss: 0.0351\n",
      "epoch 29 loss: 0.0396\n",
      "epoch 30 loss: 0.0367\n",
      "14\n",
      "epoch 1 loss: 0.7864\n",
      "epoch 2 loss: 0.4839\n",
      "epoch 3 loss: 0.4647\n",
      "epoch 4 loss: 0.3047\n",
      "epoch 5 loss: 0.1584\n",
      "epoch 6 loss: 0.0943\n",
      "epoch 7 loss: 0.0628\n",
      "epoch 8 loss: 0.0585\n",
      "epoch 9 loss: 0.0504\n",
      "epoch 10 loss: 0.0465\n",
      "epoch 11 loss: 0.0466\n",
      "epoch 12 loss: 0.0411\n",
      "epoch 13 loss: 0.0466\n",
      "epoch 14 loss: 0.0371\n",
      "epoch 15 loss: 0.0392\n",
      "epoch 16 loss: 0.0366\n",
      "epoch 17 loss: 0.0374\n",
      "epoch 18 loss: 0.0393\n",
      "epoch 19 loss: 0.0385\n",
      "epoch 20 loss: 0.0388\n",
      "epoch 21 loss: 0.0346\n",
      "epoch 22 loss: 0.0352\n",
      "epoch 23 loss: 0.0344\n",
      "epoch 24 loss: 0.0347\n",
      "epoch 25 loss: 0.0366\n",
      "epoch 26 loss: 0.0339\n",
      "epoch 27 loss: 0.0342\n",
      "epoch 28 loss: 0.0336\n",
      "epoch 29 loss: 0.0322\n",
      "epoch 30 loss: 0.0331\n",
      "15\n",
      "epoch 1 loss: 0.8172\n",
      "epoch 2 loss: 0.5423\n",
      "epoch 3 loss: 0.3034\n",
      "epoch 4 loss: 0.1631\n",
      "epoch 5 loss: 0.1853\n",
      "epoch 6 loss: 0.1578\n",
      "epoch 7 loss: 0.1003\n",
      "epoch 8 loss: 0.0851\n",
      "epoch 9 loss: 0.0666\n",
      "epoch 10 loss: 0.0674\n",
      "epoch 11 loss: 0.0682\n",
      "epoch 12 loss: 0.0675\n",
      "epoch 13 loss: 0.0546\n",
      "epoch 14 loss: 0.0638\n",
      "epoch 15 loss: 0.0568\n",
      "epoch 16 loss: 0.0530\n",
      "epoch 17 loss: 0.0489\n",
      "epoch 18 loss: 0.0580\n",
      "epoch 19 loss: 0.0474\n",
      "epoch 20 loss: 0.0465\n",
      "epoch 21 loss: 0.0453\n",
      "epoch 22 loss: 0.0425\n",
      "epoch 23 loss: 0.0390\n",
      "epoch 24 loss: 0.0420\n",
      "epoch 25 loss: 0.0444\n",
      "epoch 26 loss: 0.0421\n",
      "epoch 27 loss: 0.0421\n",
      "epoch 28 loss: 0.0404\n",
      "epoch 29 loss: 0.0409\n",
      "epoch 30 loss: 0.0379\n",
      "16\n",
      "epoch 1 loss: 0.7575\n",
      "epoch 2 loss: 0.6152\n",
      "epoch 3 loss: 0.3924\n",
      "epoch 4 loss: 0.2576\n",
      "epoch 5 loss: 0.1339\n",
      "epoch 6 loss: 0.0802\n",
      "epoch 7 loss: 0.0649\n",
      "epoch 8 loss: 0.0587\n",
      "epoch 9 loss: 0.0488\n",
      "epoch 10 loss: 0.0538\n",
      "epoch 11 loss: 0.0441\n",
      "epoch 12 loss: 0.0425\n",
      "epoch 13 loss: 0.0436\n",
      "epoch 14 loss: 0.0422\n",
      "epoch 15 loss: 0.0395\n",
      "epoch 16 loss: 0.0445\n",
      "epoch 17 loss: 0.0392\n",
      "epoch 18 loss: 0.0446\n",
      "epoch 19 loss: 0.0371\n",
      "epoch 20 loss: 0.0418\n",
      "epoch 21 loss: 0.0368\n",
      "epoch 22 loss: 0.0382\n",
      "epoch 23 loss: 0.0354\n",
      "epoch 24 loss: 0.0336\n",
      "epoch 25 loss: 0.0332\n",
      "epoch 26 loss: 0.0348\n",
      "epoch 27 loss: 0.0327\n",
      "epoch 28 loss: 0.0338\n",
      "epoch 29 loss: 0.0348\n",
      "epoch 30 loss: 0.0305\n",
      "17\n",
      "epoch 1 loss: 0.9959\n",
      "epoch 2 loss: 0.6945\n",
      "epoch 3 loss: 0.4211\n",
      "epoch 4 loss: 0.3595\n",
      "epoch 5 loss: 0.2274\n",
      "epoch 6 loss: 0.1143\n",
      "epoch 7 loss: 0.0794\n",
      "epoch 8 loss: 0.0928\n",
      "epoch 9 loss: 0.0730\n",
      "epoch 10 loss: 0.0709\n",
      "epoch 11 loss: 0.0632\n",
      "epoch 12 loss: 0.0582\n",
      "epoch 13 loss: 0.0513\n",
      "epoch 14 loss: 0.0559\n",
      "epoch 15 loss: 0.0479\n",
      "epoch 16 loss: 0.0433\n",
      "epoch 17 loss: 0.0459\n",
      "epoch 18 loss: 0.0444\n",
      "epoch 19 loss: 0.0424\n",
      "epoch 20 loss: 0.0393\n",
      "epoch 21 loss: 0.0442\n",
      "epoch 22 loss: 0.0427\n",
      "epoch 23 loss: 0.0454\n",
      "epoch 24 loss: 0.0400\n",
      "epoch 25 loss: 0.0357\n",
      "epoch 26 loss: 0.0362\n",
      "epoch 27 loss: 0.0394\n",
      "epoch 28 loss: 0.0343\n",
      "epoch 29 loss: 0.0364\n",
      "epoch 30 loss: 0.0380\n",
      "18\n",
      "epoch 1 loss: 0.7804\n",
      "epoch 2 loss: 0.4552\n",
      "epoch 3 loss: 0.3991\n",
      "epoch 4 loss: 0.2041\n",
      "epoch 5 loss: 0.1083\n",
      "epoch 6 loss: 0.0825\n",
      "epoch 7 loss: 0.0587\n",
      "epoch 8 loss: 0.0525\n",
      "epoch 9 loss: 0.0502\n",
      "epoch 10 loss: 0.0485\n",
      "epoch 11 loss: 0.0470\n",
      "epoch 12 loss: 0.0431\n",
      "epoch 13 loss: 0.0386\n",
      "epoch 14 loss: 0.0407\n",
      "epoch 15 loss: 0.0425\n",
      "epoch 16 loss: 0.0388\n",
      "epoch 17 loss: 0.0387\n",
      "epoch 18 loss: 0.0356\n",
      "epoch 19 loss: 0.0357\n",
      "epoch 20 loss: 0.0374\n",
      "epoch 21 loss: 0.0318\n",
      "epoch 22 loss: 0.0346\n",
      "epoch 23 loss: 0.0385\n",
      "epoch 24 loss: 0.0367\n",
      "epoch 25 loss: 0.0318\n",
      "epoch 26 loss: 0.0307\n",
      "epoch 27 loss: 0.0320\n",
      "epoch 28 loss: 0.0328\n",
      "epoch 29 loss: 0.0299\n",
      "epoch 30 loss: 0.0343\n",
      "19\n",
      "epoch 1 loss: 0.8188\n",
      "epoch 2 loss: 0.5966\n",
      "epoch 3 loss: 0.5076\n",
      "epoch 4 loss: 0.3137\n",
      "epoch 5 loss: 0.1889\n",
      "epoch 6 loss: 0.1037\n",
      "epoch 7 loss: 0.0662\n",
      "epoch 8 loss: 0.0674\n",
      "epoch 9 loss: 0.0498\n",
      "epoch 10 loss: 0.0517\n",
      "epoch 11 loss: 0.0517\n",
      "epoch 12 loss: 0.0507\n",
      "epoch 13 loss: 0.0449\n",
      "epoch 14 loss: 0.0519\n",
      "epoch 15 loss: 0.0439\n",
      "epoch 16 loss: 0.0407\n",
      "epoch 17 loss: 0.0443\n",
      "epoch 18 loss: 0.0448\n",
      "epoch 19 loss: 0.0403\n",
      "epoch 20 loss: 0.0468\n",
      "epoch 21 loss: 0.0354\n",
      "epoch 22 loss: 0.0404\n",
      "epoch 23 loss: 0.0362\n",
      "epoch 24 loss: 0.0355\n",
      "epoch 25 loss: 0.0321\n",
      "epoch 26 loss: 0.0342\n",
      "epoch 27 loss: 0.0366\n",
      "epoch 28 loss: 0.0428\n",
      "epoch 29 loss: 0.0348\n",
      "epoch 30 loss: 0.0317\n",
      "20\n",
      "epoch 1 loss: 0.7673\n",
      "epoch 2 loss: 0.5688\n",
      "epoch 3 loss: 0.4211\n",
      "epoch 4 loss: 0.3891\n",
      "epoch 5 loss: 0.3573\n",
      "epoch 6 loss: 0.2658\n",
      "epoch 7 loss: 0.1965\n",
      "epoch 8 loss: 0.1152\n",
      "epoch 9 loss: 0.0707\n",
      "epoch 10 loss: 0.0591\n",
      "epoch 11 loss: 0.0482\n",
      "epoch 12 loss: 0.0449\n",
      "epoch 13 loss: 0.0544\n",
      "epoch 14 loss: 0.0465\n",
      "epoch 15 loss: 0.0417\n",
      "epoch 16 loss: 0.0381\n",
      "epoch 17 loss: 0.0404\n",
      "epoch 18 loss: 0.0405\n",
      "epoch 19 loss: 0.0392\n",
      "epoch 20 loss: 0.0370\n",
      "epoch 21 loss: 0.0425\n",
      "epoch 22 loss: 0.0339\n",
      "epoch 23 loss: 0.0357\n",
      "epoch 24 loss: 0.0391\n",
      "epoch 25 loss: 0.0318\n",
      "epoch 26 loss: 0.0357\n",
      "epoch 27 loss: 0.0342\n",
      "epoch 28 loss: 0.0326\n",
      "epoch 29 loss: 0.0315\n",
      "epoch 30 loss: 0.0346\n",
      "21\n",
      "epoch 1 loss: 0.9580\n",
      "epoch 2 loss: 0.5562\n",
      "epoch 3 loss: 0.5046\n",
      "epoch 4 loss: 0.4610\n",
      "epoch 5 loss: 0.2847\n",
      "epoch 6 loss: 0.2496\n",
      "epoch 7 loss: 0.1707\n",
      "epoch 8 loss: 0.0962\n",
      "epoch 9 loss: 0.0871\n",
      "epoch 10 loss: 0.0740\n",
      "epoch 11 loss: 0.0693\n",
      "epoch 12 loss: 0.0720\n",
      "epoch 13 loss: 0.0565\n",
      "epoch 14 loss: 0.0693\n",
      "epoch 15 loss: 0.0679\n",
      "epoch 16 loss: 0.0541\n",
      "epoch 17 loss: 0.0574\n",
      "epoch 18 loss: 0.0585\n",
      "epoch 19 loss: 0.0560\n",
      "epoch 20 loss: 0.0478\n",
      "epoch 21 loss: 0.0549\n",
      "epoch 22 loss: 0.0463\n",
      "epoch 23 loss: 0.0573\n",
      "epoch 24 loss: 0.0522\n",
      "epoch 25 loss: 0.0566\n",
      "epoch 26 loss: 0.0487\n",
      "epoch 27 loss: 0.0460\n",
      "epoch 28 loss: 0.0470\n",
      "epoch 29 loss: 0.0486\n",
      "epoch 30 loss: 0.0468\n",
      "22\n",
      "epoch 1 loss: 0.8524\n",
      "epoch 2 loss: 0.5038\n",
      "epoch 3 loss: 0.4186\n",
      "epoch 4 loss: 0.2673\n",
      "epoch 5 loss: 0.2942\n",
      "epoch 6 loss: 0.2711\n",
      "epoch 7 loss: 0.1277\n",
      "epoch 8 loss: 0.0906\n",
      "epoch 9 loss: 0.0695\n",
      "epoch 10 loss: 0.0609\n",
      "epoch 11 loss: 0.0509\n",
      "epoch 12 loss: 0.0494\n",
      "epoch 13 loss: 0.0546\n",
      "epoch 14 loss: 0.0488\n",
      "epoch 15 loss: 0.0455\n",
      "epoch 16 loss: 0.0450\n",
      "epoch 17 loss: 0.0505\n",
      "epoch 18 loss: 0.0442\n",
      "epoch 19 loss: 0.0467\n",
      "epoch 20 loss: 0.0408\n",
      "epoch 21 loss: 0.0431\n",
      "epoch 22 loss: 0.0411\n",
      "epoch 23 loss: 0.0400\n",
      "epoch 24 loss: 0.0378\n",
      "epoch 25 loss: 0.0442\n",
      "epoch 26 loss: 0.0359\n",
      "epoch 27 loss: 0.0332\n",
      "epoch 28 loss: 0.0365\n",
      "epoch 29 loss: 0.0366\n",
      "epoch 30 loss: 0.0352\n",
      "23\n",
      "epoch 1 loss: 0.9334\n",
      "epoch 2 loss: 0.6142\n",
      "epoch 3 loss: 0.4683\n",
      "epoch 4 loss: 0.3657\n",
      "epoch 5 loss: 0.2073\n",
      "epoch 6 loss: 0.1133\n",
      "epoch 7 loss: 0.0825\n",
      "epoch 8 loss: 0.0609\n",
      "epoch 9 loss: 0.0576\n",
      "epoch 10 loss: 0.0486\n",
      "epoch 11 loss: 0.0511\n",
      "epoch 12 loss: 0.0499\n",
      "epoch 13 loss: 0.0457\n",
      "epoch 14 loss: 0.0417\n",
      "epoch 15 loss: 0.0412\n",
      "epoch 16 loss: 0.0408\n",
      "epoch 17 loss: 0.0368\n",
      "epoch 18 loss: 0.0444\n",
      "epoch 19 loss: 0.0376\n",
      "epoch 20 loss: 0.0379\n",
      "epoch 21 loss: 0.0371\n",
      "epoch 22 loss: 0.0341\n",
      "epoch 23 loss: 0.0347\n",
      "epoch 24 loss: 0.0331\n",
      "epoch 25 loss: 0.0324\n",
      "epoch 26 loss: 0.0388\n",
      "epoch 27 loss: 0.0336\n",
      "epoch 28 loss: 0.0313\n",
      "epoch 29 loss: 0.0309\n",
      "epoch 30 loss: 0.0320\n",
      "24\n",
      "epoch 1 loss: 0.6696\n",
      "epoch 2 loss: 0.5242\n",
      "epoch 3 loss: 0.4091\n",
      "epoch 4 loss: 0.4108\n",
      "epoch 5 loss: 0.3208\n",
      "epoch 6 loss: 0.1537\n",
      "epoch 7 loss: 0.0885\n",
      "epoch 8 loss: 0.0639\n",
      "epoch 9 loss: 0.0575\n",
      "epoch 10 loss: 0.0510\n",
      "epoch 11 loss: 0.0490\n",
      "epoch 12 loss: 0.0472\n",
      "epoch 13 loss: 0.0445\n",
      "epoch 14 loss: 0.0409\n",
      "epoch 15 loss: 0.0385\n",
      "epoch 16 loss: 0.0381\n",
      "epoch 17 loss: 0.0366\n",
      "epoch 18 loss: 0.0358\n",
      "epoch 19 loss: 0.0354\n",
      "epoch 20 loss: 0.0347\n",
      "epoch 21 loss: 0.0316\n",
      "epoch 22 loss: 0.0339\n",
      "epoch 23 loss: 0.0347\n",
      "epoch 24 loss: 0.0327\n",
      "epoch 25 loss: 0.0351\n",
      "epoch 26 loss: 0.0312\n",
      "epoch 27 loss: 0.0322\n",
      "epoch 28 loss: 0.0295\n",
      "epoch 29 loss: 0.0321\n",
      "epoch 30 loss: 0.0312\n",
      "25\n",
      "epoch 1 loss: 0.8216\n",
      "epoch 2 loss: 0.5311\n",
      "epoch 3 loss: 0.4644\n",
      "epoch 4 loss: 0.4581\n",
      "epoch 5 loss: 0.3312\n",
      "epoch 6 loss: 0.4689\n",
      "epoch 7 loss: 0.3785\n",
      "epoch 8 loss: 0.2674\n",
      "epoch 9 loss: 0.1156\n",
      "epoch 10 loss: 0.0752\n",
      "epoch 11 loss: 0.0610\n",
      "epoch 12 loss: 0.0556\n",
      "epoch 13 loss: 0.0504\n",
      "epoch 14 loss: 0.0493\n",
      "epoch 15 loss: 0.0382\n",
      "epoch 16 loss: 0.0444\n",
      "epoch 17 loss: 0.0397\n",
      "epoch 18 loss: 0.0374\n",
      "epoch 19 loss: 0.0445\n",
      "epoch 20 loss: 0.0365\n",
      "epoch 21 loss: 0.0376\n",
      "epoch 22 loss: 0.0389\n",
      "epoch 23 loss: 0.0386\n",
      "epoch 24 loss: 0.0386\n",
      "epoch 25 loss: 0.0329\n",
      "epoch 26 loss: 0.0347\n",
      "epoch 27 loss: 0.0306\n",
      "epoch 28 loss: 0.0338\n",
      "epoch 29 loss: 0.0334\n",
      "epoch 30 loss: 0.0288\n",
      "26\n",
      "epoch 1 loss: 0.8986\n",
      "epoch 2 loss: 0.7134\n",
      "epoch 3 loss: 0.5571\n",
      "epoch 4 loss: 0.5638\n",
      "epoch 5 loss: 0.4807\n",
      "epoch 6 loss: 0.3121\n",
      "epoch 7 loss: 0.1762\n",
      "epoch 8 loss: 0.1107\n",
      "epoch 9 loss: 0.0722\n",
      "epoch 10 loss: 0.0578\n",
      "epoch 11 loss: 0.0466\n",
      "epoch 12 loss: 0.0512\n",
      "epoch 13 loss: 0.0450\n",
      "epoch 14 loss: 0.0483\n",
      "epoch 15 loss: 0.0485\n",
      "epoch 16 loss: 0.0445\n",
      "epoch 17 loss: 0.0434\n",
      "epoch 18 loss: 0.0425\n",
      "epoch 19 loss: 0.0413\n",
      "epoch 20 loss: 0.0397\n",
      "epoch 21 loss: 0.0433\n",
      "epoch 22 loss: 0.0413\n",
      "epoch 23 loss: 0.0424\n",
      "epoch 24 loss: 0.0409\n",
      "epoch 25 loss: 0.0380\n",
      "epoch 26 loss: 0.0348\n",
      "epoch 27 loss: 0.0343\n",
      "epoch 28 loss: 0.0353\n",
      "epoch 29 loss: 0.0393\n",
      "epoch 30 loss: 0.0343\n",
      "27\n",
      "epoch 1 loss: 0.8596\n",
      "epoch 2 loss: 0.6595\n",
      "epoch 3 loss: 0.4450\n",
      "epoch 4 loss: 0.4668\n",
      "epoch 5 loss: 0.4017\n",
      "epoch 6 loss: 0.2629\n",
      "epoch 7 loss: 0.2600\n",
      "epoch 8 loss: 0.2534\n",
      "epoch 9 loss: 0.1642\n",
      "epoch 10 loss: 0.0933\n",
      "epoch 11 loss: 0.0798\n",
      "epoch 12 loss: 0.0674\n",
      "epoch 13 loss: 0.0658\n",
      "epoch 14 loss: 0.0821\n",
      "epoch 15 loss: 0.0570\n",
      "epoch 16 loss: 0.0603\n",
      "epoch 17 loss: 0.0640\n",
      "epoch 18 loss: 0.0563\n",
      "epoch 19 loss: 0.0492\n",
      "epoch 20 loss: 0.0490\n",
      "epoch 21 loss: 0.0583\n",
      "epoch 22 loss: 0.0509\n",
      "epoch 23 loss: 0.0623\n",
      "epoch 24 loss: 0.0506\n",
      "epoch 25 loss: 0.0437\n",
      "epoch 26 loss: 0.0459\n",
      "epoch 27 loss: 0.0457\n",
      "epoch 28 loss: 0.0475\n",
      "epoch 29 loss: 0.0437\n",
      "epoch 30 loss: 0.0465\n",
      "28\n",
      "epoch 1 loss: 0.9104\n",
      "epoch 2 loss: 0.4157\n",
      "epoch 3 loss: 0.2354\n",
      "epoch 4 loss: 0.2206\n",
      "epoch 5 loss: 0.0976\n",
      "epoch 6 loss: 0.0753\n",
      "epoch 7 loss: 0.0760\n",
      "epoch 8 loss: 0.0623\n",
      "epoch 9 loss: 0.0633\n",
      "epoch 10 loss: 0.0573\n",
      "epoch 11 loss: 0.0577\n",
      "epoch 12 loss: 0.0555\n",
      "epoch 13 loss: 0.0463\n",
      "epoch 14 loss: 0.0494\n",
      "epoch 15 loss: 0.0479\n",
      "epoch 16 loss: 0.0518\n",
      "epoch 17 loss: 0.0426\n",
      "epoch 18 loss: 0.0430\n",
      "epoch 19 loss: 0.0447\n",
      "epoch 20 loss: 0.0404\n",
      "epoch 21 loss: 0.0425\n",
      "epoch 22 loss: 0.0362\n",
      "epoch 23 loss: 0.0369\n",
      "epoch 24 loss: 0.0334\n",
      "epoch 25 loss: 0.0366\n",
      "epoch 26 loss: 0.0393\n",
      "epoch 27 loss: 0.0348\n",
      "epoch 28 loss: 0.0372\n",
      "epoch 29 loss: 0.0400\n",
      "epoch 30 loss: 0.0335\n",
      "29\n",
      "epoch 1 loss: 0.7577\n",
      "epoch 2 loss: 0.5769\n",
      "epoch 3 loss: 0.4545\n",
      "epoch 4 loss: 0.3054\n",
      "epoch 5 loss: 0.1695\n",
      "epoch 6 loss: 0.1070\n",
      "epoch 7 loss: 0.0688\n",
      "epoch 8 loss: 0.0537\n",
      "epoch 9 loss: 0.0505\n",
      "epoch 10 loss: 0.0492\n",
      "epoch 11 loss: 0.0504\n",
      "epoch 12 loss: 0.0458\n",
      "epoch 13 loss: 0.0435\n",
      "epoch 14 loss: 0.0423\n",
      "epoch 15 loss: 0.0391\n",
      "epoch 16 loss: 0.0344\n",
      "epoch 17 loss: 0.0352\n",
      "epoch 18 loss: 0.0331\n",
      "epoch 19 loss: 0.0337\n",
      "epoch 20 loss: 0.0350\n",
      "epoch 21 loss: 0.0360\n",
      "epoch 22 loss: 0.0343\n",
      "epoch 23 loss: 0.0369\n",
      "epoch 24 loss: 0.0335\n",
      "epoch 25 loss: 0.0337\n",
      "epoch 26 loss: 0.0325\n",
      "epoch 27 loss: 0.0313\n",
      "epoch 28 loss: 0.0319\n",
      "epoch 29 loss: 0.0312\n",
      "epoch 30 loss: 0.0310\n",
      "30\n",
      "epoch 1 loss: 1.0301\n",
      "epoch 2 loss: 0.6662\n",
      "epoch 3 loss: 0.5231\n",
      "epoch 4 loss: 0.3299\n",
      "epoch 5 loss: 0.2756\n",
      "epoch 6 loss: 0.2161\n",
      "epoch 7 loss: 0.1476\n",
      "epoch 8 loss: 0.0821\n",
      "epoch 9 loss: 0.0735\n",
      "epoch 10 loss: 0.0669\n",
      "epoch 11 loss: 0.0608\n",
      "epoch 12 loss: 0.0556\n",
      "epoch 13 loss: 0.0448\n",
      "epoch 14 loss: 0.0441\n",
      "epoch 15 loss: 0.0568\n",
      "epoch 16 loss: 0.0445\n",
      "epoch 17 loss: 0.0537\n",
      "epoch 18 loss: 0.0453\n",
      "epoch 19 loss: 0.0441\n",
      "epoch 20 loss: 0.0450\n",
      "epoch 21 loss: 0.0458\n",
      "epoch 22 loss: 0.0476\n",
      "epoch 23 loss: 0.0454\n",
      "epoch 24 loss: 0.0424\n",
      "epoch 25 loss: 0.0432\n",
      "epoch 26 loss: 0.0418\n",
      "epoch 27 loss: 0.0358\n",
      "epoch 28 loss: 0.0424\n",
      "epoch 29 loss: 0.0369\n",
      "epoch 30 loss: 0.0372\n",
      "31\n",
      "epoch 1 loss: 0.9536\n",
      "epoch 2 loss: 0.5846\n",
      "epoch 3 loss: 0.3622\n",
      "epoch 4 loss: 0.2689\n",
      "epoch 5 loss: 0.2597\n",
      "epoch 6 loss: 0.1690\n",
      "epoch 7 loss: 0.1297\n",
      "epoch 8 loss: 0.0847\n",
      "epoch 9 loss: 0.0740\n",
      "epoch 10 loss: 0.0633\n",
      "epoch 11 loss: 0.0558\n",
      "epoch 12 loss: 0.0475\n",
      "epoch 13 loss: 0.0506\n",
      "epoch 14 loss: 0.0504\n",
      "epoch 15 loss: 0.0437\n",
      "epoch 16 loss: 0.0495\n",
      "epoch 17 loss: 0.0415\n",
      "epoch 18 loss: 0.0422\n",
      "epoch 19 loss: 0.0418\n",
      "epoch 20 loss: 0.0436\n",
      "epoch 21 loss: 0.0405\n",
      "epoch 22 loss: 0.0364\n",
      "epoch 23 loss: 0.0399\n",
      "epoch 24 loss: 0.0384\n",
      "epoch 25 loss: 0.0359\n",
      "epoch 26 loss: 0.0351\n",
      "epoch 27 loss: 0.0333\n",
      "epoch 28 loss: 0.0381\n",
      "epoch 29 loss: 0.0327\n",
      "epoch 30 loss: 0.0344\n",
      "32\n",
      "epoch 1 loss: 0.7164\n",
      "epoch 2 loss: 0.5533\n",
      "epoch 3 loss: 0.4920\n",
      "epoch 4 loss: 0.3243\n",
      "epoch 5 loss: 0.1622\n",
      "epoch 6 loss: 0.0989\n",
      "epoch 7 loss: 0.0756\n",
      "epoch 8 loss: 0.0595\n",
      "epoch 9 loss: 0.0622\n",
      "epoch 10 loss: 0.0546\n",
      "epoch 11 loss: 0.0526\n",
      "epoch 12 loss: 0.0459\n",
      "epoch 13 loss: 0.0479\n",
      "epoch 14 loss: 0.0511\n",
      "epoch 15 loss: 0.0432\n",
      "epoch 16 loss: 0.0433\n",
      "epoch 17 loss: 0.0407\n",
      "epoch 18 loss: 0.0418\n",
      "epoch 19 loss: 0.0447\n",
      "epoch 20 loss: 0.0399\n",
      "epoch 21 loss: 0.0413\n",
      "epoch 22 loss: 0.0432\n",
      "epoch 23 loss: 0.0427\n",
      "epoch 24 loss: 0.0361\n",
      "epoch 25 loss: 0.0427\n",
      "epoch 26 loss: 0.0385\n",
      "epoch 27 loss: 0.0377\n",
      "epoch 28 loss: 0.0442\n",
      "epoch 29 loss: 0.0353\n",
      "epoch 30 loss: 0.0392\n",
      "33\n",
      "epoch 1 loss: 0.8270\n",
      "epoch 2 loss: 0.4510\n",
      "epoch 3 loss: 0.4717\n",
      "epoch 4 loss: 0.3454\n",
      "epoch 5 loss: 0.4064\n",
      "epoch 6 loss: 0.1592\n",
      "epoch 7 loss: 0.1027\n",
      "epoch 8 loss: 0.0680\n",
      "epoch 9 loss: 0.0508\n",
      "epoch 10 loss: 0.0548\n",
      "epoch 11 loss: 0.0502\n",
      "epoch 12 loss: 0.0459\n",
      "epoch 13 loss: 0.0408\n",
      "epoch 14 loss: 0.0415\n",
      "epoch 15 loss: 0.0428\n",
      "epoch 16 loss: 0.0387\n",
      "epoch 17 loss: 0.0426\n",
      "epoch 18 loss: 0.0425\n",
      "epoch 19 loss: 0.0363\n",
      "epoch 20 loss: 0.0356\n",
      "epoch 21 loss: 0.0429\n",
      "epoch 22 loss: 0.0410\n",
      "epoch 23 loss: 0.0402\n",
      "epoch 24 loss: 0.0339\n",
      "epoch 25 loss: 0.0392\n",
      "epoch 26 loss: 0.0354\n",
      "epoch 27 loss: 0.0342\n",
      "epoch 28 loss: 0.0303\n",
      "epoch 29 loss: 0.0344\n",
      "epoch 30 loss: 0.0370\n",
      "34\n",
      "epoch 1 loss: 1.0346\n",
      "epoch 2 loss: 0.6637\n",
      "epoch 3 loss: 0.4954\n",
      "epoch 4 loss: 0.2898\n",
      "epoch 5 loss: 0.1741\n",
      "epoch 6 loss: 0.0932\n",
      "epoch 7 loss: 0.0624\n",
      "epoch 8 loss: 0.0613\n",
      "epoch 9 loss: 0.0516\n",
      "epoch 10 loss: 0.0536\n",
      "epoch 11 loss: 0.0508\n",
      "epoch 12 loss: 0.0492\n",
      "epoch 13 loss: 0.0450\n",
      "epoch 14 loss: 0.0457\n",
      "epoch 15 loss: 0.0416\n",
      "epoch 16 loss: 0.0510\n",
      "epoch 17 loss: 0.0469\n",
      "epoch 18 loss: 0.0397\n",
      "epoch 19 loss: 0.0441\n",
      "epoch 20 loss: 0.0436\n",
      "epoch 21 loss: 0.0414\n",
      "epoch 22 loss: 0.0442\n",
      "epoch 23 loss: 0.0398\n",
      "epoch 24 loss: 0.0399\n",
      "epoch 25 loss: 0.0376\n",
      "epoch 26 loss: 0.0393\n",
      "epoch 27 loss: 0.0417\n",
      "epoch 28 loss: 0.0366\n",
      "epoch 29 loss: 0.0420\n",
      "epoch 30 loss: 0.0334\n",
      "35\n",
      "epoch 1 loss: 0.7436\n",
      "epoch 2 loss: 0.5451\n",
      "epoch 3 loss: 0.5459\n",
      "epoch 4 loss: 0.3555\n",
      "epoch 5 loss: 0.3216\n",
      "epoch 6 loss: 0.1662\n",
      "epoch 7 loss: 0.1086\n",
      "epoch 8 loss: 0.0719\n",
      "epoch 9 loss: 0.0627\n",
      "epoch 10 loss: 0.0587\n",
      "epoch 11 loss: 0.0528\n",
      "epoch 12 loss: 0.0532\n",
      "epoch 13 loss: 0.0457\n",
      "epoch 14 loss: 0.0415\n",
      "epoch 15 loss: 0.0376\n",
      "epoch 16 loss: 0.0475\n",
      "epoch 17 loss: 0.0393\n",
      "epoch 18 loss: 0.0365\n",
      "epoch 19 loss: 0.0378\n",
      "epoch 20 loss: 0.0458\n",
      "epoch 21 loss: 0.0369\n",
      "epoch 22 loss: 0.0395\n",
      "epoch 23 loss: 0.0397\n",
      "epoch 24 loss: 0.0344\n",
      "epoch 25 loss: 0.0336\n",
      "epoch 26 loss: 0.0355\n",
      "epoch 27 loss: 0.0339\n",
      "epoch 28 loss: 0.0381\n",
      "epoch 29 loss: 0.0377\n",
      "epoch 30 loss: 0.0346\n",
      "36\n",
      "epoch 1 loss: 0.7473\n",
      "epoch 2 loss: 0.6770\n",
      "epoch 3 loss: 0.6323\n",
      "epoch 4 loss: 0.3865\n",
      "epoch 5 loss: 0.1892\n",
      "epoch 6 loss: 0.0984\n",
      "epoch 7 loss: 0.0665\n",
      "epoch 8 loss: 0.0560\n",
      "epoch 9 loss: 0.0485\n",
      "epoch 10 loss: 0.0547\n",
      "epoch 11 loss: 0.0493\n",
      "epoch 12 loss: 0.0457\n",
      "epoch 13 loss: 0.0402\n",
      "epoch 14 loss: 0.0414\n",
      "epoch 15 loss: 0.0400\n",
      "epoch 16 loss: 0.0427\n",
      "epoch 17 loss: 0.0389\n",
      "epoch 18 loss: 0.0422\n",
      "epoch 19 loss: 0.0363\n",
      "epoch 20 loss: 0.0447\n",
      "epoch 21 loss: 0.0378\n",
      "epoch 22 loss: 0.0428\n",
      "epoch 23 loss: 0.0332\n",
      "epoch 24 loss: 0.0355\n",
      "epoch 25 loss: 0.0355\n",
      "epoch 26 loss: 0.0346\n",
      "epoch 27 loss: 0.0337\n",
      "epoch 28 loss: 0.0327\n",
      "epoch 29 loss: 0.0357\n",
      "epoch 30 loss: 0.0356\n",
      "37\n",
      "epoch 1 loss: 0.9478\n",
      "epoch 2 loss: 0.8413\n",
      "epoch 3 loss: 0.6710\n",
      "epoch 4 loss: 0.6802\n",
      "epoch 5 loss: 0.3838\n",
      "epoch 6 loss: 0.2220\n",
      "epoch 7 loss: 0.1121\n",
      "epoch 8 loss: 0.0812\n",
      "epoch 9 loss: 0.0705\n",
      "epoch 10 loss: 0.0639\n",
      "epoch 11 loss: 0.0548\n",
      "epoch 12 loss: 0.0557\n",
      "epoch 13 loss: 0.0555\n",
      "epoch 14 loss: 0.0526\n",
      "epoch 15 loss: 0.0519\n",
      "epoch 16 loss: 0.0441\n",
      "epoch 17 loss: 0.0498\n",
      "epoch 18 loss: 0.0458\n",
      "epoch 19 loss: 0.0410\n",
      "epoch 20 loss: 0.0519\n",
      "epoch 21 loss: 0.0386\n",
      "epoch 22 loss: 0.0421\n",
      "epoch 23 loss: 0.0384\n",
      "epoch 24 loss: 0.0415\n",
      "epoch 25 loss: 0.0359\n",
      "epoch 26 loss: 0.0449\n",
      "epoch 27 loss: 0.0338\n",
      "epoch 28 loss: 0.0403\n",
      "epoch 29 loss: 0.0343\n",
      "epoch 30 loss: 0.0374\n",
      "38\n",
      "epoch 1 loss: 0.6613\n",
      "epoch 2 loss: 0.4122\n",
      "epoch 3 loss: 0.3505\n",
      "epoch 4 loss: 0.2468\n",
      "epoch 5 loss: 0.1564\n",
      "epoch 6 loss: 0.0962\n",
      "epoch 7 loss: 0.0809\n",
      "epoch 8 loss: 0.0681\n",
      "epoch 9 loss: 0.0674\n",
      "epoch 10 loss: 0.0549\n",
      "epoch 11 loss: 0.0598\n",
      "epoch 12 loss: 0.0524\n",
      "epoch 13 loss: 0.0441\n",
      "epoch 14 loss: 0.0475\n",
      "epoch 15 loss: 0.0551\n",
      "epoch 16 loss: 0.0424\n",
      "epoch 17 loss: 0.0447\n",
      "epoch 18 loss: 0.0494\n",
      "epoch 19 loss: 0.0377\n",
      "epoch 20 loss: 0.0414\n",
      "epoch 21 loss: 0.0428\n",
      "epoch 22 loss: 0.0417\n",
      "epoch 23 loss: 0.0365\n",
      "epoch 24 loss: 0.0358\n",
      "epoch 25 loss: 0.0328\n",
      "epoch 26 loss: 0.0304\n",
      "epoch 27 loss: 0.0375\n",
      "epoch 28 loss: 0.0350\n",
      "epoch 29 loss: 0.0379\n",
      "epoch 30 loss: 0.0302\n",
      "39\n",
      "epoch 1 loss: 0.7617\n",
      "epoch 2 loss: 0.4900\n",
      "epoch 3 loss: 0.3374\n",
      "epoch 4 loss: 0.3031\n",
      "epoch 5 loss: 0.1370\n",
      "epoch 6 loss: 0.0916\n",
      "epoch 7 loss: 0.0667\n",
      "epoch 8 loss: 0.0587\n",
      "epoch 9 loss: 0.0683\n",
      "epoch 10 loss: 0.0593\n",
      "epoch 11 loss: 0.0649\n",
      "epoch 12 loss: 0.0556\n",
      "epoch 13 loss: 0.0492\n",
      "epoch 14 loss: 0.0432\n",
      "epoch 15 loss: 0.0425\n",
      "epoch 16 loss: 0.0436\n",
      "epoch 17 loss: 0.0454\n",
      "epoch 18 loss: 0.0450\n",
      "epoch 19 loss: 0.0398\n",
      "epoch 20 loss: 0.0341\n",
      "epoch 21 loss: 0.0386\n",
      "epoch 22 loss: 0.0346\n",
      "epoch 23 loss: 0.0350\n",
      "epoch 24 loss: 0.0384\n",
      "epoch 25 loss: 0.0383\n",
      "epoch 26 loss: 0.0367\n",
      "epoch 27 loss: 0.0346\n",
      "epoch 28 loss: 0.0388\n",
      "epoch 29 loss: 0.0337\n",
      "epoch 30 loss: 0.0344\n",
      "40\n",
      "epoch 1 loss: 0.7081\n",
      "epoch 2 loss: 0.9418\n",
      "epoch 3 loss: 0.5502\n",
      "epoch 4 loss: 0.3556\n",
      "epoch 5 loss: 0.1940\n",
      "epoch 6 loss: 0.1078\n",
      "epoch 7 loss: 0.0885\n",
      "epoch 8 loss: 0.0619\n",
      "epoch 9 loss: 0.0574\n",
      "epoch 10 loss: 0.0583\n",
      "epoch 11 loss: 0.0547\n",
      "epoch 12 loss: 0.0519\n",
      "epoch 13 loss: 0.0539\n",
      "epoch 14 loss: 0.0491\n",
      "epoch 15 loss: 0.0485\n",
      "epoch 16 loss: 0.0449\n",
      "epoch 17 loss: 0.0498\n",
      "epoch 18 loss: 0.0481\n",
      "epoch 19 loss: 0.0394\n",
      "epoch 20 loss: 0.0452\n",
      "epoch 21 loss: 0.0378\n",
      "epoch 22 loss: 0.0358\n",
      "epoch 23 loss: 0.0404\n",
      "epoch 24 loss: 0.0404\n",
      "epoch 25 loss: 0.0390\n",
      "epoch 26 loss: 0.0371\n",
      "epoch 27 loss: 0.0365\n",
      "epoch 28 loss: 0.0352\n",
      "epoch 29 loss: 0.0395\n",
      "epoch 30 loss: 0.0399\n",
      "41\n",
      "epoch 1 loss: 0.7354\n",
      "epoch 2 loss: 0.6924\n",
      "epoch 3 loss: 0.5221\n",
      "epoch 4 loss: 0.5127\n",
      "epoch 5 loss: 0.4877\n",
      "epoch 6 loss: 0.4532\n",
      "epoch 7 loss: 0.3295\n",
      "epoch 8 loss: 0.1359\n",
      "epoch 9 loss: 0.1049\n",
      "epoch 10 loss: 0.0743\n",
      "epoch 11 loss: 0.0643\n",
      "epoch 12 loss: 0.0543\n",
      "epoch 13 loss: 0.0563\n",
      "epoch 14 loss: 0.0465\n",
      "epoch 15 loss: 0.0479\n",
      "epoch 16 loss: 0.0514\n",
      "epoch 17 loss: 0.0422\n",
      "epoch 18 loss: 0.0413\n",
      "epoch 19 loss: 0.0452\n",
      "epoch 20 loss: 0.0416\n",
      "epoch 21 loss: 0.0416\n",
      "epoch 22 loss: 0.0391\n",
      "epoch 23 loss: 0.0396\n",
      "epoch 24 loss: 0.0340\n",
      "epoch 25 loss: 0.0382\n",
      "epoch 26 loss: 0.0398\n",
      "epoch 27 loss: 0.0385\n",
      "epoch 28 loss: 0.0355\n",
      "epoch 29 loss: 0.0349\n",
      "epoch 30 loss: 0.0362\n",
      "42\n",
      "epoch 1 loss: 1.3261\n",
      "epoch 2 loss: 0.8480\n",
      "epoch 3 loss: 0.5100\n",
      "epoch 4 loss: 0.3232\n",
      "epoch 5 loss: 0.1195\n",
      "epoch 6 loss: 0.0787\n",
      "epoch 7 loss: 0.0786\n",
      "epoch 8 loss: 0.0734\n",
      "epoch 9 loss: 0.0729\n",
      "epoch 10 loss: 0.0644\n",
      "epoch 11 loss: 0.0648\n",
      "epoch 12 loss: 0.0498\n",
      "epoch 13 loss: 0.0513\n",
      "epoch 14 loss: 0.0439\n",
      "epoch 15 loss: 0.0450\n",
      "epoch 16 loss: 0.0459\n",
      "epoch 17 loss: 0.0463\n",
      "epoch 18 loss: 0.0437\n",
      "epoch 19 loss: 0.0457\n",
      "epoch 20 loss: 0.0405\n",
      "epoch 21 loss: 0.0438\n",
      "epoch 22 loss: 0.0422\n",
      "epoch 23 loss: 0.0418\n",
      "epoch 24 loss: 0.0403\n",
      "epoch 25 loss: 0.0382\n",
      "epoch 26 loss: 0.0401\n",
      "epoch 27 loss: 0.0397\n",
      "epoch 28 loss: 0.0375\n",
      "epoch 29 loss: 0.0370\n",
      "epoch 30 loss: 0.0347\n",
      "43\n",
      "epoch 1 loss: 0.7827\n",
      "epoch 2 loss: 0.5100\n",
      "epoch 3 loss: 0.4893\n",
      "epoch 4 loss: 0.5747\n",
      "epoch 5 loss: 0.3763\n",
      "epoch 6 loss: 0.2239\n",
      "epoch 7 loss: 0.1224\n",
      "epoch 8 loss: 0.0712\n",
      "epoch 9 loss: 0.0584\n",
      "epoch 10 loss: 0.0530\n",
      "epoch 11 loss: 0.0515\n",
      "epoch 12 loss: 0.0480\n",
      "epoch 13 loss: 0.0425\n",
      "epoch 14 loss: 0.0451\n",
      "epoch 15 loss: 0.0476\n",
      "epoch 16 loss: 0.0399\n",
      "epoch 17 loss: 0.0408\n",
      "epoch 18 loss: 0.0368\n",
      "epoch 19 loss: 0.0411\n",
      "epoch 20 loss: 0.0374\n",
      "epoch 21 loss: 0.0388\n",
      "epoch 22 loss: 0.0379\n",
      "epoch 23 loss: 0.0358\n",
      "epoch 24 loss: 0.0344\n",
      "epoch 25 loss: 0.0382\n",
      "epoch 26 loss: 0.0340\n",
      "epoch 27 loss: 0.0335\n",
      "epoch 28 loss: 0.0388\n",
      "epoch 29 loss: 0.0315\n",
      "epoch 30 loss: 0.0314\n",
      "44\n",
      "epoch 1 loss: 0.8956\n",
      "epoch 2 loss: 0.6522\n",
      "epoch 3 loss: 0.3842\n",
      "epoch 4 loss: 0.1562\n",
      "epoch 5 loss: 0.0985\n",
      "epoch 6 loss: 0.0759\n",
      "epoch 7 loss: 0.0695\n",
      "epoch 8 loss: 0.0625\n",
      "epoch 9 loss: 0.0543\n",
      "epoch 10 loss: 0.0596\n",
      "epoch 11 loss: 0.0536\n",
      "epoch 12 loss: 0.0432\n",
      "epoch 13 loss: 0.0455\n",
      "epoch 14 loss: 0.0459\n",
      "epoch 15 loss: 0.0407\n",
      "epoch 16 loss: 0.0398\n",
      "epoch 17 loss: 0.0432\n",
      "epoch 18 loss: 0.0418\n",
      "epoch 19 loss: 0.0404\n",
      "epoch 20 loss: 0.0375\n",
      "epoch 21 loss: 0.0412\n",
      "epoch 22 loss: 0.0334\n",
      "epoch 23 loss: 0.0335\n",
      "epoch 24 loss: 0.0366\n",
      "epoch 25 loss: 0.0354\n",
      "epoch 26 loss: 0.0444\n",
      "epoch 27 loss: 0.0354\n",
      "epoch 28 loss: 0.0344\n",
      "epoch 29 loss: 0.0328\n",
      "epoch 30 loss: 0.0374\n",
      "45\n",
      "epoch 1 loss: 0.8437\n",
      "epoch 2 loss: 0.6292\n",
      "epoch 3 loss: 0.4840\n",
      "epoch 4 loss: 0.4176\n",
      "epoch 5 loss: 0.3012\n",
      "epoch 6 loss: 0.2733\n",
      "epoch 7 loss: 0.3932\n",
      "epoch 8 loss: 0.2258\n",
      "epoch 9 loss: 0.1109\n",
      "epoch 10 loss: 0.0718\n",
      "epoch 11 loss: 0.0555\n",
      "epoch 12 loss: 0.0541\n",
      "epoch 13 loss: 0.0525\n",
      "epoch 14 loss: 0.0488\n",
      "epoch 15 loss: 0.0429\n",
      "epoch 16 loss: 0.0464\n",
      "epoch 17 loss: 0.0440\n",
      "epoch 18 loss: 0.0402\n",
      "epoch 19 loss: 0.0423\n",
      "epoch 20 loss: 0.0380\n",
      "epoch 21 loss: 0.0407\n",
      "epoch 22 loss: 0.0376\n",
      "epoch 23 loss: 0.0416\n",
      "epoch 24 loss: 0.0353\n",
      "epoch 25 loss: 0.0403\n",
      "epoch 26 loss: 0.0324\n",
      "epoch 27 loss: 0.0374\n",
      "epoch 28 loss: 0.0355\n",
      "epoch 29 loss: 0.0342\n",
      "epoch 30 loss: 0.0352\n",
      "46\n",
      "epoch 1 loss: 0.9084\n",
      "epoch 2 loss: 0.6193\n",
      "epoch 3 loss: 0.4659\n",
      "epoch 4 loss: 0.3836\n",
      "epoch 5 loss: 0.2604\n",
      "epoch 6 loss: 0.1336\n",
      "epoch 7 loss: 0.0785\n",
      "epoch 8 loss: 0.0578\n",
      "epoch 9 loss: 0.0581\n",
      "epoch 10 loss: 0.0497\n",
      "epoch 11 loss: 0.0483\n",
      "epoch 12 loss: 0.0442\n",
      "epoch 13 loss: 0.0478\n",
      "epoch 14 loss: 0.0451\n",
      "epoch 15 loss: 0.0463\n",
      "epoch 16 loss: 0.0431\n",
      "epoch 17 loss: 0.0404\n",
      "epoch 18 loss: 0.0409\n",
      "epoch 19 loss: 0.0413\n",
      "epoch 20 loss: 0.0365\n",
      "epoch 21 loss: 0.0411\n",
      "epoch 22 loss: 0.0442\n",
      "epoch 23 loss: 0.0361\n",
      "epoch 24 loss: 0.0323\n",
      "epoch 25 loss: 0.0376\n",
      "epoch 26 loss: 0.0357\n",
      "epoch 27 loss: 0.0325\n",
      "epoch 28 loss: 0.0344\n",
      "epoch 29 loss: 0.0336\n",
      "epoch 30 loss: 0.0354\n",
      "47\n",
      "epoch 1 loss: 0.7670\n",
      "epoch 2 loss: 0.5688\n",
      "epoch 3 loss: 0.5518\n",
      "epoch 4 loss: 0.4270\n",
      "epoch 5 loss: 0.3015\n",
      "epoch 6 loss: 0.1178\n",
      "epoch 7 loss: 0.0831\n",
      "epoch 8 loss: 0.0587\n",
      "epoch 9 loss: 0.0501\n",
      "epoch 10 loss: 0.0458\n",
      "epoch 11 loss: 0.0493\n",
      "epoch 12 loss: 0.0439\n",
      "epoch 13 loss: 0.0381\n",
      "epoch 14 loss: 0.0453\n",
      "epoch 15 loss: 0.0374\n",
      "epoch 16 loss: 0.0372\n",
      "epoch 17 loss: 0.0386\n",
      "epoch 18 loss: 0.0381\n",
      "epoch 19 loss: 0.0374\n",
      "epoch 20 loss: 0.0357\n",
      "epoch 21 loss: 0.0357\n",
      "epoch 22 loss: 0.0368\n",
      "epoch 23 loss: 0.0344\n",
      "epoch 24 loss: 0.0339\n",
      "epoch 25 loss: 0.0337\n",
      "epoch 26 loss: 0.0315\n",
      "epoch 27 loss: 0.0335\n",
      "epoch 28 loss: 0.0314\n",
      "epoch 29 loss: 0.0324\n",
      "epoch 30 loss: 0.0311\n",
      "48\n",
      "epoch 1 loss: 0.7031\n",
      "epoch 2 loss: 0.4788\n",
      "epoch 3 loss: 0.3995\n",
      "epoch 4 loss: 0.2648\n",
      "epoch 5 loss: 0.1566\n",
      "epoch 6 loss: 0.0898\n",
      "epoch 7 loss: 0.0602\n",
      "epoch 8 loss: 0.0543\n",
      "epoch 9 loss: 0.0502\n",
      "epoch 10 loss: 0.0489\n",
      "epoch 11 loss: 0.0470\n",
      "epoch 12 loss: 0.0475\n",
      "epoch 13 loss: 0.0408\n",
      "epoch 14 loss: 0.0401\n",
      "epoch 15 loss: 0.0387\n",
      "epoch 16 loss: 0.0394\n",
      "epoch 17 loss: 0.0373\n",
      "epoch 18 loss: 0.0394\n",
      "epoch 19 loss: 0.0370\n",
      "epoch 20 loss: 0.0384\n",
      "epoch 21 loss: 0.0345\n",
      "epoch 22 loss: 0.0357\n",
      "epoch 23 loss: 0.0340\n",
      "epoch 24 loss: 0.0364\n",
      "epoch 25 loss: 0.0327\n",
      "epoch 26 loss: 0.0329\n",
      "epoch 27 loss: 0.0335\n",
      "epoch 28 loss: 0.0339\n",
      "epoch 29 loss: 0.0320\n",
      "epoch 30 loss: 0.0314\n",
      "49\n",
      "epoch 1 loss: 0.7307\n",
      "epoch 2 loss: 0.5176\n",
      "epoch 3 loss: 0.4806\n",
      "epoch 4 loss: 0.3853\n",
      "epoch 5 loss: 0.2797\n",
      "epoch 6 loss: 0.1590\n",
      "epoch 7 loss: 0.0845\n",
      "epoch 8 loss: 0.0788\n",
      "epoch 9 loss: 0.0648\n",
      "epoch 10 loss: 0.0693\n",
      "epoch 11 loss: 0.0535\n",
      "epoch 12 loss: 0.0479\n",
      "epoch 13 loss: 0.0505\n",
      "epoch 14 loss: 0.0451\n",
      "epoch 15 loss: 0.0462\n",
      "epoch 16 loss: 0.0470\n",
      "epoch 17 loss: 0.0400\n",
      "epoch 18 loss: 0.0400\n",
      "epoch 19 loss: 0.0453\n",
      "epoch 20 loss: 0.0387\n",
      "epoch 21 loss: 0.0412\n",
      "epoch 22 loss: 0.0409\n",
      "epoch 23 loss: 0.0386\n",
      "epoch 24 loss: 0.0449\n",
      "epoch 25 loss: 0.0360\n",
      "epoch 26 loss: 0.0390\n",
      "epoch 27 loss: 0.0380\n",
      "epoch 28 loss: 0.0375\n",
      "epoch 29 loss: 0.0355\n",
      "epoch 30 loss: 0.0340\n",
      "50\n",
      "epoch 1 loss: 0.9256\n",
      "epoch 2 loss: 0.6104\n",
      "epoch 3 loss: 0.5835\n",
      "epoch 4 loss: 0.4983\n",
      "epoch 5 loss: 0.3375\n",
      "epoch 6 loss: 0.2190\n",
      "epoch 7 loss: 0.1238\n",
      "epoch 8 loss: 0.0780\n",
      "epoch 9 loss: 0.0590\n",
      "epoch 10 loss: 0.0555\n",
      "epoch 11 loss: 0.0475\n",
      "epoch 12 loss: 0.0511\n",
      "epoch 13 loss: 0.0445\n",
      "epoch 14 loss: 0.0453\n",
      "epoch 15 loss: 0.0463\n",
      "epoch 16 loss: 0.0488\n",
      "epoch 17 loss: 0.0378\n",
      "epoch 18 loss: 0.0397\n",
      "epoch 19 loss: 0.0388\n",
      "epoch 20 loss: 0.0361\n",
      "epoch 21 loss: 0.0368\n",
      "epoch 22 loss: 0.0396\n",
      "epoch 23 loss: 0.0356\n",
      "epoch 24 loss: 0.0365\n",
      "epoch 25 loss: 0.0357\n",
      "epoch 26 loss: 0.0344\n",
      "epoch 27 loss: 0.0340\n",
      "epoch 28 loss: 0.0310\n",
      "epoch 29 loss: 0.0359\n",
      "epoch 30 loss: 0.0359\n",
      "51\n",
      "epoch 1 loss: 0.7460\n",
      "epoch 2 loss: 0.4014\n",
      "epoch 3 loss: 0.3282\n",
      "epoch 4 loss: 0.2397\n",
      "epoch 5 loss: 0.1366\n",
      "epoch 6 loss: 0.0744\n",
      "epoch 7 loss: 0.0721\n",
      "epoch 8 loss: 0.0603\n",
      "epoch 9 loss: 0.0555\n",
      "epoch 10 loss: 0.0506\n",
      "epoch 11 loss: 0.0547\n",
      "epoch 12 loss: 0.0503\n",
      "epoch 13 loss: 0.0443\n",
      "epoch 14 loss: 0.0461\n",
      "epoch 15 loss: 0.0462\n",
      "epoch 16 loss: 0.0437\n",
      "epoch 17 loss: 0.0383\n",
      "epoch 18 loss: 0.0338\n",
      "epoch 19 loss: 0.0391\n",
      "epoch 20 loss: 0.0354\n",
      "epoch 21 loss: 0.0341\n",
      "epoch 22 loss: 0.0363\n",
      "epoch 23 loss: 0.0376\n",
      "epoch 24 loss: 0.0328\n",
      "epoch 25 loss: 0.0365\n",
      "epoch 26 loss: 0.0360\n",
      "epoch 27 loss: 0.0365\n",
      "epoch 28 loss: 0.0381\n",
      "epoch 29 loss: 0.0312\n",
      "epoch 30 loss: 0.0363\n",
      "52\n",
      "epoch 1 loss: 1.0982\n",
      "epoch 2 loss: 0.6017\n",
      "epoch 3 loss: 0.5645\n",
      "epoch 4 loss: 0.3813\n",
      "epoch 5 loss: 0.2404\n",
      "epoch 6 loss: 0.1951\n",
      "epoch 7 loss: 0.1779\n",
      "epoch 8 loss: 0.1354\n",
      "epoch 9 loss: 0.1162\n",
      "epoch 10 loss: 0.0946\n",
      "epoch 11 loss: 0.0682\n",
      "epoch 12 loss: 0.0731\n",
      "epoch 13 loss: 0.0671\n",
      "epoch 14 loss: 0.0611\n",
      "epoch 15 loss: 0.0642\n",
      "epoch 16 loss: 0.0489\n",
      "epoch 17 loss: 0.0460\n",
      "epoch 18 loss: 0.0511\n",
      "epoch 19 loss: 0.0415\n",
      "epoch 20 loss: 0.0556\n",
      "epoch 21 loss: 0.0469\n",
      "epoch 22 loss: 0.0454\n",
      "epoch 23 loss: 0.0512\n",
      "epoch 24 loss: 0.0427\n",
      "epoch 25 loss: 0.0419\n",
      "epoch 26 loss: 0.0417\n",
      "epoch 27 loss: 0.0422\n",
      "epoch 28 loss: 0.0377\n",
      "epoch 29 loss: 0.0388\n",
      "epoch 30 loss: 0.0376\n",
      "53\n",
      "epoch 1 loss: 0.8407\n",
      "epoch 2 loss: 0.5225\n",
      "epoch 3 loss: 0.6428\n",
      "epoch 4 loss: 0.5102\n",
      "epoch 5 loss: 0.3323\n",
      "epoch 6 loss: 0.1268\n",
      "epoch 7 loss: 0.0964\n",
      "epoch 8 loss: 0.0799\n",
      "epoch 9 loss: 0.0618\n",
      "epoch 10 loss: 0.0694\n",
      "epoch 11 loss: 0.0616\n",
      "epoch 12 loss: 0.0553\n",
      "epoch 13 loss: 0.0478\n",
      "epoch 14 loss: 0.0563\n",
      "epoch 15 loss: 0.0462\n",
      "epoch 16 loss: 0.0442\n",
      "epoch 17 loss: 0.0468\n",
      "epoch 18 loss: 0.0433\n",
      "epoch 19 loss: 0.0458\n",
      "epoch 20 loss: 0.0462\n",
      "epoch 21 loss: 0.0335\n",
      "epoch 22 loss: 0.0455\n",
      "epoch 23 loss: 0.0427\n",
      "epoch 24 loss: 0.0457\n",
      "epoch 25 loss: 0.0413\n",
      "epoch 26 loss: 0.0407\n",
      "epoch 27 loss: 0.0337\n",
      "epoch 28 loss: 0.0369\n",
      "epoch 29 loss: 0.0376\n",
      "epoch 30 loss: 0.0349\n",
      "54\n",
      "epoch 1 loss: 0.6204\n",
      "epoch 2 loss: 0.5302\n",
      "epoch 3 loss: 0.5229\n",
      "epoch 4 loss: 0.3696\n",
      "epoch 5 loss: 0.1879\n",
      "epoch 6 loss: 0.1108\n",
      "epoch 7 loss: 0.0789\n",
      "epoch 8 loss: 0.0682\n",
      "epoch 9 loss: 0.0650\n",
      "epoch 10 loss: 0.0571\n",
      "epoch 11 loss: 0.0501\n",
      "epoch 12 loss: 0.0557\n",
      "epoch 13 loss: 0.0552\n",
      "epoch 14 loss: 0.0467\n",
      "epoch 15 loss: 0.0403\n",
      "epoch 16 loss: 0.0475\n",
      "epoch 17 loss: 0.0458\n",
      "epoch 18 loss: 0.0465\n",
      "epoch 19 loss: 0.0455\n",
      "epoch 20 loss: 0.0399\n",
      "epoch 21 loss: 0.0418\n",
      "epoch 22 loss: 0.0374\n",
      "epoch 23 loss: 0.0399\n",
      "epoch 24 loss: 0.0353\n",
      "epoch 25 loss: 0.0397\n",
      "epoch 26 loss: 0.0333\n",
      "epoch 27 loss: 0.0387\n",
      "epoch 28 loss: 0.0345\n",
      "epoch 29 loss: 0.0363\n",
      "epoch 30 loss: 0.0336\n",
      "55\n",
      "epoch 1 loss: 0.8087\n",
      "epoch 2 loss: 0.6477\n",
      "epoch 3 loss: 0.4623\n",
      "epoch 4 loss: 0.4151\n",
      "epoch 5 loss: 0.2711\n",
      "epoch 6 loss: 0.1549\n",
      "epoch 7 loss: 0.0876\n",
      "epoch 8 loss: 0.0664\n",
      "epoch 9 loss: 0.0514\n",
      "epoch 10 loss: 0.0524\n",
      "epoch 11 loss: 0.0457\n",
      "epoch 12 loss: 0.0491\n",
      "epoch 13 loss: 0.0455\n",
      "epoch 14 loss: 0.0421\n",
      "epoch 15 loss: 0.0427\n",
      "epoch 16 loss: 0.0392\n",
      "epoch 17 loss: 0.0397\n",
      "epoch 18 loss: 0.0374\n",
      "epoch 19 loss: 0.0400\n",
      "epoch 20 loss: 0.0395\n",
      "epoch 21 loss: 0.0421\n",
      "epoch 22 loss: 0.0346\n",
      "epoch 23 loss: 0.0408\n",
      "epoch 24 loss: 0.0321\n",
      "epoch 25 loss: 0.0338\n",
      "epoch 26 loss: 0.0376\n",
      "epoch 27 loss: 0.0359\n",
      "epoch 28 loss: 0.0344\n",
      "epoch 29 loss: 0.0371\n",
      "epoch 30 loss: 0.0322\n",
      "56\n",
      "epoch 1 loss: 0.9024\n",
      "epoch 2 loss: 0.5278\n",
      "epoch 3 loss: 0.6309\n",
      "epoch 4 loss: 0.6518\n",
      "epoch 5 loss: 0.4812\n",
      "epoch 6 loss: 0.3423\n",
      "epoch 7 loss: 0.3940\n",
      "epoch 8 loss: 0.4644\n",
      "epoch 9 loss: 0.1912\n",
      "epoch 10 loss: 0.1080\n",
      "epoch 11 loss: 0.0812\n",
      "epoch 12 loss: 0.0665\n",
      "epoch 13 loss: 0.0677\n",
      "epoch 14 loss: 0.0607\n",
      "epoch 15 loss: 0.0488\n",
      "epoch 16 loss: 0.0479\n",
      "epoch 17 loss: 0.0559\n",
      "epoch 18 loss: 0.0420\n",
      "epoch 19 loss: 0.0441\n",
      "epoch 20 loss: 0.0474\n",
      "epoch 21 loss: 0.0466\n",
      "epoch 22 loss: 0.0384\n",
      "epoch 23 loss: 0.0433\n",
      "epoch 24 loss: 0.0405\n",
      "epoch 25 loss: 0.0404\n",
      "epoch 26 loss: 0.0407\n",
      "epoch 27 loss: 0.0378\n",
      "epoch 28 loss: 0.0368\n",
      "epoch 29 loss: 0.0369\n",
      "epoch 30 loss: 0.0342\n",
      "57\n",
      "epoch 1 loss: 1.1234\n",
      "epoch 2 loss: 0.6887\n",
      "epoch 3 loss: 0.4979\n",
      "epoch 4 loss: 0.2703\n",
      "epoch 5 loss: 0.2214\n",
      "epoch 6 loss: 0.1404\n",
      "epoch 7 loss: 0.0870\n",
      "epoch 8 loss: 0.0693\n",
      "epoch 9 loss: 0.0750\n",
      "epoch 10 loss: 0.0648\n",
      "epoch 11 loss: 0.0516\n",
      "epoch 12 loss: 0.0484\n",
      "epoch 13 loss: 0.0511\n",
      "epoch 14 loss: 0.0487\n",
      "epoch 15 loss: 0.0467\n",
      "epoch 16 loss: 0.0452\n",
      "epoch 17 loss: 0.0408\n",
      "epoch 18 loss: 0.0364\n",
      "epoch 19 loss: 0.0418\n",
      "epoch 20 loss: 0.0423\n",
      "epoch 21 loss: 0.0442\n",
      "epoch 22 loss: 0.0405\n",
      "epoch 23 loss: 0.0400\n",
      "epoch 24 loss: 0.0452\n",
      "epoch 25 loss: 0.0374\n",
      "epoch 26 loss: 0.0377\n",
      "epoch 27 loss: 0.0348\n",
      "epoch 28 loss: 0.0368\n",
      "epoch 29 loss: 0.0373\n",
      "epoch 30 loss: 0.0348\n",
      "58\n",
      "epoch 1 loss: 0.6670\n",
      "epoch 2 loss: 0.4796\n",
      "epoch 3 loss: 0.4031\n",
      "epoch 4 loss: 0.3506\n",
      "epoch 5 loss: 0.2135\n",
      "epoch 6 loss: 0.1092\n",
      "epoch 7 loss: 0.0817\n",
      "epoch 8 loss: 0.0620\n",
      "epoch 9 loss: 0.0511\n",
      "epoch 10 loss: 0.0493\n",
      "epoch 11 loss: 0.0533\n",
      "epoch 12 loss: 0.0420\n",
      "epoch 13 loss: 0.0481\n",
      "epoch 14 loss: 0.0396\n",
      "epoch 15 loss: 0.0406\n",
      "epoch 16 loss: 0.0375\n",
      "epoch 17 loss: 0.0428\n",
      "epoch 18 loss: 0.0395\n",
      "epoch 19 loss: 0.0387\n",
      "epoch 20 loss: 0.0390\n",
      "epoch 21 loss: 0.0388\n",
      "epoch 22 loss: 0.0387\n",
      "epoch 23 loss: 0.0374\n",
      "epoch 24 loss: 0.0333\n",
      "epoch 25 loss: 0.0316\n",
      "epoch 26 loss: 0.0364\n",
      "epoch 27 loss: 0.0323\n",
      "epoch 28 loss: 0.0311\n",
      "epoch 29 loss: 0.0358\n",
      "epoch 30 loss: 0.0373\n",
      "59\n",
      "epoch 1 loss: 1.0142\n",
      "epoch 2 loss: 0.5029\n",
      "epoch 3 loss: 0.3489\n",
      "epoch 4 loss: 0.3569\n",
      "epoch 5 loss: 0.2060\n",
      "epoch 6 loss: 0.1480\n",
      "epoch 7 loss: 0.1002\n",
      "epoch 8 loss: 0.0760\n",
      "epoch 9 loss: 0.0805\n",
      "epoch 10 loss: 0.0651\n",
      "epoch 11 loss: 0.0694\n",
      "epoch 12 loss: 0.0546\n",
      "epoch 13 loss: 0.0513\n",
      "epoch 14 loss: 0.0508\n",
      "epoch 15 loss: 0.0617\n",
      "epoch 16 loss: 0.0538\n",
      "epoch 17 loss: 0.0469\n",
      "epoch 18 loss: 0.0469\n",
      "epoch 19 loss: 0.0501\n",
      "epoch 20 loss: 0.0489\n",
      "epoch 21 loss: 0.0464\n",
      "epoch 22 loss: 0.0467\n",
      "epoch 23 loss: 0.0453\n",
      "epoch 24 loss: 0.0406\n",
      "epoch 25 loss: 0.0400\n",
      "epoch 26 loss: 0.0447\n",
      "epoch 27 loss: 0.0414\n",
      "epoch 28 loss: 0.0451\n",
      "epoch 29 loss: 0.0352\n",
      "epoch 30 loss: 0.0420\n",
      "60\n",
      "epoch 1 loss: 0.8667\n",
      "epoch 2 loss: 0.6200\n",
      "epoch 3 loss: 0.3547\n",
      "epoch 4 loss: 0.2283\n",
      "epoch 5 loss: 0.1390\n",
      "epoch 6 loss: 0.0892\n",
      "epoch 7 loss: 0.0718\n",
      "epoch 8 loss: 0.0685\n",
      "epoch 9 loss: 0.0576\n",
      "epoch 10 loss: 0.0582\n",
      "epoch 11 loss: 0.0611\n",
      "epoch 12 loss: 0.0549\n",
      "epoch 13 loss: 0.0504\n",
      "epoch 14 loss: 0.0575\n",
      "epoch 15 loss: 0.0468\n",
      "epoch 16 loss: 0.0434\n",
      "epoch 17 loss: 0.0460\n",
      "epoch 18 loss: 0.0399\n",
      "epoch 19 loss: 0.0472\n",
      "epoch 20 loss: 0.0575\n",
      "epoch 21 loss: 0.0448\n",
      "epoch 22 loss: 0.0423\n",
      "epoch 23 loss: 0.0415\n",
      "epoch 24 loss: 0.0384\n",
      "epoch 25 loss: 0.0321\n",
      "epoch 26 loss: 0.0409\n",
      "epoch 27 loss: 0.0349\n",
      "epoch 28 loss: 0.0360\n",
      "epoch 29 loss: 0.0369\n",
      "epoch 30 loss: 0.0356\n",
      "61\n",
      "epoch 1 loss: 1.0571\n",
      "epoch 2 loss: 0.5288\n",
      "epoch 3 loss: 0.4593\n",
      "epoch 4 loss: 0.4220\n",
      "epoch 5 loss: 0.4040\n",
      "epoch 6 loss: 0.3281\n",
      "epoch 7 loss: 0.1937\n",
      "epoch 8 loss: 0.1164\n",
      "epoch 9 loss: 0.0980\n",
      "epoch 10 loss: 0.0756\n",
      "epoch 11 loss: 0.0586\n",
      "epoch 12 loss: 0.0621\n",
      "epoch 13 loss: 0.0555\n",
      "epoch 14 loss: 0.0601\n",
      "epoch 15 loss: 0.0512\n",
      "epoch 16 loss: 0.0490\n",
      "epoch 17 loss: 0.0452\n",
      "epoch 18 loss: 0.0510\n",
      "epoch 19 loss: 0.0497\n",
      "epoch 20 loss: 0.0428\n",
      "epoch 21 loss: 0.0474\n",
      "epoch 22 loss: 0.0440\n",
      "epoch 23 loss: 0.0458\n",
      "epoch 24 loss: 0.0415\n",
      "epoch 25 loss: 0.0430\n",
      "epoch 26 loss: 0.0415\n",
      "epoch 27 loss: 0.0397\n",
      "epoch 28 loss: 0.0446\n",
      "epoch 29 loss: 0.0378\n",
      "epoch 30 loss: 0.0368\n",
      "62\n",
      "epoch 1 loss: 0.7955\n",
      "epoch 2 loss: 0.5144\n",
      "epoch 3 loss: 0.3168\n",
      "epoch 4 loss: 0.1653\n",
      "epoch 5 loss: 0.1129\n",
      "epoch 6 loss: 0.0784\n",
      "epoch 7 loss: 0.0599\n",
      "epoch 8 loss: 0.0570\n",
      "epoch 9 loss: 0.0519\n",
      "epoch 10 loss: 0.0476\n",
      "epoch 11 loss: 0.0491\n",
      "epoch 12 loss: 0.0453\n",
      "epoch 13 loss: 0.0437\n",
      "epoch 14 loss: 0.0423\n",
      "epoch 15 loss: 0.0429\n",
      "epoch 16 loss: 0.0426\n",
      "epoch 17 loss: 0.0428\n",
      "epoch 18 loss: 0.0369\n",
      "epoch 19 loss: 0.0383\n",
      "epoch 20 loss: 0.0368\n",
      "epoch 21 loss: 0.0382\n",
      "epoch 22 loss: 0.0404\n",
      "epoch 23 loss: 0.0369\n",
      "epoch 24 loss: 0.0395\n",
      "epoch 25 loss: 0.0366\n",
      "epoch 26 loss: 0.0340\n",
      "epoch 27 loss: 0.0403\n",
      "epoch 28 loss: 0.0351\n",
      "epoch 29 loss: 0.0351\n",
      "epoch 30 loss: 0.0337\n",
      "63\n",
      "epoch 1 loss: 0.7202\n",
      "epoch 2 loss: 0.5618\n",
      "epoch 3 loss: 0.4824\n",
      "epoch 4 loss: 0.3222\n",
      "epoch 5 loss: 0.2086\n",
      "epoch 6 loss: 0.0982\n",
      "epoch 7 loss: 0.0764\n",
      "epoch 8 loss: 0.0641\n",
      "epoch 9 loss: 0.0635\n",
      "epoch 10 loss: 0.0660\n",
      "epoch 11 loss: 0.0491\n",
      "epoch 12 loss: 0.0434\n",
      "epoch 13 loss: 0.0450\n",
      "epoch 14 loss: 0.0408\n",
      "epoch 15 loss: 0.0402\n",
      "epoch 16 loss: 0.0399\n",
      "epoch 17 loss: 0.0384\n",
      "epoch 18 loss: 0.0433\n",
      "epoch 19 loss: 0.0406\n",
      "epoch 20 loss: 0.0368\n",
      "epoch 21 loss: 0.0415\n",
      "epoch 22 loss: 0.0349\n",
      "epoch 23 loss: 0.0396\n",
      "epoch 24 loss: 0.0368\n",
      "epoch 25 loss: 0.0375\n",
      "epoch 26 loss: 0.0357\n",
      "epoch 27 loss: 0.0391\n",
      "epoch 28 loss: 0.0355\n",
      "epoch 29 loss: 0.0341\n",
      "epoch 30 loss: 0.0312\n",
      "64\n",
      "epoch 1 loss: 0.9498\n",
      "epoch 2 loss: 0.7625\n",
      "epoch 3 loss: 0.5428\n",
      "epoch 4 loss: 0.4221\n",
      "epoch 5 loss: 0.3129\n",
      "epoch 6 loss: 0.2605\n",
      "epoch 7 loss: 0.1901\n",
      "epoch 8 loss: 0.1790\n",
      "epoch 9 loss: 0.1115\n",
      "epoch 10 loss: 0.0796\n",
      "epoch 11 loss: 0.0738\n",
      "epoch 12 loss: 0.0648\n",
      "epoch 13 loss: 0.0555\n",
      "epoch 14 loss: 0.0544\n",
      "epoch 15 loss: 0.0494\n",
      "epoch 16 loss: 0.0538\n",
      "epoch 17 loss: 0.0517\n",
      "epoch 18 loss: 0.0560\n",
      "epoch 19 loss: 0.0463\n",
      "epoch 20 loss: 0.0544\n",
      "epoch 21 loss: 0.0442\n",
      "epoch 22 loss: 0.0452\n",
      "epoch 23 loss: 0.0488\n",
      "epoch 24 loss: 0.0423\n",
      "epoch 25 loss: 0.0439\n",
      "epoch 26 loss: 0.0435\n",
      "epoch 27 loss: 0.0454\n",
      "epoch 28 loss: 0.0401\n",
      "epoch 29 loss: 0.0388\n",
      "epoch 30 loss: 0.0419\n",
      "65\n",
      "epoch 1 loss: 0.6333\n",
      "epoch 2 loss: 0.5016\n",
      "epoch 3 loss: 0.3818\n",
      "epoch 4 loss: 0.2399\n",
      "epoch 5 loss: 0.1211\n",
      "epoch 6 loss: 0.0867\n",
      "epoch 7 loss: 0.0583\n",
      "epoch 8 loss: 0.0518\n",
      "epoch 9 loss: 0.0506\n",
      "epoch 10 loss: 0.0418\n",
      "epoch 11 loss: 0.0518\n",
      "epoch 12 loss: 0.0424\n",
      "epoch 13 loss: 0.0431\n",
      "epoch 14 loss: 0.0405\n",
      "epoch 15 loss: 0.0426\n",
      "epoch 16 loss: 0.0380\n",
      "epoch 17 loss: 0.0360\n",
      "epoch 18 loss: 0.0399\n",
      "epoch 19 loss: 0.0352\n",
      "epoch 20 loss: 0.0440\n",
      "epoch 21 loss: 0.0386\n",
      "epoch 22 loss: 0.0358\n",
      "epoch 23 loss: 0.0358\n",
      "epoch 24 loss: 0.0329\n",
      "epoch 25 loss: 0.0319\n",
      "epoch 26 loss: 0.0347\n",
      "epoch 27 loss: 0.0318\n",
      "epoch 28 loss: 0.0328\n",
      "epoch 29 loss: 0.0345\n",
      "epoch 30 loss: 0.0315\n",
      "66\n",
      "epoch 1 loss: 0.6722\n",
      "epoch 2 loss: 0.5156\n",
      "epoch 3 loss: 0.4396\n",
      "epoch 4 loss: 0.3766\n",
      "epoch 5 loss: 0.2219\n",
      "epoch 6 loss: 0.0985\n",
      "epoch 7 loss: 0.0792\n",
      "epoch 8 loss: 0.0652\n",
      "epoch 9 loss: 0.0613\n",
      "epoch 10 loss: 0.0520\n",
      "epoch 11 loss: 0.0481\n",
      "epoch 12 loss: 0.0489\n",
      "epoch 13 loss: 0.0439\n",
      "epoch 14 loss: 0.0456\n",
      "epoch 15 loss: 0.0433\n",
      "epoch 16 loss: 0.0423\n",
      "epoch 17 loss: 0.0428\n",
      "epoch 18 loss: 0.0353\n",
      "epoch 19 loss: 0.0402\n",
      "epoch 20 loss: 0.0407\n",
      "epoch 21 loss: 0.0364\n",
      "epoch 22 loss: 0.0356\n",
      "epoch 23 loss: 0.0354\n",
      "epoch 24 loss: 0.0375\n",
      "epoch 25 loss: 0.0345\n",
      "epoch 26 loss: 0.0364\n",
      "epoch 27 loss: 0.0339\n",
      "epoch 28 loss: 0.0353\n",
      "epoch 29 loss: 0.0315\n",
      "epoch 30 loss: 0.0338\n",
      "67\n",
      "epoch 1 loss: 0.5820\n",
      "epoch 2 loss: 0.5399\n",
      "epoch 3 loss: 0.4728\n",
      "epoch 4 loss: 0.3942\n",
      "epoch 5 loss: 0.3375\n",
      "epoch 6 loss: 0.1671\n",
      "epoch 7 loss: 0.0840\n",
      "epoch 8 loss: 0.0600\n",
      "epoch 9 loss: 0.0546\n",
      "epoch 10 loss: 0.0528\n",
      "epoch 11 loss: 0.0534\n",
      "epoch 12 loss: 0.0533\n",
      "epoch 13 loss: 0.0466\n",
      "epoch 14 loss: 0.0453\n",
      "epoch 15 loss: 0.0513\n",
      "epoch 16 loss: 0.0373\n",
      "epoch 17 loss: 0.0381\n",
      "epoch 18 loss: 0.0386\n",
      "epoch 19 loss: 0.0429\n",
      "epoch 20 loss: 0.0391\n",
      "epoch 21 loss: 0.0404\n",
      "epoch 22 loss: 0.0333\n",
      "epoch 23 loss: 0.0352\n",
      "epoch 24 loss: 0.0362\n",
      "epoch 25 loss: 0.0379\n",
      "epoch 26 loss: 0.0323\n",
      "epoch 27 loss: 0.0372\n",
      "epoch 28 loss: 0.0320\n",
      "epoch 29 loss: 0.0348\n",
      "epoch 30 loss: 0.0319\n",
      "68\n",
      "epoch 1 loss: 0.8418\n",
      "epoch 2 loss: 0.7224\n",
      "epoch 3 loss: 0.6981\n",
      "epoch 4 loss: 0.4379\n",
      "epoch 5 loss: 0.2829\n",
      "epoch 6 loss: 0.1796\n",
      "epoch 7 loss: 0.1116\n",
      "epoch 8 loss: 0.0715\n",
      "epoch 9 loss: 0.0665\n",
      "epoch 10 loss: 0.0576\n",
      "epoch 11 loss: 0.0498\n",
      "epoch 12 loss: 0.0538\n",
      "epoch 13 loss: 0.0544\n",
      "epoch 14 loss: 0.0503\n",
      "epoch 15 loss: 0.0512\n",
      "epoch 16 loss: 0.0528\n",
      "epoch 17 loss: 0.0494\n",
      "epoch 18 loss: 0.0463\n",
      "epoch 19 loss: 0.0476\n",
      "epoch 20 loss: 0.0510\n",
      "epoch 21 loss: 0.0459\n",
      "epoch 22 loss: 0.0401\n",
      "epoch 23 loss: 0.0502\n",
      "epoch 24 loss: 0.0399\n",
      "epoch 25 loss: 0.0386\n",
      "epoch 26 loss: 0.0382\n",
      "epoch 27 loss: 0.0439\n",
      "epoch 28 loss: 0.0397\n",
      "epoch 29 loss: 0.0396\n",
      "epoch 30 loss: 0.0355\n",
      "69\n",
      "epoch 1 loss: 0.8855\n",
      "epoch 2 loss: 0.5815\n",
      "epoch 3 loss: 0.5388\n",
      "epoch 4 loss: 0.4345\n",
      "epoch 5 loss: 0.2369\n",
      "epoch 6 loss: 0.1361\n",
      "epoch 7 loss: 0.0878\n",
      "epoch 8 loss: 0.0635\n",
      "epoch 9 loss: 0.0638\n",
      "epoch 10 loss: 0.0525\n",
      "epoch 11 loss: 0.0474\n",
      "epoch 12 loss: 0.0459\n",
      "epoch 13 loss: 0.0454\n",
      "epoch 14 loss: 0.0472\n",
      "epoch 15 loss: 0.0399\n",
      "epoch 16 loss: 0.0421\n",
      "epoch 17 loss: 0.0446\n",
      "epoch 18 loss: 0.0405\n",
      "epoch 19 loss: 0.0436\n",
      "epoch 20 loss: 0.0431\n",
      "epoch 21 loss: 0.0392\n",
      "epoch 22 loss: 0.0362\n",
      "epoch 23 loss: 0.0391\n",
      "epoch 24 loss: 0.0389\n",
      "epoch 25 loss: 0.0367\n",
      "epoch 26 loss: 0.0316\n",
      "epoch 27 loss: 0.0330\n",
      "epoch 28 loss: 0.0339\n",
      "epoch 29 loss: 0.0324\n",
      "epoch 30 loss: 0.0373\n",
      "70\n",
      "epoch 1 loss: 0.8365\n",
      "epoch 2 loss: 0.4508\n",
      "epoch 3 loss: 0.2429\n",
      "epoch 4 loss: 0.1434\n",
      "epoch 5 loss: 0.1089\n",
      "epoch 6 loss: 0.0861\n",
      "epoch 7 loss: 0.0841\n",
      "epoch 8 loss: 0.0622\n",
      "epoch 9 loss: 0.0639\n",
      "epoch 10 loss: 0.0626\n",
      "epoch 11 loss: 0.0542\n",
      "epoch 12 loss: 0.0584\n",
      "epoch 13 loss: 0.0525\n",
      "epoch 14 loss: 0.0515\n",
      "epoch 15 loss: 0.0498\n",
      "epoch 16 loss: 0.0559\n",
      "epoch 17 loss: 0.0480\n",
      "epoch 18 loss: 0.0440\n",
      "epoch 19 loss: 0.0454\n",
      "epoch 20 loss: 0.0457\n",
      "epoch 21 loss: 0.0432\n",
      "epoch 22 loss: 0.0439\n",
      "epoch 23 loss: 0.0401\n",
      "epoch 24 loss: 0.0370\n",
      "epoch 25 loss: 0.0391\n",
      "epoch 26 loss: 0.0428\n",
      "epoch 27 loss: 0.0423\n",
      "epoch 28 loss: 0.0392\n",
      "epoch 29 loss: 0.0345\n",
      "epoch 30 loss: 0.0375\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T04:04:28.057914Z",
     "start_time": "2025-10-17T04:00:25.481270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"vector\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "\n",
    "results_aep_fourier_w_matrix_gru = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier_GRU(\n",
    "        cont_dim=cont_dim,     # full feature dim per step\n",
    "        fourier_dim=F_pairs, # only used in hand-rolled branch\n",
    "        xf_mode=\"vector\",           # or \"matrix\" to match your original\n",
    "        d_model=128,\n",
    "        nhead=4,\n",
    "        H=24,\n",
    "        use_gate=True,\n",
    "        nonneg_U0=False,\n",
    "        use_gru=True,               # turn on GRU backbone (process all x together)\n",
    "    )\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix_gru = pd.concat([results_aep_fourier_w_matrix_gru, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix_gru.to_csv(out_dir + '/results_aep_fourier_gru_kw3_km6_ky10_matrix.csv', index=False)"
   ],
   "id": "82289d7a5555a9d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:1484: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {ep + 1} loss: {float(loss):.4f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6447\n",
      "epoch 2 loss: 0.4360\n",
      "epoch 3 loss: 0.2471\n",
      "epoch 4 loss: 0.2152\n",
      "epoch 5 loss: 0.1813\n",
      "epoch 6 loss: 0.1534\n",
      "epoch 7 loss: 0.1146\n",
      "epoch 8 loss: 0.1067\n",
      "epoch 9 loss: 0.1185\n",
      "epoch 10 loss: 0.0838\n",
      "epoch 11 loss: 0.0920\n",
      "epoch 12 loss: 0.0837\n",
      "epoch 13 loss: 0.0753\n",
      "epoch 14 loss: 0.0688\n",
      "epoch 15 loss: 0.0767\n",
      "epoch 16 loss: 0.0677\n",
      "epoch 17 loss: 0.0642\n",
      "epoch 18 loss: 0.0660\n",
      "epoch 19 loss: 0.0629\n",
      "epoch 20 loss: 0.0602\n",
      "epoch 21 loss: 0.0596\n",
      "epoch 22 loss: 0.0577\n",
      "epoch 23 loss: 0.0576\n",
      "epoch 24 loss: 0.0523\n",
      "epoch 25 loss: 0.0439\n",
      "epoch 26 loss: 0.0478\n",
      "epoch 27 loss: 0.0471\n",
      "epoch 28 loss: 0.0452\n",
      "epoch 29 loss: 0.0405\n",
      "epoch 30 loss: 0.0405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_40241/131365095.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_fourier_w_matrix_gru = pd.concat([results_aep_fourier_w_matrix_gru, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "epoch 1 loss: 0.8370\n",
      "epoch 2 loss: 0.4444\n",
      "epoch 3 loss: 0.3336\n",
      "epoch 4 loss: 0.2254\n",
      "epoch 5 loss: 0.1976\n",
      "epoch 6 loss: 0.1595\n",
      "epoch 7 loss: 0.1479\n",
      "epoch 8 loss: 0.1307\n",
      "epoch 9 loss: 0.1259\n",
      "epoch 10 loss: 0.1124\n",
      "epoch 11 loss: 0.1105\n",
      "epoch 12 loss: 0.1046\n",
      "epoch 13 loss: 0.1189\n",
      "epoch 14 loss: 0.1022\n",
      "epoch 15 loss: 0.0902\n",
      "epoch 16 loss: 0.0912\n",
      "epoch 17 loss: 0.0906\n",
      "epoch 18 loss: 0.0830\n",
      "epoch 19 loss: 0.0744\n",
      "epoch 20 loss: 0.0810\n",
      "epoch 21 loss: 0.0744\n",
      "epoch 22 loss: 0.0693\n",
      "epoch 23 loss: 0.0644\n",
      "epoch 24 loss: 0.0699\n",
      "epoch 25 loss: 0.0692\n",
      "epoch 26 loss: 0.0567\n",
      "epoch 27 loss: 0.0520\n",
      "epoch 28 loss: 0.0518\n",
      "epoch 29 loss: 0.0480\n",
      "epoch 30 loss: 0.0494\n",
      "3\n",
      "epoch 1 loss: 0.6624\n",
      "epoch 2 loss: 0.4632\n",
      "epoch 3 loss: 0.2553\n",
      "epoch 4 loss: 0.2030\n",
      "epoch 5 loss: 0.1693\n",
      "epoch 6 loss: 0.1458\n",
      "epoch 7 loss: 0.1316\n",
      "epoch 8 loss: 0.1231\n",
      "epoch 9 loss: 0.1071\n",
      "epoch 10 loss: 0.1058\n",
      "epoch 11 loss: 0.1038\n",
      "epoch 12 loss: 0.0895\n",
      "epoch 13 loss: 0.0888\n",
      "epoch 14 loss: 0.0940\n",
      "epoch 15 loss: 0.0817\n",
      "epoch 16 loss: 0.0772\n",
      "epoch 17 loss: 0.0770\n",
      "epoch 18 loss: 0.0779\n",
      "epoch 19 loss: 0.0648\n",
      "epoch 20 loss: 0.0740\n",
      "epoch 21 loss: 0.0635\n",
      "epoch 22 loss: 0.0614\n",
      "epoch 23 loss: 0.0609\n",
      "epoch 24 loss: 0.0573\n",
      "epoch 25 loss: 0.0543\n",
      "epoch 26 loss: 0.0551\n",
      "epoch 27 loss: 0.0580\n",
      "epoch 28 loss: 0.0517\n",
      "epoch 29 loss: 0.0595\n",
      "epoch 30 loss: 0.0507\n",
      "4\n",
      "epoch 1 loss: 0.7479\n",
      "epoch 2 loss: 0.2970\n",
      "epoch 3 loss: 0.2263\n",
      "epoch 4 loss: 0.1621\n",
      "epoch 5 loss: 0.1340\n",
      "epoch 6 loss: 0.1379\n",
      "epoch 7 loss: 0.1070\n",
      "epoch 8 loss: 0.1038\n",
      "epoch 9 loss: 0.1075\n",
      "epoch 10 loss: 0.0889\n",
      "epoch 11 loss: 0.0892\n",
      "epoch 12 loss: 0.0869\n",
      "epoch 13 loss: 0.0791\n",
      "epoch 14 loss: 0.0749\n",
      "epoch 15 loss: 0.0786\n",
      "epoch 16 loss: 0.0798\n",
      "epoch 17 loss: 0.0606\n",
      "epoch 18 loss: 0.0694\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 32\u001B[0m\n\u001B[1;32m     20\u001B[0m model \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mRNN_fourier_GRU(\n\u001B[1;32m     21\u001B[0m     cont_dim\u001B[38;5;241m=\u001B[39mcont_dim,     \u001B[38;5;66;03m# full feature dim per step\u001B[39;00m\n\u001B[1;32m     22\u001B[0m     fourier_dim\u001B[38;5;241m=\u001B[39mF_pairs, \u001B[38;5;66;03m# only used in hand-rolled branch\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     29\u001B[0m     use_gru\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,               \u001B[38;5;66;03m# turn on GRU backbone (process all x together)\u001B[39;00m\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     31\u001B[0m trainer \u001B[38;5;241m=\u001B[39m model_class\u001B[38;5;241m.\u001B[39mRNN_train_fourier(model, train_config, fourier_conf)\n\u001B[0;32m---> 32\u001B[0m forcast, true \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_reduced\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m result \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mday\u001B[39m\u001B[38;5;124m'\u001B[39m: df_reduced[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mds\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mdate\u001B[38;5;241m.\u001B[39mmax(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhour\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m24\u001B[39m)), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_hat\u001B[39m\u001B[38;5;124m'\u001B[39m: forcast, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m: true})\n\u001B[1;32m     36\u001B[0m results_aep_fourier_w_matrix_gru \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([results_aep_fourier_w_matrix_gru, result])\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Desktop/Downscaling/work_summary_9_26/model_summary.py:1481\u001B[0m, in \u001B[0;36mRNN_train_fourier.__call__\u001B[0;34m(self, df)\u001B[0m\n\u001B[1;32m   1477\u001B[0m prior_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mreg_loss(lambda0\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_config\u001B[38;5;241m.\u001B[39mlambda0,\n\u001B[1;32m   1478\u001B[0m                                  lambdaf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_config\u001B[38;5;241m.\u001B[39mlambdaf,\n\u001B[1;32m   1479\u001B[0m                                  harmonic_orders\u001B[38;5;241m=\u001B[39mharmonic_orders)\n\u001B[1;32m   1480\u001B[0m loss \u001B[38;5;241m=\u001B[39m data_loss \u001B[38;5;241m+\u001B[39m prior_loss\n\u001B[0;32m-> 1481\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1482\u001B[0m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m   1483\u001B[0m opt\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:647\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    637\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    638\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    639\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    640\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    645\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    646\u001B[0m     )\n\u001B[0;32m--> 647\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    648\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    349\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    351\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 354\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:829\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    827\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    828\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 829\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    833\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "34d07cb93e10a743"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T04:04:42.990303Z",
     "start_time": "2025-10-17T04:04:42.786655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k = 24*3\n",
    "x_ax = np.arange(k)\n",
    "\n",
    "plt.plot(x_ax, results_aep_fourier_w_matrix_gru['y_hat'][:k], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.plot(x_ax, results_aep_fourier_w_matrix_gru['y'][:k], marker=\"o\", linestyle=\"-\", color=\"r\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_Tplus1\")\n",
    "plt.title(\"Line plot of y_Tplus1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "417e3cb139fad504",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d48fbf9dc0ae77f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T19:35:59.917268Z",
     "start_time": "2025-10-05T19:33:35.449168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_asym_feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_asy_con = pd.concat([results_aep_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_asy_con.to_csv(out_dir + '/results_aep_asy_con.csv', index=False)"
   ],
   "id": "179956393a2055ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1 loss: 0.843499481678009\n",
      "epoch 2 loss: 0.6137679219245911\n",
      "epoch 3 loss: 0.3631959557533264\n",
      "epoch 4 loss: 0.26193296909332275\n",
      "epoch 5 loss: 0.22270193696022034\n",
      "epoch 6 loss: 0.2109493911266327\n",
      "epoch 7 loss: 0.19311872124671936\n",
      "epoch 8 loss: 0.19898222386837006\n",
      "epoch 9 loss: 0.17515374720096588\n",
      "epoch 10 loss: 0.17962010204792023\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_90350/3290770879.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_asy_con = pd.concat([results_aep_asy_con, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.8709108233451843\n",
      "epoch 2 loss: 0.5882691740989685\n",
      "epoch 3 loss: 0.26602426171302795\n",
      "epoch 4 loss: 0.18810944259166718\n",
      "epoch 5 loss: 0.2501952648162842\n",
      "epoch 6 loss: 0.20993615686893463\n",
      "epoch 7 loss: 0.21392302215099335\n",
      "epoch 8 loss: 0.2036062330007553\n",
      "epoch 9 loss: 0.2183883935213089\n",
      "epoch 10 loss: 0.17008648812770844\n",
      "3\n",
      "epoch 1 loss: 0.7883762717247009\n",
      "epoch 2 loss: 0.6203092932701111\n",
      "epoch 3 loss: 0.38305506110191345\n",
      "epoch 4 loss: 0.25954315066337585\n",
      "epoch 5 loss: 0.2062516212463379\n",
      "epoch 6 loss: 0.19591347873210907\n",
      "epoch 7 loss: 0.1750093549489975\n",
      "epoch 8 loss: 0.19537052512168884\n",
      "epoch 9 loss: 0.23730887472629547\n",
      "epoch 10 loss: 0.17832441627979279\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "66446dfd759b4316"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "28e3e8a9af95c7cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T21:51:14.027592Z",
     "start_time": "2025-10-05T21:13:56.948927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"cpu\"))\n",
    "results_arma_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2004-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2008-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_aep.loc[(df_aep['ds'] >= date_start) & (df_aep['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_ARMA_Feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_arma_asy_con.to_csv(out_dir + '/results_arma_asy_con.csv', index=False)"
   ],
   "id": "21e72c18be0b2f32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1 loss: 1.0848135948181152\n",
      "epoch 2 loss: 0.8289082050323486\n",
      "epoch 3 loss: 0.5471181273460388\n",
      "epoch 4 loss: 0.3092515170574188\n",
      "epoch 5 loss: 0.2255319207906723\n",
      "epoch 6 loss: 0.20444394648075104\n",
      "epoch 7 loss: 0.20347830653190613\n",
      "epoch 8 loss: 0.19901487231254578\n",
      "epoch 9 loss: 0.18264152109622955\n",
      "epoch 10 loss: 0.17185232043266296\n",
      "epoch 11 loss: 0.18201546370983124\n",
      "epoch 12 loss: 0.19392389059066772\n",
      "epoch 13 loss: 0.19880421459674835\n",
      "epoch 14 loss: 0.2136233001947403\n",
      "epoch 15 loss: 0.22045555710792542\n",
      "epoch 16 loss: 0.2065289467573166\n",
      "epoch 17 loss: 0.18171022832393646\n",
      "epoch 18 loss: 0.20525896549224854\n",
      "epoch 19 loss: 0.20475207269191742\n",
      "epoch 20 loss: 0.1908627599477768\n",
      "epoch 21 loss: 0.18000002205371857\n",
      "epoch 22 loss: 0.16746078431606293\n",
      "epoch 23 loss: 0.20252200961112976\n",
      "epoch 24 loss: 0.17895463109016418\n",
      "epoch 25 loss: 0.1951626092195511\n",
      "epoch 26 loss: 0.20337796211242676\n",
      "epoch 27 loss: 0.20773832499980927\n",
      "epoch 28 loss: 0.19920021295547485\n",
      "epoch 29 loss: 0.2096223086118698\n",
      "epoch 30 loss: 0.2387205958366394\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_92021/753006187.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7937965989112854\n",
      "epoch 2 loss: 0.7392899990081787\n",
      "epoch 3 loss: 0.4693567752838135\n",
      "epoch 4 loss: 0.3668544590473175\n",
      "epoch 5 loss: 0.3165898323059082\n",
      "epoch 6 loss: 0.21177078783512115\n",
      "epoch 7 loss: 0.2524019777774811\n",
      "epoch 8 loss: 0.21147876977920532\n",
      "epoch 9 loss: 0.24370695650577545\n",
      "epoch 10 loss: 0.15603190660476685\n",
      "epoch 11 loss: 0.20825667679309845\n",
      "epoch 12 loss: 0.1745002120733261\n",
      "epoch 13 loss: 0.19807398319244385\n",
      "epoch 14 loss: 0.1844349205493927\n",
      "epoch 15 loss: 0.1742566078901291\n",
      "epoch 16 loss: 0.1576041579246521\n",
      "epoch 17 loss: 0.1681801676750183\n",
      "epoch 18 loss: 0.2171725034713745\n",
      "epoch 19 loss: 0.19856038689613342\n",
      "epoch 20 loss: 0.17577944695949554\n",
      "epoch 21 loss: 0.17505770921707153\n",
      "epoch 22 loss: 0.17071223258972168\n",
      "epoch 23 loss: 0.1970372349023819\n",
      "epoch 24 loss: 0.2048713117837906\n",
      "epoch 25 loss: 0.1909770369529724\n",
      "epoch 26 loss: 0.18660518527030945\n",
      "epoch 27 loss: 0.20314301550388336\n",
      "epoch 28 loss: 0.18595866858959198\n",
      "epoch 29 loss: 0.2032654732465744\n",
      "epoch 30 loss: 0.21901629865169525\n",
      "3\n",
      "epoch 1 loss: 0.9322571754455566\n",
      "epoch 2 loss: 0.7314719557762146\n",
      "epoch 3 loss: 0.38377487659454346\n",
      "epoch 4 loss: 0.26859286427497864\n",
      "epoch 5 loss: 0.2600814998149872\n",
      "epoch 6 loss: 0.1980275958776474\n",
      "epoch 7 loss: 0.18394692242145538\n",
      "epoch 8 loss: 0.16504180431365967\n",
      "epoch 9 loss: 0.19914376735687256\n",
      "epoch 10 loss: 0.16772426664829254\n",
      "epoch 11 loss: 0.22244834899902344\n",
      "epoch 12 loss: 0.19234783947467804\n",
      "epoch 13 loss: 0.23225037753582\n",
      "epoch 14 loss: 0.16613253951072693\n",
      "epoch 15 loss: 0.17248477041721344\n",
      "epoch 16 loss: 0.18086668848991394\n",
      "epoch 17 loss: 0.17261962592601776\n",
      "epoch 18 loss: 0.22033467888832092\n",
      "epoch 19 loss: 0.17591604590415955\n",
      "epoch 20 loss: 0.22718670964241028\n",
      "epoch 21 loss: 0.1831929236650467\n",
      "epoch 22 loss: 0.19863930344581604\n",
      "epoch 23 loss: 0.2031373232603073\n",
      "epoch 24 loss: 0.1876252144575119\n",
      "epoch 25 loss: 0.2218533754348755\n",
      "epoch 26 loss: 0.23701897263526917\n",
      "epoch 27 loss: 0.18699568510055542\n",
      "epoch 28 loss: 0.24618178606033325\n",
      "epoch 29 loss: 0.1927347630262375\n",
      "epoch 30 loss: 0.2453739494085312\n",
      "4\n",
      "epoch 1 loss: 0.9912475347518921\n",
      "epoch 2 loss: 0.6875414848327637\n",
      "epoch 3 loss: 0.5740550756454468\n",
      "epoch 4 loss: 0.32976120710372925\n",
      "epoch 5 loss: 0.22934694588184357\n",
      "epoch 6 loss: 0.2419426292181015\n",
      "epoch 7 loss: 0.22525645792484283\n",
      "epoch 8 loss: 0.25619301199913025\n",
      "epoch 9 loss: 0.18229566514492035\n",
      "epoch 10 loss: 0.1646522581577301\n",
      "epoch 11 loss: 0.21534810960292816\n",
      "epoch 12 loss: 0.1893334686756134\n",
      "epoch 13 loss: 0.22639256715774536\n",
      "epoch 14 loss: 0.25623106956481934\n",
      "epoch 15 loss: 0.20375142991542816\n",
      "epoch 16 loss: 0.19244053959846497\n",
      "epoch 17 loss: 0.19915102422237396\n",
      "epoch 18 loss: 0.19122952222824097\n",
      "epoch 19 loss: 0.23187828063964844\n",
      "epoch 20 loss: 0.20495650172233582\n",
      "epoch 21 loss: 0.2295117825269699\n",
      "epoch 22 loss: 0.1852780133485794\n",
      "epoch 23 loss: 0.1804170459508896\n",
      "epoch 24 loss: 0.230600044131279\n",
      "epoch 25 loss: 0.22636868059635162\n",
      "epoch 26 loss: 0.1826699674129486\n",
      "epoch 27 loss: 0.24107412993907928\n",
      "epoch 28 loss: 0.16091801226139069\n",
      "epoch 29 loss: 0.16344469785690308\n",
      "epoch 30 loss: 0.19891230762004852\n",
      "5\n",
      "epoch 1 loss: 0.8958339095115662\n",
      "epoch 2 loss: 0.7815483808517456\n",
      "epoch 3 loss: 0.49864500761032104\n",
      "epoch 4 loss: 0.34425729513168335\n",
      "epoch 5 loss: 0.17510321736335754\n",
      "epoch 6 loss: 0.20753127336502075\n",
      "epoch 7 loss: 0.20179477334022522\n",
      "epoch 8 loss: 0.16884613037109375\n",
      "epoch 9 loss: 0.1818147748708725\n",
      "epoch 10 loss: 0.19470705091953278\n",
      "epoch 11 loss: 0.14858227968215942\n",
      "epoch 12 loss: 0.21706925332546234\n",
      "epoch 13 loss: 0.20403644442558289\n",
      "epoch 14 loss: 0.210252046585083\n",
      "epoch 15 loss: 0.22446151077747345\n",
      "epoch 16 loss: 0.21454983949661255\n",
      "epoch 17 loss: 0.17913885414600372\n",
      "epoch 18 loss: 0.23371003568172455\n",
      "epoch 19 loss: 0.16161130368709564\n",
      "epoch 20 loss: 0.18735364079475403\n",
      "epoch 21 loss: 0.19568276405334473\n",
      "epoch 22 loss: 0.22215375304222107\n",
      "epoch 23 loss: 0.22522418200969696\n",
      "epoch 24 loss: 0.19442829489707947\n",
      "epoch 25 loss: 0.17725275456905365\n",
      "epoch 26 loss: 0.17141321301460266\n",
      "epoch 27 loss: 0.1656162291765213\n",
      "epoch 28 loss: 0.2170076221227646\n",
      "epoch 29 loss: 0.20111723244190216\n",
      "epoch 30 loss: 0.217791348695755\n",
      "6\n",
      "epoch 1 loss: 0.9477403163909912\n",
      "epoch 2 loss: 0.9114291667938232\n",
      "epoch 3 loss: 0.6840234398841858\n",
      "epoch 4 loss: 0.46574291586875916\n",
      "epoch 5 loss: 0.22248128056526184\n",
      "epoch 6 loss: 0.2407001256942749\n",
      "epoch 7 loss: 0.16288593411445618\n",
      "epoch 8 loss: 0.24475930631160736\n",
      "epoch 9 loss: 0.2593957781791687\n",
      "epoch 10 loss: 0.24173346161842346\n",
      "epoch 11 loss: 0.2600189745426178\n",
      "epoch 12 loss: 0.19355528056621552\n",
      "epoch 13 loss: 0.2081683874130249\n",
      "epoch 14 loss: 0.19626890122890472\n",
      "epoch 15 loss: 0.20998579263687134\n",
      "epoch 16 loss: 0.2102646380662918\n",
      "epoch 17 loss: 0.23114410042762756\n",
      "epoch 18 loss: 0.1729210466146469\n",
      "epoch 19 loss: 0.18438485264778137\n",
      "epoch 20 loss: 0.19646964967250824\n",
      "epoch 21 loss: 0.19011452794075012\n",
      "epoch 22 loss: 0.1981724053621292\n",
      "epoch 23 loss: 0.18136626482009888\n",
      "epoch 24 loss: 0.1956988126039505\n",
      "epoch 25 loss: 0.19216026365756989\n",
      "epoch 26 loss: 0.1514550745487213\n",
      "epoch 27 loss: 0.20304377377033234\n",
      "epoch 28 loss: 0.16692309081554413\n",
      "epoch 29 loss: 0.22667324542999268\n",
      "epoch 30 loss: 0.19249595701694489\n",
      "7\n",
      "epoch 1 loss: 1.0011169910430908\n",
      "epoch 2 loss: 0.7247860431671143\n",
      "epoch 3 loss: 0.5351740717887878\n",
      "epoch 4 loss: 0.3738512098789215\n",
      "epoch 5 loss: 0.2672427296638489\n",
      "epoch 6 loss: 0.1900027096271515\n",
      "epoch 7 loss: 0.21976563334465027\n",
      "epoch 8 loss: 0.2022702991962433\n",
      "epoch 9 loss: 0.19340257346630096\n",
      "epoch 10 loss: 0.21796134114265442\n",
      "epoch 11 loss: 0.18979792296886444\n",
      "epoch 12 loss: 0.22243304550647736\n",
      "epoch 13 loss: 0.20751559734344482\n",
      "epoch 14 loss: 0.16101528704166412\n",
      "epoch 15 loss: 0.19408243894577026\n",
      "epoch 16 loss: 0.21601958572864532\n",
      "epoch 17 loss: 0.2520303428173065\n",
      "epoch 18 loss: 0.2317979633808136\n",
      "epoch 19 loss: 0.1915101557970047\n",
      "epoch 20 loss: 0.18850548565387726\n",
      "epoch 21 loss: 0.21194376051425934\n",
      "epoch 22 loss: 0.15738049149513245\n",
      "epoch 23 loss: 0.19271990656852722\n",
      "epoch 24 loss: 0.20120154321193695\n",
      "epoch 25 loss: 0.1838066428899765\n",
      "epoch 26 loss: 0.18196091055870056\n",
      "epoch 27 loss: 0.21378587186336517\n",
      "epoch 28 loss: 0.19638583064079285\n",
      "epoch 29 loss: 0.20640002191066742\n",
      "epoch 30 loss: 0.18312114477157593\n",
      "8\n",
      "epoch 1 loss: 1.1150612831115723\n",
      "epoch 2 loss: 0.7019141316413879\n",
      "epoch 3 loss: 0.5037775635719299\n",
      "epoch 4 loss: 0.3194047212600708\n",
      "epoch 5 loss: 0.20520879328250885\n",
      "epoch 6 loss: 0.22500114142894745\n",
      "epoch 7 loss: 0.22937168180942535\n",
      "epoch 8 loss: 0.23205187916755676\n",
      "epoch 9 loss: 0.19212399423122406\n",
      "epoch 10 loss: 0.2031460404396057\n",
      "epoch 11 loss: 0.17378780245780945\n",
      "epoch 12 loss: 0.21281203627586365\n",
      "epoch 13 loss: 0.18318551778793335\n",
      "epoch 14 loss: 0.19342471659183502\n",
      "epoch 15 loss: 0.21468017995357513\n",
      "epoch 16 loss: 0.20617355406284332\n",
      "epoch 17 loss: 0.22282515466213226\n",
      "epoch 18 loss: 0.20956943929195404\n",
      "epoch 19 loss: 0.21235117316246033\n",
      "epoch 20 loss: 0.18958984315395355\n",
      "epoch 21 loss: 0.2149895876646042\n",
      "epoch 22 loss: 0.20340637862682343\n",
      "epoch 23 loss: 0.20669673383235931\n",
      "epoch 24 loss: 0.1942577213048935\n",
      "epoch 25 loss: 0.19204303622245789\n",
      "epoch 26 loss: 0.26022008061408997\n",
      "epoch 27 loss: 0.20698659121990204\n",
      "epoch 28 loss: 0.14822998642921448\n",
      "epoch 29 loss: 0.19186222553253174\n",
      "epoch 30 loss: 0.15439321100711823\n",
      "9\n",
      "epoch 1 loss: 0.9634352326393127\n",
      "epoch 2 loss: 0.56256103515625\n",
      "epoch 3 loss: 0.4503844082355499\n",
      "epoch 4 loss: 0.390078604221344\n",
      "epoch 5 loss: 0.28166255354881287\n",
      "epoch 6 loss: 0.22756212949752808\n",
      "epoch 7 loss: 0.2150740921497345\n",
      "epoch 8 loss: 0.27093514800071716\n",
      "epoch 9 loss: 0.2302282303571701\n",
      "epoch 10 loss: 0.2376248836517334\n",
      "epoch 11 loss: 0.17489659786224365\n",
      "epoch 12 loss: 0.18104012310504913\n",
      "epoch 13 loss: 0.18124307692050934\n",
      "epoch 14 loss: 0.2112933248281479\n",
      "epoch 15 loss: 0.1867847740650177\n",
      "epoch 16 loss: 0.20359481871128082\n",
      "epoch 17 loss: 0.18672797083854675\n",
      "epoch 18 loss: 0.17256546020507812\n",
      "epoch 19 loss: 0.17328029870986938\n",
      "epoch 20 loss: 0.14184126257896423\n",
      "epoch 21 loss: 0.21891644597053528\n",
      "epoch 22 loss: 0.17120806872844696\n",
      "epoch 23 loss: 0.17196577787399292\n",
      "epoch 24 loss: 0.21407091617584229\n",
      "epoch 25 loss: 0.18963582813739777\n",
      "epoch 26 loss: 0.17953985929489136\n",
      "epoch 27 loss: 0.17191803455352783\n",
      "epoch 28 loss: 0.2050756961107254\n",
      "epoch 29 loss: 0.22568272054195404\n",
      "epoch 30 loss: 0.19328667223453522\n",
      "10\n",
      "epoch 1 loss: 0.8088291883468628\n",
      "epoch 2 loss: 0.6563645601272583\n",
      "epoch 3 loss: 0.5221431851387024\n",
      "epoch 4 loss: 0.38173341751098633\n",
      "epoch 5 loss: 0.2628324627876282\n",
      "epoch 6 loss: 0.2459608018398285\n",
      "epoch 7 loss: 0.20331695675849915\n",
      "epoch 8 loss: 0.21301990747451782\n",
      "epoch 9 loss: 0.2083016037940979\n",
      "epoch 10 loss: 0.18008753657341003\n",
      "epoch 11 loss: 0.24216347932815552\n",
      "epoch 12 loss: 0.17638221383094788\n",
      "epoch 13 loss: 0.1795060634613037\n",
      "epoch 14 loss: 0.18237045407295227\n",
      "epoch 15 loss: 0.2117912769317627\n",
      "epoch 16 loss: 0.20942778885364532\n",
      "epoch 17 loss: 0.17448681592941284\n",
      "epoch 18 loss: 0.181203231215477\n",
      "epoch 19 loss: 0.20089685916900635\n",
      "epoch 20 loss: 0.2153632491827011\n",
      "epoch 21 loss: 0.1981760561466217\n",
      "epoch 22 loss: 0.19805972278118134\n",
      "epoch 23 loss: 0.18851925432682037\n",
      "epoch 24 loss: 0.16109561920166016\n",
      "epoch 25 loss: 0.21278339624404907\n",
      "epoch 26 loss: 0.20357677340507507\n",
      "epoch 27 loss: 0.22374758124351501\n",
      "epoch 28 loss: 0.1781529188156128\n",
      "epoch 29 loss: 0.18350820243358612\n",
      "epoch 30 loss: 0.186534583568573\n",
      "11\n",
      "epoch 1 loss: 1.2631375789642334\n",
      "epoch 2 loss: 0.7426676750183105\n",
      "epoch 3 loss: 0.49155670404434204\n",
      "epoch 4 loss: 0.3426972031593323\n",
      "epoch 5 loss: 0.27620917558670044\n",
      "epoch 6 loss: 0.23353376984596252\n",
      "epoch 7 loss: 0.243123397231102\n",
      "epoch 8 loss: 0.19420534372329712\n",
      "epoch 9 loss: 0.16443587839603424\n",
      "epoch 10 loss: 0.2373121976852417\n",
      "epoch 11 loss: 0.19620804488658905\n",
      "epoch 12 loss: 0.18244555592536926\n",
      "epoch 13 loss: 0.18864724040031433\n",
      "epoch 14 loss: 0.2090056836605072\n",
      "epoch 15 loss: 0.19102847576141357\n",
      "epoch 16 loss: 0.15020865201950073\n",
      "epoch 17 loss: 0.22107218205928802\n",
      "epoch 18 loss: 0.20907847583293915\n",
      "epoch 19 loss: 0.23336781561374664\n",
      "epoch 20 loss: 0.23206640779972076\n",
      "epoch 21 loss: 0.22415122389793396\n",
      "epoch 22 loss: 0.20278288424015045\n",
      "epoch 23 loss: 0.20271199941635132\n",
      "epoch 24 loss: 0.20435312390327454\n",
      "epoch 25 loss: 0.18144287168979645\n",
      "epoch 26 loss: 0.19927838444709778\n",
      "epoch 27 loss: 0.1787014603614807\n",
      "epoch 28 loss: 0.17865031957626343\n",
      "epoch 29 loss: 0.15511105954647064\n",
      "epoch 30 loss: 0.16870997846126556\n",
      "12\n",
      "epoch 1 loss: 0.9658201932907104\n",
      "epoch 2 loss: 0.9120051860809326\n",
      "epoch 3 loss: 0.532891571521759\n",
      "epoch 4 loss: 0.38047686219215393\n",
      "epoch 5 loss: 0.2695920169353485\n",
      "epoch 6 loss: 0.24195295572280884\n",
      "epoch 7 loss: 0.22934941947460175\n",
      "epoch 8 loss: 0.1901310235261917\n",
      "epoch 9 loss: 0.19577008485794067\n",
      "epoch 10 loss: 0.15526968240737915\n",
      "epoch 11 loss: 0.22510425746440887\n",
      "epoch 12 loss: 0.19919833540916443\n",
      "epoch 13 loss: 0.22704888880252838\n",
      "epoch 14 loss: 0.2156400978565216\n",
      "epoch 15 loss: 0.2188563197851181\n",
      "epoch 16 loss: 0.2303791642189026\n",
      "epoch 17 loss: 0.20815296471118927\n",
      "epoch 18 loss: 0.1730424165725708\n",
      "epoch 19 loss: 0.1813754439353943\n",
      "epoch 20 loss: 0.19452381134033203\n",
      "epoch 21 loss: 0.2069735825061798\n",
      "epoch 22 loss: 0.17611506581306458\n",
      "epoch 23 loss: 0.22105349600315094\n",
      "epoch 24 loss: 0.20211860537528992\n",
      "epoch 25 loss: 0.1772601455450058\n",
      "epoch 26 loss: 0.24228623509407043\n",
      "epoch 27 loss: 0.21330061554908752\n",
      "epoch 28 loss: 0.17591457068920135\n",
      "epoch 29 loss: 0.2047245055437088\n",
      "epoch 30 loss: 0.16972824931144714\n",
      "13\n",
      "epoch 1 loss: 0.8962108492851257\n",
      "epoch 2 loss: 0.6584824919700623\n",
      "epoch 3 loss: 0.5188365578651428\n",
      "epoch 4 loss: 0.24556829035282135\n",
      "epoch 5 loss: 0.2199731320142746\n",
      "epoch 6 loss: 0.25860080122947693\n",
      "epoch 7 loss: 0.22622741758823395\n",
      "epoch 8 loss: 0.20583957433700562\n",
      "epoch 9 loss: 0.20677140355110168\n",
      "epoch 10 loss: 0.1628226339817047\n",
      "epoch 11 loss: 0.24023321270942688\n",
      "epoch 12 loss: 0.17484232783317566\n",
      "epoch 13 loss: 0.18297864496707916\n",
      "epoch 14 loss: 0.1988239586353302\n",
      "epoch 15 loss: 0.20604485273361206\n",
      "epoch 16 loss: 0.18679767847061157\n",
      "epoch 17 loss: 0.2094668298959732\n",
      "epoch 18 loss: 0.177454873919487\n",
      "epoch 19 loss: 0.22764118015766144\n",
      "epoch 20 loss: 0.204987570643425\n",
      "epoch 21 loss: 0.18151122331619263\n",
      "epoch 22 loss: 0.19063857197761536\n",
      "epoch 23 loss: 0.220304936170578\n",
      "epoch 24 loss: 0.19047610461711884\n",
      "epoch 25 loss: 0.15728865563869476\n",
      "epoch 26 loss: 0.20809102058410645\n",
      "epoch 27 loss: 0.18627293407917023\n",
      "epoch 28 loss: 0.22817681729793549\n",
      "epoch 29 loss: 0.22064097225666046\n",
      "epoch 30 loss: 0.18403767049312592\n",
      "14\n",
      "epoch 1 loss: 0.876460611820221\n",
      "epoch 2 loss: 0.6449458599090576\n",
      "epoch 3 loss: 0.6174132823944092\n",
      "epoch 4 loss: 0.36987361311912537\n",
      "epoch 5 loss: 0.27568861842155457\n",
      "epoch 6 loss: 0.23289453983306885\n",
      "epoch 7 loss: 0.2206430584192276\n",
      "epoch 8 loss: 0.21254006028175354\n",
      "epoch 9 loss: 0.171113058924675\n",
      "epoch 10 loss: 0.20175768435001373\n",
      "epoch 11 loss: 0.18865899741649628\n",
      "epoch 12 loss: 0.2057378590106964\n",
      "epoch 13 loss: 0.19740787148475647\n",
      "epoch 14 loss: 0.16839046776294708\n",
      "epoch 15 loss: 0.2073548287153244\n",
      "epoch 16 loss: 0.20741364359855652\n",
      "epoch 17 loss: 0.17807568609714508\n",
      "epoch 18 loss: 0.1969721019268036\n",
      "epoch 19 loss: 0.20492349565029144\n",
      "epoch 20 loss: 0.1972840577363968\n",
      "epoch 21 loss: 0.19203421473503113\n",
      "epoch 22 loss: 0.18865621089935303\n",
      "epoch 23 loss: 0.18444332480430603\n",
      "epoch 24 loss: 0.1611662358045578\n",
      "epoch 25 loss: 0.17939874529838562\n",
      "epoch 26 loss: 0.18738718330860138\n",
      "epoch 27 loss: 0.18350982666015625\n",
      "epoch 28 loss: 0.14765231311321259\n",
      "epoch 29 loss: 0.2003922313451767\n",
      "epoch 30 loss: 0.19043274223804474\n",
      "15\n",
      "epoch 1 loss: 0.9192091822624207\n",
      "epoch 2 loss: 0.6522042751312256\n",
      "epoch 3 loss: 0.43523529171943665\n",
      "epoch 4 loss: 0.32984787225723267\n",
      "epoch 5 loss: 0.2431001216173172\n",
      "epoch 6 loss: 0.18851308524608612\n",
      "epoch 7 loss: 0.20985423028469086\n",
      "epoch 8 loss: 0.20767991244792938\n",
      "epoch 9 loss: 0.20538590848445892\n",
      "epoch 10 loss: 0.20310786366462708\n",
      "epoch 11 loss: 0.20745331048965454\n",
      "epoch 12 loss: 0.20725031197071075\n",
      "epoch 13 loss: 0.21297769248485565\n",
      "epoch 14 loss: 0.18277525901794434\n",
      "epoch 15 loss: 0.2237587869167328\n",
      "epoch 16 loss: 0.20122826099395752\n",
      "epoch 17 loss: 0.18902355432510376\n",
      "epoch 18 loss: 0.2486993968486786\n",
      "epoch 19 loss: 0.19789963960647583\n",
      "epoch 20 loss: 0.21579542756080627\n",
      "epoch 21 loss: 0.18838320672512054\n",
      "epoch 22 loss: 0.20379817485809326\n",
      "epoch 23 loss: 0.2085164338350296\n",
      "epoch 24 loss: 0.19450724124908447\n",
      "epoch 25 loss: 0.20188400149345398\n",
      "epoch 26 loss: 0.15533974766731262\n",
      "epoch 27 loss: 0.20088301599025726\n",
      "epoch 28 loss: 0.21786810457706451\n",
      "epoch 29 loss: 0.22344598174095154\n",
      "epoch 30 loss: 0.1751292645931244\n",
      "16\n",
      "epoch 1 loss: 0.9107357263565063\n",
      "epoch 2 loss: 0.7426508069038391\n",
      "epoch 3 loss: 0.5184281468391418\n",
      "epoch 4 loss: 0.28282761573791504\n",
      "epoch 5 loss: 0.28843453526496887\n",
      "epoch 6 loss: 0.2748351991176605\n",
      "epoch 7 loss: 0.19484500586986542\n",
      "epoch 8 loss: 0.2151617407798767\n",
      "epoch 9 loss: 0.23996461927890778\n",
      "epoch 10 loss: 0.2166820764541626\n",
      "epoch 11 loss: 0.23263876140117645\n",
      "epoch 12 loss: 0.19618305563926697\n",
      "epoch 13 loss: 0.26744240522384644\n",
      "epoch 14 loss: 0.1812431663274765\n",
      "epoch 15 loss: 0.24207456409931183\n",
      "epoch 16 loss: 0.1957024484872818\n",
      "epoch 17 loss: 0.19966359436511993\n",
      "epoch 18 loss: 0.19745615124702454\n",
      "epoch 19 loss: 0.17946554720401764\n",
      "epoch 20 loss: 0.19267499446868896\n",
      "epoch 21 loss: 0.20202669501304626\n",
      "epoch 22 loss: 0.209230437874794\n",
      "epoch 23 loss: 0.17101815342903137\n",
      "epoch 24 loss: 0.21935495734214783\n",
      "epoch 25 loss: 0.17709660530090332\n",
      "epoch 26 loss: 0.1969251036643982\n",
      "epoch 27 loss: 0.19155676662921906\n",
      "epoch 28 loss: 0.20185209810733795\n",
      "epoch 29 loss: 0.22082531452178955\n",
      "epoch 30 loss: 0.2004123330116272\n",
      "17\n",
      "epoch 1 loss: 0.9097228050231934\n",
      "epoch 2 loss: 0.6047460436820984\n",
      "epoch 3 loss: 0.46557095646858215\n",
      "epoch 4 loss: 0.30693450570106506\n",
      "epoch 5 loss: 0.26837530732154846\n",
      "epoch 6 loss: 0.1814216822385788\n",
      "epoch 7 loss: 0.2326308935880661\n",
      "epoch 8 loss: 0.20552174746990204\n",
      "epoch 9 loss: 0.18596871197223663\n",
      "epoch 10 loss: 0.1969429850578308\n",
      "epoch 11 loss: 0.21782264113426208\n",
      "epoch 12 loss: 0.20780348777770996\n",
      "epoch 13 loss: 0.21601831912994385\n",
      "epoch 14 loss: 0.2048567235469818\n",
      "epoch 15 loss: 0.2491968721151352\n",
      "epoch 16 loss: 0.17528606951236725\n",
      "epoch 17 loss: 0.1999833583831787\n",
      "epoch 18 loss: 0.15861991047859192\n",
      "epoch 19 loss: 0.17558352649211884\n",
      "epoch 20 loss: 0.16598153114318848\n",
      "epoch 21 loss: 0.2126627266407013\n",
      "epoch 22 loss: 0.2397812008857727\n",
      "epoch 23 loss: 0.20081572234630585\n",
      "epoch 24 loss: 0.20749613642692566\n",
      "epoch 25 loss: 0.25360599160194397\n",
      "epoch 26 loss: 0.224979430437088\n",
      "epoch 27 loss: 0.19445937871932983\n",
      "epoch 28 loss: 0.19284266233444214\n",
      "epoch 29 loss: 0.17835374176502228\n",
      "epoch 30 loss: 0.20181724429130554\n",
      "18\n",
      "epoch 1 loss: 0.7994500994682312\n",
      "epoch 2 loss: 0.7208985686302185\n",
      "epoch 3 loss: 0.5521944761276245\n",
      "epoch 4 loss: 0.29599669575691223\n",
      "epoch 5 loss: 0.24892301857471466\n",
      "epoch 6 loss: 0.25658950209617615\n",
      "epoch 7 loss: 0.19668786227703094\n",
      "epoch 8 loss: 0.2551056146621704\n",
      "epoch 9 loss: 0.2016609013080597\n",
      "epoch 10 loss: 0.20767375826835632\n",
      "epoch 11 loss: 0.2061835527420044\n",
      "epoch 12 loss: 0.2066633701324463\n",
      "epoch 13 loss: 0.1657637059688568\n",
      "epoch 14 loss: 0.14812248945236206\n",
      "epoch 15 loss: 0.19190295040607452\n",
      "epoch 16 loss: 0.21799534559249878\n",
      "epoch 17 loss: 0.21465858817100525\n",
      "epoch 18 loss: 0.18079502880573273\n",
      "epoch 19 loss: 0.21401235461235046\n",
      "epoch 20 loss: 0.17678973078727722\n",
      "epoch 21 loss: 0.1951342672109604\n",
      "epoch 22 loss: 0.2085317224264145\n",
      "epoch 23 loss: 0.21270206570625305\n",
      "epoch 24 loss: 0.19404220581054688\n",
      "epoch 25 loss: 0.2066563218832016\n",
      "epoch 26 loss: 0.17802400887012482\n",
      "epoch 27 loss: 0.18397067487239838\n",
      "epoch 28 loss: 0.1887269914150238\n",
      "epoch 29 loss: 0.19109083712100983\n",
      "epoch 30 loss: 0.22387468814849854\n",
      "19\n",
      "epoch 1 loss: 0.9894277453422546\n",
      "epoch 2 loss: 0.8111698031425476\n",
      "epoch 3 loss: 0.365831583738327\n",
      "epoch 4 loss: 0.24759647250175476\n",
      "epoch 5 loss: 0.21461175382137299\n",
      "epoch 6 loss: 0.19983920454978943\n",
      "epoch 7 loss: 0.23754310607910156\n",
      "epoch 8 loss: 0.20645244419574738\n",
      "epoch 9 loss: 0.16724516451358795\n",
      "epoch 10 loss: 0.2444475293159485\n",
      "epoch 11 loss: 0.20813000202178955\n",
      "epoch 12 loss: 0.19378602504730225\n",
      "epoch 13 loss: 0.21056921780109406\n",
      "epoch 14 loss: 0.20740148425102234\n",
      "epoch 15 loss: 0.2130918800830841\n",
      "epoch 16 loss: 0.19480781257152557\n",
      "epoch 17 loss: 0.222183957695961\n",
      "epoch 18 loss: 0.20211338996887207\n",
      "epoch 19 loss: 0.1936625987291336\n",
      "epoch 20 loss: 0.19943499565124512\n",
      "epoch 21 loss: 0.2195231020450592\n",
      "epoch 22 loss: 0.18101222813129425\n",
      "epoch 23 loss: 0.21414482593536377\n",
      "epoch 24 loss: 0.19039662182331085\n",
      "epoch 25 loss: 0.2049388587474823\n",
      "epoch 26 loss: 0.22868278622627258\n",
      "epoch 27 loss: 0.1959916651248932\n",
      "epoch 28 loss: 0.17918522655963898\n",
      "epoch 29 loss: 0.1468670815229416\n",
      "epoch 30 loss: 0.19133037328720093\n",
      "20\n",
      "epoch 1 loss: 0.7831248044967651\n",
      "epoch 2 loss: 0.6957051157951355\n",
      "epoch 3 loss: 0.4571681022644043\n",
      "epoch 4 loss: 0.3356427252292633\n",
      "epoch 5 loss: 0.24856609106063843\n",
      "epoch 6 loss: 0.20144280791282654\n",
      "epoch 7 loss: 0.24527789652347565\n",
      "epoch 8 loss: 0.23249849677085876\n",
      "epoch 9 loss: 0.22086988389492035\n",
      "epoch 10 loss: 0.18949712812900543\n",
      "epoch 11 loss: 0.2067057490348816\n",
      "epoch 12 loss: 0.21976782381534576\n",
      "epoch 13 loss: 0.17632067203521729\n",
      "epoch 14 loss: 0.21616633236408234\n",
      "epoch 15 loss: 0.24871115386486053\n",
      "epoch 16 loss: 0.17869679629802704\n",
      "epoch 17 loss: 0.18910028040409088\n",
      "epoch 18 loss: 0.17849889397621155\n",
      "epoch 19 loss: 0.2040499746799469\n",
      "epoch 20 loss: 0.19325949251651764\n",
      "epoch 21 loss: 0.15760409832000732\n",
      "epoch 22 loss: 0.18662115931510925\n",
      "epoch 23 loss: 0.21168972551822662\n",
      "epoch 24 loss: 0.16285665333271027\n",
      "epoch 25 loss: 0.16919966042041779\n",
      "epoch 26 loss: 0.17642076313495636\n",
      "epoch 27 loss: 0.16249911487102509\n",
      "epoch 28 loss: 0.17985619604587555\n",
      "epoch 29 loss: 0.18847039341926575\n",
      "epoch 30 loss: 0.18790040910243988\n",
      "21\n",
      "epoch 1 loss: 0.7624818682670593\n",
      "epoch 2 loss: 0.670321524143219\n",
      "epoch 3 loss: 0.6787340044975281\n",
      "epoch 4 loss: 0.3635874092578888\n",
      "epoch 5 loss: 0.271299809217453\n",
      "epoch 6 loss: 0.25746315717697144\n",
      "epoch 7 loss: 0.21366743743419647\n",
      "epoch 8 loss: 0.1881513148546219\n",
      "epoch 9 loss: 0.2241009771823883\n",
      "epoch 10 loss: 0.1852886825799942\n",
      "epoch 11 loss: 0.1775546669960022\n",
      "epoch 12 loss: 0.18427807092666626\n",
      "epoch 13 loss: 0.1846916228532791\n",
      "epoch 14 loss: 0.1813768893480301\n",
      "epoch 15 loss: 0.21876519918441772\n",
      "epoch 16 loss: 0.21355482935905457\n",
      "epoch 17 loss: 0.20288830995559692\n",
      "epoch 18 loss: 0.19036869704723358\n",
      "epoch 19 loss: 0.20186935365200043\n",
      "epoch 20 loss: 0.19900327920913696\n",
      "epoch 21 loss: 0.17895938456058502\n",
      "epoch 22 loss: 0.2050859034061432\n",
      "epoch 23 loss: 0.25849005579948425\n",
      "epoch 24 loss: 0.18126435577869415\n",
      "epoch 25 loss: 0.2038462609052658\n",
      "epoch 26 loss: 0.2085583359003067\n",
      "epoch 27 loss: 0.207711324095726\n",
      "epoch 28 loss: 0.17028911411762238\n",
      "epoch 29 loss: 0.1736426204442978\n",
      "epoch 30 loss: 0.18090775609016418\n",
      "22\n",
      "epoch 1 loss: 0.7507895827293396\n",
      "epoch 2 loss: 0.6763332486152649\n",
      "epoch 3 loss: 0.48828205466270447\n",
      "epoch 4 loss: 0.2967836260795593\n",
      "epoch 5 loss: 0.2926550805568695\n",
      "epoch 6 loss: 0.23208051919937134\n",
      "epoch 7 loss: 0.20121373236179352\n",
      "epoch 8 loss: 0.22203058004379272\n",
      "epoch 9 loss: 0.23550604283809662\n",
      "epoch 10 loss: 0.22148405015468597\n",
      "epoch 11 loss: 0.1897936910390854\n",
      "epoch 12 loss: 0.17192289233207703\n",
      "epoch 13 loss: 0.21373112499713898\n",
      "epoch 14 loss: 0.17613914608955383\n",
      "epoch 15 loss: 0.21069085597991943\n",
      "epoch 16 loss: 0.20169101655483246\n",
      "epoch 17 loss: 0.21356259286403656\n",
      "epoch 18 loss: 0.16971109807491302\n",
      "epoch 19 loss: 0.22112058103084564\n",
      "epoch 20 loss: 0.22116056084632874\n",
      "epoch 21 loss: 0.1894451081752777\n",
      "epoch 22 loss: 0.191425159573555\n",
      "epoch 23 loss: 0.21149228513240814\n",
      "epoch 24 loss: 0.2022392898797989\n",
      "epoch 25 loss: 0.2073235809803009\n",
      "epoch 26 loss: 0.1548333615064621\n",
      "epoch 27 loss: 0.19345074892044067\n",
      "epoch 28 loss: 0.19742339849472046\n",
      "epoch 29 loss: 0.23696275055408478\n",
      "epoch 30 loss: 0.22326256334781647\n",
      "23\n",
      "epoch 1 loss: 0.8971673846244812\n",
      "epoch 2 loss: 0.7254232168197632\n",
      "epoch 3 loss: 0.6423183083534241\n",
      "epoch 4 loss: 0.5048398971557617\n",
      "epoch 5 loss: 0.25403934717178345\n",
      "epoch 6 loss: 0.21457254886627197\n",
      "epoch 7 loss: 0.21055853366851807\n",
      "epoch 8 loss: 0.19640277326107025\n",
      "epoch 9 loss: 0.16664817929267883\n",
      "epoch 10 loss: 0.21451014280319214\n",
      "epoch 11 loss: 0.20512650907039642\n",
      "epoch 12 loss: 0.22184453904628754\n",
      "epoch 13 loss: 0.17633873224258423\n",
      "epoch 14 loss: 0.21795900166034698\n",
      "epoch 15 loss: 0.2036142796278\n",
      "epoch 16 loss: 0.23647436499595642\n",
      "epoch 17 loss: 0.14864687621593475\n",
      "epoch 18 loss: 0.19484364986419678\n",
      "epoch 19 loss: 0.1873001754283905\n",
      "epoch 20 loss: 0.23054516315460205\n",
      "epoch 21 loss: 0.19467882812023163\n",
      "epoch 22 loss: 0.1818052977323532\n",
      "epoch 23 loss: 0.18240447342395782\n",
      "epoch 24 loss: 0.20142841339111328\n",
      "epoch 25 loss: 0.1941118687391281\n",
      "epoch 26 loss: 0.24219976365566254\n",
      "epoch 27 loss: 0.1662643402814865\n",
      "epoch 28 loss: 0.13674435019493103\n",
      "epoch 29 loss: 0.1717320680618286\n",
      "epoch 30 loss: 0.20381046831607819\n",
      "24\n",
      "epoch 1 loss: 0.9773725271224976\n",
      "epoch 2 loss: 0.82647705078125\n",
      "epoch 3 loss: 0.4420798122882843\n",
      "epoch 4 loss: 0.29520484805107117\n",
      "epoch 5 loss: 0.27265995740890503\n",
      "epoch 6 loss: 0.21479037404060364\n",
      "epoch 7 loss: 0.20236875116825104\n",
      "epoch 8 loss: 0.21941886842250824\n",
      "epoch 9 loss: 0.1928277462720871\n",
      "epoch 10 loss: 0.2192772477865219\n",
      "epoch 11 loss: 0.20613916218280792\n",
      "epoch 12 loss: 0.18611858785152435\n",
      "epoch 13 loss: 0.18935024738311768\n",
      "epoch 14 loss: 0.2155931293964386\n",
      "epoch 15 loss: 0.24576041102409363\n",
      "epoch 16 loss: 0.20729416608810425\n",
      "epoch 17 loss: 0.19230733811855316\n",
      "epoch 18 loss: 0.23535564541816711\n",
      "epoch 19 loss: 0.22336360812187195\n",
      "epoch 20 loss: 0.19370630383491516\n",
      "epoch 21 loss: 0.2188955694437027\n",
      "epoch 22 loss: 0.17708618938922882\n",
      "epoch 23 loss: 0.24290867149829865\n",
      "epoch 24 loss: 0.16828742623329163\n",
      "epoch 25 loss: 0.2019062638282776\n",
      "epoch 26 loss: 0.17977696657180786\n",
      "epoch 27 loss: 0.22875291109085083\n",
      "epoch 28 loss: 0.22154828906059265\n",
      "epoch 29 loss: 0.20594675838947296\n",
      "epoch 30 loss: 0.19531746208667755\n",
      "25\n",
      "epoch 1 loss: 0.7709868550300598\n",
      "epoch 2 loss: 0.9400405883789062\n",
      "epoch 3 loss: 0.5112863779067993\n",
      "epoch 4 loss: 0.31749650835990906\n",
      "epoch 5 loss: 0.19852809607982635\n",
      "epoch 6 loss: 0.246907576918602\n",
      "epoch 7 loss: 0.19241610169410706\n",
      "epoch 8 loss: 0.19007939100265503\n",
      "epoch 9 loss: 0.220037579536438\n",
      "epoch 10 loss: 0.2161860316991806\n",
      "epoch 11 loss: 0.20052817463874817\n",
      "epoch 12 loss: 0.21543267369270325\n",
      "epoch 13 loss: 0.22917959094047546\n",
      "epoch 14 loss: 0.1925540566444397\n",
      "epoch 15 loss: 0.17019614577293396\n",
      "epoch 16 loss: 0.18011078238487244\n",
      "epoch 17 loss: 0.25085732340812683\n",
      "epoch 18 loss: 0.19407473504543304\n",
      "epoch 19 loss: 0.19269928336143494\n",
      "epoch 20 loss: 0.1885690838098526\n",
      "epoch 21 loss: 0.2579306662082672\n",
      "epoch 22 loss: 0.21537750959396362\n",
      "epoch 23 loss: 0.2186872661113739\n",
      "epoch 24 loss: 0.22305677831172943\n",
      "epoch 25 loss: 0.20120568573474884\n",
      "epoch 26 loss: 0.20253399014472961\n",
      "epoch 27 loss: 0.22622789442539215\n",
      "epoch 28 loss: 0.20046326518058777\n",
      "epoch 29 loss: 0.18551570177078247\n",
      "epoch 30 loss: 0.16705600917339325\n",
      "26\n",
      "epoch 1 loss: 0.8472405076026917\n",
      "epoch 2 loss: 0.897381603717804\n",
      "epoch 3 loss: 0.513157069683075\n",
      "epoch 4 loss: 0.3601738214492798\n",
      "epoch 5 loss: 0.29592400789260864\n",
      "epoch 6 loss: 0.2791537046432495\n",
      "epoch 7 loss: 0.23052915930747986\n",
      "epoch 8 loss: 0.23844431340694427\n",
      "epoch 9 loss: 0.18803423643112183\n",
      "epoch 10 loss: 0.19369907677173615\n",
      "epoch 11 loss: 0.19470223784446716\n",
      "epoch 12 loss: 0.1931232064962387\n",
      "epoch 13 loss: 0.1854136437177658\n",
      "epoch 14 loss: 0.23373889923095703\n",
      "epoch 15 loss: 0.2339506596326828\n",
      "epoch 16 loss: 0.17716608941555023\n",
      "epoch 17 loss: 0.21943219006061554\n",
      "epoch 18 loss: 0.16749632358551025\n",
      "epoch 19 loss: 0.17354035377502441\n",
      "epoch 20 loss: 0.20043854415416718\n",
      "epoch 21 loss: 0.19390557706356049\n",
      "epoch 22 loss: 0.24035045504570007\n",
      "epoch 23 loss: 0.18205347657203674\n",
      "epoch 24 loss: 0.20867562294006348\n",
      "epoch 25 loss: 0.18719634413719177\n",
      "epoch 26 loss: 0.200327068567276\n",
      "epoch 27 loss: 0.187198668718338\n",
      "epoch 28 loss: 0.20777365565299988\n",
      "epoch 29 loss: 0.21340158581733704\n",
      "epoch 30 loss: 0.17939844727516174\n",
      "27\n",
      "epoch 1 loss: 0.7649153470993042\n",
      "epoch 2 loss: 0.8397578001022339\n",
      "epoch 3 loss: 0.4879409670829773\n",
      "epoch 4 loss: 0.3920595645904541\n",
      "epoch 5 loss: 0.2657739520072937\n",
      "epoch 6 loss: 0.242497518658638\n",
      "epoch 7 loss: 0.2304157316684723\n",
      "epoch 8 loss: 0.20481057465076447\n",
      "epoch 9 loss: 0.20739910006523132\n",
      "epoch 10 loss: 0.17336052656173706\n",
      "epoch 11 loss: 0.240444153547287\n",
      "epoch 12 loss: 0.2254370003938675\n",
      "epoch 13 loss: 0.1863463670015335\n",
      "epoch 14 loss: 0.23034782707691193\n",
      "epoch 15 loss: 0.22097384929656982\n",
      "epoch 16 loss: 0.186981663107872\n",
      "epoch 17 loss: 0.18909715116024017\n",
      "epoch 18 loss: 0.20631100237369537\n",
      "epoch 19 loss: 0.2300243377685547\n",
      "epoch 20 loss: 0.19136279821395874\n",
      "epoch 21 loss: 0.1678004115819931\n",
      "epoch 22 loss: 0.19409394264221191\n",
      "epoch 23 loss: 0.1834135800600052\n",
      "epoch 24 loss: 0.20463697612285614\n",
      "epoch 25 loss: 0.16939295828342438\n",
      "epoch 26 loss: 0.23620754480361938\n",
      "epoch 27 loss: 0.17534947395324707\n",
      "epoch 28 loss: 0.2188715785741806\n",
      "epoch 29 loss: 0.2157125473022461\n",
      "epoch 30 loss: 0.18540558218955994\n",
      "28\n",
      "epoch 1 loss: 0.8599568009376526\n",
      "epoch 2 loss: 0.6712058186531067\n",
      "epoch 3 loss: 0.43672963976860046\n",
      "epoch 4 loss: 0.24324581027030945\n",
      "epoch 5 loss: 0.24272362887859344\n",
      "epoch 6 loss: 0.20741134881973267\n",
      "epoch 7 loss: 0.2120293527841568\n",
      "epoch 8 loss: 0.22440211474895477\n",
      "epoch 9 loss: 0.21372532844543457\n",
      "epoch 10 loss: 0.24488325417041779\n",
      "epoch 11 loss: 0.1828976571559906\n",
      "epoch 12 loss: 0.18118028342723846\n",
      "epoch 13 loss: 0.19689124822616577\n",
      "epoch 14 loss: 0.19202443957328796\n",
      "epoch 15 loss: 0.17154471576213837\n",
      "epoch 16 loss: 0.22920015454292297\n",
      "epoch 17 loss: 0.18910564482212067\n",
      "epoch 18 loss: 0.21558447182178497\n",
      "epoch 19 loss: 0.15334568917751312\n",
      "epoch 20 loss: 0.18440745770931244\n",
      "epoch 21 loss: 0.18992523849010468\n",
      "epoch 22 loss: 0.18330764770507812\n",
      "epoch 23 loss: 0.19641521573066711\n",
      "epoch 24 loss: 0.16543421149253845\n",
      "epoch 25 loss: 0.23843708634376526\n",
      "epoch 26 loss: 0.22959651052951813\n",
      "epoch 27 loss: 0.20525172352790833\n",
      "epoch 28 loss: 0.19559811055660248\n",
      "epoch 29 loss: 0.17383190989494324\n",
      "epoch 30 loss: 0.21772761642932892\n",
      "29\n",
      "epoch 1 loss: 0.8741199374198914\n",
      "epoch 2 loss: 0.8153318166732788\n",
      "epoch 3 loss: 0.46121320128440857\n",
      "epoch 4 loss: 0.35333487391471863\n",
      "epoch 5 loss: 0.23374557495117188\n",
      "epoch 6 loss: 0.23581258952617645\n",
      "epoch 7 loss: 0.2061052918434143\n",
      "epoch 8 loss: 0.2377229779958725\n",
      "epoch 9 loss: 0.23181438446044922\n",
      "epoch 10 loss: 0.2006521075963974\n",
      "epoch 11 loss: 0.1833217740058899\n",
      "epoch 12 loss: 0.18978942930698395\n",
      "epoch 13 loss: 0.20534257590770721\n",
      "epoch 14 loss: 0.18715213239192963\n",
      "epoch 15 loss: 0.20016098022460938\n",
      "epoch 16 loss: 0.20665498077869415\n",
      "epoch 17 loss: 0.19267058372497559\n",
      "epoch 18 loss: 0.2135525494813919\n",
      "epoch 19 loss: 0.1908855140209198\n",
      "epoch 20 loss: 0.19155852496623993\n",
      "epoch 21 loss: 0.1909235715866089\n",
      "epoch 22 loss: 0.21782062947750092\n",
      "epoch 23 loss: 0.1960771381855011\n",
      "epoch 24 loss: 0.1908341944217682\n",
      "epoch 25 loss: 0.1743498146533966\n",
      "epoch 26 loss: 0.18677575886249542\n",
      "epoch 27 loss: 0.2028321474790573\n",
      "epoch 28 loss: 0.12679557502269745\n",
      "epoch 29 loss: 0.1982460916042328\n",
      "epoch 30 loss: 0.1877111792564392\n",
      "30\n",
      "epoch 1 loss: 0.8861668705940247\n",
      "epoch 2 loss: 0.7622819542884827\n",
      "epoch 3 loss: 0.523853600025177\n",
      "epoch 4 loss: 0.3591592013835907\n",
      "epoch 5 loss: 0.28937259316444397\n",
      "epoch 6 loss: 0.2301596999168396\n",
      "epoch 7 loss: 0.2455727458000183\n",
      "epoch 8 loss: 0.2253326028585434\n",
      "epoch 9 loss: 0.1982010453939438\n",
      "epoch 10 loss: 0.21620365977287292\n",
      "epoch 11 loss: 0.20127296447753906\n",
      "epoch 12 loss: 0.21298213303089142\n",
      "epoch 13 loss: 0.21268630027770996\n",
      "epoch 14 loss: 0.19443857669830322\n",
      "epoch 15 loss: 0.21097584068775177\n",
      "epoch 16 loss: 0.17588214576244354\n",
      "epoch 17 loss: 0.15760260820388794\n",
      "epoch 18 loss: 0.1835203319787979\n",
      "epoch 19 loss: 0.18967826664447784\n",
      "epoch 20 loss: 0.20786701142787933\n",
      "epoch 21 loss: 0.21504366397857666\n",
      "epoch 22 loss: 0.17154057323932648\n",
      "epoch 23 loss: 0.19979240000247955\n",
      "epoch 24 loss: 0.2298709601163864\n",
      "epoch 25 loss: 0.15781015157699585\n",
      "epoch 26 loss: 0.21093526482582092\n",
      "epoch 27 loss: 0.2001112997531891\n",
      "epoch 28 loss: 0.22193099558353424\n",
      "epoch 29 loss: 0.17863309383392334\n",
      "epoch 30 loss: 0.2061140239238739\n",
      "31\n",
      "epoch 1 loss: 0.8590033650398254\n",
      "epoch 2 loss: 0.708012044429779\n",
      "epoch 3 loss: 0.4012978971004486\n",
      "epoch 4 loss: 0.28738299012184143\n",
      "epoch 5 loss: 0.2740902304649353\n",
      "epoch 6 loss: 0.24230709671974182\n",
      "epoch 7 loss: 0.23609916865825653\n",
      "epoch 8 loss: 0.18672913312911987\n",
      "epoch 9 loss: 0.25609755516052246\n",
      "epoch 10 loss: 0.16128677129745483\n",
      "epoch 11 loss: 0.21942539513111115\n",
      "epoch 12 loss: 0.1812247484922409\n",
      "epoch 13 loss: 0.17034190893173218\n",
      "epoch 14 loss: 0.2171798199415207\n",
      "epoch 15 loss: 0.1949150711297989\n",
      "epoch 16 loss: 0.19088564813137054\n",
      "epoch 17 loss: 0.20782358944416046\n",
      "epoch 18 loss: 0.2101534903049469\n",
      "epoch 19 loss: 0.19245846569538116\n",
      "epoch 20 loss: 0.22086945176124573\n",
      "epoch 21 loss: 0.21996386349201202\n",
      "epoch 22 loss: 0.15048740804195404\n",
      "epoch 23 loss: 0.20110632479190826\n",
      "epoch 24 loss: 0.22691190242767334\n",
      "epoch 25 loss: 0.1965111941099167\n",
      "epoch 26 loss: 0.1748460978269577\n",
      "epoch 27 loss: 0.1880931854248047\n",
      "epoch 28 loss: 0.19994519650936127\n",
      "epoch 29 loss: 0.2140045315027237\n",
      "epoch 30 loss: 0.2339671105146408\n",
      "32\n",
      "epoch 1 loss: 0.8262423276901245\n",
      "epoch 2 loss: 0.6613062024116516\n",
      "epoch 3 loss: 0.4853588342666626\n",
      "epoch 4 loss: 0.39372578263282776\n",
      "epoch 5 loss: 0.3468968868255615\n",
      "epoch 6 loss: 0.212701216340065\n",
      "epoch 7 loss: 0.22628800570964813\n",
      "epoch 8 loss: 0.22813378274440765\n",
      "epoch 9 loss: 0.2314547896385193\n",
      "epoch 10 loss: 0.17776009440422058\n",
      "epoch 11 loss: 0.22681263089179993\n",
      "epoch 12 loss: 0.2053961306810379\n",
      "epoch 13 loss: 0.17252610623836517\n",
      "epoch 14 loss: 0.2185700237751007\n",
      "epoch 15 loss: 0.23562566936016083\n",
      "epoch 16 loss: 0.25115782022476196\n",
      "epoch 17 loss: 0.185159370303154\n",
      "epoch 18 loss: 0.22079350054264069\n",
      "epoch 19 loss: 0.19829273223876953\n",
      "epoch 20 loss: 0.1647779643535614\n",
      "epoch 21 loss: 0.19137394428253174\n",
      "epoch 22 loss: 0.19578322768211365\n",
      "epoch 23 loss: 0.20464970171451569\n",
      "epoch 24 loss: 0.17320814728736877\n",
      "epoch 25 loss: 0.1960478276014328\n",
      "epoch 26 loss: 0.1803911328315735\n",
      "epoch 27 loss: 0.18198969960212708\n",
      "epoch 28 loss: 0.19850385189056396\n",
      "epoch 29 loss: 0.18333087861537933\n",
      "epoch 30 loss: 0.18071241676807404\n",
      "33\n",
      "epoch 1 loss: 0.8311231136322021\n",
      "epoch 2 loss: 0.7901812195777893\n",
      "epoch 3 loss: 0.45040881633758545\n",
      "epoch 4 loss: 0.41548097133636475\n",
      "epoch 5 loss: 0.2589919865131378\n",
      "epoch 6 loss: 0.20258654654026031\n",
      "epoch 7 loss: 0.2197098433971405\n",
      "epoch 8 loss: 0.23193368315696716\n",
      "epoch 9 loss: 0.2070319801568985\n",
      "epoch 10 loss: 0.1697792410850525\n",
      "epoch 11 loss: 0.22407998144626617\n",
      "epoch 12 loss: 0.18812765181064606\n",
      "epoch 13 loss: 0.22267396748065948\n",
      "epoch 14 loss: 0.20801831781864166\n",
      "epoch 15 loss: 0.19913913309574127\n",
      "epoch 16 loss: 0.22880499064922333\n",
      "epoch 17 loss: 0.18124397099018097\n",
      "epoch 18 loss: 0.21025769412517548\n",
      "epoch 19 loss: 0.19720350205898285\n",
      "epoch 20 loss: 0.22352662682533264\n",
      "epoch 21 loss: 0.2105891853570938\n",
      "epoch 22 loss: 0.22265222668647766\n",
      "epoch 23 loss: 0.19646060466766357\n",
      "epoch 24 loss: 0.1921711564064026\n",
      "epoch 25 loss: 0.2045866847038269\n",
      "epoch 26 loss: 0.22319142520427704\n",
      "epoch 27 loss: 0.18289600312709808\n",
      "epoch 28 loss: 0.22451151907444\n",
      "epoch 29 loss: 0.20291264355182648\n",
      "epoch 30 loss: 0.20907162129878998\n",
      "34\n",
      "epoch 1 loss: 0.9699147343635559\n",
      "epoch 2 loss: 0.7115221619606018\n",
      "epoch 3 loss: 0.5575652718544006\n",
      "epoch 4 loss: 0.34173783659935\n",
      "epoch 5 loss: 0.365084707736969\n",
      "epoch 6 loss: 0.23844939470291138\n",
      "epoch 7 loss: 0.1904078722000122\n",
      "epoch 8 loss: 0.22054041922092438\n",
      "epoch 9 loss: 0.21551677584648132\n",
      "epoch 10 loss: 0.22544975578784943\n",
      "epoch 11 loss: 0.20029368996620178\n",
      "epoch 12 loss: 0.2179575115442276\n",
      "epoch 13 loss: 0.20183850824832916\n",
      "epoch 14 loss: 0.18305185437202454\n",
      "epoch 15 loss: 0.20354868471622467\n",
      "epoch 16 loss: 0.23067079484462738\n",
      "epoch 17 loss: 0.2124544233083725\n",
      "epoch 18 loss: 0.1518273949623108\n",
      "epoch 19 loss: 0.23885227739810944\n",
      "epoch 20 loss: 0.19840069115161896\n",
      "epoch 21 loss: 0.20928189158439636\n",
      "epoch 22 loss: 0.19274994730949402\n",
      "epoch 23 loss: 0.20656543970108032\n",
      "epoch 24 loss: 0.1825239360332489\n",
      "epoch 25 loss: 0.20928169786930084\n",
      "epoch 26 loss: 0.20944413542747498\n",
      "epoch 27 loss: 0.1718146651983261\n",
      "epoch 28 loss: 0.21974679827690125\n",
      "epoch 29 loss: 0.16606390476226807\n",
      "epoch 30 loss: 0.20747484266757965\n",
      "35\n",
      "epoch 1 loss: 0.9466055035591125\n",
      "epoch 2 loss: 0.7996450066566467\n",
      "epoch 3 loss: 0.5932989120483398\n",
      "epoch 4 loss: 0.34111857414245605\n",
      "epoch 5 loss: 0.24309267103672028\n",
      "epoch 6 loss: 0.1973758190870285\n",
      "epoch 7 loss: 0.22510084509849548\n",
      "epoch 8 loss: 0.19569432735443115\n",
      "epoch 9 loss: 0.19944597780704498\n",
      "epoch 10 loss: 0.19154225289821625\n",
      "epoch 11 loss: 0.18354679644107819\n",
      "epoch 12 loss: 0.24655073881149292\n",
      "epoch 13 loss: 0.22845353186130524\n",
      "epoch 14 loss: 0.18988360464572906\n",
      "epoch 15 loss: 0.16477760672569275\n",
      "epoch 16 loss: 0.19875426590442657\n",
      "epoch 17 loss: 0.1832050383090973\n",
      "epoch 18 loss: 0.19337168335914612\n",
      "epoch 19 loss: 0.19975420832633972\n",
      "epoch 20 loss: 0.18945229053497314\n",
      "epoch 21 loss: 0.22319142520427704\n",
      "epoch 22 loss: 0.18782897293567657\n",
      "epoch 23 loss: 0.21021167933940887\n",
      "epoch 24 loss: 0.17797185480594635\n",
      "epoch 25 loss: 0.18103137612342834\n",
      "epoch 26 loss: 0.1749594807624817\n",
      "epoch 27 loss: 0.180522158741951\n",
      "epoch 28 loss: 0.22588130831718445\n",
      "epoch 29 loss: 0.1996868997812271\n",
      "epoch 30 loss: 0.22221285104751587\n",
      "36\n",
      "epoch 1 loss: 0.8295586109161377\n",
      "epoch 2 loss: 0.7155051231384277\n",
      "epoch 3 loss: 0.38722100853919983\n",
      "epoch 4 loss: 0.28455060720443726\n",
      "epoch 5 loss: 0.23887568712234497\n",
      "epoch 6 loss: 0.18660478293895721\n",
      "epoch 7 loss: 0.18719829618930817\n",
      "epoch 8 loss: 0.2287197858095169\n",
      "epoch 9 loss: 0.19826704263687134\n",
      "epoch 10 loss: 0.1857396960258484\n",
      "epoch 11 loss: 0.18533365428447723\n",
      "epoch 12 loss: 0.2042151838541031\n",
      "epoch 13 loss: 0.21395768225193024\n",
      "epoch 14 loss: 0.19275051355361938\n",
      "epoch 15 loss: 0.22649553418159485\n",
      "epoch 16 loss: 0.1743043065071106\n",
      "epoch 17 loss: 0.1504848450422287\n",
      "epoch 18 loss: 0.2092837542295456\n",
      "epoch 19 loss: 0.22456519305706024\n",
      "epoch 20 loss: 0.19455713033676147\n",
      "epoch 21 loss: 0.21228046715259552\n",
      "epoch 22 loss: 0.16872847080230713\n",
      "epoch 23 loss: 0.21349069476127625\n",
      "epoch 24 loss: 0.1653955578804016\n",
      "epoch 25 loss: 0.19996047019958496\n",
      "epoch 26 loss: 0.16585630178451538\n",
      "epoch 27 loss: 0.19234499335289001\n",
      "epoch 28 loss: 0.22432708740234375\n",
      "epoch 29 loss: 0.2092985063791275\n",
      "epoch 30 loss: 0.21213215589523315\n",
      "37\n",
      "epoch 1 loss: 0.9662334322929382\n",
      "epoch 2 loss: 0.6861615777015686\n",
      "epoch 3 loss: 0.605206310749054\n",
      "epoch 4 loss: 0.299769788980484\n",
      "epoch 5 loss: 0.24790164828300476\n",
      "epoch 6 loss: 0.250914067029953\n",
      "epoch 7 loss: 0.22666779160499573\n",
      "epoch 8 loss: 0.2787182629108429\n",
      "epoch 9 loss: 0.2423129826784134\n",
      "epoch 10 loss: 0.2109408974647522\n",
      "epoch 11 loss: 0.25323718786239624\n",
      "epoch 12 loss: 0.19985975325107574\n",
      "epoch 13 loss: 0.19745571911334991\n",
      "epoch 14 loss: 0.2281467169523239\n",
      "epoch 15 loss: 0.2131934016942978\n",
      "epoch 16 loss: 0.21759742498397827\n",
      "epoch 17 loss: 0.16502298414707184\n",
      "epoch 18 loss: 0.17465439438819885\n",
      "epoch 19 loss: 0.2061728537082672\n",
      "epoch 20 loss: 0.20398837327957153\n",
      "epoch 21 loss: 0.20050445199012756\n",
      "epoch 22 loss: 0.20897582173347473\n",
      "epoch 23 loss: 0.23074783384799957\n",
      "epoch 24 loss: 0.19841617345809937\n",
      "epoch 25 loss: 0.19336630403995514\n",
      "epoch 26 loss: 0.19672136008739471\n",
      "epoch 27 loss: 0.21353688836097717\n",
      "epoch 28 loss: 0.2047533541917801\n",
      "epoch 29 loss: 0.18970246613025665\n",
      "epoch 30 loss: 0.1611696183681488\n",
      "38\n",
      "epoch 1 loss: 0.9189626574516296\n",
      "epoch 2 loss: 0.8146336078643799\n",
      "epoch 3 loss: 0.6315855383872986\n",
      "epoch 4 loss: 0.3342519998550415\n",
      "epoch 5 loss: 0.2883031964302063\n",
      "epoch 6 loss: 0.19732286036014557\n",
      "epoch 7 loss: 0.23590683937072754\n",
      "epoch 8 loss: 0.20903320610523224\n",
      "epoch 9 loss: 0.21613207459449768\n",
      "epoch 10 loss: 0.21478527784347534\n",
      "epoch 11 loss: 0.2290802299976349\n",
      "epoch 12 loss: 0.18633539974689484\n",
      "epoch 13 loss: 0.19871065020561218\n",
      "epoch 14 loss: 0.20013116300106049\n",
      "epoch 15 loss: 0.18987174332141876\n",
      "epoch 16 loss: 0.21996888518333435\n",
      "epoch 17 loss: 0.20384268462657928\n",
      "epoch 18 loss: 0.18511363863945007\n",
      "epoch 19 loss: 0.18893462419509888\n",
      "epoch 20 loss: 0.2533676028251648\n",
      "epoch 21 loss: 0.21225710213184357\n",
      "epoch 22 loss: 0.20954008400440216\n",
      "epoch 23 loss: 0.19287973642349243\n",
      "epoch 24 loss: 0.20098942518234253\n",
      "epoch 25 loss: 0.18021456897258759\n",
      "epoch 26 loss: 0.19897200167179108\n",
      "epoch 27 loss: 0.23049142956733704\n",
      "epoch 28 loss: 0.1739802211523056\n",
      "epoch 29 loss: 0.2391113042831421\n",
      "epoch 30 loss: 0.16380776464939117\n",
      "39\n",
      "epoch 1 loss: 0.9316532015800476\n",
      "epoch 2 loss: 0.8281919956207275\n",
      "epoch 3 loss: 0.4893258213996887\n",
      "epoch 4 loss: 0.3475545048713684\n",
      "epoch 5 loss: 0.257185697555542\n",
      "epoch 6 loss: 0.2364058792591095\n",
      "epoch 7 loss: 0.2351456582546234\n",
      "epoch 8 loss: 0.18458929657936096\n",
      "epoch 9 loss: 0.18275664746761322\n",
      "epoch 10 loss: 0.23247723281383514\n",
      "epoch 11 loss: 0.18841305375099182\n",
      "epoch 12 loss: 0.1605214923620224\n",
      "epoch 13 loss: 0.22580860555171967\n",
      "epoch 14 loss: 0.21889713406562805\n",
      "epoch 15 loss: 0.1706947684288025\n",
      "epoch 16 loss: 0.141514852643013\n",
      "epoch 17 loss: 0.17487818002700806\n",
      "epoch 18 loss: 0.1868031769990921\n",
      "epoch 19 loss: 0.19371215999126434\n",
      "epoch 20 loss: 0.16793565452098846\n",
      "epoch 21 loss: 0.20892155170440674\n",
      "epoch 22 loss: 0.2172781378030777\n",
      "epoch 23 loss: 0.1932678520679474\n",
      "epoch 24 loss: 0.21122078597545624\n",
      "epoch 25 loss: 0.15321573615074158\n",
      "epoch 26 loss: 0.16154222190380096\n",
      "epoch 27 loss: 0.17005591094493866\n",
      "epoch 28 loss: 0.1991560161113739\n",
      "epoch 29 loss: 0.1890118271112442\n",
      "epoch 30 loss: 0.23195618391036987\n",
      "40\n",
      "epoch 1 loss: 0.9212175011634827\n",
      "epoch 2 loss: 0.8486689925193787\n",
      "epoch 3 loss: 0.5637422800064087\n",
      "epoch 4 loss: 0.34183937311172485\n",
      "epoch 5 loss: 0.30914780497550964\n",
      "epoch 6 loss: 0.26619911193847656\n",
      "epoch 7 loss: 0.1808575689792633\n",
      "epoch 8 loss: 0.21164418756961823\n",
      "epoch 9 loss: 0.19522690773010254\n",
      "epoch 10 loss: 0.2189721316099167\n",
      "epoch 11 loss: 0.17447054386138916\n",
      "epoch 12 loss: 0.19227176904678345\n",
      "epoch 13 loss: 0.21880842745304108\n",
      "epoch 14 loss: 0.23837994039058685\n",
      "epoch 15 loss: 0.19921816885471344\n",
      "epoch 16 loss: 0.19255879521369934\n",
      "epoch 17 loss: 0.1750061959028244\n",
      "epoch 18 loss: 0.2063661366701126\n",
      "epoch 19 loss: 0.17665258049964905\n",
      "epoch 20 loss: 0.2254280149936676\n",
      "epoch 21 loss: 0.20174172520637512\n",
      "epoch 22 loss: 0.1902915984392166\n",
      "epoch 23 loss: 0.20518387854099274\n",
      "epoch 24 loss: 0.20363114774227142\n",
      "epoch 25 loss: 0.21645615994930267\n",
      "epoch 26 loss: 0.22981862723827362\n",
      "epoch 27 loss: 0.16768778860569\n",
      "epoch 28 loss: 0.182367742061615\n",
      "epoch 29 loss: 0.19553887844085693\n",
      "epoch 30 loss: 0.17686687409877777\n",
      "41\n",
      "epoch 1 loss: 0.976248562335968\n",
      "epoch 2 loss: 0.5799595713615417\n",
      "epoch 3 loss: 0.48571205139160156\n",
      "epoch 4 loss: 0.22266247868537903\n",
      "epoch 5 loss: 0.2718017101287842\n",
      "epoch 6 loss: 0.2225995510816574\n",
      "epoch 7 loss: 0.2708713114261627\n",
      "epoch 8 loss: 0.20776355266571045\n",
      "epoch 9 loss: 0.22095157206058502\n",
      "epoch 10 loss: 0.18695056438446045\n",
      "epoch 11 loss: 0.1533193290233612\n",
      "epoch 12 loss: 0.2146880179643631\n",
      "epoch 13 loss: 0.1892126351594925\n",
      "epoch 14 loss: 0.1826041340827942\n",
      "epoch 15 loss: 0.2255813479423523\n",
      "epoch 16 loss: 0.1658673733472824\n",
      "epoch 17 loss: 0.17401213943958282\n",
      "epoch 18 loss: 0.18794354796409607\n",
      "epoch 19 loss: 0.16610272228717804\n",
      "epoch 20 loss: 0.21737174689769745\n",
      "epoch 21 loss: 0.21823042631149292\n",
      "epoch 22 loss: 0.22887660562992096\n",
      "epoch 23 loss: 0.22006718814373016\n",
      "epoch 24 loss: 0.19657695293426514\n",
      "epoch 25 loss: 0.2156686931848526\n",
      "epoch 26 loss: 0.15647588670253754\n",
      "epoch 27 loss: 0.19318519532680511\n",
      "epoch 28 loss: 0.2263079434633255\n",
      "epoch 29 loss: 0.20842352509498596\n",
      "epoch 30 loss: 0.1628548502922058\n",
      "42\n",
      "epoch 1 loss: 0.8966147899627686\n",
      "epoch 2 loss: 0.8227152228355408\n",
      "epoch 3 loss: 0.5663511753082275\n",
      "epoch 4 loss: 0.3550098240375519\n",
      "epoch 5 loss: 0.2249479591846466\n",
      "epoch 6 loss: 0.22396759688854218\n",
      "epoch 7 loss: 0.23722685873508453\n",
      "epoch 8 loss: 0.21791192889213562\n",
      "epoch 9 loss: 0.2470276802778244\n",
      "epoch 10 loss: 0.20415890216827393\n",
      "epoch 11 loss: 0.21968302130699158\n",
      "epoch 12 loss: 0.20506703853607178\n",
      "epoch 13 loss: 0.22717298567295074\n",
      "epoch 14 loss: 0.21860052645206451\n",
      "epoch 15 loss: 0.2061624825000763\n",
      "epoch 16 loss: 0.17458418011665344\n",
      "epoch 17 loss: 0.16556429862976074\n",
      "epoch 18 loss: 0.20820258557796478\n",
      "epoch 19 loss: 0.22626741230487823\n",
      "epoch 20 loss: 0.1982010304927826\n",
      "epoch 21 loss: 0.19997815787792206\n",
      "epoch 22 loss: 0.195914164185524\n",
      "epoch 23 loss: 0.1592259705066681\n",
      "epoch 24 loss: 0.2026393562555313\n",
      "epoch 25 loss: 0.1886124312877655\n",
      "epoch 26 loss: 0.13280105590820312\n",
      "epoch 27 loss: 0.24637258052825928\n",
      "epoch 28 loss: 0.1948237121105194\n",
      "epoch 29 loss: 0.17132815718650818\n",
      "epoch 30 loss: 0.20278316736221313\n",
      "43\n",
      "epoch 1 loss: 0.8068018555641174\n",
      "epoch 2 loss: 0.7911936640739441\n",
      "epoch 3 loss: 0.4565978944301605\n",
      "epoch 4 loss: 0.3218143880367279\n",
      "epoch 5 loss: 0.2898494005203247\n",
      "epoch 6 loss: 0.20337681472301483\n",
      "epoch 7 loss: 0.17700254917144775\n",
      "epoch 8 loss: 0.19168466329574585\n",
      "epoch 9 loss: 0.1937570720911026\n",
      "epoch 10 loss: 0.217511847615242\n",
      "epoch 11 loss: 0.22616316378116608\n",
      "epoch 12 loss: 0.2216227501630783\n",
      "epoch 13 loss: 0.2090674191713333\n",
      "epoch 14 loss: 0.21772035956382751\n",
      "epoch 15 loss: 0.2001229226589203\n",
      "epoch 16 loss: 0.2616505026817322\n",
      "epoch 17 loss: 0.17840221524238586\n",
      "epoch 18 loss: 0.20604442059993744\n",
      "epoch 19 loss: 0.20839102566242218\n",
      "epoch 20 loss: 0.20459513366222382\n",
      "epoch 21 loss: 0.19819720089435577\n",
      "epoch 22 loss: 0.2037651687860489\n",
      "epoch 23 loss: 0.1775786429643631\n",
      "epoch 24 loss: 0.19624711573123932\n",
      "epoch 25 loss: 0.1566823124885559\n",
      "epoch 26 loss: 0.17161257565021515\n",
      "epoch 27 loss: 0.21023504436016083\n",
      "epoch 28 loss: 0.2111649215221405\n",
      "epoch 29 loss: 0.17589999735355377\n",
      "epoch 30 loss: 0.1658424735069275\n",
      "44\n",
      "epoch 1 loss: 0.7597070932388306\n",
      "epoch 2 loss: 0.8417098522186279\n",
      "epoch 3 loss: 0.5650725364685059\n",
      "epoch 4 loss: 0.3763829171657562\n",
      "epoch 5 loss: 0.32529589533805847\n",
      "epoch 6 loss: 0.2789342403411865\n",
      "epoch 7 loss: 0.2174571305513382\n",
      "epoch 8 loss: 0.21696680784225464\n",
      "epoch 9 loss: 0.21246470510959625\n",
      "epoch 10 loss: 0.20197610557079315\n",
      "epoch 11 loss: 0.23994076251983643\n",
      "epoch 12 loss: 0.21769142150878906\n",
      "epoch 13 loss: 0.21141751110553741\n",
      "epoch 14 loss: 0.20947624742984772\n",
      "epoch 15 loss: 0.19155928492546082\n",
      "epoch 16 loss: 0.21223780512809753\n",
      "epoch 17 loss: 0.1830514520406723\n",
      "epoch 18 loss: 0.21095944941043854\n",
      "epoch 19 loss: 0.18188267946243286\n",
      "epoch 20 loss: 0.2140325903892517\n",
      "epoch 21 loss: 0.1713140904903412\n",
      "epoch 22 loss: 0.19341248273849487\n",
      "epoch 23 loss: 0.21505853533744812\n",
      "epoch 24 loss: 0.19165578484535217\n",
      "epoch 25 loss: 0.20722538232803345\n",
      "epoch 26 loss: 0.17906606197357178\n",
      "epoch 27 loss: 0.2227163463830948\n",
      "epoch 28 loss: 0.15900084376335144\n",
      "epoch 29 loss: 0.18359671533107758\n",
      "epoch 30 loss: 0.22997136414051056\n",
      "45\n",
      "epoch 1 loss: 0.9435527920722961\n",
      "epoch 2 loss: 0.683008074760437\n",
      "epoch 3 loss: 0.5566142797470093\n",
      "epoch 4 loss: 0.36032018065452576\n",
      "epoch 5 loss: 0.250762403011322\n",
      "epoch 6 loss: 0.2053195685148239\n",
      "epoch 7 loss: 0.2065245360136032\n",
      "epoch 8 loss: 0.19773927330970764\n",
      "epoch 9 loss: 0.18912793695926666\n",
      "epoch 10 loss: 0.2089923620223999\n",
      "epoch 11 loss: 0.210415318608284\n",
      "epoch 12 loss: 0.1586000919342041\n",
      "epoch 13 loss: 0.1902737021446228\n",
      "epoch 14 loss: 0.19599385559558868\n",
      "epoch 15 loss: 0.2141532003879547\n",
      "epoch 16 loss: 0.1906237006187439\n",
      "epoch 17 loss: 0.20947925746440887\n",
      "epoch 18 loss: 0.21359357237815857\n",
      "epoch 19 loss: 0.15533758699893951\n",
      "epoch 20 loss: 0.2150469571352005\n",
      "epoch 21 loss: 0.2171379029750824\n",
      "epoch 22 loss: 0.2017514407634735\n",
      "epoch 23 loss: 0.1778138428926468\n",
      "epoch 24 loss: 0.18142610788345337\n",
      "epoch 25 loss: 0.19032956659793854\n",
      "epoch 26 loss: 0.189894899725914\n",
      "epoch 27 loss: 0.1800091415643692\n",
      "epoch 28 loss: 0.22271014750003815\n",
      "epoch 29 loss: 0.20723049342632294\n",
      "epoch 30 loss: 0.21257896721363068\n",
      "46\n",
      "epoch 1 loss: 0.8464676737785339\n",
      "epoch 2 loss: 0.6991174221038818\n",
      "epoch 3 loss: 0.6330859661102295\n",
      "epoch 4 loss: 0.3297594487667084\n",
      "epoch 5 loss: 0.30439823865890503\n",
      "epoch 6 loss: 0.2711114287376404\n",
      "epoch 7 loss: 0.17053310573101044\n",
      "epoch 8 loss: 0.22757135331630707\n",
      "epoch 9 loss: 0.19549940526485443\n",
      "epoch 10 loss: 0.17945513129234314\n",
      "epoch 11 loss: 0.1808439940214157\n",
      "epoch 12 loss: 0.20843757688999176\n",
      "epoch 13 loss: 0.1990416944026947\n",
      "epoch 14 loss: 0.17339231073856354\n",
      "epoch 15 loss: 0.21524737775325775\n",
      "epoch 16 loss: 0.19102349877357483\n",
      "epoch 17 loss: 0.2024337351322174\n",
      "epoch 18 loss: 0.1897527128458023\n",
      "epoch 19 loss: 0.14074425399303436\n",
      "epoch 20 loss: 0.21373556554317474\n",
      "epoch 21 loss: 0.17000634968280792\n",
      "epoch 22 loss: 0.18058566749095917\n",
      "epoch 23 loss: 0.178493931889534\n",
      "epoch 24 loss: 0.20596982538700104\n",
      "epoch 25 loss: 0.1875213086605072\n",
      "epoch 26 loss: 0.20139992237091064\n",
      "epoch 27 loss: 0.1963045746088028\n",
      "epoch 28 loss: 0.20113016664981842\n",
      "epoch 29 loss: 0.14872290194034576\n",
      "epoch 30 loss: 0.18752625584602356\n",
      "47\n",
      "epoch 1 loss: 0.9021216630935669\n",
      "epoch 2 loss: 0.6840599775314331\n",
      "epoch 3 loss: 0.4975513815879822\n",
      "epoch 4 loss: 0.2719557285308838\n",
      "epoch 5 loss: 0.26714298129081726\n",
      "epoch 6 loss: 0.21880759298801422\n",
      "epoch 7 loss: 0.1999690979719162\n",
      "epoch 8 loss: 0.19310159981250763\n",
      "epoch 9 loss: 0.18884964287281036\n",
      "epoch 10 loss: 0.19067919254302979\n",
      "epoch 11 loss: 0.1541411131620407\n",
      "epoch 12 loss: 0.1832665055990219\n",
      "epoch 13 loss: 0.2099105268716812\n",
      "epoch 14 loss: 0.20235376060009003\n",
      "epoch 15 loss: 0.21699045598506927\n",
      "epoch 16 loss: 0.2001029998064041\n",
      "epoch 17 loss: 0.21386057138442993\n",
      "epoch 18 loss: 0.2324189692735672\n",
      "epoch 19 loss: 0.21204781532287598\n",
      "epoch 20 loss: 0.18630054593086243\n",
      "epoch 21 loss: 0.22717832028865814\n",
      "epoch 22 loss: 0.17800022661685944\n",
      "epoch 23 loss: 0.1894555240869522\n",
      "epoch 24 loss: 0.17352986335754395\n",
      "epoch 25 loss: 0.1989145427942276\n",
      "epoch 26 loss: 0.22969652712345123\n",
      "epoch 27 loss: 0.1791309416294098\n",
      "epoch 28 loss: 0.1760847121477127\n",
      "epoch 29 loss: 0.1924555003643036\n",
      "epoch 30 loss: 0.17687948048114777\n",
      "48\n",
      "epoch 1 loss: 0.9085976481437683\n",
      "epoch 2 loss: 0.7628815770149231\n",
      "epoch 3 loss: 0.5485141277313232\n",
      "epoch 4 loss: 0.31287312507629395\n",
      "epoch 5 loss: 0.23424576222896576\n",
      "epoch 6 loss: 0.2012663334608078\n",
      "epoch 7 loss: 0.1824633926153183\n",
      "epoch 8 loss: 0.22178074717521667\n",
      "epoch 9 loss: 0.16276831924915314\n",
      "epoch 10 loss: 0.20036737620830536\n",
      "epoch 11 loss: 0.16902704536914825\n",
      "epoch 12 loss: 0.20427405834197998\n",
      "epoch 13 loss: 0.18383195996284485\n",
      "epoch 14 loss: 0.1837228387594223\n",
      "epoch 15 loss: 0.20963309705257416\n",
      "epoch 16 loss: 0.17028184235095978\n",
      "epoch 17 loss: 0.18812985718250275\n",
      "epoch 18 loss: 0.20479990541934967\n",
      "epoch 19 loss: 0.15941280126571655\n",
      "epoch 20 loss: 0.22593140602111816\n",
      "epoch 21 loss: 0.18804310262203217\n",
      "epoch 22 loss: 0.19094246625900269\n",
      "epoch 23 loss: 0.21918968856334686\n",
      "epoch 24 loss: 0.20189420878887177\n",
      "epoch 25 loss: 0.19826988875865936\n",
      "epoch 26 loss: 0.2566636800765991\n",
      "epoch 27 loss: 0.16522255539894104\n",
      "epoch 28 loss: 0.22591276466846466\n",
      "epoch 29 loss: 0.20225536823272705\n",
      "epoch 30 loss: 0.19496674835681915\n",
      "49\n",
      "epoch 1 loss: 0.957879364490509\n",
      "epoch 2 loss: 1.0009921789169312\n",
      "epoch 3 loss: 0.608768880367279\n",
      "epoch 4 loss: 0.3366535007953644\n",
      "epoch 5 loss: 0.24537518620491028\n",
      "epoch 6 loss: 0.227341428399086\n",
      "epoch 7 loss: 0.23117361962795258\n",
      "epoch 8 loss: 0.18821819126605988\n",
      "epoch 9 loss: 0.1719502955675125\n",
      "epoch 10 loss: 0.22398413717746735\n",
      "epoch 11 loss: 0.24084606766700745\n",
      "epoch 12 loss: 0.21851935982704163\n",
      "epoch 13 loss: 0.22874513268470764\n",
      "epoch 14 loss: 0.23549522459506989\n",
      "epoch 15 loss: 0.231295645236969\n",
      "epoch 16 loss: 0.2060946673154831\n",
      "epoch 17 loss: 0.22408966720104218\n",
      "epoch 18 loss: 0.2223602533340454\n",
      "epoch 19 loss: 0.2036392092704773\n",
      "epoch 20 loss: 0.19273214042186737\n",
      "epoch 21 loss: 0.21800614893436432\n",
      "epoch 22 loss: 0.16390681266784668\n",
      "epoch 23 loss: 0.15586762130260468\n",
      "epoch 24 loss: 0.22615587711334229\n",
      "epoch 25 loss: 0.20060455799102783\n",
      "epoch 26 loss: 0.16260094940662384\n",
      "epoch 27 loss: 0.1782042384147644\n",
      "epoch 28 loss: 0.2370118349790573\n",
      "epoch 29 loss: 0.2133002132177353\n",
      "epoch 30 loss: 0.169118732213974\n",
      "50\n",
      "epoch 1 loss: 0.9080495238304138\n",
      "epoch 2 loss: 0.7519010305404663\n",
      "epoch 3 loss: 0.5511029958724976\n",
      "epoch 4 loss: 0.4562624990940094\n",
      "epoch 5 loss: 0.2756746709346771\n",
      "epoch 6 loss: 0.2966315746307373\n",
      "epoch 7 loss: 0.23385988175868988\n",
      "epoch 8 loss: 0.25690749287605286\n",
      "epoch 9 loss: 0.21187685430049896\n",
      "epoch 10 loss: 0.2414318472146988\n",
      "epoch 11 loss: 0.16667592525482178\n",
      "epoch 12 loss: 0.19672489166259766\n",
      "epoch 13 loss: 0.21790924668312073\n",
      "epoch 14 loss: 0.2395072728395462\n",
      "epoch 15 loss: 0.20005175471305847\n",
      "epoch 16 loss: 0.2197147011756897\n",
      "epoch 17 loss: 0.20458438992500305\n",
      "epoch 18 loss: 0.17982274293899536\n",
      "epoch 19 loss: 0.1832210272550583\n",
      "epoch 20 loss: 0.20032446086406708\n",
      "epoch 21 loss: 0.20977351069450378\n",
      "epoch 22 loss: 0.2125585526227951\n",
      "epoch 23 loss: 0.1944684386253357\n",
      "epoch 24 loss: 0.17051716148853302\n",
      "epoch 25 loss: 0.21648085117340088\n",
      "epoch 26 loss: 0.19719469547271729\n",
      "epoch 27 loss: 0.18993914127349854\n",
      "epoch 28 loss: 0.22144539654254913\n",
      "epoch 29 loss: 0.17157332599163055\n",
      "epoch 30 loss: 0.1522621065378189\n",
      "51\n",
      "epoch 1 loss: 0.9994841814041138\n",
      "epoch 2 loss: 0.7529869675636292\n",
      "epoch 3 loss: 0.4859701991081238\n",
      "epoch 4 loss: 0.3672087490558624\n",
      "epoch 5 loss: 0.2766101062297821\n",
      "epoch 6 loss: 0.3115677833557129\n",
      "epoch 7 loss: 0.2226160317659378\n",
      "epoch 8 loss: 0.1938829869031906\n",
      "epoch 9 loss: 0.25300583243370056\n",
      "epoch 10 loss: 0.21511849761009216\n",
      "epoch 11 loss: 0.22764118015766144\n",
      "epoch 12 loss: 0.20032301545143127\n",
      "epoch 13 loss: 0.18330475687980652\n",
      "epoch 14 loss: 0.24808728694915771\n",
      "epoch 15 loss: 0.21923866868019104\n",
      "epoch 16 loss: 0.217070072889328\n",
      "epoch 17 loss: 0.22842568159103394\n",
      "epoch 18 loss: 0.15806443989276886\n",
      "epoch 19 loss: 0.22924287617206573\n",
      "epoch 20 loss: 0.16177015006542206\n",
      "epoch 21 loss: 0.20648594200611115\n",
      "epoch 22 loss: 0.13088524341583252\n",
      "epoch 23 loss: 0.17462801933288574\n",
      "epoch 24 loss: 0.18863734602928162\n",
      "epoch 25 loss: 0.202333465218544\n",
      "epoch 26 loss: 0.19106541574001312\n",
      "epoch 27 loss: 0.1968814581632614\n",
      "epoch 28 loss: 0.19094112515449524\n",
      "epoch 29 loss: 0.22990350425243378\n",
      "epoch 30 loss: 0.18568186461925507\n",
      "52\n",
      "epoch 1 loss: 0.939367413520813\n",
      "epoch 2 loss: 0.7922130823135376\n",
      "epoch 3 loss: 0.6214563250541687\n",
      "epoch 4 loss: 0.34285855293273926\n",
      "epoch 5 loss: 0.300167977809906\n",
      "epoch 6 loss: 0.1817498356103897\n",
      "epoch 7 loss: 0.218835711479187\n",
      "epoch 8 loss: 0.2196313738822937\n",
      "epoch 9 loss: 0.24223285913467407\n",
      "epoch 10 loss: 0.2022448182106018\n",
      "epoch 11 loss: 0.18805228173732758\n",
      "epoch 12 loss: 0.18618589639663696\n",
      "epoch 13 loss: 0.20078197121620178\n",
      "epoch 14 loss: 0.19312883913516998\n",
      "epoch 15 loss: 0.20310913026332855\n",
      "epoch 16 loss: 0.17487750947475433\n",
      "epoch 17 loss: 0.1918870508670807\n",
      "epoch 18 loss: 0.18567019701004028\n",
      "epoch 19 loss: 0.21518853306770325\n",
      "epoch 20 loss: 0.17951226234436035\n",
      "epoch 21 loss: 0.18628579378128052\n",
      "epoch 22 loss: 0.21664942800998688\n",
      "epoch 23 loss: 0.2054816037416458\n",
      "epoch 24 loss: 0.21854889392852783\n",
      "epoch 25 loss: 0.21960173547267914\n",
      "epoch 26 loss: 0.18314863741397858\n",
      "epoch 27 loss: 0.231659933924675\n",
      "epoch 28 loss: 0.24470430612564087\n",
      "epoch 29 loss: 0.16450005769729614\n",
      "epoch 30 loss: 0.18716083467006683\n",
      "53\n",
      "epoch 1 loss: 0.9528713822364807\n",
      "epoch 2 loss: 0.9142645001411438\n",
      "epoch 3 loss: 0.6645323634147644\n",
      "epoch 4 loss: 0.3719457983970642\n",
      "epoch 5 loss: 0.3168103098869324\n",
      "epoch 6 loss: 0.28585731983184814\n",
      "epoch 7 loss: 0.22168266773223877\n",
      "epoch 8 loss: 0.22035962343215942\n",
      "epoch 9 loss: 0.1949416548013687\n",
      "epoch 10 loss: 0.20692414045333862\n",
      "epoch 11 loss: 0.18417766690254211\n",
      "epoch 12 loss: 0.23189108073711395\n",
      "epoch 13 loss: 0.2285999357700348\n",
      "epoch 14 loss: 0.18205352127552032\n",
      "epoch 15 loss: 0.22557587921619415\n",
      "epoch 16 loss: 0.1566888839006424\n",
      "epoch 17 loss: 0.19592121243476868\n",
      "epoch 18 loss: 0.2144603431224823\n",
      "epoch 19 loss: 0.19006329774856567\n",
      "epoch 20 loss: 0.21277473866939545\n",
      "epoch 21 loss: 0.20793987810611725\n",
      "epoch 22 loss: 0.1652175486087799\n",
      "epoch 23 loss: 0.15501661598682404\n",
      "epoch 24 loss: 0.16927175223827362\n",
      "epoch 25 loss: 0.14337463676929474\n",
      "epoch 26 loss: 0.1863194704055786\n",
      "epoch 27 loss: 0.19613368809223175\n",
      "epoch 28 loss: 0.17473699152469635\n",
      "epoch 29 loss: 0.20966002345085144\n",
      "epoch 30 loss: 0.21790571510791779\n",
      "54\n",
      "epoch 1 loss: 0.9528045654296875\n",
      "epoch 2 loss: 0.889359712600708\n",
      "epoch 3 loss: 0.536221444606781\n",
      "epoch 4 loss: 0.36768320202827454\n",
      "epoch 5 loss: 0.2691988945007324\n",
      "epoch 6 loss: 0.22093716263771057\n",
      "epoch 7 loss: 0.2272113710641861\n",
      "epoch 8 loss: 0.18358716368675232\n",
      "epoch 9 loss: 0.22645574808120728\n",
      "epoch 10 loss: 0.21539683640003204\n",
      "epoch 11 loss: 0.2102125585079193\n",
      "epoch 12 loss: 0.22203181684017181\n",
      "epoch 13 loss: 0.20852124691009521\n",
      "epoch 14 loss: 0.22625908255577087\n",
      "epoch 15 loss: 0.23868879675865173\n",
      "epoch 16 loss: 0.21539932489395142\n",
      "epoch 17 loss: 0.22569972276687622\n",
      "epoch 18 loss: 0.19163307547569275\n",
      "epoch 19 loss: 0.2336200773715973\n",
      "epoch 20 loss: 0.19374892115592957\n",
      "epoch 21 loss: 0.22956277430057526\n",
      "epoch 22 loss: 0.21408624947071075\n",
      "epoch 23 loss: 0.2079770267009735\n",
      "epoch 24 loss: 0.1852143555879593\n",
      "epoch 25 loss: 0.1766934096813202\n",
      "epoch 26 loss: 0.16563288867473602\n",
      "epoch 27 loss: 0.1894739270210266\n",
      "epoch 28 loss: 0.20932205021381378\n",
      "epoch 29 loss: 0.16726012527942657\n",
      "epoch 30 loss: 0.17533284425735474\n",
      "55\n",
      "epoch 1 loss: 0.8610432744026184\n",
      "epoch 2 loss: 0.9141782522201538\n",
      "epoch 3 loss: 0.5848039984703064\n",
      "epoch 4 loss: 0.35861822962760925\n",
      "epoch 5 loss: 0.31179773807525635\n",
      "epoch 6 loss: 0.23076169192790985\n",
      "epoch 7 loss: 0.239310160279274\n",
      "epoch 8 loss: 0.21521298587322235\n",
      "epoch 9 loss: 0.23485249280929565\n",
      "epoch 10 loss: 0.17352259159088135\n",
      "epoch 11 loss: 0.2176435887813568\n",
      "epoch 12 loss: 0.1822076290845871\n",
      "epoch 13 loss: 0.19434607028961182\n",
      "epoch 14 loss: 0.20512345433235168\n",
      "epoch 15 loss: 0.17328232526779175\n",
      "epoch 16 loss: 0.22161884605884552\n",
      "epoch 17 loss: 0.18347333371639252\n",
      "epoch 18 loss: 0.20876893401145935\n",
      "epoch 19 loss: 0.15725985169410706\n",
      "epoch 20 loss: 0.17307822406291962\n",
      "epoch 21 loss: 0.2075936645269394\n",
      "epoch 22 loss: 0.19261477887630463\n",
      "epoch 23 loss: 0.20466561615467072\n",
      "epoch 24 loss: 0.20817190408706665\n",
      "epoch 25 loss: 0.15077969431877136\n",
      "epoch 26 loss: 0.162744402885437\n",
      "epoch 27 loss: 0.1852579265832901\n",
      "epoch 28 loss: 0.20816253125667572\n",
      "epoch 29 loss: 0.18332470953464508\n",
      "epoch 30 loss: 0.1953711360692978\n",
      "56\n",
      "epoch 1 loss: 0.8462749719619751\n",
      "epoch 2 loss: 0.6356655359268188\n",
      "epoch 3 loss: 0.4938541054725647\n",
      "epoch 4 loss: 0.3066362738609314\n",
      "epoch 5 loss: 0.2607075572013855\n",
      "epoch 6 loss: 0.20873449742794037\n",
      "epoch 7 loss: 0.23428598046302795\n",
      "epoch 8 loss: 0.22175446152687073\n",
      "epoch 9 loss: 0.24361655116081238\n",
      "epoch 10 loss: 0.20810945332050323\n",
      "epoch 11 loss: 0.21440675854682922\n",
      "epoch 12 loss: 0.1860300451517105\n",
      "epoch 13 loss: 0.2232750654220581\n",
      "epoch 14 loss: 0.18997818231582642\n",
      "epoch 15 loss: 0.22081618010997772\n",
      "epoch 16 loss: 0.19331330060958862\n",
      "epoch 17 loss: 0.18999703228473663\n",
      "epoch 18 loss: 0.22706720232963562\n",
      "epoch 19 loss: 0.2025071233510971\n",
      "epoch 20 loss: 0.2042160928249359\n",
      "epoch 21 loss: 0.15602611005306244\n",
      "epoch 22 loss: 0.1693733036518097\n",
      "epoch 23 loss: 0.17666596174240112\n",
      "epoch 24 loss: 0.1913186013698578\n",
      "epoch 25 loss: 0.18557776510715485\n",
      "epoch 26 loss: 0.20779815316200256\n",
      "epoch 27 loss: 0.20859545469284058\n",
      "epoch 28 loss: 0.2134617418050766\n",
      "epoch 29 loss: 0.2173873633146286\n",
      "epoch 30 loss: 0.16222169995307922\n",
      "57\n",
      "epoch 1 loss: 0.9028988480567932\n",
      "epoch 2 loss: 0.6308934092521667\n",
      "epoch 3 loss: 0.5572571754455566\n",
      "epoch 4 loss: 0.4043780267238617\n",
      "epoch 5 loss: 0.24229441583156586\n",
      "epoch 6 loss: 0.2245858758687973\n",
      "epoch 7 loss: 0.21997548639774323\n",
      "epoch 8 loss: 0.2024628221988678\n",
      "epoch 9 loss: 0.25515931844711304\n",
      "epoch 10 loss: 0.2037094682455063\n",
      "epoch 11 loss: 0.22914713621139526\n",
      "epoch 12 loss: 0.21017973124980927\n",
      "epoch 13 loss: 0.22017885744571686\n",
      "epoch 14 loss: 0.21021854877471924\n",
      "epoch 15 loss: 0.26033782958984375\n",
      "epoch 16 loss: 0.19844432175159454\n",
      "epoch 17 loss: 0.19576093554496765\n",
      "epoch 18 loss: 0.17852838337421417\n",
      "epoch 19 loss: 0.16517122089862823\n",
      "epoch 20 loss: 0.14002808928489685\n",
      "epoch 21 loss: 0.21835178136825562\n",
      "epoch 22 loss: 0.18115298449993134\n",
      "epoch 23 loss: 0.18481077253818512\n",
      "epoch 24 loss: 0.19777972996234894\n",
      "epoch 25 loss: 0.20411358773708344\n",
      "epoch 26 loss: 0.20472820103168488\n",
      "epoch 27 loss: 0.2060500830411911\n",
      "epoch 28 loss: 0.2006273865699768\n",
      "epoch 29 loss: 0.18394699692726135\n",
      "epoch 30 loss: 0.18680842220783234\n",
      "58\n",
      "epoch 1 loss: 0.9504834413528442\n",
      "epoch 2 loss: 0.5093938708305359\n",
      "epoch 3 loss: 0.3460094928741455\n",
      "epoch 4 loss: 0.22328457236289978\n",
      "epoch 5 loss: 0.2664559781551361\n",
      "epoch 6 loss: 0.2499426007270813\n",
      "epoch 7 loss: 0.19297726452350616\n",
      "epoch 8 loss: 0.22071649134159088\n",
      "epoch 9 loss: 0.23993289470672607\n",
      "epoch 10 loss: 0.191217303276062\n",
      "epoch 11 loss: 0.1992701292037964\n",
      "epoch 12 loss: 0.17803268134593964\n",
      "epoch 13 loss: 0.19392788410186768\n",
      "epoch 14 loss: 0.20062540471553802\n",
      "epoch 15 loss: 0.17495329678058624\n",
      "epoch 16 loss: 0.21330291032791138\n",
      "epoch 17 loss: 0.20543719828128815\n",
      "epoch 18 loss: 0.18107730150222778\n",
      "epoch 19 loss: 0.19090954959392548\n",
      "epoch 20 loss: 0.24089352786540985\n",
      "epoch 21 loss: 0.19860894978046417\n",
      "epoch 22 loss: 0.2046467661857605\n",
      "epoch 23 loss: 0.26272571086883545\n",
      "epoch 24 loss: 0.22322069108486176\n",
      "epoch 25 loss: 0.23125220835208893\n",
      "epoch 26 loss: 0.18188658356666565\n",
      "epoch 27 loss: 0.20036128163337708\n",
      "epoch 28 loss: 0.20688046514987946\n",
      "epoch 29 loss: 0.22324931621551514\n",
      "epoch 30 loss: 0.18906018137931824\n",
      "59\n",
      "epoch 1 loss: 0.8655062913894653\n",
      "epoch 2 loss: 0.7326779961585999\n",
      "epoch 3 loss: 0.4811026453971863\n",
      "epoch 4 loss: 0.341033935546875\n",
      "epoch 5 loss: 0.2450840026140213\n",
      "epoch 6 loss: 0.23980717360973358\n",
      "epoch 7 loss: 0.2201673835515976\n",
      "epoch 8 loss: 0.20185039937496185\n",
      "epoch 9 loss: 0.20834720134735107\n",
      "epoch 10 loss: 0.2061307728290558\n",
      "epoch 11 loss: 0.2469959259033203\n",
      "epoch 12 loss: 0.18800492584705353\n",
      "epoch 13 loss: 0.22651194036006927\n",
      "epoch 14 loss: 0.1980360746383667\n",
      "epoch 15 loss: 0.2126029133796692\n",
      "epoch 16 loss: 0.2123795449733734\n",
      "epoch 17 loss: 0.22463443875312805\n",
      "epoch 18 loss: 0.18219828605651855\n",
      "epoch 19 loss: 0.22226829826831818\n",
      "epoch 20 loss: 0.22186480462551117\n",
      "epoch 21 loss: 0.22195401787757874\n",
      "epoch 22 loss: 0.219905823469162\n",
      "epoch 23 loss: 0.22078421711921692\n",
      "epoch 24 loss: 0.16236700117588043\n",
      "epoch 25 loss: 0.16873840987682343\n",
      "epoch 26 loss: 0.1967284083366394\n",
      "epoch 27 loss: 0.24640271067619324\n",
      "epoch 28 loss: 0.16576896607875824\n",
      "epoch 29 loss: 0.18701210618019104\n",
      "epoch 30 loss: 0.18576887249946594\n",
      "60\n",
      "epoch 1 loss: 0.9621986746788025\n",
      "epoch 2 loss: 0.6566236019134521\n",
      "epoch 3 loss: 0.4713444709777832\n",
      "epoch 4 loss: 0.2975651025772095\n",
      "epoch 5 loss: 0.214780792593956\n",
      "epoch 6 loss: 0.21594849228858948\n",
      "epoch 7 loss: 0.21906410157680511\n",
      "epoch 8 loss: 0.17931830883026123\n",
      "epoch 9 loss: 0.2001691460609436\n",
      "epoch 10 loss: 0.2191709727048874\n",
      "epoch 11 loss: 0.18028944730758667\n",
      "epoch 12 loss: 0.14516393840312958\n",
      "epoch 13 loss: 0.21641060709953308\n",
      "epoch 14 loss: 0.15917600691318512\n",
      "epoch 15 loss: 0.21580851078033447\n",
      "epoch 16 loss: 0.20620352029800415\n",
      "epoch 17 loss: 0.19048482179641724\n",
      "epoch 18 loss: 0.17687061429023743\n",
      "epoch 19 loss: 0.21601749956607819\n",
      "epoch 20 loss: 0.20530174672603607\n",
      "epoch 21 loss: 0.21785715222358704\n",
      "epoch 22 loss: 0.22230446338653564\n",
      "epoch 23 loss: 0.17266345024108887\n",
      "epoch 24 loss: 0.16075454652309418\n",
      "epoch 25 loss: 0.21530012786388397\n",
      "epoch 26 loss: 0.19319047033786774\n",
      "epoch 27 loss: 0.2105318009853363\n",
      "epoch 28 loss: 0.1786617636680603\n",
      "epoch 29 loss: 0.19731773436069489\n",
      "epoch 30 loss: 0.17151398956775665\n",
      "61\n",
      "epoch 1 loss: 0.8809735774993896\n",
      "epoch 2 loss: 0.6360882520675659\n",
      "epoch 3 loss: 0.5553621649742126\n",
      "epoch 4 loss: 0.30169057846069336\n",
      "epoch 5 loss: 0.2185218334197998\n",
      "epoch 6 loss: 0.17509892582893372\n",
      "epoch 7 loss: 0.2462119460105896\n",
      "epoch 8 loss: 0.18067362904548645\n",
      "epoch 9 loss: 0.17476026713848114\n",
      "epoch 10 loss: 0.22866126894950867\n",
      "epoch 11 loss: 0.1740904599428177\n",
      "epoch 12 loss: 0.19921909272670746\n",
      "epoch 13 loss: 0.22369691729545593\n",
      "epoch 14 loss: 0.20941050350666046\n",
      "epoch 15 loss: 0.18859821557998657\n",
      "epoch 16 loss: 0.17723138630390167\n",
      "epoch 17 loss: 0.17581425607204437\n",
      "epoch 18 loss: 0.20150387287139893\n",
      "epoch 19 loss: 0.2127150595188141\n",
      "epoch 20 loss: 0.20013460516929626\n",
      "epoch 21 loss: 0.1969429850578308\n",
      "epoch 22 loss: 0.2265697866678238\n",
      "epoch 23 loss: 0.1991170197725296\n",
      "epoch 24 loss: 0.2157120257616043\n",
      "epoch 25 loss: 0.1965678483247757\n",
      "epoch 26 loss: 0.2217063158750534\n",
      "epoch 27 loss: 0.16915762424468994\n",
      "epoch 28 loss: 0.24198880791664124\n",
      "epoch 29 loss: 0.21060074865818024\n",
      "epoch 30 loss: 0.20958314836025238\n",
      "62\n",
      "epoch 1 loss: 0.9244428277015686\n",
      "epoch 2 loss: 0.7022722363471985\n",
      "epoch 3 loss: 0.6385942101478577\n",
      "epoch 4 loss: 0.42663052678108215\n",
      "epoch 5 loss: 0.2645707130432129\n",
      "epoch 6 loss: 0.2285134643316269\n",
      "epoch 7 loss: 0.230301633477211\n",
      "epoch 8 loss: 0.20149178802967072\n",
      "epoch 9 loss: 0.2153197079896927\n",
      "epoch 10 loss: 0.2589012086391449\n",
      "epoch 11 loss: 0.22108370065689087\n",
      "epoch 12 loss: 0.23708584904670715\n",
      "epoch 13 loss: 0.16242669522762299\n",
      "epoch 14 loss: 0.2325850874185562\n",
      "epoch 15 loss: 0.2249229997396469\n",
      "epoch 16 loss: 0.15343959629535675\n",
      "epoch 17 loss: 0.17672766745090485\n",
      "epoch 18 loss: 0.18557918071746826\n",
      "epoch 19 loss: 0.22091874480247498\n",
      "epoch 20 loss: 0.24031342566013336\n",
      "epoch 21 loss: 0.20639833807945251\n",
      "epoch 22 loss: 0.18684321641921997\n",
      "epoch 23 loss: 0.21283747255802155\n",
      "epoch 24 loss: 0.2181844711303711\n",
      "epoch 25 loss: 0.2084541916847229\n",
      "epoch 26 loss: 0.17810694873332977\n",
      "epoch 27 loss: 0.1977468729019165\n",
      "epoch 28 loss: 0.20270608365535736\n",
      "epoch 29 loss: 0.16562291979789734\n",
      "epoch 30 loss: 0.2343279868364334\n",
      "63\n",
      "epoch 1 loss: 0.8443686962127686\n",
      "epoch 2 loss: 0.7595522403717041\n",
      "epoch 3 loss: 0.47267651557922363\n",
      "epoch 4 loss: 0.3857383131980896\n",
      "epoch 5 loss: 0.26612618565559387\n",
      "epoch 6 loss: 0.2513047754764557\n",
      "epoch 7 loss: 0.21410556137561798\n",
      "epoch 8 loss: 0.22178488969802856\n",
      "epoch 9 loss: 0.19273586571216583\n",
      "epoch 10 loss: 0.1792944222688675\n",
      "epoch 11 loss: 0.2552536725997925\n",
      "epoch 12 loss: 0.24081020057201385\n",
      "epoch 13 loss: 0.23278403282165527\n",
      "epoch 14 loss: 0.1573876440525055\n",
      "epoch 15 loss: 0.2108696550130844\n",
      "epoch 16 loss: 0.17857709527015686\n",
      "epoch 17 loss: 0.22686733305454254\n",
      "epoch 18 loss: 0.17856812477111816\n",
      "epoch 19 loss: 0.1817711442708969\n",
      "epoch 20 loss: 0.18594707548618317\n",
      "epoch 21 loss: 0.2041228860616684\n",
      "epoch 22 loss: 0.17986346781253815\n",
      "epoch 23 loss: 0.18859536945819855\n",
      "epoch 24 loss: 0.22275540232658386\n",
      "epoch 25 loss: 0.1644161492586136\n",
      "epoch 26 loss: 0.20578299462795258\n",
      "epoch 27 loss: 0.1606844961643219\n",
      "epoch 28 loss: 0.22220595180988312\n",
      "epoch 29 loss: 0.1668860912322998\n",
      "epoch 30 loss: 0.2487218677997589\n",
      "64\n",
      "epoch 1 loss: 1.1150728464126587\n",
      "epoch 2 loss: 0.6711283326148987\n",
      "epoch 3 loss: 0.5378397107124329\n",
      "epoch 4 loss: 0.2896980345249176\n",
      "epoch 5 loss: 0.33340519666671753\n",
      "epoch 6 loss: 0.23039451241493225\n",
      "epoch 7 loss: 0.24086153507232666\n",
      "epoch 8 loss: 0.23532909154891968\n",
      "epoch 9 loss: 0.17069189250469208\n",
      "epoch 10 loss: 0.18328724801540375\n",
      "epoch 11 loss: 0.20334923267364502\n",
      "epoch 12 loss: 0.17752783000469208\n",
      "epoch 13 loss: 0.20573577284812927\n",
      "epoch 14 loss: 0.1933300644159317\n",
      "epoch 15 loss: 0.1967676877975464\n",
      "epoch 16 loss: 0.22309713065624237\n",
      "epoch 17 loss: 0.21829868853092194\n",
      "epoch 18 loss: 0.16468121111392975\n",
      "epoch 19 loss: 0.18870867788791656\n",
      "epoch 20 loss: 0.1660633385181427\n",
      "epoch 21 loss: 0.1930813193321228\n",
      "epoch 22 loss: 0.2039637416601181\n",
      "epoch 23 loss: 0.15703609585762024\n",
      "epoch 24 loss: 0.18460732698440552\n",
      "epoch 25 loss: 0.18174678087234497\n",
      "epoch 26 loss: 0.19710297882556915\n",
      "epoch 27 loss: 0.22086068987846375\n",
      "epoch 28 loss: 0.1686834692955017\n",
      "epoch 29 loss: 0.181207537651062\n",
      "epoch 30 loss: 0.2098333239555359\n",
      "65\n",
      "epoch 1 loss: 0.94822096824646\n",
      "epoch 2 loss: 0.7833007574081421\n",
      "epoch 3 loss: 0.4440141022205353\n",
      "epoch 4 loss: 0.2465941309928894\n",
      "epoch 5 loss: 0.23345451056957245\n",
      "epoch 6 loss: 0.19524313509464264\n",
      "epoch 7 loss: 0.24996308982372284\n",
      "epoch 8 loss: 0.17025820910930634\n",
      "epoch 9 loss: 0.20795892179012299\n",
      "epoch 10 loss: 0.21875329315662384\n",
      "epoch 11 loss: 0.20900209248065948\n",
      "epoch 12 loss: 0.22411774098873138\n",
      "epoch 13 loss: 0.20413093268871307\n",
      "epoch 14 loss: 0.1873210221529007\n",
      "epoch 15 loss: 0.2211640626192093\n",
      "epoch 16 loss: 0.18427343666553497\n",
      "epoch 17 loss: 0.21047323942184448\n",
      "epoch 18 loss: 0.2479470819234848\n",
      "epoch 19 loss: 0.18202731013298035\n",
      "epoch 20 loss: 0.16206368803977966\n",
      "epoch 21 loss: 0.18195421993732452\n",
      "epoch 22 loss: 0.17018933594226837\n",
      "epoch 23 loss: 0.19223053753376007\n",
      "epoch 24 loss: 0.20005159080028534\n",
      "epoch 25 loss: 0.1622454822063446\n",
      "epoch 26 loss: 0.19903795421123505\n",
      "epoch 27 loss: 0.19861698150634766\n",
      "epoch 28 loss: 0.1846080720424652\n",
      "epoch 29 loss: 0.23824746906757355\n",
      "epoch 30 loss: 0.18468940258026123\n",
      "66\n",
      "epoch 1 loss: 0.9081348180770874\n",
      "epoch 2 loss: 0.6053347587585449\n",
      "epoch 3 loss: 0.40173250436782837\n",
      "epoch 4 loss: 0.33195242285728455\n",
      "epoch 5 loss: 0.273032546043396\n",
      "epoch 6 loss: 0.27456119656562805\n",
      "epoch 7 loss: 0.17438086867332458\n",
      "epoch 8 loss: 0.19595463573932648\n",
      "epoch 9 loss: 0.20547440648078918\n",
      "epoch 10 loss: 0.21223951876163483\n",
      "epoch 11 loss: 0.206955224275589\n",
      "epoch 12 loss: 0.17243677377700806\n",
      "epoch 13 loss: 0.1995031088590622\n",
      "epoch 14 loss: 0.25458788871765137\n",
      "epoch 15 loss: 0.20046867430210114\n",
      "epoch 16 loss: 0.18262320756912231\n",
      "epoch 17 loss: 0.17075328528881073\n",
      "epoch 18 loss: 0.2238415628671646\n",
      "epoch 19 loss: 0.18308262526988983\n",
      "epoch 20 loss: 0.23918889462947845\n",
      "epoch 21 loss: 0.19903697073459625\n",
      "epoch 22 loss: 0.2163056582212448\n",
      "epoch 23 loss: 0.16281194984912872\n",
      "epoch 24 loss: 0.18668904900550842\n",
      "epoch 25 loss: 0.16014449298381805\n",
      "epoch 26 loss: 0.19578266143798828\n",
      "epoch 27 loss: 0.1912774294614792\n",
      "epoch 28 loss: 0.17268973588943481\n",
      "epoch 29 loss: 0.18793372809886932\n",
      "epoch 30 loss: 0.18220923840999603\n",
      "67\n",
      "epoch 1 loss: 1.1063920259475708\n",
      "epoch 2 loss: 0.6002790331840515\n",
      "epoch 3 loss: 0.49461811780929565\n",
      "epoch 4 loss: 0.357815146446228\n",
      "epoch 5 loss: 0.2392309606075287\n",
      "epoch 6 loss: 0.21821632981300354\n",
      "epoch 7 loss: 0.20946632325649261\n",
      "epoch 8 loss: 0.20390398800373077\n",
      "epoch 9 loss: 0.1965104341506958\n",
      "epoch 10 loss: 0.2377648800611496\n",
      "epoch 11 loss: 0.20974618196487427\n",
      "epoch 12 loss: 0.20977461338043213\n",
      "epoch 13 loss: 0.23672358691692352\n",
      "epoch 14 loss: 0.22394579648971558\n",
      "epoch 15 loss: 0.17415113747119904\n",
      "epoch 16 loss: 0.1928788125514984\n",
      "epoch 17 loss: 0.236644446849823\n",
      "epoch 18 loss: 0.18842452764511108\n",
      "epoch 19 loss: 0.18596334755420685\n",
      "epoch 20 loss: 0.22470363974571228\n",
      "epoch 21 loss: 0.20091582834720612\n",
      "epoch 22 loss: 0.1831132471561432\n",
      "epoch 23 loss: 0.16823260486125946\n",
      "epoch 24 loss: 0.20173606276512146\n",
      "epoch 25 loss: 0.1798262894153595\n",
      "epoch 26 loss: 0.17879027128219604\n",
      "epoch 27 loss: 0.20926643908023834\n",
      "epoch 28 loss: 0.21959300339221954\n",
      "epoch 29 loss: 0.22138479351997375\n",
      "epoch 30 loss: 0.21349266171455383\n",
      "68\n",
      "epoch 1 loss: 0.9398539662361145\n",
      "epoch 2 loss: 0.7239345908164978\n",
      "epoch 3 loss: 0.45083490014076233\n",
      "epoch 4 loss: 0.3419972360134125\n",
      "epoch 5 loss: 0.2031506896018982\n",
      "epoch 6 loss: 0.2327820360660553\n",
      "epoch 7 loss: 0.23904600739479065\n",
      "epoch 8 loss: 0.2004472017288208\n",
      "epoch 9 loss: 0.20825982093811035\n",
      "epoch 10 loss: 0.2143198847770691\n",
      "epoch 11 loss: 0.23640720546245575\n",
      "epoch 12 loss: 0.18007251620292664\n",
      "epoch 13 loss: 0.196127787232399\n",
      "epoch 14 loss: 0.18387500941753387\n",
      "epoch 15 loss: 0.1651519238948822\n",
      "epoch 16 loss: 0.21410849690437317\n",
      "epoch 17 loss: 0.18292251229286194\n",
      "epoch 18 loss: 0.212478369474411\n",
      "epoch 19 loss: 0.23535096645355225\n",
      "epoch 20 loss: 0.23929674923419952\n",
      "epoch 21 loss: 0.232010155916214\n",
      "epoch 22 loss: 0.1447388082742691\n",
      "epoch 23 loss: 0.24570125341415405\n",
      "epoch 24 loss: 0.20055189728736877\n",
      "epoch 25 loss: 0.20177893340587616\n",
      "epoch 26 loss: 0.16336622834205627\n",
      "epoch 27 loss: 0.2020040899515152\n",
      "epoch 28 loss: 0.18802852928638458\n",
      "epoch 29 loss: 0.2087479829788208\n",
      "epoch 30 loss: 0.22185350954532623\n",
      "69\n",
      "epoch 1 loss: 0.8885178565979004\n",
      "epoch 2 loss: 0.6253753304481506\n",
      "epoch 3 loss: 0.3525051474571228\n",
      "epoch 4 loss: 0.28715780377388\n",
      "epoch 5 loss: 0.2141162008047104\n",
      "epoch 6 loss: 0.2709336578845978\n",
      "epoch 7 loss: 0.20837779343128204\n",
      "epoch 8 loss: 0.21677885949611664\n",
      "epoch 9 loss: 0.23358972370624542\n",
      "epoch 10 loss: 0.21732594072818756\n",
      "epoch 11 loss: 0.20713715255260468\n",
      "epoch 12 loss: 0.20102344453334808\n",
      "epoch 13 loss: 0.21620748937129974\n",
      "epoch 14 loss: 0.2647269368171692\n",
      "epoch 15 loss: 0.2075892686843872\n",
      "epoch 16 loss: 0.21325479447841644\n",
      "epoch 17 loss: 0.1815822571516037\n",
      "epoch 18 loss: 0.17811626195907593\n",
      "epoch 19 loss: 0.20704902708530426\n",
      "epoch 20 loss: 0.18721075356006622\n",
      "epoch 21 loss: 0.2048705667257309\n",
      "epoch 22 loss: 0.20991143584251404\n",
      "epoch 23 loss: 0.19721272587776184\n",
      "epoch 24 loss: 0.18823359906673431\n",
      "epoch 25 loss: 0.1826772689819336\n",
      "epoch 26 loss: 0.22855165600776672\n",
      "epoch 27 loss: 0.22579425573349\n",
      "epoch 28 loss: 0.19490748643875122\n",
      "epoch 29 loss: 0.22015884518623352\n",
      "epoch 30 loss: 0.1862764060497284\n",
      "70\n",
      "epoch 1 loss: 1.0442067384719849\n",
      "epoch 2 loss: 0.7737119793891907\n",
      "epoch 3 loss: 0.6549566388130188\n",
      "epoch 4 loss: 0.3694271445274353\n",
      "epoch 5 loss: 0.25487756729125977\n",
      "epoch 6 loss: 0.21119874715805054\n",
      "epoch 7 loss: 0.22524918615818024\n",
      "epoch 8 loss: 0.21771465241909027\n",
      "epoch 9 loss: 0.21682710945606232\n",
      "epoch 10 loss: 0.20639419555664062\n",
      "epoch 11 loss: 0.18871906399726868\n",
      "epoch 12 loss: 0.1884491890668869\n",
      "epoch 13 loss: 0.20601333677768707\n",
      "epoch 14 loss: 0.19908402860164642\n",
      "epoch 15 loss: 0.15007491409778595\n",
      "epoch 16 loss: 0.22861219942569733\n",
      "epoch 17 loss: 0.16875168681144714\n",
      "epoch 18 loss: 0.13248476386070251\n",
      "epoch 19 loss: 0.21708530187606812\n",
      "epoch 20 loss: 0.22154663503170013\n",
      "epoch 21 loss: 0.19458670914173126\n",
      "epoch 22 loss: 0.18415330350399017\n",
      "epoch 23 loss: 0.21050721406936646\n",
      "epoch 24 loss: 0.21914047002792358\n",
      "epoch 25 loss: 0.20250649750232697\n",
      "epoch 26 loss: 0.2460305541753769\n",
      "epoch 27 loss: 0.20303063094615936\n",
      "epoch 28 loss: 0.19755779206752777\n",
      "epoch 29 loss: 0.20022156834602356\n",
      "epoch 30 loss: 0.15322557091712952\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T21:51:17.619472Z",
     "start_time": "2025-10-05T21:51:17.327748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k = 24*3\n",
    "x_ax = np.arange(len(results_arma_asy_con['y'][:k]))\n",
    "\n",
    "plt.plot(x_ax, results_arma_asy_con['y_hat'][:k], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "plt.plot(x_ax, results_arma_asy_con['y'][:k], marker=\"o\", linestyle=\"-\", color=\"r\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"y_Tplus1\")\n",
    "plt.title(\"Line plot of y_Tplus1\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a0e378d1a273b1af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHHCAYAAACiOWx7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAnNRJREFUeJztnQecE3X6/z9JtvdC2cLSRHpTLIBUpQiKFLFgP3sHsf3VO9t5Pw8UBNtZznqKBQQ9OQRRQEDEilIFQWBhCwu77AK7bMvO//V8J5NNskk2yU6Smcnzfr1CkplhMt9k9jufeapJkiQJDMMwDMMwjFfM3lczDMMwDMMwBIsmhmEYhmEYH2DRxDAMwzAM4wMsmhiGYRiGYXyARRPDMAzDMIwPsGhiGIZhGIbxARZNDMMwDMMwPsCiiWEYhmEYxgdYNDEMwzAMw/gAiyaGiWD27dsHk8mEt99+G1qGjvHxxx+Hlvjxxx8xePBgJCYmiuP79ddfoTfWrFkjjp2eGYZpHhZNDGNQSAjRBfGnn35CpLJ9+3YhtkgcqkldXR0uueQSlJWV4bnnnsN//vMfdOjQAcHiuuuuE79lcw/aTkucOHECjz32GM4//3xkZGToQqAzjDeivK5lGMbQ0IX+5MmTiI6OhlFF0xNPPIERI0agY8eOqu13z5492L9/P15//XXceOONCDa33HILRo0aZX+/d+9ePProo7j55psxdOhQ+/JTTjkFWuLIkSN48skn0b59e/Tr148tWozuYdHEMBEM3fnHxcWF+zB0R0lJiXhOS0sLyecNGjRIPBTIekiiiZZdddVV0CrZ2dkoKipCVlaWOOYzzzwz3IfEMC2C3XMME8G4i2kiF09SUhIKCgowadIk8bp169a47777YLVanf5/Q0MD5s2bh169egnx1bZtW2EVOXr0aLOfrXzOn3/+ibFjx4rYoJycHGGZkCSp2f+/adMmjBs3DikpKWI/5513HjZu3GhfT2MiFxoxcuRIuwurOWvHqlWrhPWGjodE0cSJE7Fjxw6n4x4+fLh4TfunfZIlyx00NlpPLjxXNmzYINZ98MEHUBuyql144YX48ssv0b9/f/Hb9OzZE4sXL/bp/7pz89EYXcf5wgsviN8+ISEB6enpOOOMM7BgwQL7+tjYWCGYGMYosGhiGKYJJI5IyGRmZuLZZ58VImHOnDl47bXXnLYjgXT//ffjnHPOwfz58/GXv/wF77//vvi/FPfjy+dQvAuJrdmzZ2PAgAEiBoYe3ti2bZsQNr/99hseeOAB/O1vfxMuK7qof//992KbYcOG4e677xavH374YRF3RI8ePXp43O9XX30ljp0sSRQLNXPmTCFuaHxKXBSNmfZH0P5pn4888ojb/XXu3Fn8X/pOXKFlycnJQpQFgz/++AOXXXaZEJZPP/00oqKihMhbuXKlKvsn1ySNn8QYCWdyg5JAU75/hjEkEsMwhuStt94ic430448/etxm7969YhvaVuHaa68Vy5588kmnbU877TRpwIAB9vfr1q0T273//vtO2y1fvtztcleUz7nrrrvsyxoaGqQLLrhAiomJkQ4fPmxfTts99thj9veTJk0S2+zZs8e+rLCwUEpOTpaGDRtmX7Zw4ULxf1evXi35Qv/+/aU2bdpIpaWl9mW//fabZDabpWuuuca+jPZH+6X9N8err74qtt2xY4d9WW1trdSqVSvxHQQC/aauv5sjHTp0EOs/+eQT+7KKigopOztb/I6u43D8fuj/ujuu4cOHi4fCxIkTpV69eql2zAyjB9jSxDCMW2699Van92TZIXeTwsKFC5GamorRo0eLgF/lQdYicpetXr3ap8+588477a/JXUXva2trhdXHk3WK3E7kOiRLjmP8zBVXXIH169fj2LFjfo+XYm+obAC5pijTS6Fv375ijMuWLUMgXHrppcI95mhtWrFihfiughmPRK7OyZMn29+TG/Oaa64Rbs3i4uIW759clwcPHhSlFxgmUmDRxDBME+giT3FMjlDMimOsErl/Kioq0KZNG7Gt44NSzZVgaW+YzWYn4UN07dpVPHsqE3D48GFUVVWhW7duTdaR643irA4cOAB/oWw4wtN+SeRUVlYGJC4mTJjgFOtDAio3NxfnnnsugkWXLl2ECPXnu/WHBx98UIjjs846C6eeeiruuOMOfPvtty3eL8NoGc6eYximCRaLpdltSJyQYHIXr0O4iq5Ihiw8ZJmj+Kg+ffrgv//9L26//XYhGrWGq9BytPA5nhckJHfu3ImlS5di+fLl+OSTT/Dyyy+LrD6Kb2IYI8KiiWGYgKCaQORCo0Dn+Pj4gPZBwotcfooFhNi1a5d49lRXicQYZWvRBduV33//XQiRvLw8rwLAHUpxSk/7bdWqlcioCwQKdqfjJoF59tlnC0vZ1VdfjWCye/dukYXo+B00990qFsXy8nK3ljhXqyB9HxRsTg9yqU6ZMgX/+Mc/8NBDD3EpC8aQaO82h2EYXUCxOmR9+Pvf/95kXX19vdsLrztefPFF+2u6yNN7KrZJJQTcQdaOMWPG4LPPPnNyMx06dEi4wIYMGSLidwhF5PhyLBQTRdlf77zzjtP2W7duFTFU48ePR6BQ5tq0adPw8ccfi1IIZG2iWKlgUlhYiCVLltjfU5zXu+++K8borQwAiWEq3UAiSIGsSa4uz9LSUqf3MTExIpOOfkNfMicZRo+wpYlhDM6bb74p3CeuTJ8+vUX7pTIElH5P6ewUQE1ChsQOxTqRK4pKEEydOtXrPsgaQcd27bXXCgvMF198gf/9738ipd+be++pp54SqfMkkMjNRaLk1VdfRU1NjShdoEACgUTWrFmzRPwV1Q2iOCJyK7rjmWeeESn6VDTyhhtuENXSqRYRBby3tPcdueief/55ESBPxxNsyHpHY6BAbSrpQOcBCcu33nrL6/+jCueLFi0S1jESxlT9/L333mtSbZx+bxJfZGmk/VMtKxK8F1xwgSiloEDLSISSiCM+//xzEUBO3HXXXeK7ZRjdEO70PYZhgltywNPjwIEDHksOJCYmNtkfpfy7mzJee+01UYogPj5epPz36dNHeuCBB0QJAG8on0NlA8aMGSMlJCRIbdu2FZ9jtVqdtnUtOUD88ssv0tixY6WkpCTxf0eOHClt2LChyee8/vrrUufOnSWLxeJT+YGvvvpKOuecc8R4UlJSpAkTJkjbt2932safkgOOUIo+lS84ePCg1BJ8KTlApRtWrFgh9e3bV4qNjZW6d+/e5HjdlRwg5syZI+Xm5or/R9/FTz/91KTkAJVSoPIOmZmZYrtTTjlFuv/++0VpA9dj8XQO0vnHMHrCRP+EW7gxDBN5UGo/WTQo0y5SOO2000Q5g6+//jqon0MxS7179xZuNYZh1INjmhiGYUIA9V4jNya56RiG0Scc08QwDBNEKJD8559/Fm1oKNicMs0coWB6qj3lDaqHRA+GYcILW5oYhmGCCLkgqScfZZRRc17XVHzKSiMx5e1B/f8Yhgk/HNPEMAwTRqqrq0XrF29QfSTXGkkMw4QeFk0MwzAMwzA+wO45hmEYhmEYH+BAcJWgdhBUvI2KuvnTuoFhGIZhmPBBDrfjx48jJyen2X6QLJpUggST0u+KYRiGYRh9QUkZ7dq187oNiyaVUNoG0Jeu9L1SC8q6od5XSpuKSCKSxx7p44/ksRM8/sgdfySPPRzjp76MZPRwbP/jCRZNKqG45EgwBUM0UVd32m+k/QFF8tgjffyRPHaCxx+544/ksYdz/L6E1nAgOMMwDMMwjA+waGIYhmEYhvEBFk0MwzAMwzA+wKKJYRiGYRjGB1g0MQzDMAzD+ACLJoZhGIZhGB9g0cQwDMMwDOMDLJoYhmEYhmF8gEUTwzAMwzCMD3BFcIbRG1YrsG4dUFQEZGcDQ4cCFku4j4phGMbwsGhiGD2xeDEwfTpw8GDjMmowOX8+MGVKOI+MYRjG8LB7jmH0JJimTnUWTERBgbyc1jMMwzBBg0UTw+jFJUcWJklquk5ZNmOGvB3DMAwTFNg9xzBaxWqF6ZtvkLt2Lcy7dze1MLkKpwMH5FinESNCeZQMwzARA4smhtFw7FLUwYM4w5//R8HhDMMwTFBg0cQwWo1dcueKaw7KpmMYhtEyVv1mALNoYhi9xC55w2SSs+ho8mEYhtEqi/WdAcyB4AyjJejuy1vskifBRMybp5u7NYZhIpDF+s8AZtHEMFoikJgkuktbtEgXd2kMw0QoVmNkALNoYhgt4WtM0uOPN77etYsFE8Mw+raiSw4ZwBqGRRPD0J3NmjXABx/Iz+G806GYJLIcKS43V2h5Xh7w8MNAdLS8rKQkpIfIMAwTNCu6xjOAWTQxkQ350Dt2BEaOBK64Qn6m97Q8HGKKYpIoILK52CUSTLm58nu6O2MYhjGCFT1b2xnALJqYyMVbUOLFFwNt27oXU8GGXG0UoxQT4z12id4T/gaOMwzDaNWKPlTbGcAsmpjIxJegxNLS8GV4TJ4MJCWJl9uvvBL1K1cCe/c6xy7RBEOwpYlhGK1j8dGKrvEMYBZNTGQSSGp/KDM8KE6prAySyYQ/L7oI0vDhTScTFk0Mw+iJKVOAhQsBs1m3GcBc3JKJTAINNgxVj7ft2+Xnzp1hjY11v40imtg9xzCMXujXD2hokK1LNJ/S844dQGIi9ACLJiYyS/cfOtSyfQU7w2PbNvEk9ejheRslpoktTYza6LjNBaNx1q6Vn885B9iyBaiokEMPeveGHmDRxERu6f6WEOwMD19EE7vnmGCg8zYXjMb55hv5mUIO6uqA778Hfv9dN6KJY5qYyM2SC4RQZXgooqlnz+ZFE1nNamuDezxMZGCANheMTixNw4YB3bvLr0k06QQWTYyx8aUBrqvbITNTfnaXGkv7CXaGB32GL6KpVSu5LAFtX1gYvONhIgODtLlgNEx+PrBvnzx/Dh7cKJp27oReYNHEGBtfsuToIvDcc8CCBcDq1bLl5pNPGotHupKejlBkzgnRpkwq7qAMFI5rYtTCIG0uGB1YmQYMkEuqsKWJYTSGrwHbVMhy2jQ5I47ugih2g+6ISEQpYuq22+Rt77knuHfbNisTZc4hPt77thzXxKiFQdpcMDqJZyIcRZM3b4CG4EBwxti0pHQ/iSfHsgIUqEgC6rffgDfeALp2DU52kVJuoFev5rflquCMWhikzQWjk3gm4pRTgKgo4MQJOcTAk3VfQ7BoYoydKk0PcmNRXRB3kAuMhIcvgd0UQ/TYY8DMmbLVyXGfamYXKZYmX0QTW5oYtdtcUNC3u7t+f/5WGMYVmpN37ZLPoyFD5GXUQ5OEE8U0kbWJRRPDhDlVmu5iFHGjFFNrSel+5Y/aVYQp2UUffQS0bt0yC5QimrwFgSuwaGLUbnNBfRd13OaC0Sjr1jUWt0xLa1xOLjpFNJ13HrQOxzQxxk6Vrq+Xn8ky5HoX42/pfrJi3Xuv+3UkxuhBcVEtafLrkDnnl6WJ3XOMGtDfQpcuTZfrqM0FoxPXnILOgsHZ0sQYv6wA3SUvXQrs2QNs2BC4FcjXTDx3FihfLzhK5hy5FD1kzjl6IE890Q5n0EK2NDFqQOfR7t3y6yuvBN5/X67cTAG8bGFi1AwCV+jWTX5m0cQwGkuVJsHUkn5xgWQNKb2VqL7NxInNX3hcM+eoYq4XD2Qm8nBEEVs1NYCnPnUM4wtLlsjPdENx7bWyaDp8mAUT0zJKS4GtW+XXrjFxOrM0sXuO0T+hSpUONGvIn/o2XuKZ3HkgS5GJk4gTr5e/URDY8TGMAtUnIyiuSTkHyUJLgpxhAkWZ++icophPd5YmmtiOH4fWYdHE6J9QpUor2UXuKoWrJdo8xDN59kCacBBy2YE3Hj/AxZqZwKGirsrFbfJkICcHSE6WT74//gj30TFGjGciMjKANm3ES5Fdp3FYNDG6hObxNWuADz4A1liHQlLqFQWzX5ySXaTs0198EW0eajStX2/y6IE8ADkYPPbwAS7WzATOZ5/JqvzMM4H27eVzXGkYvWNHuI+OMUI80zA3oklnLjoWTYzuIDcVJaXZk9RGWXBL1XNwGwaudqo0BXNTULdrJp63ffsq2rxkznkzUimiqR0OcrFmpuWuOceEBcVFx6KJCfTudulSYNMm+T0lFbje9K4BGrrpRzRxIDijK5S4Hlc31YmyOpA8kmCCyVE+kQWKBJOaqdK0LwrqdiyieeQIcOml8nrXg/O1yS+5R5TMOcXP74ORSnHP5eEAF2tmAuPoUWDVKvm1Y50mxdKkWEAZpiV18845BxunzcclH0xxWvx4anc8Ri9YNDFM4NDdyDffmLB2bS4SE03CsusuricW1fg/PCReP5vyBGYuHgpLSRDam3hrsUKQBcp1klAqiY8d2/w+lQuTm55zQ4ZIQv+5c9EplqaucQe4WDMTGJ9/Ltc069MHOPXUxuXsnmNUvLuVDhbgrGem4kwswkE03sh+XyFbmip++B2p0DbsnmM07YIbPToKc+eeIZ7JI+ZONEzHfHTEfhxAOzx27F6ss4xwbr4bKlyb/H7xhRwbQlaoJ55wtke7i9j2UtSShjF+vPuPVUTTmdkHODOcUc815yiaqGIzZxkwLaybp3gB5mEGzGg8n3ZAFk1x+btgrdX2ecaiidFNcW/SHgr0Bzcca3ATXsXf8KRY9jD+DyeREN64HsUCRaLt/POBF16Qlz/zTPOVwr2IJqqR+eGH8mvHDgSO7rm041wVnAkASvNesUJ+7dpCpVMnufYXlRygGwKGaWHdPDMktMcBDEVj1ko+2ovSKbGoxY8LtX2esWhidFXcm5iMxdiHjliDkXgNtyIJVahFNKogu7Q0FdejtHFxRakU7iicXGo0Obonr7rKgmPHgLPPlkOfFGMWfVeKpUmoypMngz4kxiAo0biPPCKLImqf0rt305sAJb6O45oYX/DxrjUbjds1wIJd6Cpe1/ym7bgmFk2Mrop7k2BahKnIhfNGUajDQlyKGzMXi2uBNy9YyBWgOxRVSJXCaTuXzDlX9+S338p/qhRrHhPTaMwir19NfDoqkSD/X+5Bx/ibgqpYQ0mNKxXBHeG4JsYfsn27ay2C83a/21x0uSdYNDGMVxzTT7/+2vN25JKbDxIhUpMTV3n/aNkMjBllDbhfbljau9B2dMGiDCazGZ/u6ObWPUncd5/zeFJTgcunmRqtTSyamED93+Smc7V+EiyamACKAEsin7kpDTAhH3lYB+eslZ020dS5lkUTw/hcc+mppzxvSz7wPBz0eNKSrzxPcvaVu/OCabK9i83KJHXujLseiPfqnlSMUwq33NIY13RiBzfuZVro/3Y9wbhWU3BwLVZklEB7i0WUFaAzTHIjmIgZmCdccu4sTeadLJo8snbtWkyYMAE5OTkwmUz49NNPm2yzY8cOXHTRRUhNTUViYiLOPPNM5Ofn29dXV1fjjjvuQGZmJpKSknDxxRfjEN21O0DbX3DBBUhISECbNm1w//33o94l1mTNmjU4/fTTERsbiy5duuDtt98O4sgZbze8vvjAfd3O1Qum2fYutniR0ra9fDZOKVAB58p02dK0+X8smhiVrJ/uajV5E1tMCyr0htssrp72q62FqMM0FYtQbeuLqUA3d7T8v5amdfPOvV0fBS7DKpoqKyvRr18/vPTSS27X79mzB0OGDEH37t2FqNm8eTP+9re/IS6u8Ye455578Pnnn2PhwoX45ptvUFhYiCkOabNWq1UIptraWmzYsAHvvPOOEESPPvqofZu9e/eKbUaOHIlff/0VM2bMwI033ogVSkYJE5YbXleKXXzgvvrK/emXqyq+9KpTKoXbLE2HWjXNnGvOiEW7zx0oi6b8DQdFkLjRbl6ZMDa3prpNVHCV3HeFhUE7NET63aJiFl+4EKZvvkHu2rXiWct/xIvdaD+lNMwSTMEedBbb/R/+H0ZgNTphr1hOQ3ruOTmZ5YIL5H2tLujamNDimCqtNSSNQIeyZMkSp2WXXXaZdNVVV3n8P+Xl5VJ0dLS0cOFC+7IdO3aIfX333Xfi/bJlyySz2SwVFxfbt/nXv/4lpaSkSDU1NeL9Aw88IPXq1avJZ48dO9bn46+oqBCfS89qU1tbK3366afi2SisXk2/uX+PDu3qpcrMdh43sMIk7UeeZEa9200WLAjDQD/5RJJMJvnh7qDo/K6vl6TevcX7vVc94vH4HR/0/TlSOe9VseJzXOC0Xbt28iHoESOe92Efv69/eK4n2KmnystXrpRChSF/f/pbpz9Kb9+9xSLp4Y/4E9vU5nkoDdIxJIk3XfG7x/l461b5vdksSXU57cWbujVrQvrb+3P91mxF8IaGBvzvf//DAw88gLFjx2LTpk3o1KkTHnroIUyaNEls8/PPP6Ourg6jRo2y/z+ySrVv3x7fffcdBg4cKJ779OmDtm3b2reh/d12223Ytm0bTjvtNLGN4z6Ubcji5ImamhrxUDhG+eCAOB56qImyP7X3G04OHCDrS/On34MP1qKubjNGj+6NESMsiPrvHEiXXdYkxNCbr1yhdet61NWF2L0wYQJMH34Iy8yZMNGdpA0pLQ2m8nLgvfcg/e9/MFEQOICO7/0D+aZ3cJc0X9yRuWIySeJObuBAGkvj8p+KczDM1krFkYICSdy8fvihFZMn68u1YsTzPuzjHzgQUXQCFRZCXO9ckITZMhc1Zw7E+q/q7V2CRnbrDssff8C6dSsahg9HKDDi70+Wo6jm4hFcLEuSzQJl/fBDSJMnQwtYrcDdd0fZPAXuLelpKEcyTojX9kQVN/Nx167AqFEWfPWVGbujuqE78mElV3BOTsh+e38+R7OiqaSkBCdOnMA///lPPPXUU5g1axaWL18uXG+rV6/G8OHDUVxcjJiYGKS5VPsjgUTrCHp2FEzKemWdt21ICJ08eRLxLi0tiKeffhpPUL63C19++aWInQoGK1euhFHYvz+TmoM0u11S0g/o06cUNTUFcv29qCiMS0xETGWl03aF5lzc3TDPrdCgcMTMzGocPfolZs3KxNGjcUhPr0bPnqWhqaBNxQGffx6Z27cj7uhRVKeno7RnT5z19NPI/uknOWvOgWypQJRVmIqFWALHYoOSmKSuvPJHrFhR5DSBzf1XLtbbmvY6IklyR7477qhFVNRKXVYMN9J5r4XxZ191Fc6cNUsE6Tpe7sT1T5Lw3hl34p4OEkpLGy8Pz8V1wwx8jvwVK7CZCl6GECP9/uRyO8PP/0Piln6b2jvuwMqoqNB2OfDAli2ZKCjwPn+3hxx7fBitRNHhRiS0anUSx46txLJl8pKBA9vgq68GYVUhiaaVyP/yS+C660L221dVVelfNJGliZg4caKIWyL69+8v4pJeeeUVIZrCCVm8Zs6caX9PAisvLw9jxoxBSkqK6iqYTp7Ro0cjOjoaRoBasb3yiiTc+O7uVBSLyvTpp2PVqsaxizu1ykphqbGSQ5x839nZ+O7IUHx6RYwo0y8LBQX50pCUFIt77rkIBQWN63JzJcydG0ILzIQJja+tVkTdfXeTC5eSBUiWsxcs9+Az6yS75YzCo+bMoeM9DQA9ZKgA5tYK+Y4uE2WIR5XLJGXCkSMJSEm5AMOH68faZMTzXhPjHz8e1tNPh+Wuu+jutHF5u3bYcOlcXPvc1Caxhpuq5aKXiflVGO+pn4/KGPH3NyUmAnPn+v//ACQcOYILUlIghenaRzdn69ebhPWxqspLnKaLaNqPDk7zOvHSSzGYMKHxPKLmCR9/LGHLLjlTs3NNDSg1JlS/veIp0rVoatWqFaKiotBTSXe10aNHD6xfT/fUQFZWlgjwLi8vd7I2UfYcrVO2+eGHH5z2oWTXOW7jmnFH70n8uLMyEZRlRw9X6AcO1o8czH2HGhoG/aG88UbTdXLctAnz5wNxcdHOY7f1yDJNmYKocePs/+cSynSNadovt00bE8rKyLLVNOehsNCEyy+PEn12XVtuBZ1vv5UDPz1AwinXegA/PLsGCwpTMW5cf4wcGQWLpemf7OHDQAVScRxJwhxOLrpd6OZmuyjxvesNI533mhm/UiWV3D0UyfvWW2gYPBSXn2Jxm5yxDXKCgun332E2R4fU2GGo358ipamBd4CBzlH0xx6G74ICvt31IvdGB+y3t0hRaNfOhHnzaL5tOo9RNMzHtgy62h9+w3HTVuzYnYT+d42AJSa4J5w/55dm6zSR243KC+ykRpEO7Nq1Cx06yMp1wIABYrBfO1REpO2pxMCgQYPEe3resmWLcPcp0N0LCSJFkNE2jvtQtlH2wagP3a0sXOi+lxpZVNwKGSoToTQWveyyZvvl0jNlzbnuXxPlCHzMYurXphDDhhUIC5GnC5Vc2aCxwKVrXJPzdgxjQ8mE69dPlJhft8Hi8aKo1NBp3VCC75aWhvAgDQbdKFVXB/7/w/BH7G9pGOXGt3eybGk66+L29vl4717PN6jXXAN0j/lTvI4vLcRVy/6KAfeNwqGEjtj4gHZKMYTV0kQxS7t373ZK/aeU/4yMDBHMTfWULrvsMgwbNkyUA6CYJiovQOUHCKrddMMNNwg3Gf0fEkJ33XWXEDsUBE6Qu4zE0dVXX43Zs2eL+KW//vWvoraTYim69dZb8eKLL4qg8+uvvx6rVq3Cxx9/LALRGfUgYUJp/6QXXn+dTKLAWWfJyzZskJfTnEAZ+G4FAv3V0Z0W3amde67XfrkKdKp4u6lTyhFQJwkKa/P6+SpibZPtIVzdmYa22cBJ5/gtT5UNDh5sh57Y0SSuiSYwWk/bMYwd5SpIZS+a0fGVSBJVnKnR6slfdgATm49HZFwmvcxM4OGH6cIHdO4s9/tztDbTpOPp7i1Mf8SBlIYx2Tx3F/TNB74F2p3TQbR8ao4tTyzGS7U3NQlZyLIWIOuZqdiIRRg4O9QuATdIYWT16tVK0VCnx7XXXmvf5o033pC6dOkixcXFSf369RNpiI6cPHlSuv3226X09HQpISFBmjx5slRUVOS0zb59+6Rx48ZJ8fHxUqtWraR7771Xqqura3Is/fv3l2JiYqTOnTtLb731ll9j4ZIDzaenusu0feYZP8Z+ww3yf7rlFp8/l9Ja/S1tEIoM39Vf1Uv5aCfKJHgrn7ByebVPvz0d7xu4Xvzfv+JJ+66UagcazFiOiPNe0+Onchd0ksya5VM1guUYI178fu9rUsT+/lQygL4omljomd77O+klJdFFqem+qHSOt/IkixZJeigNk5dnm28GDvT5uOtr6qUCC82HnsvJHLTkie2CgT/Xb83UadI7LJoCq+fR3AXdPvYTJyQpPV3+T6tWBfWPPhRCg+bJyfhETAauwklZRuvffbfO599++6WPif//Km5qOoHpEL2f95of//DhTgVzmish9BxmyOfn9HukiPz93YkgT3dYzRUx8vRH6Ulo0eO113wXbCrh603nX//q5rBycuSVP/zQ7Odses63iVpsF+brt2ZjmpjIbXXlDhPFnFFqPgXvD6OKROoV5Q5HrBO5Aak8ArUUKECu21YDtN6fEIYeY2Q3S5c42e1CFXe9xRAwEQ75pQn6A7F5h7wldu2A3E7FvDMCe9A1V8Xbsf1Jc5MeTUaeJhdbYGb9ypX4aeZM8YzZsxubTIa47Yqv889550G44Cg0QoQ2UC8Vxd9ri0H2RtUe32I8fd0umLBoYjTX6sodZiVqnCYoPwKOaFPKwiP8FU7BbL1CsbdUcoWEUUfsEy0GpmGBvdXAp6YpItRkyBA/gglsF7+OFvli2KaNJkq6MFqESrq4xDQRSktO6priyriZDj3oIglvIsjdHVZLJz2LRZQVKBg2TC4voNTFcv38EHQjV246PWEyNXaCcoLGT8dLccOtWzf7OQmn+KbOfN0umLBoYjTX6sqO1SrqMrVbtQomZWJwkzXXHHTzRtl4VPcpWMfvT1NLime/6abGC5RksuAbjMCHmCae6T1Bqbl+iR7bxa9trSyauE0Y4xHKjiBrgK0COEHXuKeflldTa04lC/UMWzXGFfk20UQN0ymYOVLwVwS1aNJzM3HY6hS6/dwgm8Rp/nnqKffrTLabULfzFJ0jRPv2Pt2t9rl9KAot7eydHVyh5QWWPLFduGHRxGjCvNtkO1snyKjRozHg+edhooqtdPtrq+LuL67lCMh1FdBxqdDUkhL/qHICTTR0kXIVcx5LLvgomhLrKpCE4yyamOZdc+TuttWooWThLVuoCj+1yJBdLeRyeeUVedNXP2mF+nSb1cClFIyh8VUEUQgB3RW51PxryeRiopqEapjqW8CuXfKzaymjdt7mKUU0+eCaI6gOU/5M2SUgl7VuRBFSB2bOC3q9Jl0Xt2SMgWLeJUuyO+u220xaJX7A9T+QS4GK8gVYjdKxHAHdmM2Z4+dxBYCnoSjHQH2XSMwpWcktKnmQnAxQNfpjx0TZgcJCm2WAYZqJZ3K0Mt16K5Ce3rjpgAHAJZfIddV2oDv64DB2PfQmqsYfF3f+WriQBRVf75w8mWRaMrn4KthoIiNTdosnEWeowosS3vDhh0BGho8fsX9/o6XJR6icAJUV6DTnTrRtaBx3kaWdEEyaKDfAliYm2DjGFPlk3lUrctyP43JnPaaPJ2tUS+YdX+NBCeWu3h5IGSi2i+DVeBett60JQ9VORleiyWadVGqlUZFwh+5Qdv7+d+Bi02J0OvqLeN915cvof89IzRUeDAqBZJN4wqtPqwWCjVx4QQgSf+YZgNp8nn66XDx+hK/zlKN7zg9IGLU69qfd2rTspkXIqtqrGcFEsGhigo4SU0QTcrPmXbUix1WIdaqoaIxDWhOA/gjhUGRoktyzR7x8GP/EC1tDk2HD6BDbiXnQlCfO7/vukxf/5S/ur9NH31iMj6WpSIRzoVUqPHgWFR40snDydufny/9tge9dGjLEJ8EmkUnI8X0LgsSV+EtyyyrDfvJJPzVjvn/uOUcsiXEoj5LdwDHdO2nOksmiiQkJNEfYWv3h8ce9lNRXM4jSx+Nybb3yj3/I6268sWU3byEdiuIHpCrDKk2ejHE5sEG2ND33SZ44v3/8UV7et2/Tba21VrSfO13UHnbXXJrImztDbGdYlDssSnn1V4GQydqXPiItSP91XUMVooSF20+rvGP85W23ybkCdLPrd+eX/f675xw5Fi9fLE7s9jE+LISwaGJCAv3dKoHJN9zgxbwbcOR44CixTorZmeKM1MjwDdlQvPgBRXm9sDXYY7QInb/71h+w1wRz5M47m57fW15ehxzrQY8XC6W5NG1naEjsUNwgMWsW8Ne/+vb/qD9TS3zvNsEmuZjEpVbeU/lNJGgPHMCvL6zzyVruqRQVCSeKafP5vkuSAnbPKVSlyaKpdn9giT/BhEUTExKoXzKl2FMCnGJxCih+wGNhEHVQM8M34Bon/hJyPyCjVxR9rTR1Vpo8O+J6fuup8GBQISsuFdhV7vyoomOIbvAWUz03ybme2131vqUAz7qnqFlruaqhpKWlwMmTTWqA+UN9pnyRkIrY0sREKMo1neYPrxZuvyPH1UVN/UGH6Km0gapDCbFLk9EvdN4WHrQiFwVuRZO781tPhQeDilLuhPxVlEYWohs8xQKUX+Bcz21ruW+F54qQ3ay1XNX7rv021xzdHVNxy0DIlkVT1BHtzVksmpiQoPxBerO8OJmj33676fKACxiFT3/U1cnPrvOqqkMJg0uT0Sd03rZBCaJRDyvMThdU1+30WHgwqChfCokB+oP2Fm+k0l2RNwvQOgzFAXj/XfKRJ7Zrzlqu6ryX3zLXHBHTQRZN8eXac89xnSZGe6KJsP1FSx074ucpU9B/3DhEkX05yH1B1NQfJJj+9jf59WOPAdQRQeUyKi0ohsVECvSnpNQBo7qLimuuEDmwergEOJ7fSuHBrGemiguxEvztWngwV2NZTkGzNDl+OUqAOCkbR1MN/b2RYGrhXdH69SaPFqAGWDAd87EITX8X5dUMzBPbubMavfCCHG5Fw6GWS6rNj/mBZ84pJJzSVjynVLFoYiIUv0UTVVKjieH661HQty/6keIIQSM1NfXHW2/JFQCo9RLVvlFiSFVHueMluzsdoMOBU76TKcguTUa7kBvG9Xo+Be6DwL2d30rhQcqio6BwrRYeDCqKmcVVOZAwmjhRpQq1ssj95hsT1q7NRWys9zx/pen3fExHHg46/d3/BW+K9Z5wjN2kmrje8Ou+a3/LMueI9B7yd9zGWkS1eps9vlDC7jkmJLjpDeo9apxaEpBoorSNEOJL0Utv+kOpcfLOO8DDD8vLHnkkiIKpmaJTR+KD79JktImnbChPQeDNeZRIGLWt2odvu18v3n+ffr7mCg+GRTS5S8ENUDApKf+jR0dh7twz8PTTze/Huen3+9iJU4XVqRd8b6xMwkShxZ7G/Ja75+I6ypamLBSLG1gtwaKJCUfXBu9QYzZSH9Qp9JRTEGq8Fb2kCaRLl+ZrnFx3nZxEQpOM12xBNVGKTtm6ot+H2biot591YRj1cezWHEiVVJVjYajFDlFgyvM7zo5cdVFDB4vXDSaz5goPhiymKYQi1xs0H2VmAjntlCDxKzATcvbJnXgRbeBf9hntq8W9MPNb7p5ThGkKjqNot3NB1XDD7jlGe+65jz6Sny+/HOHCncX9xRdlPUe1bL75xvmOzFOPObp40c0nNbsMiXYhlUZCc+9elKAtDhZF0EVNL/4x+iMgc2YQTwhv2VCKpWm/lCeyO5W4Fl89SgmdZCtAcqX24k3CZmlqIb6k/LuizD+vveYyV2WNR+ktZyPzj+/xEP6Je2wiyhfoRu+rr+TzIGBP4/6Wu+eoa/RJczziG06i/PdiYELob549waKJCTrUZ1cxsTYrmmjDtWvl19ScN4w4NvglOncGvvhCnpzee092NYpspDa+1TihiS0kYUW2O+G2OCSOj75/qo/FhBhPSlrJ+1bZbeoY8L3di2cmzyGm6Wxb3UV/SD5VPr8yalk0qUVzKf/ucI01b5yrTMCLTwJjx+JWvIx1OAcxqBOZkpRJ5xoY7i46wt9zwg7VZ6IdtFQ0mUwoi22D3JP7ceIP+t5ZNDERxJEjclVZujNqdr6hVup0kTnnHFmVKDn7GoDmAIpPoge530iM+IJjjRNHERZs0ZSNYnEhpbZUZE1gQog30wEtU7o1q6Sk3Rm0POEY0xTI9T+zl3x+tZZKUHm8AYnJEaLIVRZNvopcR6gIec+ePliARo8GundH3O+/4xM0xoVSiQLKuPMWIN6i4R20nYCJiXItqxZwPCETOLkfNRqrCs6iiQk6yt8RXbhdm/Z6ypoLp2vOG0qIla+CKSy1JW0KqWNcMVAtt69h0dSCK5qvPgrX3H5fqwW2UEl7Mmi5w4J6ZEM+ERty8gKqQpHUWc5Pp1pPB3aUofNZrWB46Lel31StCt9+iFxHqAi5T6fLkiXA7783WUxFTalEAWXcuQonVSqT7HdwzfnV4bcplakZQCkgFWqrwGWE3CIwusico2aW338v+5LoKqDBeVPpBh8IIastabM05UbLk7zWsk80j2NEv6/dml3/j6dePCoraX9jYSgbKQpW1CEKD81rG5CRyxQbg6Nm2YpQtl1bVoCgQeZaulMiIeBrUSOVA759Li6unBRuUGo5zcMMmGFVv0NBfssz5xRq09PEc9QRbZ1jLJqY8GfOKdlFSo4+3UqFLOUsuHEHIWiX1xTbd0cXSEJplMy04IrmrVtzIFdBlZS0v+ek4pqra5WDKZcEfnUsj5PPseMa7EIf1MKWJJi89oEKXsC3z4KmmZOChFN7HMBQrFO/Q0G+CplzNqxtU8VzfLm2LE3snmPCmznnzk69aZO8XGOp8oEYBULQLq8pNl9cZh2LpqDEIV14IbBhg+9ZAJ5QQUn7ek4qsTB9fz8APAkkdAuskapCZWJboGo7qjUWb6L1eCY1Ar7VOile/msRfvMlPipMliZTllzcLrW6WIS2UgayFmDRxIRPNHkKxigvb8wumjABWiGQ+VKlbgoBWZqSqksRhToUFmpkttE6vnYtpR+V3DUthYJ1CbKyBpjf7es5aY+FmXOgRd3nFWrSs4DDgPVghImmFlrAfRW5Dz1kRU3NJowb1x8jR0b5J2h8PCl6npeNnmonpuxXodyADVOOLJooBo++NxV2qQrsnmPCI5qau6t311UyzPjS1JzWU52TBQuA1avlMK2QG8yoQp1tlqXmrGxpUvmK1kLBJKWmNfbZoYuwP7FTbs7JpCQ/XMN+leb3TEMbWTyYSiLEPaeSpcnX/37uuRKGDSvA8OGS/xag5iYqIljxAvkqxjRlpGuyKjiLJiZ0oinboTIydYv04a7etH49tIIvTc1pPd3Vt7CbQsugQHpbsKrWJhxNE8RI/Rl4DtOwQLS66Jh4GCW9z5XPcarH4WvslAfj2IkTfriGlQDDFoomc47sAo4pizBLUwvPEUXPNCdyhwwJwN3ray8oggQ6nTxqVqlvaGg8v1SIaapOT7ff+B3M187NM4smJqjQdYG00WQsxuArQp9dFKoWK6oFUgahwCVbmlS8Q/cT6j6fjzy8gLvwIaaJVhcFhSbUbt3p0JPedyurY0eWpUuBq6+Wl5NQd70Yuz0n/epn5JnY9vL5lXicRZO/eoZEbNDjHz1NVGk2K+e777bIwukWKmpZUyMPxF0PKj+pSUlBA8ywoAFHd6rgDlcJjmligkpZGTCuerGoDWIqDuDuiSapSm31HlK5qXnQM+hoLtNSIKVmUe7QL75YNcFEzMA8pyrMQ7AO7VDgt5XVU20fivv/9FMgPt6Hc1IlS1NSF/n8Sqlm95y/KBULSFs4Ric4xj+qUtPX3URFrmV3nRbUqFKfb3PN5eSoM9lYLDie0AapVcWo3E3fvzYyqlk0MUHlwD4r5oNqhki2S4iP2AKEpCFDgBUroDVcW6xoDlsGXY75EF29RcZ0C6+TkcH48XKQkKvPq3Vrv2OZqE0JCSbXIoJKcclmoQtdSkqzBSyp5uKXX8rXOq/nJF2JldT5Fp4Mad3k86u1tVgYF2JjYWxUFE3/+pf8/Je/yJbCoN54OU5UZKYki5I71KhSn69euQGF6rQsIZrq8un7Pw1agEUTE1ROfrkOebau6trO0zcYNktT54Ri4IRcdoBFk4/Nokkw0ZdFgdpkpqMr2uDBcjl4uiN3o1zolqDQnIurG95GW5R47fNF6/yxsjZX28fnax2dBLQTKstPIrAFpHaztVLBYRw4WI8Opxj4UkLfmSI2Wyia6HQiYw5x++3AgAHQXnZooFXq96uXOadQ3zoLKAQaCrXjBuaYJiaoyGZVP9FcgJB+RVP7GHmy4WBwH3npJfn5ttucI/pJaHgIriXBRHrmrob5WI3z7LFLnhqjkpiiHmCK+84VWl5gyUP9oCHi/fr1Jp+vdV5RXHMUb9LCDs6mNq1hhVkUSjzyu0swu9GoqACqq1URTW++KRv8zjwzxILJn/jQQONI89XLnFMwZ8sWzegj2oltZdHEBJX9tT5OMs89F+Y8fYNhc89lk3uOC1z6xg8/AD/+KAukG2/0GFwruQS5Flraue3l5QkSU9Q0VX7tLJyU93dZ52H9d1HqXutUimcSWCyoiJJ7zlXs1I4VICgoXywFUcfFBbwbshi++mqjJg85vgq+QIVhvvruuZiO8s1ffEVxQPVjg4GBbaqMFlhvGooxaCcCX+X7cQ/Fje66i11xQbA0tarnquB+W5kuu8yj+2oxpuAeaSI6YZ1cdI/ccFb3bjhvkMAioUXxfo7u66NIw034t1jffRUVOMxFTo5JnWudmqKJxFJCFjKOlaByT4SIphYWtqTQzH37ZO1Fp1jYskM9uJgFlOZPruhACq7uV989l3SK/J23aShCaSnQSgO9oVk0MUHlQKF8V/0J3DTg5dil4GGb4KkFAcGiqRkoyJvimYg77nC7SWMwtgX5CDwLQIkpJ2H0GSaKHmC34BVMw0fYhNPsFqunn6a/iTOa3Z/P3elVKmypcDI1Czi2GbUHDJ5Bp1IQuBIAft11QEICwpcdSiexa+qeYzcGsqQ61g+jk4v+X3PW/3z13XOWdo1ZwKT1tCCa2D3HBBW6uaWLwLYnFsluD0c4dino7rm46grEoppFkyeUwkdk6aQ0MAo0Oessp3pI9FxbG3iLOVfvM2kXpRwUWago/ulhPC22G4k1aGtrtOwLft13qFSjSaE+Qz7HpKIIsTQFIJqU8+j55+W6WsSttyJ8eKrfREK6V6/ACq5arcAXX0CYglQ8vxy/c7LqaiUuk0UTE/TClkTcFVOAjAz5zVNPcexSsCEfgE2kUoFLrUw4moIuApSCTcX9FCvTn39i44NL7IuV2n90jfG30apjhWfSZN5iyvehE77DQFHI71J87HF/rsLIr/sOld1zijUz6giLpuZOLxLcBJVm2LYN4YVOFvIT0hysKPndu2Urk78FVxfbBkmlOhT69Wt5oUzlo203f8LSdFAbQU3snmOCBv0NVlXJr3Nb1TSm7d58c4tTnplmoKsxXdTy88WEs6tQveBMQ+Ch8JF0tBxnPTMVZ2IRDjoEdrvefLfUCqTc8DsWq/wA0zAIGzENH+AF3O12n3TNIqsVXUv8ru2jsmiKsrlOYivYPeeKp7paZMxsaQ3JoBSaI3OYtzsrJUXzhRcaTz76o6BCma6DVKNQposwT0QVDv95nMqpItywpYkJGsrFgPrHxh+xTdhUtlgLjulIwHaXRpYmRwEb8XgpfKQkK8zDDJjRsn5XzVmBXG/4c2dcKtL4STh1xF6vP6vfvQ3pak1FglQUTfGd5Ata8gm2NDnSXF0tDfYi9z1F8557Gs2vl18e/IbriYmoiU0WL7WScMCiiQkaTnGnSmYFpaOq2NuL8b1Wk8ba+IWPZor8Ue2h9jggArR9RQnG/uor/ypnKDf8JILOnpiFNbYA88tgcxe6IaB4ZMWKQCnzdBejAqldZVGeUVeM+noYFz8LW/pTQ1IzBHJSWa0hGWR1mnxsclXw8MOiiQkaysQh4gIdRRMTUtF0ahIXuHTCR/Xoa7sT5R6A4pQc62H6mxBKrrbl6dPEa3LRufscugFpNkuuuSBwlW5alKrgZMlUjFiGxE9LU7BrSOqlWbVag7S2kc+zBo0kHLBoYoIGiyZtuOfax3GBSyd8vfh5aHfiGo6nVhIoiaxhz01BLaLRD5vRA9vVq86hdhA4HW+ufDHLRBmK99fAkJw8KVcE96NOU7BrSAa1HAGhpnDKbvkgLbnyPmI0UhWcRRMTNJwynINQLZZpBtskn2vmWk1N7qqpE7sHqCp3PvJEuxN3lh66GXBMPFIzCXTCtRkoHTBWvH4Q/8Tl+ADDsQbtc62BCzNyo6xdK7+m7vNqBdOkp6PelktU9rtBTU2KpYTcmqmpqhhtWmQxDEc5gkAwqTfIOFtV8JSTxULDhhsWTUzQYEuTNkRT6wa2NDW5q+7Tx+0q6iNHzMA8pyrfjpYeKhmgxCEF4oZrjuyhXcTztfgPPsAVWIOR2IuOmIIA0riVlPDXX5fff/ml/F6NlHCzGeVxsjXz+O5DxnfN+WiBcTTa6K6er2t2AqVq+otJ3UHGdNBWrSYWTUxoRZOK1WIZ39xz6TVsaXLil19k8eDG11YSI/eRW5EwJTx1WEnMuLnimporMOhpX/R/XKOSA9mXB04kycK8ep824k20UqOJzpP772+6XBf1fB2zE6jAWHOxTpaWFA9rHlN2Y1XwQGqlqQ3XaWKCnz2X29Doq2NLU+hQapzYUsK1cJcWNsglRZk89CX84x9ydg9dFP7zH3l5URHW7MzGeU8MRWy8BTu2y243f9tvtfgYPeWq0zK6cFEa98SJzR+MmvvyQm1aW+AIYC1g0eQp6e7ii+VHyM6jULVeMdmEFJXNp5uPYP2xOFQF36KBOYxFExMUjh0Djh+33XhYioC6OvkPyUssCRMcS1N0TSUScQKFhUmISMii4lhFUpnwzz0XVliwDiOwvxZ48BWKZwIefFDW9iHX9/7kqjsWJgz2vrxgbZ0F7AZwKALcc35A093nn8uv774bGDYM+sVdJVbFokQuuGCbzWw3fySalrNoYoyK8rdFTbMTDu9v/COL4lMuZCQlyZ1Bq6pEWjiJJsXIEDF4Ks0sSZBuuhm3/r8M/Lu0cdI3m4FTT0V4UDNXPUR57+Yc+YIWU2ZQS5OfNZoUKO7+6FHZAHPOOdA/JIzIKrlOtsqG1Gxm++5b4wgK99fRbSDCCcc0MUGBg8A11ErFFg9AFcHJAhgxNFOamZb+rdS58ndDA3DVVaq1zvIPXy/MZNVROgl7yoQLUd57bHvZmpl43KCiKUBL05Il8vNFF+nMHedrrNOIIGRAeCIzE1azfLNd+Wf4LZosmpjglxtg0RR2F13nhAjMoGtB5e+wtLnwpcAgmcIcW1l4yoSjfXm70KuUEp7UxZYOXn3Ia9uQSBJNJLw//VR+PXlykI4rkjCb5dg5cnseCL84Z9HEBAW2NGkEm6Wpa2oEBoMHWPk7bG0ufCkwSFdkXzLh6P+3aRP0lHB7VXCpGKWlMO455GNhS+Knn+SfhbzjVCGeaTkNtqrgpuLwF7hk0cQEXzRxYcvwYZvsO8VFQNkBMg2Ry0pxXfnYGNpT5e+wtLnwVGDQk7hxbI5aW9s4/ptuAn77TS4qZbM2BiMlPLpdW7v7V1NtQdSAGuodPuy3pUlxzY0fL9fEZFqOpZ2tKnhZcdgbHXNULhP8Zr0fs6UpbNgumLnRBnfPucuQI8HgBar8fRDtmlT+DnubC1vQbf3q1fj1iy9wWk4OLPfd53l7xTRGYki5yCuQeCLrVbACeG2iPAXHcWhvFfr0SYBhoNgx+m7pu3LtneMB2lwx+rFrTj1iOigWzSLxs4QzCZtFExNcS1OuxO65cGK7qLVtkC1NZIgYOFCH9WICyZAjy4uCS40ZEkzuKn8rm5L+CGubC4sF0vDhKKisRH9fo/ddBRPx8suitELQ0sJTUlBjjkNsQzUqdpEw7wTDoJjO6MaDYsl8YMcOYNcuWa+TpYlRB3NOtt2iSa7PcIomds8xQRVN7ZOPAidOqN4slPFPNFXtlUXTihXe44eNliEnFFBmZhN317EUufL3EkzRfpuLlpq8ghnVbjLheLxszazcE/4g3XAHgSuuOYplSkkJ0nFFIlmNtZrCHZfJoolRHdJI5eXy63ZWm5WJglLj48N6XJHI6h3yBa2V9VCwOmmEF1+KOFKE8ttv2/tpNXy9Gud23CsEEwXrar3NhTRkSPNZdR7/c/Cj2qtS5QtaTX7408HDJZqUcLo33pDfU0kjRkWyGy1NlJnordpGsGHRxKgKncjKhZjqKsaVsGsunL/Fw/Mb6zTJlYmaxg+HO7CyRfgafVxSYq8x89GhEdi02SIsAXv2NPYmpWdqnaIlweRzVl1zBDFKuy5TPsekouKILGyp9EQmCy6dP8QTTxjghkRDrPm90dL0zjvhtZazaGJUQ5k8rr1Wfk/FFJ+8nkVTuCDjwq/FsqUpDjVIwTFtpNariZ9FHKm9xd/+Ji+ihqpkAA1HvT7Vsup8DFAOalS7Ldkg6khxxFmaPPVEJr1lCEuuBli8GPjLw9lNbv7CZS1n0cSogqfJI61CFk27alk0hWPOr0Y8KpDiMOG43063NFcQ0lbE0Tp4qDDp33qrbF0irUFWNl1BwmnfPmfTGP3B+TD+YEa1R7eTrQCx5YciqkZTcz2RDWHJDTNW23dchCz7zV8aysP6HbNoYlqMt8mjPWTR9N7aDjx5hBjlBrnYNuF4Ek1hS61X23Xlik1IbLx8HjqeYhEm/TffhN3i9OWX0H8rC0rT8uS6C1FUe3wn+fxKriw2VlXwZixN/vREZgJj/XqT+I5rEIejSGsyj4XjO2bRxLQYb5NHB5to+rW8A08eYTLCKKKJmvaG2AgRWtdVaqrz8nbtsPG+RRj87JQm52dFhYHcJ55cdyGKak85VXbPtW4oNlZvw2ZEU4h6Ikc0RUVNi9C6VvB33c7Qomnt2rWYMGECcnJyYDKZ8KnSsMfGddddJ5Y7Ps4//3ynbcrKynDllVciJSUFaWlpuOGGG3BCSXG3sXnzZgwdOhRxcXHIy8vD7NmzmxzLwoUL0b17d7FNnz59sGzZsiCN2nh4O2HbQ64Gvh8dePIIkxHmEBqrNms6tb4lkDD4y1/k11QgZ/VqWHfvxSUfTIkM94k7112IotpjlcKDOGScv3E6QZoJBA9RT+SIJtvhu/NmMQ/ldxxW0VRZWYl+/frhpZde8rgNiaSioiL74wNqEeAACaZt27Zh5cqVWLp0qRBiN998s339sWPHMGbMGHTo0AE///wznnnmGTz++ON47bXX7Nts2LAB06ZNE4Jr06ZNmDRpknhs3bo1SCM3Fp5O2HhUoQ0O20UTTx6hh66Zp49vOtloMbW+xSjmpLFjhetq3QZLZLlPwtWF3hbzI1qpFBrEP0dlKsiH6yWmycdwOv1bcsPIkCGS/Tsutt38jccyDMcamGENy3ccVtE0btw4PPXUU5jspd58bGwssrKy7I/09HT7uh07dmD58uX497//jbPPPhtDhgzBCy+8gA8//BCFtn4R77//Pmpra/Hmm2+iV69euPzyy3H33Xdj7ty59v3Mnz9fiLP7778fPXr0wN///necfvrpePHFF4P8DRgDT5OHYmWiQOSUvDSePMJEl3PkSb9fluyeu+sujabWtxRSQA5FVNl9EiJs2XMJOInDfx6HIVBOCiqM6qEdjw/hdMax5IYJi+07niwtxgQsFcuuwvtYg5HYh45ieai/Y823UVmzZg3atGkjxNK5554rRFYmncgAvvvuO+GSO+OMM+zbjxo1CmazGd9//70QY7TNsGHDEONw4o8dOxazZs3C0aNHxX5pm5kzZzp9Lm3j6i50pKamRjwcLVpEXV2deKiJsj+196smc+aYcPnlFlu3CpNTPFM+2uPZZ+vR0CA1adJuhLEHEzXGb2rVSvyht4+WLwRpaVY0NDT4/VtofexR+fmiOUod9Vioq0Pr1iafprjWretRV6c9C4luzv2YGNRHJSG+/gQqdhWiri5e9+M3HTggzhwpKwv1Xj5/wgTgH/8w4+GHna/aubkS5syxYsIEyW6wMuRvHyQcx39R/RJMxuVOdeaIXBRgEabCWv8h6upa1ujPn+9Z06KJrD9TpkxBp06dsGfPHjz88MPCOkUix2KxoLi4WAgqR6KiopCRkSHWEfRM/9+RtrY7I1pHoomelWWO2yj7cMfTTz+NJ6iCmQtffvklEqiqYxAgF6RWiY0FHnggG//+dx+UlsY7iaaoU1IRG/s/tCRMTMtjDwUtGX/bAwcwkCwBx2XL36ZN+7Bs2VZDjd1UV4cJtr/Xr37/HbXFcjf0zMwxKC2lVvPufCgSWrU6iWPHVrbo3Aw2ejj3z4zNFKJp73ebsGzZTn2P32pFjwUL0BVAeXU11n7+uVdTxu7dnQH0QdeuZbjwwj+Rnl6Nnj1LxX9p6Xmlh98+mKxcvhxjbr8dFkhN/oLNkISMqr3jDqyMimqRuamKigoaQTSRK02BgrP79u2LU045RVifzqPmPmHkoYcecrJOkaWJgswpfoqC0tWEVDD98YwePRrR0dHQKhR/++ijQGIincom3DN5L7AE6Dq6D7oE2L1SL2MPFqqMn2IynnoKbRrk+iapqZ0wfnx7GGrse/fCJEmQYmMximJ6bP6R+fNNuOqqppubTPJd60svxWDCBG12VtXTuX+o1Wygcj/aNJgxXqVOteEYv2nJElhmzoTJ1uAsfc8eXHT33bDOnQvJQxjJu+/KF+urr07Fgw/2i7jfPhgo4x+bkIA4ii/zAP2VJxw5ggtSUkSD60BRPEW6F02udO7cGa1atcLu3buFaKIYpxJqj+BAfX29yKijdQQ9HzrknGqtvG9uG2W9p1grerhCJ3iwTvJg7lstHBMXu8bJMSaWTp1gaeFx62HswaRF47eloidWHoIJDSgvNyM62myssdusTKa8PEQ7uOKVl3QT6pgl166dScRCTJmi/SlQD+d+Q5tsyvaA5XCJ6scasvFT/Qm6UXdJtzQVFiKKlrvJnKBNv/tOfj1smAXR0ZaI++2DSdThw75v14LvyZ/v2Kyv5JiDKC0tRbYtDWvQoEEoLy8XWXEKq1atEvEaFBiubEMZdY4+S1Kw3bp1sweV0zZff/2102fRNrSc8Y+jR+Vn8lBaDnALFU1gc2GbrfXIQBnKymA88mXXI9o7W9CoTxVx33066DGnY8w58g1mdJlOq4IHWN6bqjxQzDhdc888M0THGklka6+uQ1hFE9VT+vXXX8WD2Lt3r3idn58v1lE228aNG7Fv3z4haiZOnIguXbqIIG2CMt0o7ummm27CDz/8gG+//RZ33nmncOtR7SfiiiuuEEHgVE6AShN89NFHIlvO0bU2ffp0kYU3Z84c/P7776IkwU8//ST2xQQmmoQe3c+iSROQucWWPEG1dJTfyMiZcwQZj5cvl19fd51OeszplNj2tgy6YzrtPxdgee9vv5WfTz8diFcn/p1xQBoyRHN1HcIqmkiYnHbaaeJBkJCh148++qgI9KailBdddBG6du0qRM+AAQOwbt06J7cYlRSgopTkriNfOpUdcKzBlJqaKoKzSZDR/7/33nvF/h1rOQ0ePBgLFiwQ/4/qRi1atEhkzvXu3TvE34j+US7IrdPq5I6KBIum8GNLdKBaOpFiaaKSbmQYOOssoHv38B1aJJDQWbY0ZdQVC6Gqu4KhAdanUETTOecE4ZgYONV1CFObIFfC6tAfMWIEJC/NilasWNHsPihTjgSPNyiAnMSWNy655BLxYNQRTV0SCiFy2snK4ZKZyIQBis/bvl1YmtaWyTfOnm7ejGJpevdd+fmaa8J0TBEChQJ9/lQW3rJZMs8aJxsH6FqnGxdogG4gFk0hbBNE7lNHayCdZHJgIkKJrmKaGO1TLidooUv0/sY7fzOfZlqyNNXXOwfsG9HStGULlVaQY00cknCZIAgm6uG3rdS5VQ8ZmXXV2y+A8t401ylNIwYPDtFxRipTwtcmyBW+mjFBsTR1NHE8k6awZYLmWuSLmuHimlwsTYqV6cIL7eFcTBBjp52bQkv66+0XgBto40Z57J07e+y0whihTZALLJoYVVEuxu0aHCxNjGYy6AabN4q+TWWH9XAl85HjxxtNnHl5wpL23nvyW3bNhSZ2+jBaiecY1OFCfC76gumut5/iBrIlETXXqJFdc5EJiyYmKKIpu4YtTZqBfCSzZ4uXg+rWib5N3cd11JHvxDcrk5SWhjU/J+Ovf5XLNmVkyAVXmeCgxERPxmLsQjf78s8xUe4LhsX66+1HwsihhA2++sqjG4hFU2TCookJimhqVcmiSVNBJy7+uNjDegs6aT6eaUdle4wcCcyaJS+urQWWyj0+mSBAMdEkjKj/Vy4Ouu0LRutDWEJHHZSWGlRDgDpPuHEDkTXz++/l1yyaIgsWTYyqKNfm1AoWTVou2GeC3oJOPPPLZ7Kl6c+6xsw5goLdjaILtcjQwVa8aJkuYpjMbvqCES9YZojtdOfuJZKTPW7y22+ytkpLA3r2DN2hMeGHRROjKnJoiYSkMls2E4sm3RXs0xOk99a9L59r+XAfP2cAXahJLBvWIcd60ONFhIRTrvWA2M5ooklxzVHTCE4Ojiz452ZUpaLMiklYAktttbxAd7Z5AxFgwT49QXov9bhsaToAZ0uTQXShdjHq+aWIJi+N1zmeKXJh0cSox+LFWLW3I5bg4sZlXbuyfyRcaLBvk9rQ9bg9vFualO0YlTHq+aV0vPdgaSIhzqIpcmHRxKjD4sWQpk5FdoOLO0h3Ve4MRAAF+/QGXY/z4NnS5LgdozJGPb+acc9R3gFNa1FRcoseJrJg0cSoGnDc5ITSXZU7A+GlYF8DwtO3SW2GDpHsosmdpUmv1229n19SmPqCBVs00RT2+uvy61NOARzaoDIRAosmRrWAY4+tzDiwJPwF+3JznRYfinZfsE9vWMoOIw41QgQWwHmMer5u6/38qmmt4/PLg2giY3nHjsA//iG/37lTfs9G9MiCRRPTcowaEGq0vk22So//xvUY1DY8fZuCVaOpJiMbSWnRvhRyZoJ1fr35pnhbgRR8/ryOzy83okkpd+aajMrRB5EHiyam5Rg1INRIkKmlb1/x8jhSUFpuENOLTTTFn5qHm2+WF40ZE9Z+npEJnV82UZ6M4yihFnR6xUU0eSl3xtEHEQiLJka1gFDJk4OOA0u0QSu5P1hrHBaFH6litmEa9bZvb385enRY+3lGLtS3xlaf6di+MhhFNEVAuTPGD1g0MaoGhNoDjBU4sERzoqkVjohnl84qurY0kShXXnKP6DARHY2Tceni5ckD8jlmBNHE0QeMIyyaGHWYMgX/vXZRk2BcDizRnmhqa5EvaGU6Nga4szTt5849YacmRT7H6ooOQ7codZpsxS05+oBxhEUToxo/tpuCjtiHmqgEecG773JgiRbdcybjWZrqs/NQWCgvYtEUPqzp8jkmlRjH0mTUclRMYLBoYlSDLsIU1xRdf7IxIpddctqhdWvxlNFgPEvTodj2aGiQ6+a0aRPug4pcTDZhbi4zjmhyLEflCkcfRB4smhhVRVMSTtg7nCM1NdyHxDhiu6AlNFQiDif1L5ookt0WSLK/Qa4GTnf83EA1fERly8I8puKw22wzvZYcIGP5woVNrU0cfRB5RIX7ABjjUF4OpKJCfhMdzeVytQZdBOh3qasTweBlZZ7bjugC8sfRlTk2Frsr5Is1u+bCS1w7WZin1h8RGZoeOpHosrglZWQqQvDtt+VzjVxybGGKLFg0MapamlJwrNHK5CkIgAkP9HuQtamoSIimo0d1LpqUdLl27bD/gGxeYtEUXmJyGjM0Dx3SoWgiHy+pPcLl4Kl+pxLwfe21YTg2RhOwIZtRVTTZLU22zBNGu2UHdO+e48w5zcbNKaJJd1RWNr52EU18jjGqi6bffvsNFrZVRixNLE2M9jCSaOIaTZouoKpL0aS45igwLj7eraWJRVNko7qlSdJt9B/TEuhnd7I0sWjSJkYSTWxp0vT5pWvRRJZyl/AC5RyjJr1M5OJXTNOUZlIEKioqYOI4loikqkrEF7N7Tkfukx/1XqfJZl6S2jVamlg0hRm9u+eUwpZugrHY0sT4LZo+//xzjB49Gm3btnW73sodCyMWpVBimvkY9VJhS5NWMaClqTylPaqrZcMApYAz4T+/klCJsgKq1+bs4tJr5hzBlibGb9HUo0cPXHzxxbjhhhvcrv/111+xdOlS/mYjtNwA0Ta2AqC5kkWT5mNOdC+abOalg6Y8e1ZTTEyYjynSSUmB1RwFS0O9rf9cnmFEE1uaGL9jmgYMGIBffvnF4/rY2Fi050jMiLY0tY5h95xeLE30m1GGtS6hi5tNqe+plS/MfDHTACYTau3953RYFdyDaKJTrcI2tfF5Ftn4ZWl65ZVXvLrgyBK1l3qNMRErmjKiOXtOL6KJBBNdI3T5UylB4Kmp2HNYFuh8MdMGDRmtgfJi4PBhw4gmxTVHfz6JiWE4LkafliayJCUk2JqxMowb0ZRu5uw5PTXt1a2LjjPnNIuptY77zzUjmjieiQmo5AC56LZs2WJ//9lnn2HSpEl4+OGHUUv9oJjIDQTn7DldiKZMiS5okn5FE9do0ixR2bZg8JojIqvWCKKJ45mYFommW265Bbt27RKv//zzT1x++eXCArVw4UI88MADgeySMYhoSpLYPacH0RSDOiTjuH5FE1uaNEt0to7LDrCliQmGaCLB1L9/f/GahNKwYcOwYMECvP322/jkk08C2SVjkOy5xHp2z2kaqnJsC8pQgsH1bmli0aRN95wuq4IrdZpcLOVsaWJaJJqo6neDLe3mq6++wvjx48XrvLw8HDmiQz8202KUi298LbvnNI/eyw5QMsrmzeJlTVklKo7KySnsntMIeq4K3oyliUUTE5BoOuOMM/DUU0/hP//5D7755htccMEFYjllznkqfMlEhmiKrWH3nObRc4HLxYtlH8mmTeJt7Jz/wz50xFUJi1mnawU9VwVvJqaJ3XNMQKJp3rx5Ihj8zjvvxCOPPIIuXbqI5YsWLcLgwYPVPkZGJ6IpBjWIqq+RF/AVTLvoVTSRYJo6FTh40GlxLgrwTtVUeT0TfvTctNeNaDpxAigtlV+zpYnxq06TQt++fZ2y5xSeeeYZWCwWNY6L0aFoSoHNyuShoi6jzQKXunHJTZ8ud4Z2wQwJDTABM2YAEycCPAeFF4O55xTXXFoaG9CZAC1NnoiLi0N0dLSau2R0Al187c16acLhC5d20aOlad26JhYmV+EkMupoO0Y77rnipiJXr6KJrUxMwJYms9kME3XH9AA37o1M0ZTNNZp0d1HTjWgqKlJ3OyZ4ZGaKpyhYUVlAabXpMIJo4ngmJmDRtGTJEqf3dXV12LRpE9555x088cQT/M1GGNRhnh529xzbsLWNHi1N1I1Xze2Y4BEXh/r4JESdPIH64iO6F01cboBpsWiaSHEDLkydOhW9evXCRx99hBtuuCGQ3TJusNZasfmFtTi+ais2705C/7tGwBJj0WSNJns1cBZN2sYhUFc3MU1DhwLt2gEFBW7jmiSYYMprJ2/HhJ2GjFZAwQlIh0k0nQpdUFMDKB0tHKzlbGlighbTNHDgQHz99ddq7jKi2fjAYhxK6IgB943CVcv+Kp7pPS3XEsqFNzuB3XO6QI+WJoqRmz/f7SoRBE7RAvPmcSydRjC3kV3AcZVHhBVaV1YmIinJ/pItTUxQRNPJkyfx/PPPIzc3V61dRjQkjM56ZiqyrM7Br1nWArFcS8JJEU1t49k9pzfRdPIk/e1CH0yZQnVNmojyArSD9PEieT2jCSxZjdbMkhLoSzRR1fyoRicMB4IzLXbPpaenOwWCU4Xw48ePi/5z7733XiC7ZFxccu3nThdOB7OH9Oq8uTNgfWqiJlx1imhqE8vuOT2JpgyUwQwrjh61iOuELiBhtHEj1TdB6VnjcPEPD6C4y1D8PjX8fwdMIyaXsgO6qNbuJp6JrGTFxfJrds8xAYum5557zkk0UTZd69atcfbZZwtBxbSMLS+vQ38XC5OrcMq1HsCvtN2MEdCKaMqMZvecLsjIsJ9H6TiKo0dbIScH+oGqDVLP3uyz8A1GYBRfzLSHHquCuxFNSotDatdo+7NhIpyARNN1112n/pEwdqr2FKm6XahEU7qF3XO6gGqp0c3N0aO2uCbZKqAbKmRxXlIti3N2m2gQPVYF95I5R1YmL1V2mAjCZ9G02dYg09eK4UzgJJySrep2Ic+eY0uTPi5qdtEEXXaiL6qUzzNduH4iDQf33BYdiyaOZ2ICFk39+/cXLjmKX/IGbcPFLVtGn9uHovC+diLoW1Q6doFimoos7cR2WrI0pUgc06Sri9offwhLgF5FU34FW5o0i0Hcc9yolwlYNO3du9fXTZkWQsHd+TPnI+uZqUIgOQonkV5N8Rwz5yFXA0HgjqIpsYHdc7pBj/3nXETTvlIWTZpFz+45NzWa+Bxj/BZNHfisCSkDZ0/BRiwSWXQ5DkHhZGEiwUTrtYJy0U2oY/ecbtBjrSYX0bTnMIsmzaLHpr2284otTUxQ6jTt3LkTd955J8477zzxoNe0jFEPEkZtq/Zh1ak3ife/ZJ6HrKq9mhJMjqIptoYtTbrBAKLpcF2qCM7l0nDaPb8ozrG0uA66gGOamGCJpk8++QS9e/fGzz//jH79+onHL7/8IpbROkY9RB2mYXLskqXBqom6TJ5EU8xJjmnSDQYQTceQIkolxMSE+4CYJqSnQzLLl5e64lLoUTRRRxXq2kOwpYlpUcmBBx54AA899BCefPJJp+WPPfaYWHfxxRcHslvGA4ld5Vvp1ErbX7DGoOw5ExoQdbJpTACj/UBdXcU0UbVBW38wEk292QKgTSwWSOkZMJUeQVT5YdTVZYlKF3oSTQcPym0O4+KANm3Ce2iMzi1NRUVFuOaaa5osv+qqq8Q6Rl3SesmlBVrXum9WGm7oopuEEzApx8aWJl0F6urK0qTEnVCNSySx20TDmFo3WjN10UrFRTQp8UxU0oJrNDEtEk0jRozAunXrmixfv349hnKXcdVpe7psaUpEFY4dsLnANEJdnVygOVWp0US+Ero1Y7SNXt1zNtFUHZ2EBli4RpOGMemt7ICLaFLimdg1x7TYPXfRRRfhwQcfFDFNAwcOFMs2btyIhQsX4oknnsB///tfp22ZlpHYKh5lSEcGjqJkUwFS2qdBKyiFLe2iiV1z+kDnoum4ST7PamoAKgtn0V6oH6O3sgMeRBNbM5kWi6bbb79dPL/88svi4W4dwYUu1aMkOhsZdUdxdGsBMLEXtIISD5OdcAyoYtec3i5oKTiOk+U1sFpjdSE81i49hmEAjtTKomnePGDRImD+fLmXL6Mh9FZ2wIN7ji1NTIvdcw0NDT49WDCpR1l8W/Fc9Ye2gsEV0ZSbxJlzuiI1FZJNJWWgVGnnpmkWLwbmPCZbmirQeJ5RhtPUqfJ6RkPozT2nxMvZrOVsaWJaLJrOPfdclCv+GCakHEuWJ6D6/doUTVnx7J7TFWYzTJmZunHR0f3X9OlAMhrLDSgo+QczZsjbMRqBLU1MpIumNWvWoNaW7qsGa9euxYQJE5CTkyNceZ9++qnHbW+99VaxzTyyxztQVlaGK6+8EikpKUhLS8MNN9yAExSZ7NJsmALU4+LikJeXh9mzZzfZP8Vjde/eXWzTp08fLFu2DFqiKkO+wJkLG6uDawFFQ7eO5cKWerYEaF00Ud4JpYArsXOOokkRTgcOyNsxGkFPMU0NDXJGC5GcjPp6+Xwj2NLEqFIRXA0qKytFYcyXXnrJ63ZLliwRgeYkrlwhwbRt2zasXLkSS5cuFULs5ptvtq8/duwYxowZI9rAUOD6M888g8cffxyvvfaafZsNGzZg2rRpQnBt2rQJkyZNEo+tW7dCK9S1zhDPcWXatDS1imZLk54valqv1aRUMklxY2lytx2jAfRkaaqsbHydnIzCQgjhRLWlsuWKLwwTWCD49u3bUVxc7HWbvn37+rSvcePGiYc3CgoKcNddd2HFihW44IILnNbt2LEDy5cvx48//ogzzjhDLHvhhRcwfvx4PPvss0Jkvf/++8I69uabbyImJga9evXCr7/+irlz59rF1fz583H++efj/vvvF+///ve/CxH24osv4pVXXoEWkHJkC07KcW2KpowotjTpDh1l0CkXruZEE1/gNISeYpoU15zZDGtMPBSnh+1PhGECF03UZ05yU2CRXGe0XM2MOQomv/rqq4WYIbHjynfffSdccopgIkaNGgWz2Yzvv/8ekydPFtsMGzZMCCaFsWPHYtasWTh69CjS09PFNjNnznTaN23jzV1YU1MjHo4WLaKurk481IT2Z2kv+9lb1xSgtrZOM8XWSkvJWGlBmkn201mTktCg4viV71Lt71QvBHP85owMWGwXtcOHraira4BWx06VTXJzo5Ba4N49ZzJJogfdwIH1onaYEdD9uZ+aimjFPVfcgLo6q3bHX1YmjrU2LhmdOza2TyHLZYcOEubOtWLy5NAVFtb9b6+z8fvzOX6LJhIjrW13EMGGhE1UVBTuvvtut+vJ4tXGpb49bZ+RkWG3htFzp06dnLZp27atfR2JJnpWljlu482i9vTTT4uaVK58+eWXSEhIgNrEdE4Sz21QggULliExHZpg8+b+5PUHKg6I978XFmJ3EOLByPIXyQRj/N3Ly9HNJpq+27gLHTrsgpbHftVV2UieddyNaJJETNOVV/6IFSuM55/T67lvOXkSF1JIAWpw8kglPv98NSwWSZPjT9u9G8MBHKpKRgGVTnGABNRll1nw4IM/YtCg0J5fev3t9Tb+qiqXH11N0dS+ffsmQiUYUPwRuc2oETBZr7QG9d5ztE6RpYmCzCl+ioLS1VbBK7/8EjWIQSxq0TuzF3qcr43oxLffltPWc2yNwbuffTa6jh+v7thXrsTo0aMRrfnmVeoTzPGbd++mDAghmtq06Yrx47tAy2On06rk6wrgJ+eSA+3aAXPmkCXgNAD0MAa6P/clCVJcHEzV1chEKc48cxyysrQ5fmnVGvF8HDSRuV5vTMKS+f77Z+Lxx+tDUs9M97+9zsaveIqCVtwyFFCblpKSEiHSFMjtd++994oMun379iErK0ts40h9fb3IqKN1BD0fcnGoK++b20ZZ747Y2FjxcIV+4KD8yCYTjsTkILd2H47/XoLoCdq4wCn1fZLq5ZPOQi6fIIw/aN+rTgjK+G3WVRJN5eUWREdbND/23KRGS9O0aQCFJQ4daoLFotmpLLLPfQoKOnjQ1uOwI/LytDn+LT9WoY+XWDlJMolsuo0bozFiBEKGrn97HY3fn8/wK3tu+PDhTrFBzfHBBx+IDLlAoFgmKhVAQdvKgwK7Kb6JgsKJQYMGibpRZJVSWLVqlYiFOvvss+3bUEado8+SFGy3bt2Ea07Z5uuvv3b6fNqGlmuJikS5B92JXQWaKzkQV8vZc7pDRyUHXFU6XdxGjaI+mNxCRdPoJIPuRNFxB0uTZzg7k/Hr9mz16tV+7fyWW24R4qVz585u11M9pd3kIrCxd+9eIY4oJoksTJm24nuOapCsPyR4iB49eoist5tuuklkuZEwuvPOO3H55ZfbyxNcccUVIvaIyglQvzwqI0Buv+eee86+3+nTpwtBOGfOHJGh9+GHH+Knn35yKkugBU5m5ABHgbq9BZrLnoup5uw5PZcc0I1ospnRSTS5TA+MFtFJBl1mjG+iibMzmaDWaXKXZecICZPTTjtNPAiKEaLXjz76qM+fQSUFqCglZfVRqYEhQ4Y4iZ3U1FQRnE2CbMCAAcK9R/t3rOU0ePBgLFiwQPw/qhu1aNEikTnXu3dvaIn6LFkImgq1J5qiq7iNip6tAEfLQpcZ1CJYNOn2HFu+nAoka7Nqe5e23kUThdWSa3Ho0BAfGKM5whoIMGLEiGaFlSMUx+QKWaVI8DRXN4pipLxxySWXiIeWseTJ7rnYUm2IJpr8lJgmywl2z+n1gkbZTdWl5EaXMzQ1DYsmXbG7ohW62KyZ8xYANFVT4L7WGiybK2XRdALJQiA5XpaUPCRqRsGuYCasFcEZ/4jvIluaUo5pQzQpgikGNTAp7XXY0qQfEhLQEBsnXlqOHnG6UGgSqotmq43Gokn7UAPl/yxrtDRpusGyrbjlqMnJcE0OJ5G3aJG2RB4TPlg06YiUHrJoyqwu0MQFTnHN5STY1BORpANrBdN4C22zNqXUHYEfpUrCW7XZJpoy5M5CjIYbLJegMaZJ0w2WbedWtzOS8dZbjWKJwnj37mXBxDTCoklHtOoni6YcFOBwiaQZ0dQuuaKxOzjbr3WFySHmhGqSauYi5sU1dwKJSEmzIMq4VQZ0j9Jg+Qgakw003WBZEeTJySgtlV9SvhFnZzKqiKZrr71WpPE3BzXJjeQaE2oT1V4WTfGoRuG2o5opN5CTxJlzeoTcI+t+b7QEXHop0LGjxtwmHsoNsGtO2yip+YpocrQ0udtOM6IpJcWe5ReCGs5MpIimiooK0ePt1FNPxf/93/+JprruoPR+qpLNqERcHMqj5KtF2ZYCzViashX3HAeB6wYSRhRXcrDG2RKgyXgTBQ4C1w1Kav5hN+45d9uFHaUidHIylHrJLp21GCZw0UTp+CSUbrvtNnz00Ufo2LEjxo0bJ1L1I7XBYKgotxW4PP67dkRTmzi2NOkx3oRcJK6WAE3GmyiwaNINlJpPMUGltvOL2qiYYdVuCr+De44tTUxQYpqoaS/VVfrtt99EE98uXbqIKt5UVPKee+7BH3/8EeiuGS9UpcmiqXavdkRT6xiu0aTHeBNP7hPNxZsosGjSDRQHRGUFSiH/UGZISKfKvFpN4XcQTWxpYoIaCF5UVCRajtDDYrGIApNbtmxBz549napuM+pQnyWLJuFH0Yhoyoxi95yecIwj8RZzopl4EzeiyRa/zmgYyjj78JNolJvSnM4xTabwu7E0sWhiVBNN5IL75JNPcOGFF4pg74ULF2LGjBkoLCzEO++8g6+++goff/wxnnzyyUB2z/hQ4DLmsHZEU7qF3XN6wjGOxJto0ky8iYtoqkAqW5p0Agmj1FMaz7Ebb9RoCr8bSxO75xh3BJS0m52dLZriTps2DT/88AP69+/fZJuRI0ciLU2+w2DUI+4UWTQlhbnAJcW77Nple32U3XN6jDchY+URqaloIvcJrddMvIkCu+f0W9Zi926RbEDJ1JpxySlQYV5bcV4pid1zTBAsTeR2I6vSSy+95FYwESSYqN8boy6pPWXRlHmyIGyBupRZRanp1EeK+HOTLJq2H2T3nJ7iTYgjLtlNmow3UeCSA7pv2qvE0mm1aGpFQ7Kin9jSxKgnmijgOy5Obr/AhJb03rn2Apfh6BpuT1V3mPxSIFsAXv0wVZup6kwTyD1CcSXR2Y3ZTSY0aDPeRIEtTfrEVrr9PHyNNts12LFXEU1xcThUGmUPz+RLHOMOrgiuMyztZdHUBodxcI/chyscqeqOpKLCHmuiyVR1xi0kjH7YJbvQo2DFBCzF7p1WbQomggPB9QfdRX3yiXh5OT7Cv/eM1F4FVaVGU0oKxzMxzcKiSW9kZqLGFCteHtlSFLZUdfeiKUWbqeqMexYvhqVHV/vbzzARllM0dkFzQGJLk75QzNInTjgtlrRWQZUz5xg/YNGkN0wmlCfkhKXApacUdMU9R5Ymb9sxGsKdn5UmhCKNXdAcaDjK2XO6wZNZmqYwrVVQ5cw5xg9YNOmQSluBy+o9oRVNnlLQFUsTWQC8bcfo4IIGjV3QHLCWy6KpJiYF8fHhPhomILO0FiuosqWJ8QMWTTqkro0smqSDBWFJVVcyrJqKplRttUZg9H9Bc8B0TD7PzGmcpal5fDU3a8EszZYmxg9YNOkQcztbgcuSg2FLVVegjKsUHLe7TTSZqs7o94LmgPmEbGmKzmTRpHl8NTdrwSzNlibGD1g06ZDYzrJoSqwoCFuqutIxJdkmmIhXP0jRbuYVo88LmkJtLSy11eJlbGsWTZrHk1laix172dLE+AGLJh2S0rOdeM44WYD6+tB/PgmjSy6RX18+Tr77l2JiMOlyLmyiC/R0QXNTgDC+TXJYD4Xx0yztcp41QGMVVNnSxPgBiyYdktJDtjTlogCFheE5BiUk5vxBcpyJiVuo6Ac9XdAUbOUGqhCPtNbR4T4axh+zdK6tybiNQ9Eaq6DKdZoYP2DRpEPMtqa9OSjEgfymGVChYP9++TkvxdZ3TvHXMbq+oBWaNXZBU+BmvfqEzqN9+4Dx48Xbt3At+iZprGOvzdJUF5ds109saWI8waJJj+TIdZriUIND20tD/vGUXJWfbzuUJNssw5Ym/V7QPv5YvLXCjI4Ne1BzgYYuaApc2FK/kMVy0CDxUoIZR45aUFUFzYmmY5DdvjExPJ0xnmHRpEdiYlARKzfBPLYj9MHgpaWwT3qtom2WJp5l9HtBmzwZkskECxqQibKwuXx9bdbLLVR0SIcO4ukU8z7xrKnGvTbRVF6fbHfNeQr3YxgWTTqlMjU8BS4JxcqUlQXEnGT3nO6JioLJ5o8gl68mRRNbmgwhmjpZ9mtWNJXVNYomhvEEiyadUttaFk0NBwrCFs/Uvr1DECVbmgzh8g1ncoFXWDTpG2rSS1Us6g+I2m5UO1VroulwtSyaOJ6J8QaLJr1iK3AZdSh8liZx82hzm7Bo0jm2gHCyNFE/Vc3Bokn/otxiQbRUh2wUadLSdKiKLU1M87Bo0inRHeSLXOyRAqxZE9o2YU6WJkU0sXvOEJYmrbrn6stYNOmaqCi5NhjdbGG/Ji1NhcfZ0sQ0D4smHUIN6Od+JIum1nUFGDlStn6HqjG9k6WJ3XOGE01atDRVl8jn2XFTKp9qOo9r0pRoamiwi6aCY2xpYpqHRZPOIGE0dSqwraKxwCVBFzpaHgrhxJYmA6JxS1NtqSya6hNSOLPJAKJJM+65ykr7y/1H5TmMLU2MN1g06QhywU2fLtdJKkKWWNYJf2I41sAkyf65GTOC76rjmCYDovFAcGupfJ5JySzO9S6aOmKfdixNSgsVsxkHjsSLl2xpYrzBoklHrF9vEndok7EYy3CBWJaCE1iDkdiHjpgkLRaT0bp1wTuGkydhbzXA2XPGDQQnYa4lpIrGVheM/i1NR486GXm00XeuRDZhsqWJ8QaLJh1RVCQLpkWYimw4mwPIQkDLaT1tFyyUO8SkJCA9nd1zRrM0tUUJairrHPvjaoPjsmiypPN5pveyA51MGqrVZDvRpeRkHDkiL2JLE+MNFk06IruNFfMx3daMwBkzZNPAPMwQ24UinknElrClyRhQSlq03Ag3C8WaCwa3VMrnWXQmiya9W5ragyYRSVOiyZqQLGLCidZyswWGcQuLJh0xzLQOeTjo8Ucj4dQeBzAU60ITz0RwTJMxMJuB7GzNBoNHV8miKaYViybdkpcnnhKkKmSiVBtxTTbRVBubbL93oOoIDOMJFk06wnzIN7+bpaQoNJlz1dVAba28gN1zhgoG15qlKbZWFk0J2SzOdUtcnNx7SUsZdDbRVB3FNZoY32DRpCdslgDVtlOrRhP56ZLlSYcxRjC4pixN9fWIrZc7RCdmszjXNVrLoLOJpkoL12hifINFk46QhgyRq+p6KlRDy8kEPnRoaGs0kWAi9w6jb7Raq0kR53Sq5bA41zVaK3BpO7eOg2s0Mb7BVzo9YbEA8+fLr12EUwNs7+fNk7cLZY0mds0ZA61WBbdd2E4iDhlZMeE+GkaFDDqtuecqGtjSxPgGiya9MWUKsGiR3ZWiUIxsNHy8SF4fJCi7RLk75BpNBkTjlibuO2cAtGZpsommsnqOaWJ8g0WTHiFhtG8fsHo1JNtf+dV4B7t6B08wEcXFQF2dbMgS11e2NBkLjQaCN5Qft4umVq3CfTSMWqKpvBw4cUIboqm0hi1NjG+waNIrpFxGjIBpwADx9lTsxs8/B/cjlXgmMnKJtFwuN2DYQHAqkKrUrQk3lUWNlqaMjHAfDaNOILhGClzaRFPJSbY0Mb7BoknvdOsmnrpiV9BFkxLPJFxzBLvnDGlpSkc5ouur7BWStSKaKi2pXEPHIKIpHUeRjGOaEU3FlSyaGN9g0WQQ0dQNO0NmaWpS2JLdc8aAfseEBPEyG0WacdGdPCRf2Gpi+TzTPZRpK/ovaSSuySaaCo6xe47xDRZNBhJNmzYF16XSxNLE7jljQRmZDnFNWgkGrymRLU118SyajBbXpBVLU2kdiybGN1g0GUQ0dcJe1Byvwe7dIbQ0sXvOeGiw7EB9mXye1SeyaDJa2YGwW5ocMjMTEyEeDOMNFk16h9oSJCfDggacgj1BddF5tDSxe844aLAquPWobA1AMp9nhkArZQesVqCsTLzsjh1BbXTOGAcWTUZwqXTtGpK4JidLE004e/fKC+jqSu8Z/aNBS5NkswaYUlk0GQItuOcWL5YtXrZz621cj/UFHeXlDOMFFk1GIAQZdGRUUgxLnTbZJpwff5QXzJolv+cJR/9osMCl+YR8YbNksGgyBOG2NNE8NXVqk3oHrWsL5OU8jzFeYNFksGDwX34JTjC44pq7Jmkx4q9uOuEIswRPOPpHg4HglkpZNEVncuyc0Zr20o2YLRY7NJBFfPp0QJKarDLDtmzGDLacMx5h0WQg0dTDtFNYm//8MziiyQwrZtW4n3Dsy3jCMUxMk1bcczHV8lU1rg1bmowkmrJwCLGoDq2Lbt067xU1aR4j8xdtxzBuYNFkJNFk2Smeg+Gio3imoViHrDqecCLFPXf4sITa2nAfEBBXI/uFE7JYNBkCaiBoS1Nrj/zQiiYqda/mdkzEwaLJCJx6qnhKqy9FBkqDIprI0kQFD32CJxz9kp0tnhJRhRQc08RPmVAvu+eSclg0GSZ5JVxxTbbzW7XtmIiDRZMRoLu2du2CmkFHlqYi8IRjeKgieFqaZoLByXiZ1CCLpuRcFk2GIVyiaehQea4k4eYOWp6XJ2/HMG5g0WTADDoKBncXdtRSS9M6DEVVJk84hkdDweA1VSYkoVK8TmvPoskwhKvsADU6nz/f7SpJmdfmzZO3Yxg3sGgymGjqad6J8vLGEkpqWpoaYEHB/e4nHLuQ4glH/2goGPxkSb39Ncc0GTOD7ocfgDVrQpg/MmUKsGgREB/vtLghp528nNYzjAdYNBlMNJ2Zon4weF2dXL+SSL7WNuEkJTlvRCZvnnCMgYZqNdUekUVTNWKB2NjwHgyjGj8carQ0bd4MjBwZ4lJvNE+dfrp4OR934zzzapjoTpPnL6YZWDQZrVaTSX3RROZzcvfRNUs0tKSJZfhweeUNNwCrV8umLZ5wjIGGqoLXl9aI56ootjIZBRJG98xrFE1hK/VmuyP4GJdiR9sRMEezhZxpHhZNBhNNbY/vFvWU1BRNSmFLClcyK2fMvn3y86WXAiNGsEvOSGjI0lRfJtc8OBnNoskIKLUl96KjPW7OgvrQl3qjD7PdERxEO7RtG+TPYwxDWEXT2rVrMWHCBOTk5MBkMuHTTz91Wv/444+je/fuSExMRHp6OkaNGoXvv//eaZuysjJceeWVSElJQVpaGm644QacOHHCaZvNmzdj6NChiIuLQ15eHmbPnt3kWBYuXCg+i7bp06cPli1bBl1BiiY2Fpb6WhEnsHEjsGCBOrECTj3nlAlHCZrq3LllO2c0HQgebkuTVCFbmmpiWTQZAaW2ZDGyUIMYRMEqzrOQl3o7cgRKETLKChYWdIbRumiqrKxEv3798NJLL7ld37VrV7z44ovYsmUL1q9fj44dO2LMmDE4fPiwfRsSTNu2bcPKlSuxdOlSIcRuvvlm+/pjx46J/9OhQwf8/PPPeOaZZ4QYe+211+zbbNiwAdOmTROCa9OmTZg0aZJ4bN26FbqBLD22ek2UQUe68cor1YkVUCxN7dvbFpSUAFVVstnJvpAxYiB4uC1NOFYtnurjWTQZAaXulwQzDiCviYvOdbugYUvZq0xqizrEsKWJ0YdoGjduHJ566ilMnjzZ7forrrhCWJc6d+6MXr16Ye7cuUIEkeWI2LFjB5YvX45///vfOPvsszFkyBC88MIL+PDDD1Fom+3ff/991NbW4s033xT7uPzyy3H33XeLfSnMnz8f559/Pu6//3706NEDf//733H66acLwaYnCpIae9A5LW9hrEATS5PSp4WCv2NiAj9gRtOWJipmeuJ4Q2h7g7lgOi6LJmsSiyYj4FjCbT+axjW52y4o2EyoRxPkGwS2NDGGi2ki4UPWodTUVGGdIr777jvhkjvjjDPs25HIMpvNdjcebTNs2DDEOFzcx44di507d+Lo0aP2bej/OULb0HK9QC64xdvci6aWxgo0sTQpooldc8YkK0s8xaAOmSgNq7XJUnlSfpHCoskIONaWVEQThROEvNSbzdJUEiMXBWZLE+MrUdA45HIj61BVVRWys7OFG65Vq1ZiXXFxMdq43CJERUUhIyNDrFO26dSpk9M2bW1/IbSOYqXoWVnmuI2yD3fU1NSIhwJZwIi6ujrxUBNlf972+803Jvx43L1ocowVWL26HsOH+175kkTW9u10mphw+LAV1dUNiN69GxT23dChA6wqjzWQsRuZcI0/qk0bmEpKhIsuPz8dnTurXC3VB2jMUVWKaEqOuHPAqOf+nDkmXH65BQcgC5aRWCUK567HEFEL7tlnrWhokII6fnN+vpjD9tTIVtWSEnlu00o+i1F/e62O35/P0bxoGjlyJH799VccOXIEr7/+Oi699FJhRXIVS6Hm6aefxhNPPNFk+ZdffokEakURBEgwemLt2lzshGfRpPDFF7+istK36N7vvsvGv//dB6Wl0eL9gw9aMHt2LZbn/ASy7e2sq8OuEAXMext7JBDq8Q9PTAQ1U6Eg3blzk/H994Xo2bM05BeVmJNyNfDDNZUhO9e0htHOfSpd8s7E33HhZy9ScBPOxRrxKDDlYtXEuxAb2x2OP3Uwxp/7+WYxh206LMdVPfusBW+9VYsbb9yCQYM00HDRoL+9VsdPRhnDiCbKnOvSpYt4DBw4EKeeeireeOMNPPTQQ8jKykIJBSU7UF9fLzLqaB1Bz4cOHXLaRnnf3DbKenfQ58+cOdPJ0kSZeRR0Tpl8aqtgOnlGjx6N6GhZwLiSmGjCm3Pl4JNcFCIJx3ECyU22GzeuP4YPl92b3liyxITZsy1N2rGUlcXheKmcnXjq2LHoMn48gokvYzcy4Rr/4SdfQ9revcLS9Mby8Vi+vDNycyXMnWvF5MlSyMb+ae0n4nX7Pt0wKMjnmtYw6rlvWrIEls8eatLrKUcqxFWfPQTrtA8hTZ4ctPHT3Fa2VU4+KoAc06TMbbNnn4kPPwzdOR5pv71Wx694igwhmlxpaGiwu8UGDRqE8vJykRU3YMAAsWzVqlViGwoMV7Z55JFHxI+gfPn0Y3Tr1k245pRtvv76a8ygoB8btA0t90RsbKx4uEKfEawf2du+KUsuqV06Sg62Rhscxqn4A5sgV7xVYgUolmDkyKhmrQXkkrv3Xvf96yTJhM6QY5pMnU9FVIj+oIP5veqBUI6fEgZKf8nFTbYMOoXCQnKrRIW08Ht8rWxpSsxKi9jf31DnvpfJxURmJ5gQdd99wMUX08BVH7/y8Stw0F6jyXFuo3nyvvuixMdrwVVnqN9ew+P35zPCGghO9ZTI9UYPYu/eveJ1fn6+KEfw8MMPY+PGjdi/f78QRtdffz0KCgpwySWXiO0p042y3m666Sb88MMP+Pbbb3HnnXeKGCiq/aRk4FEQOJUToNIEH330kciWc7QSTZ8+XWThzZkzB7///rsoSfDTTz+JfekFpQ+lNxedr23hlFoq7ohGLfIgtyXfWMKB4EYtPliAxgKXCiEtPijiBoHEBtl6yn3nDIK3ySUEhZqUj1dqQzlamkLw8YwBCKtoImFy2mmniQdBQoZeP/roo7BYLELAXHzxxaJeExXBLC0txbp160TpAAUqKUBFKc877zyMHz9elB1wrMFE2XYUZ0SCjKxR9957r9i/Yy2nwYMHY8GCBeL/UWbeokWLRKHN3r17Q0/Q3X/eeU1FU1QUFe/03TrgrUZKe+TDDAmVSEB+NefpGg3lolJoE02OhQdDfVEpLQVSIJvN49uyaDIEvhZgClKhJtothS6k2s4rV9EU5I9nDEBY3XMjRoyA5M4HZGOxD4WFKFOOBI83+vbtK8SWN8h6pViw9EzHsd2Ar4Hbzt2JvCuAO+6Q79hbt/Z9H95qpCiuub3ohOwckwpHzGgJ5WJR6MbS5G67UIkmcxqLJkPgawGmIBVqot0qNwIVSHEb9xnEj2cMgG7qNDF+9qA7ulP00r3mGnnxv/7lfy0Vd3SC3D6lKK5z8GupMCFHuVgod+CeRFOwLyrk/lu92mwXTdak1OB+IBP6Qk1ukIJcqIl2e1qrpvFMIa8TxegWFk1Go2tX+XnXLuFLue02+e0nn1BGoG+7oLinWbPcrzvFZmnqdG4nTQRKMsG5phXZLE1tccjeUDVUFxUyMFPrn/vusyAVFWLZiItSWtQKiNFY8CXhIpwaYBIlCHwOvgzw4++93H08k3I4Qfx4xgCwaDIaVKWbesJVVgIvv4zTKtZg8NlWUO2uN97wfTfVcveKJpNHr3hZNHUZw0HgRr6mHUZr1MMi4tdIOIXqokLCiFr+UFyVGVYkQy5vsas4pUWtgBgNQcGVlIJp63GocAht8NYFwU/NPCNLtjQVmpwtTXSzEMrMUEafsGgyGkuXyqKJoOy/kSPx5a6OmIzFePVV37OeXnlFfn7qKXKTABQ2Rs/je8ruObhUWWeMA100Fn5iRolF9sEpMSDBvqgomXtKmGOSTTAp8SehzNxjggydRPv2yZOKLeHmKfwV/6kMgWKx9Z0rNMmi7bnn5MPYu5cFE2PAOk2MD7fpLsH1CeUFWISpmJq/CLNnTxGuD4pJIReLO4vBL78AP/4ol0mhuCinIHLuOxcR0MVDOi0b+OkgLsNH6NSmCgt2D4UlxhKybHQlnqkW0ahBrHDdKJl7I0YE7TCYUEGTD/2QNGdt3YrB+A4Lfr1TTF8eQp7UwXaS7W9oh7g44K672B3H+A5bmoyC6226AybbsnmYgb8+bMUVV8jFMEk8uXN3kEWKoLnMSTCVlwO2JsdsaTI4ixfDtHWLeHkv5uKjkpEwd/ZwwqiEa0aeIpqOCStT41WU08ENxpAh8hPWiymGhHEoLE0U00QhoCyYGH9g0RQhReMoNqU9DmAo1jnNHa5xIlRN/v335de33uqyE7JfE9T3LzFR3eNntGexVALbFArdnDAq4pqR5yyaPG/H6Bzq3mCxoAPy0Q4HYKt1HDwONmbPde8e5M9iDAeLJqPg4+13Noq8VngmwUQx5D16uMmQYtec8fHBYhmswCLXbHRFNFVALjfA6eAGJSkJ6N9fvDwH3+K334L4WbW1gK1fKVmaaJ5jGH9g0WQUfLz9LkK22wrPL7wgB3s/+6y8/JZb3MQVKJYmds0ZlzC2uXDMRrfAikHYIF6b0CDeE5wObnwXXVAtTYVy3bFaUwyOoBVbmhi/YdEUIUXjqAZKPvKwDu5v0++5B7jyykZjkq2XsTNsaTI+YW5zQQHoG+5bjP3mjngcT4pl/bEZ+ZaOYjlnNxlfNAXV0uSUOWdiSxPjNyyaIqVoHHlVME/cs/vCdde5CV1RLE0smoxLmNtc0Ek38NmpyGlwtnZlNxSI5VyoyaCcc4546oMtOLynQsRWBgWbFTW/oZ2YJpVawAzjKyyaIqBoXIUpHZdgEZbAv9v0JqEriqWJ3XPGJZxtLhziqUwhjqdiwgyJ8M6dYUEDBmIjtsiJm0HNnKPs4fj4IH0OY1hYNBm5aBxlOgGo6X82lpim+FX7pEnoSkODvF+CLU3GJZxtLsIYT8VESFwTZ84xLYRFk5GLxj0px4Rkbf0Kn71T7mqA8i90hQIoKfMkKspzN1/G0BZLutB8cUMQS4KHOZ6K0YZoCmoGnYOliUUTEwgsmowMRTn27AlqPDfBtNRugKIsOWod4FfoiuKa69CB05ciyWL50UfirRVm9MJWfGqeYtx4KkYTcU3CPfdLXdAtTRwEzgQCiyajc/HF8vOiRXYD1LRpcusAL6ErTWvicBB45EEnzKWXCosTxZoMwC/BizVxiKcScVPu4EJNxqZ7d1jTMpCAk4jasgn19UH4DLY0MS2ERZPRscU1Yfly4PhxX0JX3Hez5yDwyGXwYPE0CN8J0UThbUFBOSmlxoxP7yclYyjMZpiHyNamM2q/xR9/qLz/hgZINtHEliYmUFg0GZ0+fYAuXYCaGmDZMl9CV9x3s+caTYh00TTEvEFUi1fyAYLClClYfcciHEZrH05KxmiYbKJJrtekctfew4dhqq8XgrwuIwutWqm7eyYyYNFkdOgOXbE20UXHS7IdxTrRM3nimlybuBo4Il00nWOiCt1ScF10AL5OnYK78Lx4fSI7G/UrV3o4KRkjZ9Bt/i048UzFyMKpPaNV3jkTKbBoigQU0USWpqqqJqsdY53o2a33gy1NkQv1BYuLQ5q1DF2xK+iiidwy1LyVKO/SBdLw4eySixTOOAP1UbFoixLsXvEn1q7NxTffmNQpzcXxTIwKsGiKBE4/HaKSGwkmim3yl5MnG9O8WTRFHjEx4mLmGNcUTHbvBjpBtmxWtW0b3A9jtEVsLIpy5XMtdesGzJ17BkaPjhLTV4uLwXONJkYFWDRFiotOyaJ7+WXggw+ANWt8r6ysBLGkpHhoSsdEiotuMDZg8+bgfQzVr3QUTZUsmiIKEkYL9ssuukuwEJfjAwzHGhQdtAqDeYuEk4OliYPAmUBh0RQpZGbKz19/DVxxBTBypGx98mUWcnTN+VNWnDGkaCL3WXV1cD7m8GE5ybMjZKFe1aZNcD6I0RxKF51622XpAizDB7gCazASe9ERk6XFLeqi03CALU1My2HRFAmQMHrkEfd3Xr7cvnEQODNokHjqie1IspZjx47gfAxZmSjYvJOJRVOkQd1xzjy4GA/hn03W5aIACzEVZxxYHHAXneo9sqWpJDpX1OhlmEBg0WR0HJqgNsHXJqgcBM6QeDnlFJgh4Wx8H7S4JhJNWShGnFQNyWzGydYupQcYw1JcYMV8TBei2RU674h5mCG2C4SGfNnSZM5rx3kFTMCwaDI6LW2CSmLqhx/k11SilzvMRy4hiGtyjGcS1cGp1yETEXQ/vA55OOjxokTCqT0OiO38RpIQUyLPg8ndA2jCyTA2WDQZnZY0QSW3HcU9ffut/J6qNauSxsLo2UVHoimYliZFNEl0rjERQ9/WRapu58SxY4iprRQvW/Vj0cQEDosmoxNoE1QSRhTv5Gql8jUOijGspYncc9s2W4NvaWLRFFGYc7NV3c5d5txRpOGUvon+/3+GscGiyejYmqD63plXpTgoxnj07g0pKQkpOI6M4m0oLQ2OaFIy59jSFGEoDZtd+w7aEMsDbNgsOWTOcbkBpiWwaDI63jrzKrg2QW1pHBRjTCwWmAYODJqLrqwMOHrUwT3HKU4ROVfRNCW5zFUkmMSiABs2H9/ZWKOpa1fVjpiJQFg0RQKeOvMSTz7ZtKdXS+KgmIiJa3rrLf9qpDaH0tW+i4VLXET6XGVymauOmFrD+lHgDZvLfpNvAiuS2iE+XpUjZSIUFk2Rgmtn3gsvlJd//716cVCM4flWGmxvp/Luu/7VSPXFNWdBPdpZ5b5z7J6L7LmKGjUf7tFTLPpImoqVyYE3bK7aLVua6rM4CJxpGSyaIgnHzrxz5sjuuqVLge3bnbejmIGcHM/7cRcHxRgeEkYXPiW7507FbtyMV9RrcWETTe1wEBZY5X533s5BxthYLKJR8+6LZaF0MRbj/XcDN2kqMU3RHdupdohMZMKiKVIhx/7kyfLrZ59tKq66dXP//5RYgwBjCxh9ouQGjMQq1EKunfQqblOtxYVrELgo2Wzm6SnSOdyvH+qS05GNYpQsXo8TJ/zfB52TUYdkS9Ox5FzOX2FaBM9KkcwDD8jP771nT8kVfP657MYjXCsyUybeosBjCxh9t7hYhKmIRr3qLS6alBvgeCaGLETR0TBfPFG8vqjmY3z6qX//Xyk1l1ElW5qeX9KOS80xLYJFUyRz9tnAsGFAXR1w773ABx8An30G3HijvP7+++VgbyUOip6pDx0LpohucWEKQosLgms0Me6QyPcLYCoWYcF/fD+/lFJzpQcr0RpHxLKO2KuaO5mJTFg0RTpDhsjPH30EXHEFMGkSUFIiW5Qos84xDoqe2SUXkQS1xQWA8nLgyBG2NDFNkUaOhDUtA21RgpqVa1Fc7Ls7eZK0GHvQxb78v5ikmjuZiUxYNEUydKv19NPu11GdpmXLQn1ETCS2uACwZ4/83C2aRRPjQnQ0LFNl6/Yl0kd46inZKO6t3IWjO7ktioPiTmYiExZNkYq3qt9KwDffijGhaHFhc80RnUwsmhg3XHqpeLoYn+CVl+qFUdxbuQtHd7I5SO5kJjJh0RSpcNVvxh+C2OJCEU0xqEHr2kJ5AYsmxoEl5SNxBJkiNmkE1jTbCjPY7mQmcmHRFKlw1W9GpRYXDSSYWtDiQhFNHbBffpOYCLRqpcZRMwaAjN13z4zCJ7hYvJ+OebgcH4gaYSZJthS5GsWD7U5mIhcWTZEKV/1mVGpxQU1Qv7i+ZWUommTOeeqTyEQc69ebhFG8EPJcNAH/wwe4QtQI24eOItjb1SgebHcyE7mwaIpwd4vHixNX/Wa8teNxSBI4C9/j2T+ntLjvHGfOMZ6M3ZOxGI/hSVs0knNQNwV703pHo/hXNUNxAORORlDcyUzkwqIpwt0tAlfhxFW/GW/QOTFuHNBFTuXuhe345hu5ZEAgHD8OHDrEoolxT3Yb32qElRRZRVbd8uXATbda8CzuFdu7CidyL4spjuc3JgBYNEUyNncLXNwtXPWb8Ym+fcXT+NzNaGiQ66K2qNxArK2FCosmxoFhJt+Cupfcu05k1ZGeJ2Po6bE7xHpTXJzT9iae35gWIDeRYiIXmjgmTpQDAsi+TTFMZLLmOzDGF9G0eDFGtdkMFMgZTDfc4N8uKHhXEVuncLkBxg3mQ74Fa2ejcbt0lOGSmv/Ib/73P7mPIc9vjAqwaGIaq34zTACWpq41m8XzypVARQWQmurbfyeRRaXClMoXWdWyaPr6z044L0iHzOgQH5NRimyB4sRNeB0JOIlt0f3QfdhIWKI4sYBRB3bPMQzTItEUv2cbenevFy0M6aben75gimBKxAl7f7CL7+3IfcEYOxK1evKStEIlL/KRh3WQg7otqMcdeEm8frZuOtatZ8HEqAeLJoZhAoPcaFRTqaYGNw7/Qyz65JPAitErQeBlSMcxUyoXo2d8S1qhRZAwA/PQANnlNhlLRIxTCVrjA0zjUnOMqrBoYhgmMChOpE8f8fKijrKLbulS4O23m+8L5lqMXhFNe9HJXoye6vMwjLekFdLddJYcR5IodklFLx/Fk2Ldq7gFNYjjUnOMqrBoYhgmcGyiqfqnLcIgUFsL/OUv3vuCubvz74h9dtHkbTsmglFqhK1eDSxYAOtXq/Fuwm1i1TKMF8UuqehlH2wVYmo/OnApJkZ1WDQxDNPiuKY/PtncxLLkqS+Yuzt/R0uTt+2YCEdJWpk2DZbzRqDnjYOFQIpGU7Pma7gZH1++mBPlGFVh0cQwTMBYe8miqS9k95wjSsySa3ySUozek2hSitEPGeKpnjPDyMFxZy5+yO0qk+0x8EMOjmPUhUUTwzAB890J2T3XEfuRgoom65X4JMe+YHTnf/XV7kXTfnQUz1ysmWkWW3Ccp8g3ChBvcvIxTAth0cQwTMAcOJEu0r2JPtjicTvH+KSaGmDhQvl1cjL9K9lF08msTlysmfENX4PeODiOUREWTQzDBAzFHW2GZxed43YKlD2+ezeQlQXk5wPrPjuKFBwX61b+0ZEFE+Mbvga9cXAcoyIsmhiGCRiKT9qX7F00tWkDDB4slyF4+WXgscfk5f/8J5CWBgzJtbVPycqCJSk+ZMfO6BwlOM5D0Ut7cBynzzEqwm1UGIYJGIo7OuvGvsBznkXT0aPytaukpHFZTIxcF1ME6VJxJyIjQ37PwUyMP0UvKUWTBJJjtVRFSHFwHKMybGliGKZFnHWDHAze17QFJjTYl5MRgB7UXsVRMBFUz+mDSxajqm1H4PHH5YXbt3su7sQwfhS9FCceB8cxQYAtTQzDtIyuXYXpKKn2BDYs2C/KBlAYCbnkOnd2/18mYzEWYipQKrkv7kQXvAkTQnL4jM4hYTRxopwlR0HfdPKRS44tTIzRLE1r167FhAkTkJOTA5PJhE8//dS+rq6uDg8++CD69OmDxMREsc0111yDwsJCp32UlZXhyiuvREpKCtLS0nDDDTfgxIkTTtts3rwZQ4cORVxcHPLy8jB79uwmx7Jw4UJ0795dbEOfuWzZsiCOnGEMRHQ00LOneDkwYTPVHRT1BzdskDWQK2ZYMR/TRdac2dfiTgzjY9FL8cyCiTGiaKqsrES/fv3w0ktyR2pHqqqq8Msvv+Bvf/ubeF68eDF27tyJiy66yGk7Ekzbtm3DypUrsXTpUiHEbr75Zvv6Y8eOYcyYMejQoQN+/vlnPPPMM3j88cfx2muv2bfZsGEDpk2bJgTXpk2bMGnSJPHYunVrkL8BhjFWZXBs3txspvdQrEMeDnqefGzFnUzr16t/nAzDMHp1z40bN0483JGamiqEkCMvvvgizjrrLOTn56N9+/bYsWMHli9fjh9//BFnnHGG2OaFF17A+PHj8eyzzwrr1Pvvv4/a2lq8+eabiImJQa9evfDrr79i7ty5dnE1f/58nH/++bj//vvF+7///e/is+nzXnnllaB/DwxjRNHkKdM7G37U10lJUePoGIZhIi+mqaKiQrjxyA1HfPfdd+K1IpiIUaNGwWw24/vvv8fkyZPFNsOGDROCSWHs2LGYNWsWjh49ivT0dLHNzJkznT6LtnF0F7pSU1MjHo4WLcWtSA81Ufan9n71QCSPXU/jN/XsKSYT6bffUG871oEDKT43CuRRl6TGtPAi+FY3p751a1EJU+tjj/TfPlhE8vgjeezhGL8/n6Mb0VRdXS1inMiNRvFLRHFxMdpQERgHoqKikJGRIdYp23Tq1NgElGjbtq19HYkmelaWOW6j7MMdTz/9NJ544okmy7/88kskJCQgGLha3iKJSB67HsYfW16O8+nF7t1YsWQJrLGxYvlVV2Vj1qwzRfyS3A0MWIehOIB2yEUBzGK5M7TkZKtWWFlVJWJTtD72YMPjj9zxR/LYQzl+CgcylGgiFXjppZdCkiT861//ghZ46KGHnKxTZGmiIHOKn1JEnZrjp5Nn9OjRiKag2wgikseut/FLDzwAU0kJzs/Lg2Sz/o4fD5x+uhUzZ1rsQeENsODJzHl4rXRq033Y6uvEvPQSRp9/vm7GHum/fTCI5PFH8tjDMX7FU2QI0aQIpv3792PVqlVOgiQrKwslLgVg6uvrRUYdrVO2OXTokNM2yvvmtlHWuyM2NlY8XKEfOFg/cjD3rXUieey6GX+fPsDXXyOK6i0NGmRffOmlwMUXu2SED5oIU7tWwJEjTrswUX2defMQNWUKJJvJXBdjDyI8/sgdfySPPZTj9+czzHoQTH/88Qe++uorZGZmOq0fNGgQysvLRVacAgmrhoYGnH322fZtKKPO0WdJCrZbt27CNads8/XXXzvtm7ah5QzD+BkMvmVL8xnhyz6XBRP9Ta9YASxYAKxeDezdywUJGYbRLGG1NFE9pd3UudPG3r17RWYbxSRlZ2dj6tSpotwAlRKwWq32GCNaT4HdPXr0EFlvN910k8hyI2F055134vLLLxeZc8QVV1whYo+onADFRFEZAcqWe+655+yfO336dAwfPhxz5szBBRdcgA8//BA//fSTU1kChmGaoXdv+ZniEKjRnLcCg88/Lz/fcgswZkzojpFhGKYFhNXSRMLktNNOEw+CYoTo9aOPPoqCggL897//xcGDB9G/f38hopQH1VVSoJICVJTyvPPOE6UGhgwZ4iR2qHQBBWeTIBswYADuvfdesX/HWk6DBw/GggULxP+julGLFi0SmXO9lYsAwzDeodYnDz0kvyb33MiRnluikCWKRBUJqttuC/mhMgzD6NLSNGLECBHc7Qlv6xTI6kSCxxt9+/bFOgqo8MIll1wiHgzD+AkJI2p9InlpieLocnvhBfl58mS5RxjDMIxO0HRME8MwGodanUyf3lQweWqJUlYGvPee/Pruu0N4oAzDMC1H89lzDMNoGLLgHjzoeb2tJYrdHUeu85Mn5aDxIUNCeaQMwzAthkUTwzCB46nBnCtUd4CsTAokpJYs4Uw5hmF0BbvnGIYJHE8N5lxxFExEebkc7+QuUJxhGEajsGhiGCZwqKwABXPbKnn7jLt4J4ZhGI3DoolhmMChOKX58+XXgQgnctM1k9nKMAyjFVg0MQzTMiguicoK5OY6L8/IUDcuimEYJsxwIDjDMOoIp4kTnRvMkdtt1Cj14qIYhmHCDIsmhmHUQWkwp0CiieKdqMiluzpO5M6j9RQXxTAMowPYPccwTOjjnZT38+Z57k/HMAyjMVg0MQwT+ngnsjC5tldhGIbROOyeYxgm9PFO5JJjCxPDMDqDRRPDMKGPd2IYhtEh7J5jGIZhGIbxARZNDMMwDMMwPsCiiWEYhmEYxgdYNDEMwzAMw/gAiyaGYRiGYRgfYNHEMAzDMAzjAyyaGIZhGIZhfIBFE8MwDMMwjA+waGIYhmEYhvEBrgiuEpKti/uxY8dU33ddXR2qqqrEvqOjoxFJRPLYI338kTx2gscfueOP5LGHY/zKdVu5jnuDRZNKHD9+XDzn5eWF+1AYhmEYhgngOp6amup1G5Pki7RimqWhoQGFhYVITk6GyWRSXQWTGDtw4ABSUlIQSUTy2CN9/JE8doLHH7njj+Sxh2P8JINIMOXk5MBs9h61xJYmlaAvul27dkH9DDp5IvEPKNLHHunjj+SxEzz+yB1/JI891ONvzsKkwIHgDMMwDMMwPsCiiWEYhmEYxgdYNOmA2NhYPPbYY+I50ojksUf6+CN57ASPP3LHH8lj1/r4ORCcYRiGYRjGB9jSxDAMwzAM4wMsmhiGYRiGYXyARRPDMAzDMIwPsGhiGIZhGIbxARZNGuell15Cx44dERcXh7PPPhs//PADjMjatWsxYcIEUZGVKqp/+umnTuspX+HRRx9FdnY24uPjMWrUKPzxxx8wAk8//TTOPPNMUU2+TZs2mDRpEnbu3Om0TXV1Ne644w5kZmYiKSkJF198MQ4dOgQj8K9//Qt9+/a1F7IbNGgQvvjii4gYuyv//Oc/xfk/Y8aMiBj/448/Lsbr+OjevXtEjJ0oKCjAVVddJcZH81qfPn3w008/RcS817Fjxya/PT3o99byb8+iScN89NFHmDlzpki9/OWXX9CvXz+MHTsWJSUlMBqVlZVifCQS3TF79mw8//zzeOWVV/D9998jMTFRfBf0h6V3vvnmGzE5bNy4EStXrhTNKseMGSO+E4V77rkHn3/+ORYuXCi2p5Y9U6ZMgRGgSvokFn7++WdxwTj33HMxceJEbNu2zfBjd+THH3/Eq6++KgSkI0Yff69evVBUVGR/rF+/PiLGfvToUZxzzjmiIS3dJGzfvh1z5sxBenp6RMx7P/74o9PvTnMfcckll2j7t6eSA4w2Oeuss6Q77rjD/t5qtUo5OTnS008/LRkZOi2XLFlif9/Q0CBlZWVJzzzzjH1ZeXm5FBsbK33wwQeS0SgpKRHfwTfffGMfa3R0tLRw4UL7Njt27BDbfPfdd5IRSU9Pl/79739HzNiPHz8unXrqqdLKlSul4cOHS9OnTxfLjT7+xx57TOrXr5/bdUYf+4MPPigNGTLE4/pIm/emT58unXLKKWLcWv7t2dKkUWpra8WdN5ljHfvb0fvvvvsOkcTevXtRXFzs9F1QnyByVxrxu6ioqBDPGRkZ4pnOA7I+OY6fXBjt27c33PitVis+/PBDYWUjN12kjJ0sjRdccIHTOIlIGD+5m8gt37lzZ1x55ZXIz8+PiLH/97//xRlnnCEsK+SWP+200/D6669H5LxXW1uL9957D9dff71w0Wn5t2fRpFGOHDkiLiBt27Z1Wk7v6Q8pklDGGwnfRUNDg4hnIbN97969xTIaY0xMDNLS0gw7/i1btoi4BaoAfOutt2LJkiXo2bNnRIydRCK53ym2zRWjj58EwNtvv43ly5eL2DYSCkOHDhUd540+9j///FOM+dRTT8WKFStw22234e6778Y777wTcfPep59+ivLyclx33XXivZZ/+6iwfjrDME0sDlu3bnWK64gEunXrhl9//VVY2RYtWoRrr71WxDEYnQMHDmD69OkinoOSPSKNcePG2V9TLBeJqA4dOuDjjz8Wgc9Ghm6QyNL0f//3f+I9WZrob5/il+j8jyTeeOMNcS6QxVHrsKVJo7Rq1QoWi6VJtgC9z8rKQiShjNfo38Wdd96JpUuXYvXq1SI4WoHGSOZruhMz6vjprrJLly4YMGCAsLhQUsD8+fMNP3ZyQ1Bix+mnn46oqCjxILFIwb/0mu6sjTx+V8iy0LVrV+zevdvwvz1lxJE11ZEePXrY3ZORMu/t378fX331FW688Ub7Mi3/9iyaNHwRoQvI119/7XRnQu8p1iOS6NSpk/hDcfwujh07JrJJjPBdUOw7CSZySa1atUqM1xE6DyjDxnH8VJKAJlcjjN8ddK7X1NQYfuznnXeecE2SlU15kPWBYnuU10YevysnTpzAnj17hKAw+m9PLnjX0iK7du0SlrZImPcU3nrrLRHTRTF9Cpr+7cMahs545cMPPxSZEm+//ba0fft26eabb5bS0tKk4uJiyWhQ9tCmTZvEg07LuXPnitf79+8X6//5z3+KsX/22WfS5s2bpYkTJ0qdOnWSTp48Kemd2267TUpNTZXWrFkjFRUV2R9VVVX2bW699Vapffv20qpVq6SffvpJGjRokHgYgf/3//6fyBTcu3ev+G3pvclkkr788kvDj90djtlzRh//vffeK857+u2//fZbadSoUVKrVq1EBqnRx/7DDz9IUVFR0j/+8Q/pjz/+kN5//30pISFBeu+99+zbGHneUzLC6felTEJXtPrbs2jSOC+88II4cWJiYkQJgo0bN0pGZPXq1UIsuT6uvfZasZ7SUP/2t79Jbdu2FULyvPPOk3bu3CkZAXfjpsdbb71l34Ymydtvv12k4tPEOnnyZCGsjMD1118vdejQQZzjrVu3Fr+tIpiMPnZfRJORx3/ZZZdJ2dnZ4rfPzc0V73fv3h0RYyc+//xzqXfv3mJO6969u/Taa685rTfyvEesWLFCzHXuxqTV395E/4TX1sUwDMMwDKN9OKaJYRiGYRjGB1g0MQzDMAzD+ACLJoZhGIZhGB9g0cQwDMMwDOMDLJoYhmEYhmF8gEUTwzAMwzCMD7BoYhiGYRiG8QEWTQzDMD5gMplEN3aGYSIXFk0Mwxie6667DpMmTQr3YTAMo3NYNDEMwzAMw/gAiyaGYSKKESNG4O6778YDDzyAjIwM0Un+8ccfd9rmjz/+wLBhwxAXF4eePXti5cqVTfZz4MABXHrppUhLSxP7mThxIvbt2yfW/f7770hISMCCBQvs23/88ceIj4/H9u3bQzBKhmGCAYsmhmEijnfeeQeJiYn4/vvvMXv2bDz55JN2YdTQ0IApU6YgJiZGrH/llVfw4IMPOv3/uro6jB07FsnJyVi3bh2+/fZbJCUl4fzzz0dtbS26d++OZ599Frfffjvy8/Nx8OBB3HrrrZg1a5YQYQzD6BNu2MswTETENJWXl4tAbrI0Wa1WIXYUzjrrLJx77rn45z//iS+//BIXXHAB9u/fj5ycHLF++fLlGDduHJYsWSJio9577z089dRT2LFjhwgQJ0gskdWJPmPMmDFi2YUXXohjx44JAWaxWMR+lO0ZhtEfUeE+AIZhmFDTt29fp/fZ2dkoKSkRr0kI5eXl2QUTMWjQIKftf/vtN+zevVtYmhyprq7Gnj177O/ffPNNdO3aFWazGdu2bWPBxDA6h0UTwzARR3R0tNN7EjPklvOVEydOYMCAAXj//febrGvdurWTuKqsrBSiqaioSIgzhmH0C4smhmEYB3r06CGCvB1FzsaNG522Of300/HRRx+hTZs2SElJcbufsrIy4RZ85JFHxL6uvPJK/PLLLyIYnGEYfcKB4AzDMA6MGjVKuNSuvfZaYSmi2CcSPo6QAGrVqpXImKP1e/fuxZo1a0RWHgV9ExT4TW6+v/71r5g7d66Io7rvvvvCNCqGYdSARRPDMIwD5EqjgO+TJ0+KAPEbb7wR//jHP5y2oXICa9euRfv27UWmHVmnbrjhBhHTRJand999F8uWLcN//vMfREVFiUw9Ch5//fXX8cUXX4RtbAzDtAzOnmMYhmEYhvEBtjQxDMMwDMP4AIsmhmEYhmEYH2DRxDAMwzAM4wMsmhiGYRiGYXyARRPDMAzDMIwPsGhiGIZhGIbxARZNDMMwDMMwPsCiiWEYhmEYxgdYNDEMwzAMw/gAiyaGYRiGYRgfYNHEMAzDMAzjAyyaGIZhGIZh0Dz/H2eCakYNJIRrAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "547af856-e054-4279-96e4-e1e4264db04d",
   "metadata": {},
   "source": [
    "## Comed"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T18:18:58.757426Z",
     "start_time": "2025-10-10T18:18:56.587919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import model_summary as model_class\n",
    "import prophet_linear_adjust as prophet_based\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "498db8ff6ea6c4cc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8da89f60-d42c-4b68-b83f-b10f930f69c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T18:18:58.818693Z",
     "start_time": "2025-10-10T18:18:58.766522Z"
    }
   },
   "source": [
    "df_comed = pd.read_csv(\"COMED_hourly.csv\")\n",
    "df_comed.rename(columns={'Datetime': 'ds', 'COMED_MW': 'y'}, inplace=True)\n",
    "df_comed['ds'] = pd.to_datetime(df_comed['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "out_dir = 'Comed_results'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "a72919bd420eae26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T17:57:59.968618Z",
     "start_time": "2025-10-03T17:49:26.645624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_demand_comed = df_comed.groupby(df_comed['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_comed, date_start, date_end, daily_demand_comed, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv(out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "68fe5f9ff5d05326",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:49:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:49:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:49:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:49:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:49:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:49:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:49:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:49:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:49:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:50:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:50:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:50:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:50:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:50:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:50:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:50:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:50:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:50:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:51:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:51:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:51:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:51:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:51:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:51:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:51:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:52:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:52:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:52:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:52:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:52:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:52:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:52:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:52:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:52:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:52:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:52:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:52:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:52:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:52:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:53:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:53:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:53:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:53:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:53:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:53:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:53:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:53:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:53:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:53:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:53:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:53:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:53:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:54:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:54:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:54:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:54:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:54:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:54:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:54:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:54:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:54:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:55:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:55:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:55:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:55:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:55:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:55:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:55:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:55:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:56:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:56:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:57:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:57:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:57:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:57:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:57:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:57:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:57:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:57:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with weekly seasonality",
   "id": "6fa4ad7e711b555b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T18:07:22.276754Z",
     "start_time": "2025-10-03T17:58:00.164644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_demand_comed = df_comed.groupby(df_comed['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet_w = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_comed, date_start, date_end, daily_demand_comed, manual = False, daily = True, weekly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_w.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_w = pd.concat(results_prophet_w, ignore_index=True)\n",
    "\n",
    "results_prophet_w.to_csv(out_dir + '/results_prophet_w.csv', index=False)"
   ],
   "id": "56304448d5c902b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:58:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:58:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:58:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:58:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:58:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:58:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:58:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:58:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:58:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:58:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:58:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:58:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:58:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:59:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:59:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:59:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:59:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:59:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:59:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:59:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:59:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:59:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:59:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:59:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:59:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:59:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:59:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:00:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:00:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:00:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:00:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:00:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:00:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:00:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:00:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:01:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:01:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:01:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:01:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:01:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:01:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:02:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:02:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:02:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:02:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:02:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:02:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:02:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:02:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:03:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:03:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:03:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:03:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:03:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:03:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:03:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:03:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:03:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:03:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:03:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:03:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:03:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:03:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:03:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:03:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:04:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:04:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:04:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:04:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:04:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:04:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:04:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:04:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:05:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:05:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:05:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:05:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:05:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:05:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:05:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:05:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:05:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:06:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:06:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:06:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:06:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:06:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:06:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:06:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:06:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:06:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:06:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:06:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:06:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:06:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:07:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:07:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:07:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:07:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:07:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "f9ee246e-5e4c-45dc-b92d-c225f8cc6dd5",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "a9fbb12a-f16f-4437-acbf-e9ba9bdc7a2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:12:54.319518Z",
     "start_time": "2025-10-03T12:11:24.475721Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con.to_csv(out_dir + '/results_aep_self_con.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1 loss: 0.7224190831184387\n",
      "epoch 2 loss: 1.0079119205474854\n",
      "epoch 3 loss: 0.8181241154670715\n",
      "epoch 4 loss: 0.42989909648895264\n",
      "epoch 5 loss: 0.2359398752450943\n",
      "epoch 6 loss: 0.1516084372997284\n",
      "epoch 7 loss: 0.15498685836791992\n",
      "epoch 8 loss: 0.11114595830440521\n",
      "epoch 9 loss: 0.1274639368057251\n",
      "epoch 10 loss: 0.10806287080049515\n",
      "epoch 11 loss: 0.10129054635763168\n",
      "epoch 12 loss: 0.10762539505958557\n",
      "epoch 13 loss: 0.1259184032678604\n",
      "epoch 14 loss: 0.11505265533924103\n",
      "epoch 15 loss: 0.07783318310976028\n",
      "epoch 16 loss: 0.11646763980388641\n",
      "epoch 17 loss: 0.06786362081766129\n",
      "epoch 18 loss: 0.1013534665107727\n",
      "epoch 19 loss: 0.10002484917640686\n",
      "epoch 20 loss: 0.07774552702903748\n",
      "epoch 21 loss: 0.08645369857549667\n",
      "epoch 22 loss: 0.0798366442322731\n",
      "epoch 23 loss: 0.06444624066352844\n",
      "epoch 24 loss: 0.09933337569236755\n",
      "epoch 25 loss: 0.07381157577037811\n",
      "epoch 26 loss: 0.09330100566148758\n",
      "epoch 27 loss: 0.09152530878782272\n",
      "epoch 28 loss: 0.07226663082838058\n",
      "epoch 29 loss: 0.08064039051532745\n",
      "epoch 30 loss: 0.08961790055036545\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_60650/1895582977.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.839419960975647\n",
      "epoch 2 loss: 0.5242214202880859\n",
      "epoch 3 loss: 0.29251426458358765\n",
      "epoch 4 loss: 0.230041965842247\n",
      "epoch 5 loss: 0.22204993665218353\n",
      "epoch 6 loss: 0.15605825185775757\n",
      "epoch 7 loss: 0.1479824036359787\n",
      "epoch 8 loss: 0.13960663974285126\n",
      "epoch 9 loss: 0.13316573202610016\n",
      "epoch 10 loss: 0.134592667222023\n",
      "epoch 11 loss: 0.14441342651844025\n",
      "epoch 12 loss: 0.10419359058141708\n",
      "epoch 13 loss: 0.10747342556715012\n",
      "epoch 14 loss: 0.1368257850408554\n",
      "epoch 15 loss: 0.13046681880950928\n",
      "epoch 16 loss: 0.08427700400352478\n",
      "epoch 17 loss: 0.07936172187328339\n",
      "epoch 18 loss: 0.13292406499385834\n",
      "epoch 19 loss: 0.09054283052682877\n",
      "epoch 20 loss: 0.08990401774644852\n",
      "epoch 21 loss: 0.08795175701379776\n",
      "epoch 22 loss: 0.13544891774654388\n",
      "epoch 23 loss: 0.07927411794662476\n",
      "epoch 24 loss: 0.07247035205364227\n",
      "epoch 25 loss: 0.07294826954603195\n",
      "epoch 26 loss: 0.10418640077114105\n",
      "epoch 27 loss: 0.07726743817329407\n",
      "epoch 28 loss: 0.0793791264295578\n",
      "epoch 29 loss: 0.07603930681943893\n",
      "epoch 30 loss: 0.08294741809368134\n",
      "3\n",
      "epoch 1 loss: 0.8703812956809998\n",
      "epoch 2 loss: 0.9899197816848755\n",
      "epoch 3 loss: 0.7237153053283691\n",
      "epoch 4 loss: 0.5355163216590881\n",
      "epoch 5 loss: 0.26729512214660645\n",
      "epoch 6 loss: 0.18906457722187042\n",
      "epoch 7 loss: 0.13849730789661407\n",
      "epoch 8 loss: 0.1429906040430069\n",
      "epoch 9 loss: 0.0902952179312706\n",
      "epoch 10 loss: 0.0928788036108017\n",
      "epoch 11 loss: 0.09236764907836914\n",
      "epoch 12 loss: 0.0730772316455841\n",
      "epoch 13 loss: 0.12312327325344086\n",
      "epoch 14 loss: 0.10184687376022339\n",
      "epoch 15 loss: 0.09666081517934799\n",
      "epoch 16 loss: 0.10043580830097198\n",
      "epoch 17 loss: 0.09298110008239746\n",
      "epoch 18 loss: 0.10882896184921265\n",
      "epoch 19 loss: 0.08165014535188675\n",
      "epoch 20 loss: 0.08391360938549042\n",
      "epoch 21 loss: 0.08383665233850479\n",
      "epoch 22 loss: 0.07456574589014053\n",
      "epoch 23 loss: 0.08417396247386932\n",
      "epoch 24 loss: 0.07663065940141678\n",
      "epoch 25 loss: 0.09076562523841858\n",
      "epoch 26 loss: 0.10943475365638733\n",
      "epoch 27 loss: 0.08173096179962158\n",
      "epoch 28 loss: 0.05669550225138664\n",
      "epoch 29 loss: 0.0817629024386406\n",
      "epoch 30 loss: 0.07643663883209229\n",
      "4\n",
      "epoch 1 loss: 0.7114657759666443\n",
      "epoch 2 loss: 0.7928512096405029\n",
      "epoch 3 loss: 0.8060733079910278\n",
      "epoch 4 loss: 0.3867282271385193\n",
      "epoch 5 loss: 0.27067771553993225\n",
      "epoch 6 loss: 0.19066117703914642\n",
      "epoch 7 loss: 0.14522765576839447\n",
      "epoch 8 loss: 0.1386023312807083\n",
      "epoch 9 loss: 0.13381938636302948\n",
      "epoch 10 loss: 0.12496906518936157\n",
      "epoch 11 loss: 0.08500777930021286\n",
      "epoch 12 loss: 0.07593102008104324\n",
      "epoch 13 loss: 0.07767539471387863\n",
      "epoch 14 loss: 0.09617168456315994\n",
      "epoch 15 loss: 0.08948898315429688\n",
      "epoch 16 loss: 0.0872737392783165\n",
      "epoch 17 loss: 0.06469883024692535\n",
      "epoch 18 loss: 0.07299692183732986\n",
      "epoch 19 loss: 0.07206041365861893\n",
      "epoch 20 loss: 0.07721947133541107\n",
      "epoch 21 loss: 0.06976296752691269\n",
      "epoch 22 loss: 0.0639948770403862\n",
      "epoch 23 loss: 0.07287640124559402\n",
      "epoch 24 loss: 0.08708889037370682\n",
      "epoch 25 loss: 0.08437884598970413\n",
      "epoch 26 loss: 0.07758940756320953\n",
      "epoch 27 loss: 0.07726939022541046\n",
      "epoch 28 loss: 0.06394407898187637\n",
      "epoch 29 loss: 0.06976040452718735\n",
      "epoch 30 loss: 0.06474314630031586\n",
      "5\n",
      "epoch 1 loss: 1.0412256717681885\n",
      "epoch 2 loss: 0.4038180112838745\n",
      "epoch 3 loss: 0.4664325714111328\n",
      "epoch 4 loss: 0.16817674040794373\n",
      "epoch 5 loss: 0.13677507638931274\n",
      "epoch 6 loss: 0.15112145245075226\n",
      "epoch 7 loss: 0.16891078650951385\n",
      "epoch 8 loss: 0.10521586239337921\n",
      "epoch 9 loss: 0.09556445479393005\n",
      "epoch 10 loss: 0.12074596434831619\n",
      "epoch 11 loss: 0.10259389877319336\n",
      "epoch 12 loss: 0.12132355570793152\n",
      "epoch 13 loss: 0.12047003954648972\n",
      "epoch 14 loss: 0.1420292854309082\n",
      "epoch 15 loss: 0.09557490050792694\n",
      "epoch 16 loss: 0.08396362513303757\n",
      "epoch 17 loss: 0.10794007033109665\n",
      "epoch 18 loss: 0.12344513088464737\n",
      "epoch 19 loss: 0.11242323368787766\n",
      "epoch 20 loss: 0.11210772395133972\n",
      "epoch 21 loss: 0.08385864645242691\n",
      "epoch 22 loss: 0.09787461906671524\n",
      "epoch 23 loss: 0.10582257807254791\n",
      "epoch 24 loss: 0.07654032856225967\n",
      "epoch 25 loss: 0.08316031098365784\n",
      "epoch 26 loss: 0.0821484625339508\n",
      "epoch 27 loss: 0.08527018874883652\n",
      "epoch 28 loss: 0.09583573043346405\n",
      "epoch 29 loss: 0.11446461081504822\n",
      "epoch 30 loss: 0.06075163558125496\n",
      "6\n",
      "epoch 1 loss: 0.9461305737495422\n",
      "epoch 2 loss: 0.4633040726184845\n",
      "epoch 3 loss: 0.4444562792778015\n",
      "epoch 4 loss: 0.22967566549777985\n",
      "epoch 5 loss: 0.17497500777244568\n",
      "epoch 6 loss: 0.1663765162229538\n",
      "epoch 7 loss: 0.1775606870651245\n",
      "epoch 8 loss: 0.10315915197134018\n",
      "epoch 9 loss: 0.11080402880907059\n",
      "epoch 10 loss: 0.16068404912948608\n",
      "epoch 11 loss: 0.10309772193431854\n",
      "epoch 12 loss: 0.10297536849975586\n",
      "epoch 13 loss: 0.09817833453416824\n",
      "epoch 14 loss: 0.0873500257730484\n",
      "epoch 15 loss: 0.0896867886185646\n",
      "epoch 16 loss: 0.09724520146846771\n",
      "epoch 17 loss: 0.08616239577531815\n",
      "epoch 18 loss: 0.09354691207408905\n",
      "epoch 19 loss: 0.08044945448637009\n",
      "epoch 20 loss: 0.07395371049642563\n",
      "epoch 21 loss: 0.09525924175977707\n",
      "epoch 22 loss: 0.09462275356054306\n",
      "epoch 23 loss: 0.08040035516023636\n",
      "epoch 24 loss: 0.07069502770900726\n",
      "epoch 25 loss: 0.06799297779798508\n",
      "epoch 26 loss: 0.05926727131009102\n",
      "epoch 27 loss: 0.07095358520746231\n",
      "epoch 28 loss: 0.07291988283395767\n",
      "epoch 29 loss: 0.06998052448034286\n",
      "epoch 30 loss: 0.06251660734415054\n",
      "7\n",
      "epoch 1 loss: 0.9812006950378418\n",
      "epoch 2 loss: 0.7757883071899414\n",
      "epoch 3 loss: 0.33538275957107544\n",
      "epoch 4 loss: 0.20019689202308655\n",
      "epoch 5 loss: 0.16686908900737762\n",
      "epoch 6 loss: 0.11128878593444824\n",
      "epoch 7 loss: 0.15598176419734955\n",
      "epoch 8 loss: 0.10496071726083755\n",
      "epoch 9 loss: 0.1588181108236313\n",
      "epoch 10 loss: 0.10862287878990173\n",
      "epoch 11 loss: 0.08537314087152481\n",
      "epoch 12 loss: 0.09494541585445404\n",
      "epoch 13 loss: 0.11288125813007355\n",
      "epoch 14 loss: 0.11244736611843109\n",
      "epoch 15 loss: 0.10461120307445526\n",
      "epoch 16 loss: 0.09411748498678207\n",
      "epoch 17 loss: 0.09130562841892242\n",
      "epoch 18 loss: 0.07496941834688187\n",
      "epoch 19 loss: 0.08938439935445786\n",
      "epoch 20 loss: 0.09124397486448288\n",
      "epoch 21 loss: 0.0738830417394638\n",
      "epoch 22 loss: 0.0686613917350769\n",
      "epoch 23 loss: 0.08200355619192123\n",
      "epoch 24 loss: 0.06764021515846252\n",
      "epoch 25 loss: 0.07152502983808517\n",
      "epoch 26 loss: 0.10017793625593185\n",
      "epoch 27 loss: 0.08236072957515717\n",
      "epoch 28 loss: 0.07033690810203552\n",
      "epoch 29 loss: 0.06839007139205933\n",
      "epoch 30 loss: 0.06553542613983154\n",
      "8\n",
      "epoch 1 loss: 0.9201651215553284\n",
      "epoch 2 loss: 0.7283837199211121\n",
      "epoch 3 loss: 0.33392131328582764\n",
      "epoch 4 loss: 0.2235766053199768\n",
      "epoch 5 loss: 0.14224940538406372\n",
      "epoch 6 loss: 0.11564938724040985\n",
      "epoch 7 loss: 0.1721000224351883\n",
      "epoch 8 loss: 0.10994184762239456\n",
      "epoch 9 loss: 0.12544889748096466\n",
      "epoch 10 loss: 0.10236246883869171\n",
      "epoch 11 loss: 0.09717066586017609\n",
      "epoch 12 loss: 0.11637604981660843\n",
      "epoch 13 loss: 0.10738184303045273\n",
      "epoch 14 loss: 0.07323666661977768\n",
      "epoch 15 loss: 0.09512694180011749\n",
      "epoch 16 loss: 0.10898946225643158\n",
      "epoch 17 loss: 0.09836531430482864\n",
      "epoch 18 loss: 0.0867137685418129\n",
      "epoch 19 loss: 0.11242321133613586\n",
      "epoch 20 loss: 0.10764508694410324\n",
      "epoch 21 loss: 0.08288834989070892\n",
      "epoch 22 loss: 0.08146446943283081\n",
      "epoch 23 loss: 0.09911398589611053\n",
      "epoch 24 loss: 0.09325447678565979\n",
      "epoch 25 loss: 0.08671174943447113\n",
      "epoch 26 loss: 0.08253523707389832\n",
      "epoch 27 loss: 0.08213824778795242\n",
      "epoch 28 loss: 0.08064326643943787\n",
      "epoch 29 loss: 0.07119756191968918\n",
      "epoch 30 loss: 0.07522261142730713\n",
      "9\n",
      "epoch 1 loss: 0.7796199917793274\n",
      "epoch 2 loss: 0.6449695825576782\n",
      "epoch 3 loss: 0.6921985149383545\n",
      "epoch 4 loss: 0.4545125663280487\n",
      "epoch 5 loss: 0.23767037689685822\n",
      "epoch 6 loss: 0.14177162945270538\n",
      "epoch 7 loss: 0.15300367772579193\n",
      "epoch 8 loss: 0.142703577876091\n",
      "epoch 9 loss: 0.11751678586006165\n",
      "epoch 10 loss: 0.07824535667896271\n",
      "epoch 11 loss: 0.09733177721500397\n",
      "epoch 12 loss: 0.1082068458199501\n",
      "epoch 13 loss: 0.07802600413560867\n",
      "epoch 14 loss: 0.0971868634223938\n",
      "epoch 15 loss: 0.07833784073591232\n",
      "epoch 16 loss: 0.10718517750501633\n",
      "epoch 17 loss: 0.08985978364944458\n",
      "epoch 18 loss: 0.1261603683233261\n",
      "epoch 19 loss: 0.14077478647232056\n",
      "epoch 20 loss: 0.09641972929239273\n",
      "epoch 21 loss: 0.07908108830451965\n",
      "epoch 22 loss: 0.09437982738018036\n",
      "epoch 23 loss: 0.07274290174245834\n",
      "epoch 24 loss: 0.07391272485256195\n",
      "epoch 25 loss: 0.09660901874303818\n",
      "epoch 26 loss: 0.08787841349840164\n",
      "epoch 27 loss: 0.06771625578403473\n",
      "epoch 28 loss: 0.08335843682289124\n",
      "epoch 29 loss: 0.0748220756649971\n",
      "epoch 30 loss: 0.06766094267368317\n",
      "10\n",
      "epoch 1 loss: 0.7299037575721741\n",
      "epoch 2 loss: 0.6852284073829651\n",
      "epoch 3 loss: 0.39615482091903687\n",
      "epoch 4 loss: 0.32471197843551636\n",
      "epoch 5 loss: 0.24783384799957275\n",
      "epoch 6 loss: 0.13962049782276154\n",
      "epoch 7 loss: 0.12605728209018707\n",
      "epoch 8 loss: 0.14131072163581848\n",
      "epoch 9 loss: 0.11715869605541229\n",
      "epoch 10 loss: 0.09273353964090347\n",
      "epoch 11 loss: 0.10671843588352203\n",
      "epoch 12 loss: 0.10202936828136444\n",
      "epoch 13 loss: 0.10136154294013977\n",
      "epoch 14 loss: 0.10169783979654312\n",
      "epoch 15 loss: 0.09843913465738297\n",
      "epoch 16 loss: 0.06965068727731705\n",
      "epoch 17 loss: 0.082132488489151\n",
      "epoch 18 loss: 0.07417432218790054\n",
      "epoch 19 loss: 0.08463796228170395\n",
      "epoch 20 loss: 0.0886617973446846\n",
      "epoch 21 loss: 0.06446108967065811\n",
      "epoch 22 loss: 0.07572345435619354\n",
      "epoch 23 loss: 0.07954170554876328\n",
      "epoch 24 loss: 0.09403671324253082\n",
      "epoch 25 loss: 0.09557073563337326\n",
      "epoch 26 loss: 0.07019276171922684\n",
      "epoch 27 loss: 0.11393725872039795\n",
      "epoch 28 loss: 0.08230474591255188\n",
      "epoch 29 loss: 0.07135269045829773\n",
      "epoch 30 loss: 0.06957346946001053\n",
      "11\n",
      "epoch 1 loss: 1.0688321590423584\n",
      "epoch 2 loss: 0.5958719849586487\n",
      "epoch 3 loss: 0.3913331627845764\n",
      "epoch 4 loss: 0.24198883771896362\n",
      "epoch 5 loss: 0.1371452957391739\n",
      "epoch 6 loss: 0.1358555108308792\n",
      "epoch 7 loss: 0.11066924780607224\n",
      "epoch 8 loss: 0.10703177005052567\n",
      "epoch 9 loss: 0.0924181193113327\n",
      "epoch 10 loss: 0.09955144673585892\n",
      "epoch 11 loss: 0.09656725078821182\n",
      "epoch 12 loss: 0.09117560088634491\n",
      "epoch 13 loss: 0.09240798652172089\n",
      "epoch 14 loss: 0.09128513932228088\n",
      "epoch 15 loss: 0.12023082375526428\n",
      "epoch 16 loss: 0.12191353738307953\n",
      "epoch 17 loss: 0.09313914179801941\n",
      "epoch 18 loss: 0.08793802559375763\n",
      "epoch 19 loss: 0.06968620419502258\n",
      "epoch 20 loss: 0.07838089019060135\n",
      "epoch 21 loss: 0.09952741116285324\n",
      "epoch 22 loss: 0.0792323425412178\n",
      "epoch 23 loss: 0.07186733931303024\n",
      "epoch 24 loss: 0.07094736397266388\n",
      "epoch 25 loss: 0.08495556563138962\n",
      "epoch 26 loss: 0.10181013494729996\n",
      "epoch 27 loss: 0.0879281535744667\n",
      "epoch 28 loss: 0.06089819222688675\n",
      "epoch 29 loss: 0.07779621332883835\n",
      "epoch 30 loss: 0.06523564457893372\n",
      "12\n",
      "epoch 1 loss: 0.5731995701789856\n",
      "epoch 2 loss: 0.4828391373157501\n",
      "epoch 3 loss: 0.2637939751148224\n",
      "epoch 4 loss: 0.1597839891910553\n",
      "epoch 5 loss: 0.12293330579996109\n",
      "epoch 6 loss: 0.17151214182376862\n",
      "epoch 7 loss: 0.11416711658239365\n",
      "epoch 8 loss: 0.10517873615026474\n",
      "epoch 9 loss: 0.09621574729681015\n",
      "epoch 10 loss: 0.12140259146690369\n",
      "epoch 11 loss: 0.17515943944454193\n",
      "epoch 12 loss: 0.12199173867702484\n",
      "epoch 13 loss: 0.08915730565786362\n",
      "epoch 14 loss: 0.0776396170258522\n",
      "epoch 15 loss: 0.0822957307100296\n",
      "epoch 16 loss: 0.08403327316045761\n",
      "epoch 17 loss: 0.10649844259023666\n",
      "epoch 18 loss: 0.081964410841465\n",
      "epoch 19 loss: 0.09018099308013916\n",
      "epoch 20 loss: 0.08390624821186066\n",
      "epoch 21 loss: 0.09438921511173248\n",
      "epoch 22 loss: 0.08858700096607208\n",
      "epoch 23 loss: 0.10485667735338211\n",
      "epoch 24 loss: 0.08904914557933807\n",
      "epoch 25 loss: 0.07777902483940125\n",
      "epoch 26 loss: 0.07710104435682297\n",
      "epoch 27 loss: 0.059525031596422195\n",
      "epoch 28 loss: 0.06669347733259201\n",
      "epoch 29 loss: 0.07354850322008133\n",
      "epoch 30 loss: 0.07012257725000381\n",
      "13\n",
      "epoch 1 loss: 0.9780998229980469\n",
      "epoch 2 loss: 0.5471919178962708\n",
      "epoch 3 loss: 1.0625654458999634\n",
      "epoch 4 loss: 0.288180410861969\n",
      "epoch 5 loss: 0.19637109339237213\n",
      "epoch 6 loss: 0.17211434245109558\n",
      "epoch 7 loss: 0.1421305537223816\n",
      "epoch 8 loss: 0.13690964877605438\n",
      "epoch 9 loss: 0.12833057343959808\n",
      "epoch 10 loss: 0.11960092186927795\n",
      "epoch 11 loss: 0.12775926291942596\n",
      "epoch 12 loss: 0.11322784423828125\n",
      "epoch 13 loss: 0.10771222412586212\n",
      "epoch 14 loss: 0.0823964849114418\n",
      "epoch 15 loss: 0.09073875844478607\n",
      "epoch 16 loss: 0.12556281685829163\n",
      "epoch 17 loss: 0.08917728811502457\n",
      "epoch 18 loss: 0.09025097638368607\n",
      "epoch 19 loss: 0.08533713966608047\n",
      "epoch 20 loss: 0.11506521701812744\n",
      "epoch 21 loss: 0.06909777224063873\n",
      "epoch 22 loss: 0.08736445754766464\n",
      "epoch 23 loss: 0.06852789968252182\n",
      "epoch 24 loss: 0.0879572331905365\n",
      "epoch 25 loss: 0.07956113666296005\n",
      "epoch 26 loss: 0.09504378587007523\n",
      "epoch 27 loss: 0.0931503027677536\n",
      "epoch 28 loss: 0.0842517539858818\n",
      "epoch 29 loss: 0.09200479090213776\n",
      "epoch 30 loss: 0.08871640264987946\n",
      "14\n",
      "epoch 1 loss: 1.0113751888275146\n",
      "epoch 2 loss: 0.6781616806983948\n",
      "epoch 3 loss: 0.5496921539306641\n",
      "epoch 4 loss: 0.32725539803504944\n",
      "epoch 5 loss: 0.14371058344841003\n",
      "epoch 6 loss: 0.13228514790534973\n",
      "epoch 7 loss: 0.1270044595003128\n",
      "epoch 8 loss: 0.14825280010700226\n",
      "epoch 9 loss: 0.09484793990850449\n",
      "epoch 10 loss: 0.1132582351565361\n",
      "epoch 11 loss: 0.07991842180490494\n",
      "epoch 12 loss: 0.08569340407848358\n",
      "epoch 13 loss: 0.1079459935426712\n",
      "epoch 14 loss: 0.10608870536088943\n",
      "epoch 15 loss: 0.0689091831445694\n",
      "epoch 16 loss: 0.07991652190685272\n",
      "epoch 17 loss: 0.07221426069736481\n",
      "epoch 18 loss: 0.11575591564178467\n",
      "epoch 19 loss: 0.07040078938007355\n",
      "epoch 20 loss: 0.08960065990686417\n",
      "epoch 21 loss: 0.07703205198049545\n",
      "epoch 22 loss: 0.0736742690205574\n",
      "epoch 23 loss: 0.09233546257019043\n",
      "epoch 24 loss: 0.08990698307752609\n",
      "epoch 25 loss: 0.07056096196174622\n",
      "epoch 26 loss: 0.07052198797464371\n",
      "epoch 27 loss: 0.07798581570386887\n",
      "epoch 28 loss: 0.08313014358282089\n",
      "epoch 29 loss: 0.07834427058696747\n",
      "epoch 30 loss: 0.0682915523648262\n",
      "15\n",
      "epoch 1 loss: 1.0319664478302002\n",
      "epoch 2 loss: 0.8407285809516907\n",
      "epoch 3 loss: 0.35685986280441284\n",
      "epoch 4 loss: 0.17038848996162415\n",
      "epoch 5 loss: 0.15251536667346954\n",
      "epoch 6 loss: 0.12255232781171799\n",
      "epoch 7 loss: 0.12825576961040497\n",
      "epoch 8 loss: 0.13592347502708435\n",
      "epoch 9 loss: 0.09359303116798401\n",
      "epoch 10 loss: 0.11432186514139175\n",
      "epoch 11 loss: 0.12043696641921997\n",
      "epoch 12 loss: 0.09394774585962296\n",
      "epoch 13 loss: 0.08453446626663208\n",
      "epoch 14 loss: 0.09147977083921432\n",
      "epoch 15 loss: 0.07813931256532669\n",
      "epoch 16 loss: 0.08092288672924042\n",
      "epoch 17 loss: 0.07236267626285553\n",
      "epoch 18 loss: 0.09235884249210358\n",
      "epoch 19 loss: 0.0728316456079483\n",
      "epoch 20 loss: 0.09479297697544098\n",
      "epoch 21 loss: 0.1268717646598816\n",
      "epoch 22 loss: 0.09211232513189316\n",
      "epoch 23 loss: 0.07266087085008621\n",
      "epoch 24 loss: 0.08399035781621933\n",
      "epoch 25 loss: 0.06200943514704704\n",
      "epoch 26 loss: 0.0631323903799057\n",
      "epoch 27 loss: 0.08200620859861374\n",
      "epoch 28 loss: 0.06451307237148285\n",
      "epoch 29 loss: 0.0586918368935585\n",
      "epoch 30 loss: 0.07340860366821289\n",
      "16\n",
      "epoch 1 loss: 0.7280681133270264\n",
      "epoch 2 loss: 0.5596928000450134\n",
      "epoch 3 loss: 0.27533817291259766\n",
      "epoch 4 loss: 0.16976745426654816\n",
      "epoch 5 loss: 0.1460741013288498\n",
      "epoch 6 loss: 0.14818774163722992\n",
      "epoch 7 loss: 0.11733678728342056\n",
      "epoch 8 loss: 0.13380257785320282\n",
      "epoch 9 loss: 0.12606629729270935\n",
      "epoch 10 loss: 0.16789467632770538\n",
      "epoch 11 loss: 0.12129828333854675\n",
      "epoch 12 loss: 0.11554953455924988\n",
      "epoch 13 loss: 0.10399562865495682\n",
      "epoch 14 loss: 0.10288775712251663\n",
      "epoch 15 loss: 0.1296565979719162\n",
      "epoch 16 loss: 0.07670342922210693\n",
      "epoch 17 loss: 0.12308000028133392\n",
      "epoch 18 loss: 0.11493665724992752\n",
      "epoch 19 loss: 0.09359239041805267\n",
      "epoch 20 loss: 0.09044336527585983\n",
      "epoch 21 loss: 0.09951192140579224\n",
      "epoch 22 loss: 0.07643259316682816\n",
      "epoch 23 loss: 0.11075253784656525\n",
      "epoch 24 loss: 0.06844048947095871\n",
      "epoch 25 loss: 0.08708582073450089\n",
      "epoch 26 loss: 0.08440940082073212\n",
      "epoch 27 loss: 0.08587035536766052\n",
      "epoch 28 loss: 0.07771383225917816\n",
      "epoch 29 loss: 0.07917819172143936\n",
      "epoch 30 loss: 0.06529533118009567\n",
      "17\n",
      "epoch 1 loss: 0.9786834120750427\n",
      "epoch 2 loss: 0.45594438910484314\n",
      "epoch 3 loss: 0.30790165066719055\n",
      "epoch 4 loss: 0.22092515230178833\n",
      "epoch 5 loss: 0.13054490089416504\n",
      "epoch 6 loss: 0.12914516031742096\n",
      "epoch 7 loss: 0.12220992147922516\n",
      "epoch 8 loss: 0.1279342919588089\n",
      "epoch 9 loss: 0.12030241638422012\n",
      "epoch 10 loss: 0.16995106637477875\n",
      "epoch 11 loss: 0.10510431975126266\n",
      "epoch 12 loss: 0.11455890536308289\n",
      "epoch 13 loss: 0.0974692553281784\n",
      "epoch 14 loss: 0.10299284756183624\n",
      "epoch 15 loss: 0.09831256419420242\n",
      "epoch 16 loss: 0.09356829524040222\n",
      "epoch 17 loss: 0.06642533093690872\n",
      "epoch 18 loss: 0.09317195415496826\n",
      "epoch 19 loss: 0.08931225538253784\n",
      "epoch 20 loss: 0.09807608276605606\n",
      "epoch 21 loss: 0.08662132173776627\n",
      "epoch 22 loss: 0.07681319862604141\n",
      "epoch 23 loss: 0.09441059827804565\n",
      "epoch 24 loss: 0.07985124737024307\n",
      "epoch 25 loss: 0.08331800252199173\n",
      "epoch 26 loss: 0.08044616878032684\n",
      "epoch 27 loss: 0.06926659494638443\n",
      "epoch 28 loss: 0.10029534250497818\n",
      "epoch 29 loss: 0.09424088895320892\n",
      "epoch 30 loss: 0.08905673027038574\n",
      "18\n",
      "epoch 1 loss: 0.9916160702705383\n",
      "epoch 2 loss: 0.6757739186286926\n",
      "epoch 3 loss: 0.269308865070343\n",
      "epoch 4 loss: 0.19305646419525146\n",
      "epoch 5 loss: 0.16146999597549438\n",
      "epoch 6 loss: 0.13657936453819275\n",
      "epoch 7 loss: 0.12173300981521606\n",
      "epoch 8 loss: 0.13792389631271362\n",
      "epoch 9 loss: 0.1132253110408783\n",
      "epoch 10 loss: 0.14209288358688354\n",
      "epoch 11 loss: 0.10564811527729034\n",
      "epoch 12 loss: 0.08523887395858765\n",
      "epoch 13 loss: 0.1377515196800232\n",
      "epoch 14 loss: 0.0837932899594307\n",
      "epoch 15 loss: 0.11345233023166656\n",
      "epoch 16 loss: 0.0971582680940628\n",
      "epoch 17 loss: 0.08092533051967621\n",
      "epoch 18 loss: 0.07956770807504654\n",
      "epoch 19 loss: 0.08234519511461258\n",
      "epoch 20 loss: 0.08283872902393341\n",
      "epoch 21 loss: 0.09196142852306366\n",
      "epoch 22 loss: 0.08231818675994873\n",
      "epoch 23 loss: 0.07294832915067673\n",
      "epoch 24 loss: 0.07102777808904648\n",
      "epoch 25 loss: 0.07428952306509018\n",
      "epoch 26 loss: 0.0658256784081459\n",
      "epoch 27 loss: 0.08557715266942978\n",
      "epoch 28 loss: 0.05787545442581177\n",
      "epoch 29 loss: 0.08147934824228287\n",
      "epoch 30 loss: 0.06123146414756775\n",
      "19\n",
      "epoch 1 loss: 0.8084568977355957\n",
      "epoch 2 loss: 0.44994187355041504\n",
      "epoch 3 loss: 0.4004861116409302\n",
      "epoch 4 loss: 0.17020465433597565\n",
      "epoch 5 loss: 0.13311667740345\n",
      "epoch 6 loss: 0.14413589239120483\n",
      "epoch 7 loss: 0.20666027069091797\n",
      "epoch 8 loss: 0.15706010162830353\n",
      "epoch 9 loss: 0.15162360668182373\n",
      "epoch 10 loss: 0.12416860461235046\n",
      "epoch 11 loss: 0.11341647058725357\n",
      "epoch 12 loss: 0.08661952614784241\n",
      "epoch 13 loss: 0.08724157512187958\n",
      "epoch 14 loss: 0.09385834634304047\n",
      "epoch 15 loss: 0.08253591507673264\n",
      "epoch 16 loss: 0.07875615358352661\n",
      "epoch 17 loss: 0.10079226642847061\n",
      "epoch 18 loss: 0.09895458817481995\n",
      "epoch 19 loss: 0.12234323471784592\n",
      "epoch 20 loss: 0.09181838482618332\n",
      "epoch 21 loss: 0.05092189460992813\n",
      "epoch 22 loss: 0.0666552409529686\n",
      "epoch 23 loss: 0.07346918433904648\n",
      "epoch 24 loss: 0.07995066046714783\n",
      "epoch 25 loss: 0.0876559317111969\n",
      "epoch 26 loss: 0.08955470472574234\n",
      "epoch 27 loss: 0.07899455726146698\n",
      "epoch 28 loss: 0.09571108967065811\n",
      "epoch 29 loss: 0.07919881492853165\n",
      "epoch 30 loss: 0.10951400548219681\n",
      "20\n",
      "epoch 1 loss: 0.7877905368804932\n",
      "epoch 2 loss: 0.5673784017562866\n",
      "epoch 3 loss: 0.3122892677783966\n",
      "epoch 4 loss: 0.16234621405601501\n",
      "epoch 5 loss: 0.15030446648597717\n",
      "epoch 6 loss: 0.14182856678962708\n",
      "epoch 7 loss: 0.14740440249443054\n",
      "epoch 8 loss: 0.1404876857995987\n",
      "epoch 9 loss: 0.11729206144809723\n",
      "epoch 10 loss: 0.12357515096664429\n",
      "epoch 11 loss: 0.1513700634241104\n",
      "epoch 12 loss: 0.13311035931110382\n",
      "epoch 13 loss: 0.11045382171869278\n",
      "epoch 14 loss: 0.10785726457834244\n",
      "epoch 15 loss: 0.11206492781639099\n",
      "epoch 16 loss: 0.10927008837461472\n",
      "epoch 17 loss: 0.09439390897750854\n",
      "epoch 18 loss: 0.10339927673339844\n",
      "epoch 19 loss: 0.08181755244731903\n",
      "epoch 20 loss: 0.09726419299840927\n",
      "epoch 21 loss: 0.09051799029111862\n",
      "epoch 22 loss: 0.07323820143938065\n",
      "epoch 23 loss: 0.07245370000600815\n",
      "epoch 24 loss: 0.07367588579654694\n",
      "epoch 25 loss: 0.07311314344406128\n",
      "epoch 26 loss: 0.09656791388988495\n",
      "epoch 27 loss: 0.0914374440908432\n",
      "epoch 28 loss: 0.09233496338129044\n",
      "epoch 29 loss: 0.09377305209636688\n",
      "epoch 30 loss: 0.08233021199703217\n",
      "21\n",
      "epoch 1 loss: 0.7870199084281921\n",
      "epoch 2 loss: 1.0131523609161377\n",
      "epoch 3 loss: 0.7737170457839966\n",
      "epoch 4 loss: 0.4704340398311615\n",
      "epoch 5 loss: 0.1925106793642044\n",
      "epoch 6 loss: 0.19681736826896667\n",
      "epoch 7 loss: 0.14128634333610535\n",
      "epoch 8 loss: 0.131312295794487\n",
      "epoch 9 loss: 0.18341928720474243\n",
      "epoch 10 loss: 0.10856541246175766\n",
      "epoch 11 loss: 0.12989501655101776\n",
      "epoch 12 loss: 0.10778655111789703\n",
      "epoch 13 loss: 0.10711748898029327\n",
      "epoch 14 loss: 0.10828123986721039\n",
      "epoch 15 loss: 0.09255709499120712\n",
      "epoch 16 loss: 0.07537339627742767\n",
      "epoch 17 loss: 0.10367944091558456\n",
      "epoch 18 loss: 0.10462943464517593\n",
      "epoch 19 loss: 0.09255599230527878\n",
      "epoch 20 loss: 0.08660218864679337\n",
      "epoch 21 loss: 0.12966212630271912\n",
      "epoch 22 loss: 0.12016256898641586\n",
      "epoch 23 loss: 0.09006140381097794\n",
      "epoch 24 loss: 0.11021779477596283\n",
      "epoch 25 loss: 0.07080098241567612\n",
      "epoch 26 loss: 0.10072486102581024\n",
      "epoch 27 loss: 0.09844762086868286\n",
      "epoch 28 loss: 0.072004534304142\n",
      "epoch 29 loss: 0.13136149942874908\n",
      "epoch 30 loss: 0.06980741769075394\n",
      "22\n",
      "epoch 1 loss: 0.7991381287574768\n",
      "epoch 2 loss: 0.7438930869102478\n",
      "epoch 3 loss: 0.3079869747161865\n",
      "epoch 4 loss: 0.1746106594800949\n",
      "epoch 5 loss: 0.17783571779727936\n",
      "epoch 6 loss: 0.13269180059432983\n",
      "epoch 7 loss: 0.1503182351589203\n",
      "epoch 8 loss: 0.10714922100305557\n",
      "epoch 9 loss: 0.08405782282352448\n",
      "epoch 10 loss: 0.09021060168743134\n",
      "epoch 11 loss: 0.09084070473909378\n",
      "epoch 12 loss: 0.10617540031671524\n",
      "epoch 13 loss: 0.09325253218412399\n",
      "epoch 14 loss: 0.1291615068912506\n",
      "epoch 15 loss: 0.1229582130908966\n",
      "epoch 16 loss: 0.07703057676553726\n",
      "epoch 17 loss: 0.07251373678445816\n",
      "epoch 18 loss: 0.07044944167137146\n",
      "epoch 19 loss: 0.08856558799743652\n",
      "epoch 20 loss: 0.06530807167291641\n",
      "epoch 21 loss: 0.11136267334222794\n",
      "epoch 22 loss: 0.07625991106033325\n",
      "epoch 23 loss: 0.1016584113240242\n",
      "epoch 24 loss: 0.08463671058416367\n",
      "epoch 25 loss: 0.11550106108188629\n",
      "epoch 26 loss: 0.09018593281507492\n",
      "epoch 27 loss: 0.0946570634841919\n",
      "epoch 28 loss: 0.1102057471871376\n",
      "epoch 29 loss: 0.07698136568069458\n",
      "epoch 30 loss: 0.0696529820561409\n",
      "23\n",
      "epoch 1 loss: 0.7479449510574341\n",
      "epoch 2 loss: 0.5678200721740723\n",
      "epoch 3 loss: 0.44385477900505066\n",
      "epoch 4 loss: 0.2332337498664856\n",
      "epoch 5 loss: 0.15608590841293335\n",
      "epoch 6 loss: 0.13165774941444397\n",
      "epoch 7 loss: 0.15578430891036987\n",
      "epoch 8 loss: 0.1191636249423027\n",
      "epoch 9 loss: 0.1381009966135025\n",
      "epoch 10 loss: 0.12992297112941742\n",
      "epoch 11 loss: 0.1322190761566162\n",
      "epoch 12 loss: 0.12568247318267822\n",
      "epoch 13 loss: 0.1156267374753952\n",
      "epoch 14 loss: 0.1060672178864479\n",
      "epoch 15 loss: 0.08350209146738052\n",
      "epoch 16 loss: 0.10615888237953186\n",
      "epoch 17 loss: 0.07909334450960159\n",
      "epoch 18 loss: 0.09139890968799591\n",
      "epoch 19 loss: 0.09169241786003113\n",
      "epoch 20 loss: 0.07381314039230347\n",
      "epoch 21 loss: 0.10226703435182571\n",
      "epoch 22 loss: 0.08025099337100983\n",
      "epoch 23 loss: 0.10504774004220963\n",
      "epoch 24 loss: 0.0783398374915123\n",
      "epoch 25 loss: 0.07829918712377548\n",
      "epoch 26 loss: 0.07789656519889832\n",
      "epoch 27 loss: 0.08378347009420395\n",
      "epoch 28 loss: 0.0774424597620964\n",
      "epoch 29 loss: 0.0634179413318634\n",
      "epoch 30 loss: 0.06560835242271423\n",
      "24\n",
      "epoch 1 loss: 0.8974412679672241\n",
      "epoch 2 loss: 0.7614001631736755\n",
      "epoch 3 loss: 0.4253559112548828\n",
      "epoch 4 loss: 0.29534363746643066\n",
      "epoch 5 loss: 0.18252316117286682\n",
      "epoch 6 loss: 0.12475556135177612\n",
      "epoch 7 loss: 0.14971567690372467\n",
      "epoch 8 loss: 0.1308387964963913\n",
      "epoch 9 loss: 0.1719415783882141\n",
      "epoch 10 loss: 0.1887194961309433\n",
      "epoch 11 loss: 0.10829845815896988\n",
      "epoch 12 loss: 0.08481015264987946\n",
      "epoch 13 loss: 0.08245131373405457\n",
      "epoch 14 loss: 0.08730459213256836\n",
      "epoch 15 loss: 0.08987876772880554\n",
      "epoch 16 loss: 0.11277012526988983\n",
      "epoch 17 loss: 0.07688392698764801\n",
      "epoch 18 loss: 0.0689454898238182\n",
      "epoch 19 loss: 0.1194458156824112\n",
      "epoch 20 loss: 0.08364643901586533\n",
      "epoch 21 loss: 0.09158313274383545\n",
      "epoch 22 loss: 0.09059732407331467\n",
      "epoch 23 loss: 0.09117300063371658\n",
      "epoch 24 loss: 0.08281492441892624\n",
      "epoch 25 loss: 0.08484229445457458\n",
      "epoch 26 loss: 0.09054463356733322\n",
      "epoch 27 loss: 0.08379264920949936\n",
      "epoch 28 loss: 0.07113824784755707\n",
      "epoch 29 loss: 0.06338344514369965\n",
      "epoch 30 loss: 0.09565610438585281\n",
      "25\n",
      "epoch 1 loss: 1.0426011085510254\n",
      "epoch 2 loss: 0.5936191082000732\n",
      "epoch 3 loss: 0.36012476682662964\n",
      "epoch 4 loss: 0.27791711688041687\n",
      "epoch 5 loss: 0.125430166721344\n",
      "epoch 6 loss: 0.12798872590065002\n",
      "epoch 7 loss: 0.14667008817195892\n",
      "epoch 8 loss: 0.11479455977678299\n",
      "epoch 9 loss: 0.09257415682077408\n",
      "epoch 10 loss: 0.11071711778640747\n",
      "epoch 11 loss: 0.1063048243522644\n",
      "epoch 12 loss: 0.09225067496299744\n",
      "epoch 13 loss: 0.08081504702568054\n",
      "epoch 14 loss: 0.13429506123065948\n",
      "epoch 15 loss: 0.10546231269836426\n",
      "epoch 16 loss: 0.0987125039100647\n",
      "epoch 17 loss: 0.0883953794836998\n",
      "epoch 18 loss: 0.10109253227710724\n",
      "epoch 19 loss: 0.09253859519958496\n",
      "epoch 20 loss: 0.09407752752304077\n",
      "epoch 21 loss: 0.06903938204050064\n",
      "epoch 22 loss: 0.08404096961021423\n",
      "epoch 23 loss: 0.07042383402585983\n",
      "epoch 24 loss: 0.07471860200166702\n",
      "epoch 25 loss: 0.1071334034204483\n",
      "epoch 26 loss: 0.10210458934307098\n",
      "epoch 27 loss: 0.07575482130050659\n",
      "epoch 28 loss: 0.06255735456943512\n",
      "epoch 29 loss: 0.08709258586168289\n",
      "epoch 30 loss: 0.07548592239618301\n",
      "26\n",
      "epoch 1 loss: 1.055012822151184\n",
      "epoch 2 loss: 0.767087459564209\n",
      "epoch 3 loss: 0.42783236503601074\n",
      "epoch 4 loss: 0.23293234407901764\n",
      "epoch 5 loss: 0.18639372289180756\n",
      "epoch 6 loss: 0.11799069494009018\n",
      "epoch 7 loss: 0.1439540535211563\n",
      "epoch 8 loss: 0.09465320408344269\n",
      "epoch 9 loss: 0.12930311262607574\n",
      "epoch 10 loss: 0.09314078837633133\n",
      "epoch 11 loss: 0.09918492287397385\n",
      "epoch 12 loss: 0.10332320630550385\n",
      "epoch 13 loss: 0.10956943035125732\n",
      "epoch 14 loss: 0.10292027145624161\n",
      "epoch 15 loss: 0.07623752951622009\n",
      "epoch 16 loss: 0.10479328036308289\n",
      "epoch 17 loss: 0.10103462636470795\n",
      "epoch 18 loss: 0.0784849226474762\n",
      "epoch 19 loss: 0.08444418013095856\n",
      "epoch 20 loss: 0.08931160718202591\n",
      "epoch 21 loss: 0.0877017080783844\n",
      "epoch 22 loss: 0.10254491120576859\n",
      "epoch 23 loss: 0.09564127773046494\n",
      "epoch 24 loss: 0.08712594956159592\n",
      "epoch 25 loss: 0.06723342090845108\n",
      "epoch 26 loss: 0.07161267101764679\n",
      "epoch 27 loss: 0.08138301223516464\n",
      "epoch 28 loss: 0.08975537121295929\n",
      "epoch 29 loss: 0.08406663686037064\n",
      "epoch 30 loss: 0.07856080681085587\n",
      "27\n",
      "epoch 1 loss: 0.829552948474884\n",
      "epoch 2 loss: 0.9525786638259888\n",
      "epoch 3 loss: 0.37680143117904663\n",
      "epoch 4 loss: 0.17831546068191528\n",
      "epoch 5 loss: 0.14676591753959656\n",
      "epoch 6 loss: 0.10279928892850876\n",
      "epoch 7 loss: 0.13949301838874817\n",
      "epoch 8 loss: 0.11738181859254837\n",
      "epoch 9 loss: 0.11654533445835114\n",
      "epoch 10 loss: 0.20226672291755676\n",
      "epoch 11 loss: 0.14484073221683502\n",
      "epoch 12 loss: 0.11684735864400864\n",
      "epoch 13 loss: 0.11514788120985031\n",
      "epoch 14 loss: 0.163641557097435\n",
      "epoch 15 loss: 0.09202844649553299\n",
      "epoch 16 loss: 0.10372717678546906\n",
      "epoch 17 loss: 0.08730383217334747\n",
      "epoch 18 loss: 0.12076832354068756\n",
      "epoch 19 loss: 0.08217252045869827\n",
      "epoch 20 loss: 0.09827689826488495\n",
      "epoch 21 loss: 0.10152965039014816\n",
      "epoch 22 loss: 0.10852370411157608\n",
      "epoch 23 loss: 0.09074623137712479\n",
      "epoch 24 loss: 0.09194577485322952\n",
      "epoch 25 loss: 0.06292683631181717\n",
      "epoch 26 loss: 0.09119157493114471\n",
      "epoch 27 loss: 0.08619731664657593\n",
      "epoch 28 loss: 0.07985129207372665\n",
      "epoch 29 loss: 0.07001200318336487\n",
      "epoch 30 loss: 0.07570219039916992\n",
      "28\n",
      "epoch 1 loss: 0.8861139416694641\n",
      "epoch 2 loss: 0.5328408479690552\n",
      "epoch 3 loss: 0.283908873796463\n",
      "epoch 4 loss: 0.15888097882270813\n",
      "epoch 5 loss: 0.15071220695972443\n",
      "epoch 6 loss: 0.1331995129585266\n",
      "epoch 7 loss: 0.14350976049900055\n",
      "epoch 8 loss: 0.11073044687509537\n",
      "epoch 9 loss: 0.10524029284715652\n",
      "epoch 10 loss: 0.10286024212837219\n",
      "epoch 11 loss: 0.11305369436740875\n",
      "epoch 12 loss: 0.1031559407711029\n",
      "epoch 13 loss: 0.08509507775306702\n",
      "epoch 14 loss: 0.1052374318242073\n",
      "epoch 15 loss: 0.07672867923974991\n",
      "epoch 16 loss: 0.07378911226987839\n",
      "epoch 17 loss: 0.08264311403036118\n",
      "epoch 18 loss: 0.07309091836214066\n",
      "epoch 19 loss: 0.07619418948888779\n",
      "epoch 20 loss: 0.09508704394102097\n",
      "epoch 21 loss: 0.07295587658882141\n",
      "epoch 22 loss: 0.11336234956979752\n",
      "epoch 23 loss: 0.06941129267215729\n",
      "epoch 24 loss: 0.09058382362127304\n",
      "epoch 25 loss: 0.07197005301713943\n",
      "epoch 26 loss: 0.05929185077548027\n",
      "epoch 27 loss: 0.07661135494709015\n",
      "epoch 28 loss: 0.08153267949819565\n",
      "epoch 29 loss: 0.061943959444761276\n",
      "epoch 30 loss: 0.08581918478012085\n",
      "29\n",
      "epoch 1 loss: 0.8201925158500671\n",
      "epoch 2 loss: 0.6093579530715942\n",
      "epoch 3 loss: 0.3954271078109741\n",
      "epoch 4 loss: 0.1893579512834549\n",
      "epoch 5 loss: 0.15582846105098724\n",
      "epoch 6 loss: 0.15273313224315643\n",
      "epoch 7 loss: 0.12367776036262512\n",
      "epoch 8 loss: 0.1356842964887619\n",
      "epoch 9 loss: 0.1633521020412445\n",
      "epoch 10 loss: 0.16327477991580963\n",
      "epoch 11 loss: 0.09576715528964996\n",
      "epoch 12 loss: 0.11045579612255096\n",
      "epoch 13 loss: 0.10370004177093506\n",
      "epoch 14 loss: 0.14089727401733398\n",
      "epoch 15 loss: 0.0767124816775322\n",
      "epoch 16 loss: 0.09827479720115662\n",
      "epoch 17 loss: 0.08377750962972641\n",
      "epoch 18 loss: 0.06583103537559509\n",
      "epoch 19 loss: 0.0673845112323761\n",
      "epoch 20 loss: 0.07262178510427475\n",
      "epoch 21 loss: 0.08095750212669373\n",
      "epoch 22 loss: 0.07874619215726852\n",
      "epoch 23 loss: 0.07038062065839767\n",
      "epoch 24 loss: 0.06130397692322731\n",
      "epoch 25 loss: 0.09646080434322357\n",
      "epoch 26 loss: 0.07199245691299438\n",
      "epoch 27 loss: 0.06119529902935028\n",
      "epoch 28 loss: 0.07252252101898193\n",
      "epoch 29 loss: 0.062288034707307816\n",
      "epoch 30 loss: 0.06537573784589767\n",
      "30\n",
      "epoch 1 loss: 0.7554401755332947\n",
      "epoch 2 loss: 0.5497686266899109\n",
      "epoch 3 loss: 0.33632588386535645\n",
      "epoch 4 loss: 0.2068415731191635\n",
      "epoch 5 loss: 0.11382181197404861\n",
      "epoch 6 loss: 0.1588105410337448\n",
      "epoch 7 loss: 0.16105422377586365\n",
      "epoch 8 loss: 0.10521601140499115\n",
      "epoch 9 loss: 0.133136585354805\n",
      "epoch 10 loss: 0.1195564940571785\n",
      "epoch 11 loss: 0.11172109097242355\n",
      "epoch 12 loss: 0.08713249117136002\n",
      "epoch 13 loss: 0.08145855367183685\n",
      "epoch 14 loss: 0.08798883110284805\n",
      "epoch 15 loss: 0.07657266408205032\n",
      "epoch 16 loss: 0.14018140733242035\n",
      "epoch 17 loss: 0.08264141529798508\n",
      "epoch 18 loss: 0.0892639085650444\n",
      "epoch 19 loss: 0.0968291163444519\n",
      "epoch 20 loss: 0.09696463495492935\n",
      "epoch 21 loss: 0.09874024987220764\n",
      "epoch 22 loss: 0.0634608119726181\n",
      "epoch 23 loss: 0.09086557477712631\n",
      "epoch 24 loss: 0.08776628971099854\n",
      "epoch 25 loss: 0.08438225835561752\n",
      "epoch 26 loss: 0.06185784563422203\n",
      "epoch 27 loss: 0.07455211877822876\n",
      "epoch 28 loss: 0.06469390541315079\n",
      "epoch 29 loss: 0.06979665905237198\n",
      "epoch 30 loss: 0.06369709223508835\n",
      "31\n",
      "epoch 1 loss: 1.034437656402588\n",
      "epoch 2 loss: 0.7287951707839966\n",
      "epoch 3 loss: 0.46805861592292786\n",
      "epoch 4 loss: 0.29068195819854736\n",
      "epoch 5 loss: 0.23911502957344055\n",
      "epoch 6 loss: 0.14572523534297943\n",
      "epoch 7 loss: 0.1631963849067688\n",
      "epoch 8 loss: 0.14919693768024445\n",
      "epoch 9 loss: 0.08537743985652924\n",
      "epoch 10 loss: 0.10618696361780167\n",
      "epoch 11 loss: 0.11692383140325546\n",
      "epoch 12 loss: 0.09934091567993164\n",
      "epoch 13 loss: 0.09419829398393631\n",
      "epoch 14 loss: 0.08232998102903366\n",
      "epoch 15 loss: 0.10195215791463852\n",
      "epoch 16 loss: 0.11731086671352386\n",
      "epoch 17 loss: 0.0800337865948677\n",
      "epoch 18 loss: 0.11161873489618301\n",
      "epoch 19 loss: 0.09015318751335144\n",
      "epoch 20 loss: 0.08650484681129456\n",
      "epoch 21 loss: 0.0948115661740303\n",
      "epoch 22 loss: 0.08515835553407669\n",
      "epoch 23 loss: 0.0695335790514946\n",
      "epoch 24 loss: 0.08755558729171753\n",
      "epoch 25 loss: 0.09960708022117615\n",
      "epoch 26 loss: 0.07863961160182953\n",
      "epoch 27 loss: 0.07817495614290237\n",
      "epoch 28 loss: 0.08455722779035568\n",
      "epoch 29 loss: 0.07415973395109177\n",
      "epoch 30 loss: 0.07472744584083557\n",
      "32\n",
      "epoch 1 loss: 0.8380513787269592\n",
      "epoch 2 loss: 0.7030201554298401\n",
      "epoch 3 loss: 0.5672061443328857\n",
      "epoch 4 loss: 0.5070056915283203\n",
      "epoch 5 loss: 0.30745619535446167\n",
      "epoch 6 loss: 0.1902676820755005\n",
      "epoch 7 loss: 0.17192012071609497\n",
      "epoch 8 loss: 0.17860443890094757\n",
      "epoch 9 loss: 0.1679849922657013\n",
      "epoch 10 loss: 0.10788331180810928\n",
      "epoch 11 loss: 0.12371812760829926\n",
      "epoch 12 loss: 0.1474962830543518\n",
      "epoch 13 loss: 0.09898775815963745\n",
      "epoch 14 loss: 0.11125198751688004\n",
      "epoch 15 loss: 0.06810767203569412\n",
      "epoch 16 loss: 0.11948196589946747\n",
      "epoch 17 loss: 0.07146327197551727\n",
      "epoch 18 loss: 0.09148023277521133\n",
      "epoch 19 loss: 0.09483861923217773\n",
      "epoch 20 loss: 0.07072699069976807\n",
      "epoch 21 loss: 0.10278691351413727\n",
      "epoch 22 loss: 0.07272420078516006\n",
      "epoch 23 loss: 0.09623240679502487\n",
      "epoch 24 loss: 0.08764674514532089\n",
      "epoch 25 loss: 0.08148477226495743\n",
      "epoch 26 loss: 0.07387255132198334\n",
      "epoch 27 loss: 0.07692672312259674\n",
      "epoch 28 loss: 0.0662151575088501\n",
      "epoch 29 loss: 0.07725448161363602\n",
      "epoch 30 loss: 0.060457613319158554\n",
      "33\n",
      "epoch 1 loss: 0.7297827005386353\n",
      "epoch 2 loss: 0.5469478368759155\n",
      "epoch 3 loss: 0.36936327815055847\n",
      "epoch 4 loss: 0.2650618851184845\n",
      "epoch 5 loss: 0.39360326528549194\n",
      "epoch 6 loss: 0.14463816583156586\n",
      "epoch 7 loss: 0.1539609134197235\n",
      "epoch 8 loss: 0.1224638968706131\n",
      "epoch 9 loss: 0.11476953327655792\n",
      "epoch 10 loss: 0.1024903953075409\n",
      "epoch 11 loss: 0.11630270630121231\n",
      "epoch 12 loss: 0.10222800076007843\n",
      "epoch 13 loss: 0.09351491928100586\n",
      "epoch 14 loss: 0.08585580438375473\n",
      "epoch 15 loss: 0.1065051257610321\n",
      "epoch 16 loss: 0.10253855586051941\n",
      "epoch 17 loss: 0.08629737794399261\n",
      "epoch 18 loss: 0.07530513405799866\n",
      "epoch 19 loss: 0.07978293299674988\n",
      "epoch 20 loss: 0.06798174232244492\n",
      "epoch 21 loss: 0.09602832049131393\n",
      "epoch 22 loss: 0.07595076411962509\n",
      "epoch 23 loss: 0.08396521210670471\n",
      "epoch 24 loss: 0.09929671138525009\n",
      "epoch 25 loss: 0.09047207236289978\n",
      "epoch 26 loss: 0.06764541566371918\n",
      "epoch 27 loss: 0.07134102284908295\n",
      "epoch 28 loss: 0.06440912932157516\n",
      "epoch 29 loss: 0.0866607055068016\n",
      "epoch 30 loss: 0.07746028155088425\n",
      "34\n",
      "epoch 1 loss: 0.8531990051269531\n",
      "epoch 2 loss: 0.5152273178100586\n",
      "epoch 3 loss: 0.28165915608406067\n",
      "epoch 4 loss: 0.1727270781993866\n",
      "epoch 5 loss: 0.15471628308296204\n",
      "epoch 6 loss: 0.1758805215358734\n",
      "epoch 7 loss: 0.13300763070583344\n",
      "epoch 8 loss: 0.0801178365945816\n",
      "epoch 9 loss: 0.163351908326149\n",
      "epoch 10 loss: 0.12760543823242188\n",
      "epoch 11 loss: 0.11869113147258759\n",
      "epoch 12 loss: 0.08975663781166077\n",
      "epoch 13 loss: 0.10803057998418808\n",
      "epoch 14 loss: 0.1929120421409607\n",
      "epoch 15 loss: 0.10990402847528458\n",
      "epoch 16 loss: 0.10014696419239044\n",
      "epoch 17 loss: 0.08864986151456833\n",
      "epoch 18 loss: 0.08072375506162643\n",
      "epoch 19 loss: 0.08020953834056854\n",
      "epoch 20 loss: 0.10067231208086014\n",
      "epoch 21 loss: 0.0814702957868576\n",
      "epoch 22 loss: 0.09432969987392426\n",
      "epoch 23 loss: 0.10713125765323639\n",
      "epoch 24 loss: 0.09159655123949051\n",
      "epoch 25 loss: 0.07154639810323715\n",
      "epoch 26 loss: 0.0752335712313652\n",
      "epoch 27 loss: 0.08044534176588058\n",
      "epoch 28 loss: 0.08777851611375809\n",
      "epoch 29 loss: 0.08044195175170898\n",
      "epoch 30 loss: 0.07923753559589386\n",
      "35\n",
      "epoch 1 loss: 0.7218444347381592\n",
      "epoch 2 loss: 0.7267752885818481\n",
      "epoch 3 loss: 0.7815259099006653\n",
      "epoch 4 loss: 0.5300634503364563\n",
      "epoch 5 loss: 0.30650144815444946\n",
      "epoch 6 loss: 0.14731232821941376\n",
      "epoch 7 loss: 0.16184286773204803\n",
      "epoch 8 loss: 0.12703581154346466\n",
      "epoch 9 loss: 0.1259678304195404\n",
      "epoch 10 loss: 0.08661984652280807\n",
      "epoch 11 loss: 0.08917627483606339\n",
      "epoch 12 loss: 0.09158393740653992\n",
      "epoch 13 loss: 0.09569333493709564\n",
      "epoch 14 loss: 0.12239678204059601\n",
      "epoch 15 loss: 0.08799764513969421\n",
      "epoch 16 loss: 0.10279016941785812\n",
      "epoch 17 loss: 0.10682334005832672\n",
      "epoch 18 loss: 0.06388410925865173\n",
      "epoch 19 loss: 0.09001681208610535\n",
      "epoch 20 loss: 0.10296020656824112\n",
      "epoch 21 loss: 0.08563199639320374\n",
      "epoch 22 loss: 0.09207957983016968\n",
      "epoch 23 loss: 0.07347442954778671\n",
      "epoch 24 loss: 0.10663331300020218\n",
      "epoch 25 loss: 0.09183935821056366\n",
      "epoch 26 loss: 0.053028516471385956\n",
      "epoch 27 loss: 0.08824413269758224\n",
      "epoch 28 loss: 0.08761868625879288\n",
      "epoch 29 loss: 0.07631248980760574\n",
      "epoch 30 loss: 0.07301865518093109\n",
      "36\n",
      "epoch 1 loss: 0.7795501947402954\n",
      "epoch 2 loss: 0.8047441244125366\n",
      "epoch 3 loss: 0.34850409626960754\n",
      "epoch 4 loss: 0.19346989691257477\n",
      "epoch 5 loss: 0.16107077896595\n",
      "epoch 6 loss: 0.12007413804531097\n",
      "epoch 7 loss: 0.15243187546730042\n",
      "epoch 8 loss: 0.11704718321561813\n",
      "epoch 9 loss: 0.09392748028039932\n",
      "epoch 10 loss: 0.10209468752145767\n",
      "epoch 11 loss: 0.11399872601032257\n",
      "epoch 12 loss: 0.10089931637048721\n",
      "epoch 13 loss: 0.08552352339029312\n",
      "epoch 14 loss: 0.09438502788543701\n",
      "epoch 15 loss: 0.0679398626089096\n",
      "epoch 16 loss: 0.08658243715763092\n",
      "epoch 17 loss: 0.10497094690799713\n",
      "epoch 18 loss: 0.09011327475309372\n",
      "epoch 19 loss: 0.07366686314344406\n",
      "epoch 20 loss: 0.08382552862167358\n",
      "epoch 21 loss: 0.09879922866821289\n",
      "epoch 22 loss: 0.11054349690675735\n",
      "epoch 23 loss: 0.057413164526224136\n",
      "epoch 24 loss: 0.06032533198595047\n",
      "epoch 25 loss: 0.07615988701581955\n",
      "epoch 26 loss: 0.07746907323598862\n",
      "epoch 27 loss: 0.05714111775159836\n",
      "epoch 28 loss: 0.05580444261431694\n",
      "epoch 29 loss: 0.07113844156265259\n",
      "epoch 30 loss: 0.10661004483699799\n",
      "37\n",
      "epoch 1 loss: 0.8297269940376282\n",
      "epoch 2 loss: 1.0284556150436401\n",
      "epoch 3 loss: 0.5231319665908813\n",
      "epoch 4 loss: 0.32829540967941284\n",
      "epoch 5 loss: 0.16476747393608093\n",
      "epoch 6 loss: 0.13405950367450714\n",
      "epoch 7 loss: 0.13307034969329834\n",
      "epoch 8 loss: 0.10690031945705414\n",
      "epoch 9 loss: 0.08535803109407425\n",
      "epoch 10 loss: 0.10449651628732681\n",
      "epoch 11 loss: 0.19260114431381226\n",
      "epoch 12 loss: 0.10804310441017151\n",
      "epoch 13 loss: 0.08203709870576859\n",
      "epoch 14 loss: 0.07787173241376877\n",
      "epoch 15 loss: 0.13436612486839294\n",
      "epoch 16 loss: 0.09894996881484985\n",
      "epoch 17 loss: 0.07133231312036514\n",
      "epoch 18 loss: 0.09132447838783264\n",
      "epoch 19 loss: 0.0944293811917305\n",
      "epoch 20 loss: 0.08278986811637878\n",
      "epoch 21 loss: 0.07121866196393967\n",
      "epoch 22 loss: 0.06384707987308502\n",
      "epoch 23 loss: 0.08107900619506836\n",
      "epoch 24 loss: 0.08524565398693085\n",
      "epoch 25 loss: 0.05903075635433197\n",
      "epoch 26 loss: 0.08469296246767044\n",
      "epoch 27 loss: 0.07611330598592758\n",
      "epoch 28 loss: 0.07893379777669907\n",
      "epoch 29 loss: 0.09663418680429459\n",
      "epoch 30 loss: 0.0674072802066803\n",
      "38\n",
      "epoch 1 loss: 0.7510678172111511\n",
      "epoch 2 loss: 0.693862795829773\n",
      "epoch 3 loss: 0.3177947998046875\n",
      "epoch 4 loss: 0.21232639253139496\n",
      "epoch 5 loss: 0.1922333836555481\n",
      "epoch 6 loss: 0.14065636694431305\n",
      "epoch 7 loss: 0.10502150654792786\n",
      "epoch 8 loss: 0.12616682052612305\n",
      "epoch 9 loss: 0.11979003995656967\n",
      "epoch 10 loss: 0.11092401295900345\n",
      "epoch 11 loss: 0.08138826489448547\n",
      "epoch 12 loss: 0.12577953934669495\n",
      "epoch 13 loss: 0.12201452255249023\n",
      "epoch 14 loss: 0.08647844940423965\n",
      "epoch 15 loss: 0.0780114158987999\n",
      "epoch 16 loss: 0.09690877795219421\n",
      "epoch 17 loss: 0.08910282701253891\n",
      "epoch 18 loss: 0.08519449084997177\n",
      "epoch 19 loss: 0.09800437092781067\n",
      "epoch 20 loss: 0.09747835993766785\n",
      "epoch 21 loss: 0.08561605960130692\n",
      "epoch 22 loss: 0.08166801184415817\n",
      "epoch 23 loss: 0.08352392911911011\n",
      "epoch 24 loss: 0.08048231154680252\n",
      "epoch 25 loss: 0.0756378099322319\n",
      "epoch 26 loss: 0.09243225306272507\n",
      "epoch 27 loss: 0.0692744255065918\n",
      "epoch 28 loss: 0.07420272380113602\n",
      "epoch 29 loss: 0.09269513189792633\n",
      "epoch 30 loss: 0.06884567439556122\n",
      "39\n",
      "epoch 1 loss: 0.7353836297988892\n",
      "epoch 2 loss: 0.8891428709030151\n",
      "epoch 3 loss: 0.567649781703949\n",
      "epoch 4 loss: 0.27202728390693665\n",
      "epoch 5 loss: 0.23409152030944824\n",
      "epoch 6 loss: 0.19968166947364807\n",
      "epoch 7 loss: 0.1693277508020401\n",
      "epoch 8 loss: 0.1337406039237976\n",
      "epoch 9 loss: 0.13587096333503723\n",
      "epoch 10 loss: 0.1271531581878662\n",
      "epoch 11 loss: 0.09821757674217224\n",
      "epoch 12 loss: 0.11175835132598877\n",
      "epoch 13 loss: 0.0990346297621727\n",
      "epoch 14 loss: 0.11362466961145401\n",
      "epoch 15 loss: 0.11151280999183655\n",
      "epoch 16 loss: 0.10840149968862534\n",
      "epoch 17 loss: 0.07747872918844223\n",
      "epoch 18 loss: 0.07763440907001495\n",
      "epoch 19 loss: 0.08574184775352478\n",
      "epoch 20 loss: 0.10923337936401367\n",
      "epoch 21 loss: 0.09201531857252121\n",
      "epoch 22 loss: 0.1016245111823082\n",
      "epoch 23 loss: 0.06782877445220947\n",
      "epoch 24 loss: 0.09239884465932846\n",
      "epoch 25 loss: 0.08178694546222687\n",
      "epoch 26 loss: 0.06971190124750137\n",
      "epoch 27 loss: 0.07605858892202377\n",
      "epoch 28 loss: 0.06841661781072617\n",
      "epoch 29 loss: 0.0959196537733078\n",
      "epoch 30 loss: 0.10431180894374847\n",
      "40\n",
      "epoch 1 loss: 0.6584984064102173\n",
      "epoch 2 loss: 0.5213846564292908\n",
      "epoch 3 loss: 0.6159980893135071\n",
      "epoch 4 loss: 0.21862921118736267\n",
      "epoch 5 loss: 0.1434987485408783\n",
      "epoch 6 loss: 0.13936185836791992\n",
      "epoch 7 loss: 0.142816424369812\n",
      "epoch 8 loss: 0.11050306260585785\n",
      "epoch 9 loss: 0.08860251307487488\n",
      "epoch 10 loss: 0.09352670609951019\n",
      "epoch 11 loss: 0.1180720329284668\n",
      "epoch 12 loss: 0.11890880018472672\n",
      "epoch 13 loss: 0.10061438381671906\n",
      "epoch 14 loss: 0.09888213872909546\n",
      "epoch 15 loss: 0.10007775574922562\n",
      "epoch 16 loss: 0.075401172041893\n",
      "epoch 17 loss: 0.08187837898731232\n",
      "epoch 18 loss: 0.08903678506612778\n",
      "epoch 19 loss: 0.08031909167766571\n",
      "epoch 20 loss: 0.08763531595468521\n",
      "epoch 21 loss: 0.08930527418851852\n",
      "epoch 22 loss: 0.09898504614830017\n",
      "epoch 23 loss: 0.1036757081747055\n",
      "epoch 24 loss: 0.09220333397388458\n",
      "epoch 25 loss: 0.10200042277574539\n",
      "epoch 26 loss: 0.07833992689847946\n",
      "epoch 27 loss: 0.08234541118144989\n",
      "epoch 28 loss: 0.08864568173885345\n",
      "epoch 29 loss: 0.07682293653488159\n",
      "epoch 30 loss: 0.0811336413025856\n",
      "41\n",
      "epoch 1 loss: 1.3235180377960205\n",
      "epoch 2 loss: 0.5432265996932983\n",
      "epoch 3 loss: 0.3218044936656952\n",
      "epoch 4 loss: 0.1833585947751999\n",
      "epoch 5 loss: 0.13368724286556244\n",
      "epoch 6 loss: 0.13350093364715576\n",
      "epoch 7 loss: 0.11583396792411804\n",
      "epoch 8 loss: 0.0955718606710434\n",
      "epoch 9 loss: 0.13633909821510315\n",
      "epoch 10 loss: 0.1250760704278946\n",
      "epoch 11 loss: 0.13113342225551605\n",
      "epoch 12 loss: 0.08999498933553696\n",
      "epoch 13 loss: 0.14400538802146912\n",
      "epoch 14 loss: 0.12181628495454788\n",
      "epoch 15 loss: 0.10727568715810776\n",
      "epoch 16 loss: 0.08350329846143723\n",
      "epoch 17 loss: 0.09501059353351593\n",
      "epoch 18 loss: 0.09579591453075409\n",
      "epoch 19 loss: 0.08284478634595871\n",
      "epoch 20 loss: 0.06965557485818863\n",
      "epoch 21 loss: 0.10240253806114197\n",
      "epoch 22 loss: 0.07278873026371002\n",
      "epoch 23 loss: 0.06891883909702301\n",
      "epoch 24 loss: 0.07325007021427155\n",
      "epoch 25 loss: 0.07232727110385895\n",
      "epoch 26 loss: 0.07278061658143997\n",
      "epoch 27 loss: 0.07644688338041306\n",
      "epoch 28 loss: 0.07710892707109451\n",
      "epoch 29 loss: 0.08049880713224411\n",
      "epoch 30 loss: 0.07825466245412827\n",
      "42\n",
      "epoch 1 loss: 0.6046202182769775\n",
      "epoch 2 loss: 0.41726425290107727\n",
      "epoch 3 loss: 0.22172220051288605\n",
      "epoch 4 loss: 0.1440594494342804\n",
      "epoch 5 loss: 0.13999201357364655\n",
      "epoch 6 loss: 0.14150172472000122\n",
      "epoch 7 loss: 0.13037124276161194\n",
      "epoch 8 loss: 0.09800092875957489\n",
      "epoch 9 loss: 0.10106909275054932\n",
      "epoch 10 loss: 0.1189650148153305\n",
      "epoch 11 loss: 0.10916939377784729\n",
      "epoch 12 loss: 0.09470897167921066\n",
      "epoch 13 loss: 0.07811886072158813\n",
      "epoch 14 loss: 0.0771251767873764\n",
      "epoch 15 loss: 0.07351713627576828\n",
      "epoch 16 loss: 0.09197425097227097\n",
      "epoch 17 loss: 0.09714838117361069\n",
      "epoch 18 loss: 0.06057234853506088\n",
      "epoch 19 loss: 0.07715543359518051\n",
      "epoch 20 loss: 0.09157509356737137\n",
      "epoch 21 loss: 0.07340172678232193\n",
      "epoch 22 loss: 0.07387947291135788\n",
      "epoch 23 loss: 0.07162085175514221\n",
      "epoch 24 loss: 0.07555358111858368\n",
      "epoch 25 loss: 0.07750394940376282\n",
      "epoch 26 loss: 0.09592585265636444\n",
      "epoch 27 loss: 0.08165212720632553\n",
      "epoch 28 loss: 0.08529012650251389\n",
      "epoch 29 loss: 0.0846259817481041\n",
      "epoch 30 loss: 0.07117912918329239\n",
      "43\n",
      "epoch 1 loss: 0.8809995651245117\n",
      "epoch 2 loss: 0.5242565274238586\n",
      "epoch 3 loss: 1.1462900638580322\n",
      "epoch 4 loss: 0.5311645269393921\n",
      "epoch 5 loss: 0.29340028762817383\n",
      "epoch 6 loss: 0.14924722909927368\n",
      "epoch 7 loss: 0.14013990759849548\n",
      "epoch 8 loss: 0.12738873064517975\n",
      "epoch 9 loss: 0.13102920353412628\n",
      "epoch 10 loss: 0.10259159654378891\n",
      "epoch 11 loss: 0.1308731883764267\n",
      "epoch 12 loss: 0.09683696180582047\n",
      "epoch 13 loss: 0.07900033891201019\n",
      "epoch 14 loss: 0.13558031618595123\n",
      "epoch 15 loss: 0.08579021692276001\n",
      "epoch 16 loss: 0.08658914268016815\n",
      "epoch 17 loss: 0.11023081839084625\n",
      "epoch 18 loss: 0.10944760590791702\n",
      "epoch 19 loss: 0.08000853657722473\n",
      "epoch 20 loss: 0.09740019589662552\n",
      "epoch 21 loss: 0.08458749949932098\n",
      "epoch 22 loss: 0.1011446937918663\n",
      "epoch 23 loss: 0.08368226885795593\n",
      "epoch 24 loss: 0.06342712789773941\n",
      "epoch 25 loss: 0.08695635944604874\n",
      "epoch 26 loss: 0.07965759187936783\n",
      "epoch 27 loss: 0.08721641451120377\n",
      "epoch 28 loss: 0.05618792399764061\n",
      "epoch 29 loss: 0.09116783738136292\n",
      "epoch 30 loss: 0.08198516070842743\n",
      "44\n",
      "epoch 1 loss: 0.8799365162849426\n",
      "epoch 2 loss: 1.0680958032608032\n",
      "epoch 3 loss: 0.5952145457267761\n",
      "epoch 4 loss: 0.5132938027381897\n",
      "epoch 5 loss: 0.22468847036361694\n",
      "epoch 6 loss: 0.14361236989498138\n",
      "epoch 7 loss: 0.14590826630592346\n",
      "epoch 8 loss: 0.1214575320482254\n",
      "epoch 9 loss: 0.10803315788507462\n",
      "epoch 10 loss: 0.08761265873908997\n",
      "epoch 11 loss: 0.11111225932836533\n",
      "epoch 12 loss: 0.12074919044971466\n",
      "epoch 13 loss: 0.10500585287809372\n",
      "epoch 14 loss: 0.10867674648761749\n",
      "epoch 15 loss: 0.081997349858284\n",
      "epoch 16 loss: 0.07574846595525742\n",
      "epoch 17 loss: 0.08756409585475922\n",
      "epoch 18 loss: 0.07625297456979752\n",
      "epoch 19 loss: 0.08590012788772583\n",
      "epoch 20 loss: 0.07677800953388214\n",
      "epoch 21 loss: 0.0819559395313263\n",
      "epoch 22 loss: 0.07968331128358841\n",
      "epoch 23 loss: 0.08115270733833313\n",
      "epoch 24 loss: 0.06497599929571152\n",
      "epoch 25 loss: 0.08258569985628128\n",
      "epoch 26 loss: 0.06952263414859772\n",
      "epoch 27 loss: 0.08331619203090668\n",
      "epoch 28 loss: 0.07064637541770935\n",
      "epoch 29 loss: 0.07745806872844696\n",
      "epoch 30 loss: 0.06478983908891678\n",
      "45\n",
      "epoch 1 loss: 1.027066707611084\n",
      "epoch 2 loss: 0.6682167053222656\n",
      "epoch 3 loss: 0.7477287650108337\n",
      "epoch 4 loss: 0.4157836139202118\n",
      "epoch 5 loss: 0.1792939007282257\n",
      "epoch 6 loss: 0.1298525631427765\n",
      "epoch 7 loss: 0.12961095571517944\n",
      "epoch 8 loss: 0.13325420022010803\n",
      "epoch 9 loss: 0.11036666482686996\n",
      "epoch 10 loss: 0.08946378529071808\n",
      "epoch 11 loss: 0.11641491204500198\n",
      "epoch 12 loss: 0.08973576128482819\n",
      "epoch 13 loss: 0.11834999173879623\n",
      "epoch 14 loss: 0.0965152233839035\n",
      "epoch 15 loss: 0.08210575580596924\n",
      "epoch 16 loss: 0.0762249231338501\n",
      "epoch 17 loss: 0.09672333300113678\n",
      "epoch 18 loss: 0.09788176417350769\n",
      "epoch 19 loss: 0.10558708757162094\n",
      "epoch 20 loss: 0.0914573147892952\n",
      "epoch 21 loss: 0.0813048854470253\n",
      "epoch 22 loss: 0.07125388085842133\n",
      "epoch 23 loss: 0.07992590218782425\n",
      "epoch 24 loss: 0.07045504450798035\n",
      "epoch 25 loss: 0.06958942115306854\n",
      "epoch 26 loss: 0.08700563758611679\n",
      "epoch 27 loss: 0.08077482134103775\n",
      "epoch 28 loss: 0.08312351256608963\n",
      "epoch 29 loss: 0.07794281095266342\n",
      "epoch 30 loss: 0.07798570394515991\n",
      "46\n",
      "epoch 1 loss: 0.8374010324478149\n",
      "epoch 2 loss: 0.8740191459655762\n",
      "epoch 3 loss: 0.40367329120635986\n",
      "epoch 4 loss: 0.21309766173362732\n",
      "epoch 5 loss: 0.1843675971031189\n",
      "epoch 6 loss: 0.13584937155246735\n",
      "epoch 7 loss: 0.11719877272844315\n",
      "epoch 8 loss: 0.11623040586709976\n",
      "epoch 9 loss: 0.12033427506685257\n",
      "epoch 10 loss: 0.10621567070484161\n",
      "epoch 11 loss: 0.11367020756006241\n",
      "epoch 12 loss: 0.0984310507774353\n",
      "epoch 13 loss: 0.08007369190454483\n",
      "epoch 14 loss: 0.08980316668748856\n",
      "epoch 15 loss: 0.108551986515522\n",
      "epoch 16 loss: 0.12547864019870758\n",
      "epoch 17 loss: 0.11754652857780457\n",
      "epoch 18 loss: 0.08349155634641647\n",
      "epoch 19 loss: 0.11563295871019363\n",
      "epoch 20 loss: 0.07268746197223663\n",
      "epoch 21 loss: 0.0901976004242897\n",
      "epoch 22 loss: 0.07981957495212555\n",
      "epoch 23 loss: 0.09619636088609695\n",
      "epoch 24 loss: 0.09408397227525711\n",
      "epoch 25 loss: 0.06858404725790024\n",
      "epoch 26 loss: 0.06839317828416824\n",
      "epoch 27 loss: 0.07628456503152847\n",
      "epoch 28 loss: 0.08711691200733185\n",
      "epoch 29 loss: 0.09334545582532883\n",
      "epoch 30 loss: 0.08359864354133606\n",
      "47\n",
      "epoch 1 loss: 0.7986326217651367\n",
      "epoch 2 loss: 0.6218898892402649\n",
      "epoch 3 loss: 0.3891991376876831\n",
      "epoch 4 loss: 0.22681210935115814\n",
      "epoch 5 loss: 0.11797264963388443\n",
      "epoch 6 loss: 0.11625257134437561\n",
      "epoch 7 loss: 0.11789470165967941\n",
      "epoch 8 loss: 0.11453742533922195\n",
      "epoch 9 loss: 0.11064863950014114\n",
      "epoch 10 loss: 0.076144739985466\n",
      "epoch 11 loss: 0.07933494448661804\n",
      "epoch 12 loss: 0.08302003890275955\n",
      "epoch 13 loss: 0.10259893536567688\n",
      "epoch 14 loss: 0.06732697039842606\n",
      "epoch 15 loss: 0.08657827973365784\n",
      "epoch 16 loss: 0.08288785070180893\n",
      "epoch 17 loss: 0.08150815218687057\n",
      "epoch 18 loss: 0.075413279235363\n",
      "epoch 19 loss: 0.07947716116905212\n",
      "epoch 20 loss: 0.07855517417192459\n",
      "epoch 21 loss: 0.06770039349794388\n",
      "epoch 22 loss: 0.07945958524942398\n",
      "epoch 23 loss: 0.07128962874412537\n",
      "epoch 24 loss: 0.08326653391122818\n",
      "epoch 25 loss: 0.06999543309211731\n",
      "epoch 26 loss: 0.06832973659038544\n",
      "epoch 27 loss: 0.08344575762748718\n",
      "epoch 28 loss: 0.06549260020256042\n",
      "epoch 29 loss: 0.0699920803308487\n",
      "epoch 30 loss: 0.06653784960508347\n",
      "48\n",
      "epoch 1 loss: 0.8809674978256226\n",
      "epoch 2 loss: 0.6465685963630676\n",
      "epoch 3 loss: 0.4176378548145294\n",
      "epoch 4 loss: 0.21287408471107483\n",
      "epoch 5 loss: 0.20934391021728516\n",
      "epoch 6 loss: 0.17031028866767883\n",
      "epoch 7 loss: 0.17269237339496613\n",
      "epoch 8 loss: 0.145951047539711\n",
      "epoch 9 loss: 0.1554897129535675\n",
      "epoch 10 loss: 0.13254539668560028\n",
      "epoch 11 loss: 0.1011330634355545\n",
      "epoch 12 loss: 0.10666211694478989\n",
      "epoch 13 loss: 0.12237870693206787\n",
      "epoch 14 loss: 0.11665826290845871\n",
      "epoch 15 loss: 0.10091207176446915\n",
      "epoch 16 loss: 0.0858071967959404\n",
      "epoch 17 loss: 0.09751197695732117\n",
      "epoch 18 loss: 0.1072317436337471\n",
      "epoch 19 loss: 0.08508728444576263\n",
      "epoch 20 loss: 0.09396465122699738\n",
      "epoch 21 loss: 0.11983747780323029\n",
      "epoch 22 loss: 0.1026255413889885\n",
      "epoch 23 loss: 0.06675869226455688\n",
      "epoch 24 loss: 0.07755474001169205\n",
      "epoch 25 loss: 0.08930788934230804\n",
      "epoch 26 loss: 0.09630457311868668\n",
      "epoch 27 loss: 0.056006453931331635\n",
      "epoch 28 loss: 0.07321567088365555\n",
      "epoch 29 loss: 0.065981924533844\n",
      "epoch 30 loss: 0.07124661654233932\n",
      "49\n",
      "epoch 1 loss: 0.8663074970245361\n",
      "epoch 2 loss: 0.8956083655357361\n",
      "epoch 3 loss: 0.6074743270874023\n",
      "epoch 4 loss: 0.4059307873249054\n",
      "epoch 5 loss: 0.297529011964798\n",
      "epoch 6 loss: 0.25181570649147034\n",
      "epoch 7 loss: 0.24200224876403809\n",
      "epoch 8 loss: 0.12794411182403564\n",
      "epoch 9 loss: 0.1294565051794052\n",
      "epoch 10 loss: 0.13966387510299683\n",
      "epoch 11 loss: 0.1407930850982666\n",
      "epoch 12 loss: 0.09538039565086365\n",
      "epoch 13 loss: 0.11157126724720001\n",
      "epoch 14 loss: 0.1041279062628746\n",
      "epoch 15 loss: 0.08722332119941711\n",
      "epoch 16 loss: 0.1051352322101593\n",
      "epoch 17 loss: 0.08822612464427948\n",
      "epoch 18 loss: 0.08800268918275833\n",
      "epoch 19 loss: 0.10007892549037933\n",
      "epoch 20 loss: 0.09544026106595993\n",
      "epoch 21 loss: 0.08363077044487\n",
      "epoch 22 loss: 0.08963681012392044\n",
      "epoch 23 loss: 0.07139310985803604\n",
      "epoch 24 loss: 0.0903203934431076\n",
      "epoch 25 loss: 0.06988228857517242\n",
      "epoch 26 loss: 0.0873691663146019\n",
      "epoch 27 loss: 0.1070302203297615\n",
      "epoch 28 loss: 0.1002856120467186\n",
      "epoch 29 loss: 0.0904521718621254\n",
      "epoch 30 loss: 0.063535675406456\n",
      "50\n",
      "epoch 1 loss: 0.998285174369812\n",
      "epoch 2 loss: 0.5960826873779297\n",
      "epoch 3 loss: 0.41569504141807556\n",
      "epoch 4 loss: 0.22472883760929108\n",
      "epoch 5 loss: 0.15823322534561157\n",
      "epoch 6 loss: 0.14984065294265747\n",
      "epoch 7 loss: 0.13921068608760834\n",
      "epoch 8 loss: 0.14210055768489838\n",
      "epoch 9 loss: 0.11931655555963516\n",
      "epoch 10 loss: 0.13162823021411896\n",
      "epoch 11 loss: 0.1151203066110611\n",
      "epoch 12 loss: 0.09885961562395096\n",
      "epoch 13 loss: 0.11982656270265579\n",
      "epoch 14 loss: 0.10331613570451736\n",
      "epoch 15 loss: 0.12199581414461136\n",
      "epoch 16 loss: 0.10201587527990341\n",
      "epoch 17 loss: 0.11115279793739319\n",
      "epoch 18 loss: 0.09323745965957642\n",
      "epoch 19 loss: 0.10193832218647003\n",
      "epoch 20 loss: 0.0844694972038269\n",
      "epoch 21 loss: 0.13843633234500885\n",
      "epoch 22 loss: 0.09670142829418182\n",
      "epoch 23 loss: 0.09574694186449051\n",
      "epoch 24 loss: 0.08915682137012482\n",
      "epoch 25 loss: 0.06658391654491425\n",
      "epoch 26 loss: 0.0749940425157547\n",
      "epoch 27 loss: 0.06989949941635132\n",
      "epoch 28 loss: 0.07141737639904022\n",
      "epoch 29 loss: 0.06297118961811066\n",
      "epoch 30 loss: 0.0766611248254776\n",
      "51\n",
      "epoch 1 loss: 1.0659065246582031\n",
      "epoch 2 loss: 0.5359829664230347\n",
      "epoch 3 loss: 0.27560174465179443\n",
      "epoch 4 loss: 0.17571349442005157\n",
      "epoch 5 loss: 0.16845516860485077\n",
      "epoch 6 loss: 0.15305280685424805\n",
      "epoch 7 loss: 0.10732956230640411\n",
      "epoch 8 loss: 0.10703152418136597\n",
      "epoch 9 loss: 0.11470642685890198\n",
      "epoch 10 loss: 0.10579918324947357\n",
      "epoch 11 loss: 0.11550319194793701\n",
      "epoch 12 loss: 0.11553216725587845\n",
      "epoch 13 loss: 0.09155124425888062\n",
      "epoch 14 loss: 0.10406430065631866\n",
      "epoch 15 loss: 0.08584245294332504\n",
      "epoch 16 loss: 0.11595600843429565\n",
      "epoch 17 loss: 0.07630889862775803\n",
      "epoch 18 loss: 0.09591379761695862\n",
      "epoch 19 loss: 0.07966203987598419\n",
      "epoch 20 loss: 0.09104008972644806\n",
      "epoch 21 loss: 0.07678533345460892\n",
      "epoch 22 loss: 0.10597433894872665\n",
      "epoch 23 loss: 0.08943287283182144\n",
      "epoch 24 loss: 0.0837329775094986\n",
      "epoch 25 loss: 0.07268013805150986\n",
      "epoch 26 loss: 0.07692639529705048\n",
      "epoch 27 loss: 0.09084337204694748\n",
      "epoch 28 loss: 0.10690836608409882\n",
      "epoch 29 loss: 0.056170132011175156\n",
      "epoch 30 loss: 0.07178712636232376\n",
      "52\n",
      "epoch 1 loss: 0.6792412400245667\n",
      "epoch 2 loss: 0.4649714529514313\n",
      "epoch 3 loss: 0.327269971370697\n",
      "epoch 4 loss: 0.23281288146972656\n",
      "epoch 5 loss: 0.14240214228630066\n",
      "epoch 6 loss: 0.14283062517642975\n",
      "epoch 7 loss: 0.1280493140220642\n",
      "epoch 8 loss: 0.14578726887702942\n",
      "epoch 9 loss: 0.11420071870088577\n",
      "epoch 10 loss: 0.13043265044689178\n",
      "epoch 11 loss: 0.10999719798564911\n",
      "epoch 12 loss: 0.11536815017461777\n",
      "epoch 13 loss: 0.11459113657474518\n",
      "epoch 14 loss: 0.10029549151659012\n",
      "epoch 15 loss: 0.08443273603916168\n",
      "epoch 16 loss: 0.1081734374165535\n",
      "epoch 17 loss: 0.13700462877750397\n",
      "epoch 18 loss: 0.15367542207241058\n",
      "epoch 19 loss: 0.10317927598953247\n",
      "epoch 20 loss: 0.08251764625310898\n",
      "epoch 21 loss: 0.06644032895565033\n",
      "epoch 22 loss: 0.0667252168059349\n",
      "epoch 23 loss: 0.08240030705928802\n",
      "epoch 24 loss: 0.07357010245323181\n",
      "epoch 25 loss: 0.09696528315544128\n",
      "epoch 26 loss: 0.07244382798671722\n",
      "epoch 27 loss: 0.09262043982744217\n",
      "epoch 28 loss: 0.08885528147220612\n",
      "epoch 29 loss: 0.11017919331789017\n",
      "epoch 30 loss: 0.0827118530869484\n",
      "53\n",
      "epoch 1 loss: 0.9374191761016846\n",
      "epoch 2 loss: 0.6031466126441956\n",
      "epoch 3 loss: 0.34557944536209106\n",
      "epoch 4 loss: 0.2010158747434616\n",
      "epoch 5 loss: 0.14163294434547424\n",
      "epoch 6 loss: 0.1134711280465126\n",
      "epoch 7 loss: 0.12668085098266602\n",
      "epoch 8 loss: 0.09712044894695282\n",
      "epoch 9 loss: 0.09474043548107147\n",
      "epoch 10 loss: 0.12733393907546997\n",
      "epoch 11 loss: 0.0983426421880722\n",
      "epoch 12 loss: 0.06994515657424927\n",
      "epoch 13 loss: 0.09205950796604156\n",
      "epoch 14 loss: 0.09453701972961426\n",
      "epoch 15 loss: 0.08132410794496536\n",
      "epoch 16 loss: 0.07536564767360687\n",
      "epoch 17 loss: 0.07745597511529922\n",
      "epoch 18 loss: 0.09534933418035507\n",
      "epoch 19 loss: 0.07875242829322815\n",
      "epoch 20 loss: 0.08177085965871811\n",
      "epoch 21 loss: 0.11251875013113022\n",
      "epoch 22 loss: 0.08652853220701218\n",
      "epoch 23 loss: 0.09050770848989487\n",
      "epoch 24 loss: 0.08420565724372864\n",
      "epoch 25 loss: 0.09173549711704254\n",
      "epoch 26 loss: 0.09278937429189682\n",
      "epoch 27 loss: 0.07584722340106964\n",
      "epoch 28 loss: 0.08049409836530685\n",
      "epoch 29 loss: 0.09442950785160065\n",
      "epoch 30 loss: 0.06383062899112701\n",
      "54\n",
      "epoch 1 loss: 0.7823991775512695\n",
      "epoch 2 loss: 0.7809524536132812\n",
      "epoch 3 loss: 0.45995980501174927\n",
      "epoch 4 loss: 0.3380197286605835\n",
      "epoch 5 loss: 0.20570428669452667\n",
      "epoch 6 loss: 0.14233696460723877\n",
      "epoch 7 loss: 0.15936315059661865\n",
      "epoch 8 loss: 0.10863420367240906\n",
      "epoch 9 loss: 0.10212794691324234\n",
      "epoch 10 loss: 0.13696154952049255\n",
      "epoch 11 loss: 0.101985864341259\n",
      "epoch 12 loss: 0.1432245522737503\n",
      "epoch 13 loss: 0.12380684167146683\n",
      "epoch 14 loss: 0.11008395254611969\n",
      "epoch 15 loss: 0.08379455655813217\n",
      "epoch 16 loss: 0.08454151451587677\n",
      "epoch 17 loss: 0.08455513417720795\n",
      "epoch 18 loss: 0.06745179742574692\n",
      "epoch 19 loss: 0.08097578585147858\n",
      "epoch 20 loss: 0.08133245259523392\n",
      "epoch 21 loss: 0.07587607204914093\n",
      "epoch 22 loss: 0.0631505474448204\n",
      "epoch 23 loss: 0.08029626309871674\n",
      "epoch 24 loss: 0.05982251092791557\n",
      "epoch 25 loss: 0.1209302470088005\n",
      "epoch 26 loss: 0.07906022667884827\n",
      "epoch 27 loss: 0.08611662685871124\n",
      "epoch 28 loss: 0.08090377599000931\n",
      "epoch 29 loss: 0.07689175009727478\n",
      "epoch 30 loss: 0.053248677402734756\n",
      "55\n",
      "epoch 1 loss: 0.8821080327033997\n",
      "epoch 2 loss: 0.5765932202339172\n",
      "epoch 3 loss: 0.5742807984352112\n",
      "epoch 4 loss: 0.21528327465057373\n",
      "epoch 5 loss: 0.14661233127117157\n",
      "epoch 6 loss: 0.12595728039741516\n",
      "epoch 7 loss: 0.10959741473197937\n",
      "epoch 8 loss: 0.0844166949391365\n",
      "epoch 9 loss: 0.12103172391653061\n",
      "epoch 10 loss: 0.08757089078426361\n",
      "epoch 11 loss: 0.110115647315979\n",
      "epoch 12 loss: 0.08507388830184937\n",
      "epoch 13 loss: 0.0653330534696579\n",
      "epoch 14 loss: 0.07813311368227005\n",
      "epoch 15 loss: 0.08689061552286148\n",
      "epoch 16 loss: 0.10396042466163635\n",
      "epoch 17 loss: 0.08566457033157349\n",
      "epoch 18 loss: 0.07810886949300766\n",
      "epoch 19 loss: 0.09793013334274292\n",
      "epoch 20 loss: 0.09106387943029404\n",
      "epoch 21 loss: 0.07958485186100006\n",
      "epoch 22 loss: 0.0967634916305542\n",
      "epoch 23 loss: 0.10779163241386414\n",
      "epoch 24 loss: 0.08811598271131516\n",
      "epoch 25 loss: 0.06018336862325668\n",
      "epoch 26 loss: 0.07818801701068878\n",
      "epoch 27 loss: 0.08592686057090759\n",
      "epoch 28 loss: 0.10655157268047333\n",
      "epoch 29 loss: 0.05989730358123779\n",
      "epoch 30 loss: 0.06622443348169327\n",
      "56\n",
      "epoch 1 loss: 1.0229902267456055\n",
      "epoch 2 loss: 0.7414240837097168\n",
      "epoch 3 loss: 0.5351630449295044\n",
      "epoch 4 loss: 0.24153830111026764\n",
      "epoch 5 loss: 0.20260073244571686\n",
      "epoch 6 loss: 0.15414147078990936\n",
      "epoch 7 loss: 0.12578725814819336\n",
      "epoch 8 loss: 0.10315337032079697\n",
      "epoch 9 loss: 0.09488321840763092\n",
      "epoch 10 loss: 0.10340765118598938\n",
      "epoch 11 loss: 0.09379307180643082\n",
      "epoch 12 loss: 0.08318492770195007\n",
      "epoch 13 loss: 0.09041844308376312\n",
      "epoch 14 loss: 0.08550061285495758\n",
      "epoch 15 loss: 0.0995352491736412\n",
      "epoch 16 loss: 0.11167103052139282\n",
      "epoch 17 loss: 0.09021824598312378\n",
      "epoch 18 loss: 0.08658303320407867\n",
      "epoch 19 loss: 0.08432289212942123\n",
      "epoch 20 loss: 0.06894972920417786\n",
      "epoch 21 loss: 0.08312321454286575\n",
      "epoch 22 loss: 0.10052631795406342\n",
      "epoch 23 loss: 0.07750490307807922\n",
      "epoch 24 loss: 0.06378214806318283\n",
      "epoch 25 loss: 0.10080362111330032\n",
      "epoch 26 loss: 0.07002291083335876\n",
      "epoch 27 loss: 0.08783852308988571\n",
      "epoch 28 loss: 0.08142032474279404\n",
      "epoch 29 loss: 0.0786801129579544\n",
      "epoch 30 loss: 0.07636185735464096\n",
      "57\n",
      "epoch 1 loss: 0.7221865653991699\n",
      "epoch 2 loss: 0.6907480359077454\n",
      "epoch 3 loss: 0.3792382776737213\n",
      "epoch 4 loss: 0.23776991665363312\n",
      "epoch 5 loss: 0.16794833540916443\n",
      "epoch 6 loss: 0.17614728212356567\n",
      "epoch 7 loss: 0.1347549706697464\n",
      "epoch 8 loss: 0.15424208343029022\n",
      "epoch 9 loss: 0.14126724004745483\n",
      "epoch 10 loss: 0.12386857718229294\n",
      "epoch 11 loss: 0.09877640753984451\n",
      "epoch 12 loss: 0.09718099236488342\n",
      "epoch 13 loss: 0.10789494216442108\n",
      "epoch 14 loss: 0.19087329506874084\n",
      "epoch 15 loss: 0.08059123903512955\n",
      "epoch 16 loss: 0.08459316194057465\n",
      "epoch 17 loss: 0.09503304958343506\n",
      "epoch 18 loss: 0.08601632714271545\n",
      "epoch 19 loss: 0.11324054002761841\n",
      "epoch 20 loss: 0.06621537357568741\n",
      "epoch 21 loss: 0.10394752770662308\n",
      "epoch 22 loss: 0.0787646621465683\n",
      "epoch 23 loss: 0.08128345012664795\n",
      "epoch 24 loss: 0.07211863994598389\n",
      "epoch 25 loss: 0.07775861024856567\n",
      "epoch 26 loss: 0.095987968146801\n",
      "epoch 27 loss: 0.07339818775653839\n",
      "epoch 28 loss: 0.06897790729999542\n",
      "epoch 29 loss: 0.09596093744039536\n",
      "epoch 30 loss: 0.0812411904335022\n",
      "58\n",
      "epoch 1 loss: 0.8940885663032532\n",
      "epoch 2 loss: 0.8373680114746094\n",
      "epoch 3 loss: 0.5815662741661072\n",
      "epoch 4 loss: 0.20417217910289764\n",
      "epoch 5 loss: 0.15219971537590027\n",
      "epoch 6 loss: 0.16260991990566254\n",
      "epoch 7 loss: 0.15226370096206665\n",
      "epoch 8 loss: 0.108050137758255\n",
      "epoch 9 loss: 0.11788163334131241\n",
      "epoch 10 loss: 0.08295394480228424\n",
      "epoch 11 loss: 0.0966913178563118\n",
      "epoch 12 loss: 0.1272529512643814\n",
      "epoch 13 loss: 0.09198836982250214\n",
      "epoch 14 loss: 0.08561395853757858\n",
      "epoch 15 loss: 0.09791074693202972\n",
      "epoch 16 loss: 0.10461244732141495\n",
      "epoch 17 loss: 0.10688252747058868\n",
      "epoch 18 loss: 0.08898329734802246\n",
      "epoch 19 loss: 0.08365938812494278\n",
      "epoch 20 loss: 0.08373904228210449\n",
      "epoch 21 loss: 0.08311156928539276\n",
      "epoch 22 loss: 0.06847911328077316\n",
      "epoch 23 loss: 0.07542281597852707\n",
      "epoch 24 loss: 0.08731179684400558\n",
      "epoch 25 loss: 0.06937187910079956\n",
      "epoch 26 loss: 0.07159524410963058\n",
      "epoch 27 loss: 0.07003682106733322\n",
      "epoch 28 loss: 0.06041387841105461\n",
      "epoch 29 loss: 0.08596643060445786\n",
      "epoch 30 loss: 0.06792207807302475\n",
      "59\n",
      "epoch 1 loss: 0.8567753434181213\n",
      "epoch 2 loss: 0.6761857271194458\n",
      "epoch 3 loss: 0.4634687304496765\n",
      "epoch 4 loss: 0.715742290019989\n",
      "epoch 5 loss: 0.34173911809921265\n",
      "epoch 6 loss: 0.17962609231472015\n",
      "epoch 7 loss: 0.1698668748140335\n",
      "epoch 8 loss: 0.14853274822235107\n",
      "epoch 9 loss: 0.1552126109600067\n",
      "epoch 10 loss: 0.13325150310993195\n",
      "epoch 11 loss: 0.10702948272228241\n",
      "epoch 12 loss: 0.12059681862592697\n",
      "epoch 13 loss: 0.11875895410776138\n",
      "epoch 14 loss: 0.1181146577000618\n",
      "epoch 15 loss: 0.08601447939872742\n",
      "epoch 16 loss: 0.0864342600107193\n",
      "epoch 17 loss: 0.08682932704687119\n",
      "epoch 18 loss: 0.11376608908176422\n",
      "epoch 19 loss: 0.09070755541324615\n",
      "epoch 20 loss: 0.08070378005504608\n",
      "epoch 21 loss: 0.08398952335119247\n",
      "epoch 22 loss: 0.0816570594906807\n",
      "epoch 23 loss: 0.09664709866046906\n",
      "epoch 24 loss: 0.08050792664289474\n",
      "epoch 25 loss: 0.06889251619577408\n",
      "epoch 26 loss: 0.08348380774259567\n",
      "epoch 27 loss: 0.07377732545137405\n",
      "epoch 28 loss: 0.0941188782453537\n",
      "epoch 29 loss: 0.07923723757266998\n",
      "epoch 30 loss: 0.1057967022061348\n",
      "60\n",
      "epoch 1 loss: 0.6308093070983887\n",
      "epoch 2 loss: 0.6330848932266235\n",
      "epoch 3 loss: 0.2945440411567688\n",
      "epoch 4 loss: 0.2178982049226761\n",
      "epoch 5 loss: 0.2286113202571869\n",
      "epoch 6 loss: 0.1675453931093216\n",
      "epoch 7 loss: 0.14350904524326324\n",
      "epoch 8 loss: 0.14520718157291412\n",
      "epoch 9 loss: 0.12394572049379349\n",
      "epoch 10 loss: 0.13120144605636597\n",
      "epoch 11 loss: 0.12916898727416992\n",
      "epoch 12 loss: 0.1102423146367073\n",
      "epoch 13 loss: 0.08366060256958008\n",
      "epoch 14 loss: 0.1188092827796936\n",
      "epoch 15 loss: 0.12976528704166412\n",
      "epoch 16 loss: 0.08890994638204575\n",
      "epoch 17 loss: 0.0989014059305191\n",
      "epoch 18 loss: 0.10508901625871658\n",
      "epoch 19 loss: 0.09760056436061859\n",
      "epoch 20 loss: 0.07224705815315247\n",
      "epoch 21 loss: 0.07096284627914429\n",
      "epoch 22 loss: 0.08567763864994049\n",
      "epoch 23 loss: 0.07629247009754181\n",
      "epoch 24 loss: 0.0650278776884079\n",
      "epoch 25 loss: 0.07163452357053757\n",
      "epoch 26 loss: 0.08258895576000214\n",
      "epoch 27 loss: 0.07268033921718597\n",
      "epoch 28 loss: 0.08839449286460876\n",
      "epoch 29 loss: 0.0856190100312233\n",
      "epoch 30 loss: 0.07032203674316406\n",
      "61\n",
      "epoch 1 loss: 0.8848420977592468\n",
      "epoch 2 loss: 0.48968181014060974\n",
      "epoch 3 loss: 0.6396573185920715\n",
      "epoch 4 loss: 0.31302735209465027\n",
      "epoch 5 loss: 0.16333693265914917\n",
      "epoch 6 loss: 0.1291120946407318\n",
      "epoch 7 loss: 0.1386464238166809\n",
      "epoch 8 loss: 0.11678232997655869\n",
      "epoch 9 loss: 0.08823448419570923\n",
      "epoch 10 loss: 0.1304628700017929\n",
      "epoch 11 loss: 0.13012544810771942\n",
      "epoch 12 loss: 0.09363676607608795\n",
      "epoch 13 loss: 0.11159718781709671\n",
      "epoch 14 loss: 0.07871764153242111\n",
      "epoch 15 loss: 0.08468218147754669\n",
      "epoch 16 loss: 0.0908348336815834\n",
      "epoch 17 loss: 0.07261017709970474\n",
      "epoch 18 loss: 0.07654068619012833\n",
      "epoch 19 loss: 0.10145887732505798\n",
      "epoch 20 loss: 0.0909435898065567\n",
      "epoch 21 loss: 0.08615601807832718\n",
      "epoch 22 loss: 0.08178190141916275\n",
      "epoch 23 loss: 0.06095770001411438\n",
      "epoch 24 loss: 0.07806478440761566\n",
      "epoch 25 loss: 0.0781971886754036\n",
      "epoch 26 loss: 0.07901027053594589\n",
      "epoch 27 loss: 0.08291449397802353\n",
      "epoch 28 loss: 0.08281555026769638\n",
      "epoch 29 loss: 0.07985658943653107\n",
      "epoch 30 loss: 0.09256845712661743\n",
      "62\n",
      "epoch 1 loss: 0.9706677794456482\n",
      "epoch 2 loss: 0.5494688153266907\n",
      "epoch 3 loss: 0.2645023763179779\n",
      "epoch 4 loss: 0.1438291221857071\n",
      "epoch 5 loss: 0.11783171445131302\n",
      "epoch 6 loss: 0.14522217214107513\n",
      "epoch 7 loss: 0.1245332658290863\n",
      "epoch 8 loss: 0.0986306443810463\n",
      "epoch 9 loss: 0.09677363932132721\n",
      "epoch 10 loss: 0.08309861272573471\n",
      "epoch 11 loss: 0.1289214789867401\n",
      "epoch 12 loss: 0.11406432837247849\n",
      "epoch 13 loss: 0.12492221593856812\n",
      "epoch 14 loss: 0.1291595995426178\n",
      "epoch 15 loss: 0.07495035976171494\n",
      "epoch 16 loss: 0.0919373631477356\n",
      "epoch 17 loss: 0.08545234054327011\n",
      "epoch 18 loss: 0.07976175844669342\n",
      "epoch 19 loss: 0.07168058305978775\n",
      "epoch 20 loss: 0.08115915954113007\n",
      "epoch 21 loss: 0.08843885362148285\n",
      "epoch 22 loss: 0.06405244767665863\n",
      "epoch 23 loss: 0.06142483651638031\n",
      "epoch 24 loss: 0.10653349757194519\n",
      "epoch 25 loss: 0.08577649295330048\n",
      "epoch 26 loss: 0.07452954351902008\n",
      "epoch 27 loss: 0.08399418741464615\n",
      "epoch 28 loss: 0.06551311165094376\n",
      "epoch 29 loss: 0.08104216307401657\n",
      "epoch 30 loss: 0.08014039695262909\n",
      "63\n",
      "epoch 1 loss: 0.7358216047286987\n",
      "epoch 2 loss: 0.8513635993003845\n",
      "epoch 3 loss: 0.4931628108024597\n",
      "epoch 4 loss: 0.24783781170845032\n",
      "epoch 5 loss: 0.18418867886066437\n",
      "epoch 6 loss: 0.1418616622686386\n",
      "epoch 7 loss: 0.13378430902957916\n",
      "epoch 8 loss: 0.10202258825302124\n",
      "epoch 9 loss: 0.1099846363067627\n",
      "epoch 10 loss: 0.12007097899913788\n",
      "epoch 11 loss: 0.12992307543754578\n",
      "epoch 12 loss: 0.11110934615135193\n",
      "epoch 13 loss: 0.10067163407802582\n",
      "epoch 14 loss: 0.08717432618141174\n",
      "epoch 15 loss: 0.09455496817827225\n",
      "epoch 16 loss: 0.05979687348008156\n",
      "epoch 17 loss: 0.08234711736440659\n",
      "epoch 18 loss: 0.0804760605096817\n",
      "epoch 19 loss: 0.07415900379419327\n",
      "epoch 20 loss: 0.0765896886587143\n",
      "epoch 21 loss: 0.10553883016109467\n",
      "epoch 22 loss: 0.06459406018257141\n",
      "epoch 23 loss: 0.08489862829446793\n",
      "epoch 24 loss: 0.09330505132675171\n",
      "epoch 25 loss: 0.09663601964712143\n",
      "epoch 26 loss: 0.07234794646501541\n",
      "epoch 27 loss: 0.07573872804641724\n",
      "epoch 28 loss: 0.07054304331541061\n",
      "epoch 29 loss: 0.07518888264894485\n",
      "epoch 30 loss: 0.0764891728758812\n",
      "64\n",
      "epoch 1 loss: 1.0350120067596436\n",
      "epoch 2 loss: 0.70848548412323\n",
      "epoch 3 loss: 0.3501490652561188\n",
      "epoch 4 loss: 0.23380768299102783\n",
      "epoch 5 loss: 0.1708015352487564\n",
      "epoch 6 loss: 0.12404777109622955\n",
      "epoch 7 loss: 0.12448649108409882\n",
      "epoch 8 loss: 0.1532934308052063\n",
      "epoch 9 loss: 0.1089164987206459\n",
      "epoch 10 loss: 0.09987766295671463\n",
      "epoch 11 loss: 0.10627293586730957\n",
      "epoch 12 loss: 0.09645359963178635\n",
      "epoch 13 loss: 0.0833662897348404\n",
      "epoch 14 loss: 0.08101098984479904\n",
      "epoch 15 loss: 0.08855512738227844\n",
      "epoch 16 loss: 0.09740602970123291\n",
      "epoch 17 loss: 0.10317838191986084\n",
      "epoch 18 loss: 0.0683475136756897\n",
      "epoch 19 loss: 0.09761030226945877\n",
      "epoch 20 loss: 0.08080623298883438\n",
      "epoch 21 loss: 0.08106233924627304\n",
      "epoch 22 loss: 0.07435893267393112\n",
      "epoch 23 loss: 0.08107060194015503\n",
      "epoch 24 loss: 0.08467631042003632\n",
      "epoch 25 loss: 0.07417594641447067\n",
      "epoch 26 loss: 0.06797413527965546\n",
      "epoch 27 loss: 0.09967232495546341\n",
      "epoch 28 loss: 0.0758906900882721\n",
      "epoch 29 loss: 0.06635686010122299\n",
      "epoch 30 loss: 0.07770231366157532\n",
      "65\n",
      "epoch 1 loss: 0.8265928626060486\n",
      "epoch 2 loss: 0.5983659029006958\n",
      "epoch 3 loss: 0.4055097997188568\n",
      "epoch 4 loss: 0.1896752417087555\n",
      "epoch 5 loss: 0.1629616767168045\n",
      "epoch 6 loss: 0.11875642091035843\n",
      "epoch 7 loss: 0.10480689257383347\n",
      "epoch 8 loss: 0.13964325189590454\n",
      "epoch 9 loss: 0.09047004580497742\n",
      "epoch 10 loss: 0.08908287435770035\n",
      "epoch 11 loss: 0.1052284836769104\n",
      "epoch 12 loss: 0.08492040634155273\n",
      "epoch 13 loss: 0.09947255998849869\n",
      "epoch 14 loss: 0.10701525211334229\n",
      "epoch 15 loss: 0.09410058706998825\n",
      "epoch 16 loss: 0.10366607457399368\n",
      "epoch 17 loss: 0.07235366851091385\n",
      "epoch 18 loss: 0.08726022392511368\n",
      "epoch 19 loss: 0.08533240109682083\n",
      "epoch 20 loss: 0.0703761875629425\n",
      "epoch 21 loss: 0.07444458454847336\n",
      "epoch 22 loss: 0.08257319778203964\n",
      "epoch 23 loss: 0.08512862026691437\n",
      "epoch 24 loss: 0.0972929447889328\n",
      "epoch 25 loss: 0.07891591638326645\n",
      "epoch 26 loss: 0.06500513851642609\n",
      "epoch 27 loss: 0.07060631364583969\n",
      "epoch 28 loss: 0.07387090474367142\n",
      "epoch 29 loss: 0.07876172661781311\n",
      "epoch 30 loss: 0.07868392020463943\n",
      "66\n",
      "epoch 1 loss: 0.8541752099990845\n",
      "epoch 2 loss: 0.7964488863945007\n",
      "epoch 3 loss: 0.4930631220340729\n",
      "epoch 4 loss: 0.25072744488716125\n",
      "epoch 5 loss: 0.139476478099823\n",
      "epoch 6 loss: 0.09749557077884674\n",
      "epoch 7 loss: 0.12250089645385742\n",
      "epoch 8 loss: 0.16840577125549316\n",
      "epoch 9 loss: 0.10376414656639099\n",
      "epoch 10 loss: 0.15199598670005798\n",
      "epoch 11 loss: 0.1361856758594513\n",
      "epoch 12 loss: 0.10296621918678284\n",
      "epoch 13 loss: 0.08337025344371796\n",
      "epoch 14 loss: 0.1301908791065216\n",
      "epoch 15 loss: 0.10424386709928513\n",
      "epoch 16 loss: 0.07989812642335892\n",
      "epoch 17 loss: 0.0727938711643219\n",
      "epoch 18 loss: 0.079953134059906\n",
      "epoch 19 loss: 0.09506828337907791\n",
      "epoch 20 loss: 0.08546433597803116\n",
      "epoch 21 loss: 0.07875283062458038\n",
      "epoch 22 loss: 0.07835967093706131\n",
      "epoch 23 loss: 0.08452119678258896\n",
      "epoch 24 loss: 0.06454228609800339\n",
      "epoch 25 loss: 0.09407968819141388\n",
      "epoch 26 loss: 0.08916431665420532\n",
      "epoch 27 loss: 0.08192482590675354\n",
      "epoch 28 loss: 0.06600584089756012\n",
      "epoch 29 loss: 0.07680710405111313\n",
      "epoch 30 loss: 0.0708027109503746\n",
      "67\n",
      "epoch 1 loss: 0.9611331820487976\n",
      "epoch 2 loss: 0.727514386177063\n",
      "epoch 3 loss: 0.5294234156608582\n",
      "epoch 4 loss: 0.2362644076347351\n",
      "epoch 5 loss: 0.1630660891532898\n",
      "epoch 6 loss: 0.10267948359251022\n",
      "epoch 7 loss: 0.15551292896270752\n",
      "epoch 8 loss: 0.13620930910110474\n",
      "epoch 9 loss: 0.11696778982877731\n",
      "epoch 10 loss: 0.12358003109693527\n",
      "epoch 11 loss: 0.09491758793592453\n",
      "epoch 12 loss: 0.09776851534843445\n",
      "epoch 13 loss: 0.19044150412082672\n",
      "epoch 14 loss: 0.07511619478464127\n",
      "epoch 15 loss: 0.07946902513504028\n",
      "epoch 16 loss: 0.0645124763250351\n",
      "epoch 17 loss: 0.09353321045637131\n",
      "epoch 18 loss: 0.09675516188144684\n",
      "epoch 19 loss: 0.07910037785768509\n",
      "epoch 20 loss: 0.08461211621761322\n",
      "epoch 21 loss: 0.06427726149559021\n",
      "epoch 22 loss: 0.08308247476816177\n",
      "epoch 23 loss: 0.10010454803705215\n",
      "epoch 24 loss: 0.08620533347129822\n",
      "epoch 25 loss: 0.07727422565221786\n",
      "epoch 26 loss: 0.06802935898303986\n",
      "epoch 27 loss: 0.06826720386743546\n",
      "epoch 28 loss: 0.07541685551404953\n",
      "epoch 29 loss: 0.09140127152204514\n",
      "epoch 30 loss: 0.08421707898378372\n",
      "68\n",
      "epoch 1 loss: 0.8681834936141968\n",
      "epoch 2 loss: 0.45129039883613586\n",
      "epoch 3 loss: 0.34654685854911804\n",
      "epoch 4 loss: 0.20335863530635834\n",
      "epoch 5 loss: 0.14148974418640137\n",
      "epoch 6 loss: 0.14661693572998047\n",
      "epoch 7 loss: 0.1475769281387329\n",
      "epoch 8 loss: 0.14613324403762817\n",
      "epoch 9 loss: 0.11378597468137741\n",
      "epoch 10 loss: 0.08931190520524979\n",
      "epoch 11 loss: 0.10748351365327835\n",
      "epoch 12 loss: 0.10052136331796646\n",
      "epoch 13 loss: 0.08365059643983841\n",
      "epoch 14 loss: 0.08562631905078888\n",
      "epoch 15 loss: 0.12194187194108963\n",
      "epoch 16 loss: 0.09068207442760468\n",
      "epoch 17 loss: 0.08418111503124237\n",
      "epoch 18 loss: 0.07504619657993317\n",
      "epoch 19 loss: 0.09494500607252121\n",
      "epoch 20 loss: 0.08085422217845917\n",
      "epoch 21 loss: 0.07413163781166077\n",
      "epoch 22 loss: 0.09093326330184937\n",
      "epoch 23 loss: 0.08990723639726639\n",
      "epoch 24 loss: 0.0818164274096489\n",
      "epoch 25 loss: 0.07293634861707687\n",
      "epoch 26 loss: 0.06615834683179855\n",
      "epoch 27 loss: 0.07590968161821365\n",
      "epoch 28 loss: 0.08462733775377274\n",
      "epoch 29 loss: 0.09289845079183578\n",
      "epoch 30 loss: 0.05998651310801506\n",
      "69\n",
      "epoch 1 loss: 0.8168025612831116\n",
      "epoch 2 loss: 0.5905327796936035\n",
      "epoch 3 loss: 0.26912617683410645\n",
      "epoch 4 loss: 0.15184038877487183\n",
      "epoch 5 loss: 0.11708357185125351\n",
      "epoch 6 loss: 0.09432593733072281\n",
      "epoch 7 loss: 0.10594961792230606\n",
      "epoch 8 loss: 0.10881216078996658\n",
      "epoch 9 loss: 0.08270379900932312\n",
      "epoch 10 loss: 0.07805051654577255\n",
      "epoch 11 loss: 0.0914640948176384\n",
      "epoch 12 loss: 0.0808233767747879\n",
      "epoch 13 loss: 0.07197686284780502\n",
      "epoch 14 loss: 0.0972341001033783\n",
      "epoch 15 loss: 0.07010511308908463\n",
      "epoch 16 loss: 0.083403579890728\n",
      "epoch 17 loss: 0.09507261961698532\n",
      "epoch 18 loss: 0.07354704290628433\n",
      "epoch 19 loss: 0.0797828659415245\n",
      "epoch 20 loss: 0.08566976338624954\n",
      "epoch 21 loss: 0.11006929725408554\n",
      "epoch 22 loss: 0.07226567715406418\n",
      "epoch 23 loss: 0.06317811459302902\n",
      "epoch 24 loss: 0.06905066967010498\n",
      "epoch 25 loss: 0.07701434940099716\n",
      "epoch 26 loss: 0.10312860459089279\n",
      "epoch 27 loss: 0.07209602743387222\n",
      "epoch 28 loss: 0.09519712626934052\n",
      "epoch 29 loss: 0.08065305650234222\n",
      "epoch 30 loss: 0.06050519645214081\n",
      "70\n",
      "epoch 1 loss: 1.1596879959106445\n",
      "epoch 2 loss: 0.7014198303222656\n",
      "epoch 3 loss: 0.27756810188293457\n",
      "epoch 4 loss: 0.19924350082874298\n",
      "epoch 5 loss: 0.1513286828994751\n",
      "epoch 6 loss: 0.16809934377670288\n",
      "epoch 7 loss: 0.15079247951507568\n",
      "epoch 8 loss: 0.13552075624465942\n",
      "epoch 9 loss: 0.14072898030281067\n",
      "epoch 10 loss: 0.09900856018066406\n",
      "epoch 11 loss: 0.12809276580810547\n",
      "epoch 12 loss: 0.09168454259634018\n",
      "epoch 13 loss: 0.08186711370944977\n",
      "epoch 14 loss: 0.07869398593902588\n",
      "epoch 15 loss: 0.06534114480018616\n",
      "epoch 16 loss: 0.09046320617198944\n",
      "epoch 17 loss: 0.08152282238006592\n",
      "epoch 18 loss: 0.07578382641077042\n",
      "epoch 19 loss: 0.09539587795734406\n",
      "epoch 20 loss: 0.10764171183109283\n",
      "epoch 21 loss: 0.060802482068538666\n",
      "epoch 22 loss: 0.0752943754196167\n",
      "epoch 23 loss: 0.08475198596715927\n",
      "epoch 24 loss: 0.07665107399225235\n",
      "epoch 25 loss: 0.09603501856327057\n",
      "epoch 26 loss: 0.07146641612052917\n",
      "epoch 27 loss: 0.12185382097959518\n",
      "epoch 28 loss: 0.07598190009593964\n",
      "epoch 29 loss: 0.06729404628276825\n",
      "epoch 30 loss: 0.09069357067346573\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "098899fc-f69c-40fd-97d5-21d4a8e72619",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + numerical weekday"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wn = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wn()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wn = pd.concat([results_aep_self_con_wn, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con_wn.to_csv(out_dir + '/results_aep_self_con_wn.csv', index=False)"
   ],
   "id": "f6b8f3248cc64895"
  },
  {
   "cell_type": "markdown",
   "id": "f21f0b6e-940d-4aba-ade0-11c129bfcf90",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + categorical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "6725e474-71bd-4c89-9874-c86e0542477d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:17:53.141666Z",
     "start_time": "2025-10-03T14:14:27.906783Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wc = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wc()\n",
    "    trainer = model_class.RNN_train_2(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "results_aep_self_con_wc.to_csv(out_dir + '/results_aep_self_con_wc.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1 loss: 0.8390329480171204\n",
      "epoch 2 loss: 0.6036105155944824\n",
      "epoch 3 loss: 0.24438445270061493\n",
      "epoch 4 loss: 0.14826078712940216\n",
      "epoch 5 loss: 0.14974439144134521\n",
      "epoch 6 loss: 0.12507973611354828\n",
      "epoch 7 loss: 0.09557902812957764\n",
      "epoch 8 loss: 0.09335751086473465\n",
      "epoch 9 loss: 0.086921326816082\n",
      "epoch 10 loss: 0.07268732041120529\n",
      "epoch 11 loss: 0.05933845043182373\n",
      "epoch 12 loss: 0.09224571287631989\n",
      "epoch 13 loss: 0.0940682664513588\n",
      "epoch 14 loss: 0.06109781563282013\n",
      "epoch 15 loss: 0.059888508170843124\n",
      "epoch 16 loss: 0.05162273719906807\n",
      "epoch 17 loss: 0.08831685036420822\n",
      "epoch 18 loss: 0.08742289990186691\n",
      "epoch 19 loss: 0.07060473412275314\n",
      "epoch 20 loss: 0.050168536603450775\n",
      "epoch 21 loss: 0.06504275649785995\n",
      "epoch 22 loss: 0.05612599849700928\n",
      "epoch 23 loss: 0.06670321524143219\n",
      "epoch 24 loss: 0.056243401020765305\n",
      "epoch 25 loss: 0.058176249265670776\n",
      "epoch 26 loss: 0.06523808091878891\n",
      "epoch 27 loss: 0.05867001786828041\n",
      "epoch 28 loss: 0.05840415507555008\n",
      "epoch 29 loss: 0.044328756630420685\n",
      "epoch 30 loss: 0.06116331368684769\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_60650/4061239959.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 1.0410021543502808\n",
      "epoch 2 loss: 0.6607019901275635\n",
      "epoch 3 loss: 0.1842181235551834\n",
      "epoch 4 loss: 0.19811159372329712\n",
      "epoch 5 loss: 0.15518803894519806\n",
      "epoch 6 loss: 0.12503014504909515\n",
      "epoch 7 loss: 0.13933658599853516\n",
      "epoch 8 loss: 0.14219160377979279\n",
      "epoch 9 loss: 0.10398723185062408\n",
      "epoch 10 loss: 0.11738032847642899\n",
      "epoch 11 loss: 0.09693284332752228\n",
      "epoch 12 loss: 0.0697757825255394\n",
      "epoch 13 loss: 0.08096786588430405\n",
      "epoch 14 loss: 0.07483503222465515\n",
      "epoch 15 loss: 0.13574755191802979\n",
      "epoch 16 loss: 0.06989134848117828\n",
      "epoch 17 loss: 0.11578453332185745\n",
      "epoch 18 loss: 0.06152272969484329\n",
      "epoch 19 loss: 0.05797957628965378\n",
      "epoch 20 loss: 0.06196713447570801\n",
      "epoch 21 loss: 0.07481169700622559\n",
      "epoch 22 loss: 0.05432567372918129\n",
      "epoch 23 loss: 0.07811460644006729\n",
      "epoch 24 loss: 0.061234086751937866\n",
      "epoch 25 loss: 0.045783936977386475\n",
      "epoch 26 loss: 0.061963919550180435\n",
      "epoch 27 loss: 0.07013934850692749\n",
      "epoch 28 loss: 0.10022807866334915\n",
      "epoch 29 loss: 0.06866725534200668\n",
      "epoch 30 loss: 0.07724808156490326\n",
      "3\n",
      "epoch 1 loss: 0.7478914856910706\n",
      "epoch 2 loss: 0.5403508543968201\n",
      "epoch 3 loss: 0.2882104516029358\n",
      "epoch 4 loss: 0.21862900257110596\n",
      "epoch 5 loss: 0.1445223093032837\n",
      "epoch 6 loss: 0.0902172401547432\n",
      "epoch 7 loss: 0.10126704722642899\n",
      "epoch 8 loss: 0.0964493528008461\n",
      "epoch 9 loss: 0.06980204582214355\n",
      "epoch 10 loss: 0.077961266040802\n",
      "epoch 11 loss: 0.06651555746793747\n",
      "epoch 12 loss: 0.06569213420152664\n",
      "epoch 13 loss: 0.06415502727031708\n",
      "epoch 14 loss: 0.06840412318706512\n",
      "epoch 15 loss: 0.07778363674879074\n",
      "epoch 16 loss: 0.07398193329572678\n",
      "epoch 17 loss: 0.06025645509362221\n",
      "epoch 18 loss: 0.07116997241973877\n",
      "epoch 19 loss: 0.06674912571907043\n",
      "epoch 20 loss: 0.05939871072769165\n",
      "epoch 21 loss: 0.04727768152952194\n",
      "epoch 22 loss: 0.06723081320524216\n",
      "epoch 23 loss: 0.07377379387617111\n",
      "epoch 24 loss: 0.07213684916496277\n",
      "epoch 25 loss: 0.05232718214392662\n",
      "epoch 26 loss: 0.06546615809202194\n",
      "epoch 27 loss: 0.055603668093681335\n",
      "epoch 28 loss: 0.07132706046104431\n",
      "epoch 29 loss: 0.07894503325223923\n",
      "epoch 30 loss: 0.07865305244922638\n",
      "4\n",
      "epoch 1 loss: 0.9571015238761902\n",
      "epoch 2 loss: 0.8816968202590942\n",
      "epoch 3 loss: 0.35278749465942383\n",
      "epoch 4 loss: 0.27469876408576965\n",
      "epoch 5 loss: 0.18592485785484314\n",
      "epoch 6 loss: 0.11669731140136719\n",
      "epoch 7 loss: 0.12226399779319763\n",
      "epoch 8 loss: 0.10698967427015305\n",
      "epoch 9 loss: 0.11931397765874863\n",
      "epoch 10 loss: 0.08076096326112747\n",
      "epoch 11 loss: 0.10651934891939163\n",
      "epoch 12 loss: 0.1829773485660553\n",
      "epoch 13 loss: 0.14354488253593445\n",
      "epoch 14 loss: 0.09993670135736465\n",
      "epoch 15 loss: 0.0834355503320694\n",
      "epoch 16 loss: 0.07852306216955185\n",
      "epoch 17 loss: 0.08100192993879318\n",
      "epoch 18 loss: 0.07375811040401459\n",
      "epoch 19 loss: 0.09388992190361023\n",
      "epoch 20 loss: 0.06377100944519043\n",
      "epoch 21 loss: 0.07856490463018417\n",
      "epoch 22 loss: 0.06946967542171478\n",
      "epoch 23 loss: 0.06877725571393967\n",
      "epoch 24 loss: 0.09058864414691925\n",
      "epoch 25 loss: 0.08337089419364929\n",
      "epoch 26 loss: 0.07383149862289429\n",
      "epoch 27 loss: 0.07396389544010162\n",
      "epoch 28 loss: 0.11249815672636032\n",
      "epoch 29 loss: 0.054887790232896805\n",
      "epoch 30 loss: 0.06854479759931564\n",
      "5\n",
      "epoch 1 loss: 0.685922384262085\n",
      "epoch 2 loss: 0.579845666885376\n",
      "epoch 3 loss: 0.25034499168395996\n",
      "epoch 4 loss: 0.20189307630062103\n",
      "epoch 5 loss: 0.1661304086446762\n",
      "epoch 6 loss: 0.12791156768798828\n",
      "epoch 7 loss: 0.12096486985683441\n",
      "epoch 8 loss: 0.14606915414333344\n",
      "epoch 9 loss: 0.09888511151075363\n",
      "epoch 10 loss: 0.0788571685552597\n",
      "epoch 11 loss: 0.0718747153878212\n",
      "epoch 12 loss: 0.0651642233133316\n",
      "epoch 13 loss: 0.04927148297429085\n",
      "epoch 14 loss: 0.06167450174689293\n",
      "epoch 15 loss: 0.06423848867416382\n",
      "epoch 16 loss: 0.06359577178955078\n",
      "epoch 17 loss: 0.076594777405262\n",
      "epoch 18 loss: 0.06587865948677063\n",
      "epoch 19 loss: 0.06022848188877106\n",
      "epoch 20 loss: 0.07254093885421753\n",
      "epoch 21 loss: 0.06966061145067215\n",
      "epoch 22 loss: 0.06543043255805969\n",
      "epoch 23 loss: 0.0490298792719841\n",
      "epoch 24 loss: 0.06427814066410065\n",
      "epoch 25 loss: 0.05060252547264099\n",
      "epoch 26 loss: 0.0683646872639656\n",
      "epoch 27 loss: 0.05346072092652321\n",
      "epoch 28 loss: 0.05269180238246918\n",
      "epoch 29 loss: 0.04626775532960892\n",
      "epoch 30 loss: 0.06690284609794617\n",
      "6\n",
      "epoch 1 loss: 0.7097570896148682\n",
      "epoch 2 loss: 0.7271444797515869\n",
      "epoch 3 loss: 0.7025752067565918\n",
      "epoch 4 loss: 0.43766283988952637\n",
      "epoch 5 loss: 0.25380563735961914\n",
      "epoch 6 loss: 0.16508200764656067\n",
      "epoch 7 loss: 0.12194796651601791\n",
      "epoch 8 loss: 0.07133878767490387\n",
      "epoch 9 loss: 0.07365827262401581\n",
      "epoch 10 loss: 0.09085512906312943\n",
      "epoch 11 loss: 0.0726122111082077\n",
      "epoch 12 loss: 0.08922156691551208\n",
      "epoch 13 loss: 0.08230803906917572\n",
      "epoch 14 loss: 0.09505297243595123\n",
      "epoch 15 loss: 0.05470426753163338\n",
      "epoch 16 loss: 0.059587281197309494\n",
      "epoch 17 loss: 0.07513368874788284\n",
      "epoch 18 loss: 0.09096994251012802\n",
      "epoch 19 loss: 0.06861580908298492\n",
      "epoch 20 loss: 0.06584063172340393\n",
      "epoch 21 loss: 0.07246025651693344\n",
      "epoch 22 loss: 0.0588272288441658\n",
      "epoch 23 loss: 0.04803657904267311\n",
      "epoch 24 loss: 0.053297486156225204\n",
      "epoch 25 loss: 0.06503945589065552\n",
      "epoch 26 loss: 0.0626598447561264\n",
      "epoch 27 loss: 0.05701899901032448\n",
      "epoch 28 loss: 0.058286745101213455\n",
      "epoch 29 loss: 0.060174427926540375\n",
      "epoch 30 loss: 0.058875441551208496\n",
      "7\n",
      "epoch 1 loss: 0.8716666102409363\n",
      "epoch 2 loss: 0.47954386472702026\n",
      "epoch 3 loss: 0.3487277925014496\n",
      "epoch 4 loss: 0.3183097541332245\n",
      "epoch 5 loss: 0.18131132423877716\n",
      "epoch 6 loss: 0.1679271012544632\n",
      "epoch 7 loss: 0.11924663186073303\n",
      "epoch 8 loss: 0.1181170791387558\n",
      "epoch 9 loss: 0.1386176347732544\n",
      "epoch 10 loss: 0.1376682072877884\n",
      "epoch 11 loss: 0.12142346799373627\n",
      "epoch 12 loss: 0.08262750506401062\n",
      "epoch 13 loss: 0.07413467019796371\n",
      "epoch 14 loss: 0.09101539105176926\n",
      "epoch 15 loss: 0.06913670152425766\n",
      "epoch 16 loss: 0.07330132275819778\n",
      "epoch 17 loss: 0.0865054801106453\n",
      "epoch 18 loss: 0.0678630843758583\n",
      "epoch 19 loss: 0.06010105460882187\n",
      "epoch 20 loss: 0.07682099938392639\n",
      "epoch 21 loss: 0.07110290229320526\n",
      "epoch 22 loss: 0.06349125504493713\n",
      "epoch 23 loss: 0.09429824352264404\n",
      "epoch 24 loss: 0.07601022720336914\n",
      "epoch 25 loss: 0.06757578998804092\n",
      "epoch 26 loss: 0.07288355380296707\n",
      "epoch 27 loss: 0.07440848648548126\n",
      "epoch 28 loss: 0.07313024997711182\n",
      "epoch 29 loss: 0.059046536684036255\n",
      "epoch 30 loss: 0.04711112007498741\n",
      "8\n",
      "epoch 1 loss: 0.9022054076194763\n",
      "epoch 2 loss: 0.658177375793457\n",
      "epoch 3 loss: 0.3157687783241272\n",
      "epoch 4 loss: 0.21855506300926208\n",
      "epoch 5 loss: 0.1342235952615738\n",
      "epoch 6 loss: 0.15971365571022034\n",
      "epoch 7 loss: 0.10660509765148163\n",
      "epoch 8 loss: 0.08952560275793076\n",
      "epoch 9 loss: 0.12548956274986267\n",
      "epoch 10 loss: 0.08748557418584824\n",
      "epoch 11 loss: 0.10012122988700867\n",
      "epoch 12 loss: 0.08247829973697662\n",
      "epoch 13 loss: 0.07500991225242615\n",
      "epoch 14 loss: 0.07434709370136261\n",
      "epoch 15 loss: 0.05943069979548454\n",
      "epoch 16 loss: 0.058348339051008224\n",
      "epoch 17 loss: 0.0649213045835495\n",
      "epoch 18 loss: 0.06784478574991226\n",
      "epoch 19 loss: 0.06756430864334106\n",
      "epoch 20 loss: 0.06327646970748901\n",
      "epoch 21 loss: 0.0642351508140564\n",
      "epoch 22 loss: 0.06903699785470963\n",
      "epoch 23 loss: 0.07050392031669617\n",
      "epoch 24 loss: 0.08430679142475128\n",
      "epoch 25 loss: 0.07110028713941574\n",
      "epoch 26 loss: 0.07598219811916351\n",
      "epoch 27 loss: 0.06454616785049438\n",
      "epoch 28 loss: 0.06457532942295074\n",
      "epoch 29 loss: 0.06512012332677841\n",
      "epoch 30 loss: 0.05160558596253395\n",
      "9\n",
      "epoch 1 loss: 0.9092668294906616\n",
      "epoch 2 loss: 0.5157414078712463\n",
      "epoch 3 loss: 0.3017731010913849\n",
      "epoch 4 loss: 0.18782804906368256\n",
      "epoch 5 loss: 0.15261097252368927\n",
      "epoch 6 loss: 0.13304921984672546\n",
      "epoch 7 loss: 0.1156894639134407\n",
      "epoch 8 loss: 0.11392129957675934\n",
      "epoch 9 loss: 0.11659474670886993\n",
      "epoch 10 loss: 0.10565111041069031\n",
      "epoch 11 loss: 0.07588639855384827\n",
      "epoch 12 loss: 0.07413315027952194\n",
      "epoch 13 loss: 0.08303288370370865\n",
      "epoch 14 loss: 0.08454988896846771\n",
      "epoch 15 loss: 0.06682219356298447\n",
      "epoch 16 loss: 0.08016876131296158\n",
      "epoch 17 loss: 0.06330852210521698\n",
      "epoch 18 loss: 0.05707579478621483\n",
      "epoch 19 loss: 0.0777234435081482\n",
      "epoch 20 loss: 0.11850006133317947\n",
      "epoch 21 loss: 0.05686761811375618\n",
      "epoch 22 loss: 0.07024401426315308\n",
      "epoch 23 loss: 0.05753704532980919\n",
      "epoch 24 loss: 0.07085876911878586\n",
      "epoch 25 loss: 0.07028858363628387\n",
      "epoch 26 loss: 0.055682163685560226\n",
      "epoch 27 loss: 0.06197551265358925\n",
      "epoch 28 loss: 0.05889540910720825\n",
      "epoch 29 loss: 0.06095300614833832\n",
      "epoch 30 loss: 0.049037110060453415\n",
      "10\n",
      "epoch 1 loss: 0.8865581154823303\n",
      "epoch 2 loss: 0.6116985082626343\n",
      "epoch 3 loss: 0.5010201930999756\n",
      "epoch 4 loss: 0.2349483072757721\n",
      "epoch 5 loss: 0.14406420290470123\n",
      "epoch 6 loss: 0.13053086400032043\n",
      "epoch 7 loss: 0.10649461299180984\n",
      "epoch 8 loss: 0.10091669112443924\n",
      "epoch 9 loss: 0.0876515582203865\n",
      "epoch 10 loss: 0.10106076300144196\n",
      "epoch 11 loss: 0.06838250160217285\n",
      "epoch 12 loss: 0.08512729406356812\n",
      "epoch 13 loss: 0.08333861082792282\n",
      "epoch 14 loss: 0.14106765389442444\n",
      "epoch 15 loss: 0.07042305171489716\n",
      "epoch 16 loss: 0.05535309389233589\n",
      "epoch 17 loss: 0.06578431278467178\n",
      "epoch 18 loss: 0.07195013761520386\n",
      "epoch 19 loss: 0.0949951559305191\n",
      "epoch 20 loss: 0.062142904847860336\n",
      "epoch 21 loss: 0.07002609968185425\n",
      "epoch 22 loss: 0.07107085734605789\n",
      "epoch 23 loss: 0.07324638962745667\n",
      "epoch 24 loss: 0.07854072749614716\n",
      "epoch 25 loss: 0.060225799679756165\n",
      "epoch 26 loss: 0.054263170808553696\n",
      "epoch 27 loss: 0.0694693848490715\n",
      "epoch 28 loss: 0.049325305968523026\n",
      "epoch 29 loss: 0.062402743846178055\n",
      "epoch 30 loss: 0.06331895291805267\n",
      "11\n",
      "epoch 1 loss: 0.7820624113082886\n",
      "epoch 2 loss: 0.7576131820678711\n",
      "epoch 3 loss: 0.5277190804481506\n",
      "epoch 4 loss: 0.2390400618314743\n",
      "epoch 5 loss: 0.15107057988643646\n",
      "epoch 6 loss: 0.12735030055046082\n",
      "epoch 7 loss: 0.1105441078543663\n",
      "epoch 8 loss: 0.08514683693647385\n",
      "epoch 9 loss: 0.07401038706302643\n",
      "epoch 10 loss: 0.07853661477565765\n",
      "epoch 11 loss: 0.08351175487041473\n",
      "epoch 12 loss: 0.09915507584810257\n",
      "epoch 13 loss: 0.06025855615735054\n",
      "epoch 14 loss: 0.06664828956127167\n",
      "epoch 15 loss: 0.06535258889198303\n",
      "epoch 16 loss: 0.07156538218259811\n",
      "epoch 17 loss: 0.0798470675945282\n",
      "epoch 18 loss: 0.05640878155827522\n",
      "epoch 19 loss: 0.07086188346147537\n",
      "epoch 20 loss: 0.0800914615392685\n",
      "epoch 21 loss: 0.06977422535419464\n",
      "epoch 22 loss: 0.07112889736890793\n",
      "epoch 23 loss: 0.060533665120601654\n",
      "epoch 24 loss: 0.07088665664196014\n",
      "epoch 25 loss: 0.066916324198246\n",
      "epoch 26 loss: 0.053642865270376205\n",
      "epoch 27 loss: 0.05877275764942169\n",
      "epoch 28 loss: 0.05940859392285347\n",
      "epoch 29 loss: 0.05729569494724274\n",
      "epoch 30 loss: 0.04637150093913078\n",
      "12\n",
      "epoch 1 loss: 0.7630745768547058\n",
      "epoch 2 loss: 0.47527939081192017\n",
      "epoch 3 loss: 0.311909019947052\n",
      "epoch 4 loss: 0.25518569350242615\n",
      "epoch 5 loss: 0.14005450904369354\n",
      "epoch 6 loss: 0.14791464805603027\n",
      "epoch 7 loss: 0.13382364809513092\n",
      "epoch 8 loss: 0.10886965692043304\n",
      "epoch 9 loss: 0.13268762826919556\n",
      "epoch 10 loss: 0.09018302708864212\n",
      "epoch 11 loss: 0.07981476187705994\n",
      "epoch 12 loss: 0.06700436770915985\n",
      "epoch 13 loss: 0.07383250445127487\n",
      "epoch 14 loss: 0.07176117599010468\n",
      "epoch 15 loss: 0.09322318434715271\n",
      "epoch 16 loss: 0.06173357740044594\n",
      "epoch 17 loss: 0.06987263262271881\n",
      "epoch 18 loss: 0.07609233260154724\n",
      "epoch 19 loss: 0.07384027540683746\n",
      "epoch 20 loss: 0.08102106302976608\n",
      "epoch 21 loss: 0.07081577181816101\n",
      "epoch 22 loss: 0.06595871597528458\n",
      "epoch 23 loss: 0.0669344887137413\n",
      "epoch 24 loss: 0.08025849610567093\n",
      "epoch 25 loss: 0.057307008653879166\n",
      "epoch 26 loss: 0.05153432488441467\n",
      "epoch 27 loss: 0.06381477415561676\n",
      "epoch 28 loss: 0.0643341913819313\n",
      "epoch 29 loss: 0.0689157173037529\n",
      "epoch 30 loss: 0.060515787452459335\n",
      "13\n",
      "epoch 1 loss: 0.5585052967071533\n",
      "epoch 2 loss: 0.7800109386444092\n",
      "epoch 3 loss: 0.45579877495765686\n",
      "epoch 4 loss: 0.24297520518302917\n",
      "epoch 5 loss: 0.1283128559589386\n",
      "epoch 6 loss: 0.09346827864646912\n",
      "epoch 7 loss: 0.12108196318149567\n",
      "epoch 8 loss: 0.11311572790145874\n",
      "epoch 9 loss: 0.10900451987981796\n",
      "epoch 10 loss: 0.09201638400554657\n",
      "epoch 11 loss: 0.07213930040597916\n",
      "epoch 12 loss: 0.1264411211013794\n",
      "epoch 13 loss: 0.07506376504898071\n",
      "epoch 14 loss: 0.06568673998117447\n",
      "epoch 15 loss: 0.0691106766462326\n",
      "epoch 16 loss: 0.08032631129026413\n",
      "epoch 17 loss: 0.07565033435821533\n",
      "epoch 18 loss: 0.0649884045124054\n",
      "epoch 19 loss: 0.06841813027858734\n",
      "epoch 20 loss: 0.06207995489239693\n",
      "epoch 21 loss: 0.07181508839130402\n",
      "epoch 22 loss: 0.0568646602332592\n",
      "epoch 23 loss: 0.06213061511516571\n",
      "epoch 24 loss: 0.052480652928352356\n",
      "epoch 25 loss: 0.07160235196352005\n",
      "epoch 26 loss: 0.06484641134738922\n",
      "epoch 27 loss: 0.07978235185146332\n",
      "epoch 28 loss: 0.05816671624779701\n",
      "epoch 29 loss: 0.06293268501758575\n",
      "epoch 30 loss: 0.04527883231639862\n",
      "14\n",
      "epoch 1 loss: 0.7961679100990295\n",
      "epoch 2 loss: 0.6169000267982483\n",
      "epoch 3 loss: 0.4699280560016632\n",
      "epoch 4 loss: 0.1731734275817871\n",
      "epoch 5 loss: 0.17141792178153992\n",
      "epoch 6 loss: 0.12260319292545319\n",
      "epoch 7 loss: 0.10248115658760071\n",
      "epoch 8 loss: 0.1238688975572586\n",
      "epoch 9 loss: 0.13214363157749176\n",
      "epoch 10 loss: 0.09351370483636856\n",
      "epoch 11 loss: 0.09028615057468414\n",
      "epoch 12 loss: 0.10823863744735718\n",
      "epoch 13 loss: 0.08336427062749863\n",
      "epoch 14 loss: 0.07129008322954178\n",
      "epoch 15 loss: 0.059324417263269424\n",
      "epoch 16 loss: 0.07073859870433807\n",
      "epoch 17 loss: 0.10099568217992783\n",
      "epoch 18 loss: 0.08127646148204803\n",
      "epoch 19 loss: 0.09753521531820297\n",
      "epoch 20 loss: 0.04600461199879646\n",
      "epoch 21 loss: 0.05741915851831436\n",
      "epoch 22 loss: 0.05649229884147644\n",
      "epoch 23 loss: 0.060497213155031204\n",
      "epoch 24 loss: 0.07734770327806473\n",
      "epoch 25 loss: 0.08117951452732086\n",
      "epoch 26 loss: 0.05532558634877205\n",
      "epoch 27 loss: 0.05268826335668564\n",
      "epoch 28 loss: 0.06749188899993896\n",
      "epoch 29 loss: 0.06255044788122177\n",
      "epoch 30 loss: 0.05751921981573105\n",
      "15\n",
      "epoch 1 loss: 0.6169281601905823\n",
      "epoch 2 loss: 0.3678838610649109\n",
      "epoch 3 loss: 0.19010956585407257\n",
      "epoch 4 loss: 0.14462405443191528\n",
      "epoch 5 loss: 0.1047583669424057\n",
      "epoch 6 loss: 0.16490669548511505\n",
      "epoch 7 loss: 0.09916467219591141\n",
      "epoch 8 loss: 0.09597250074148178\n",
      "epoch 9 loss: 0.09072388708591461\n",
      "epoch 10 loss: 0.08603902161121368\n",
      "epoch 11 loss: 0.08403032273054123\n",
      "epoch 12 loss: 0.08261621743440628\n",
      "epoch 13 loss: 0.0691005066037178\n",
      "epoch 14 loss: 0.0753634050488472\n",
      "epoch 15 loss: 0.07889574021100998\n",
      "epoch 16 loss: 0.06683234125375748\n",
      "epoch 17 loss: 0.06944499164819717\n",
      "epoch 18 loss: 0.06574675440788269\n",
      "epoch 19 loss: 0.04950636252760887\n",
      "epoch 20 loss: 0.0842733234167099\n",
      "epoch 21 loss: 0.05522901564836502\n",
      "epoch 22 loss: 0.05309615284204483\n",
      "epoch 23 loss: 0.060865581035614014\n",
      "epoch 24 loss: 0.06111576408147812\n",
      "epoch 25 loss: 0.05250076949596405\n",
      "epoch 26 loss: 0.05234218388795853\n",
      "epoch 27 loss: 0.05548764392733574\n",
      "epoch 28 loss: 0.06733515113592148\n",
      "epoch 29 loss: 0.052305012941360474\n",
      "epoch 30 loss: 0.055487167090177536\n",
      "16\n",
      "epoch 1 loss: 0.8116574883460999\n",
      "epoch 2 loss: 0.585925281047821\n",
      "epoch 3 loss: 0.3209165036678314\n",
      "epoch 4 loss: 0.18177546560764313\n",
      "epoch 5 loss: 0.11506009846925735\n",
      "epoch 6 loss: 0.12330181896686554\n",
      "epoch 7 loss: 0.10002721846103668\n",
      "epoch 8 loss: 0.12947605550289154\n",
      "epoch 9 loss: 0.10379648953676224\n",
      "epoch 10 loss: 0.11626255512237549\n",
      "epoch 11 loss: 0.08814728260040283\n",
      "epoch 12 loss: 0.06695444136857986\n",
      "epoch 13 loss: 0.09148856997489929\n",
      "epoch 14 loss: 0.07073227316141129\n",
      "epoch 15 loss: 0.0958661139011383\n",
      "epoch 16 loss: 0.08829580247402191\n",
      "epoch 17 loss: 0.09560436010360718\n",
      "epoch 18 loss: 0.07181841880083084\n",
      "epoch 19 loss: 0.0690334215760231\n",
      "epoch 20 loss: 0.07277308404445648\n",
      "epoch 21 loss: 0.06622295081615448\n",
      "epoch 22 loss: 0.05684588849544525\n",
      "epoch 23 loss: 0.06096303090453148\n",
      "epoch 24 loss: 0.05983898788690567\n",
      "epoch 25 loss: 0.11621727049350739\n",
      "epoch 26 loss: 0.07928377389907837\n",
      "epoch 27 loss: 0.07343513518571854\n",
      "epoch 28 loss: 0.05910624563694\n",
      "epoch 29 loss: 0.06387989223003387\n",
      "epoch 30 loss: 0.059924136847257614\n",
      "17\n",
      "epoch 1 loss: 0.8314632177352905\n",
      "epoch 2 loss: 0.7933065891265869\n",
      "epoch 3 loss: 0.7610861659049988\n",
      "epoch 4 loss: 0.33614808320999146\n",
      "epoch 5 loss: 0.17803771793842316\n",
      "epoch 6 loss: 0.15317805111408234\n",
      "epoch 7 loss: 0.10218197107315063\n",
      "epoch 8 loss: 0.10053941607475281\n",
      "epoch 9 loss: 0.13779997825622559\n",
      "epoch 10 loss: 0.09346523880958557\n",
      "epoch 11 loss: 0.11645269393920898\n",
      "epoch 12 loss: 0.08389122784137726\n",
      "epoch 13 loss: 0.08975038677453995\n",
      "epoch 14 loss: 0.06207386776804924\n",
      "epoch 15 loss: 0.052532684057950974\n",
      "epoch 16 loss: 0.06073113903403282\n",
      "epoch 17 loss: 0.06313291192054749\n",
      "epoch 18 loss: 0.057013653218746185\n",
      "epoch 19 loss: 0.061057087033987045\n",
      "epoch 20 loss: 0.05629407986998558\n",
      "epoch 21 loss: 0.07423342019319534\n",
      "epoch 22 loss: 0.0680573582649231\n",
      "epoch 23 loss: 0.05609356239438057\n",
      "epoch 24 loss: 0.06246516481041908\n",
      "epoch 25 loss: 0.07303540408611298\n",
      "epoch 26 loss: 0.05816586688160896\n",
      "epoch 27 loss: 0.06287222355604172\n",
      "epoch 28 loss: 0.07933385670185089\n",
      "epoch 29 loss: 0.06987106055021286\n",
      "epoch 30 loss: 0.059146467596292496\n",
      "18\n",
      "epoch 1 loss: 0.6890917420387268\n",
      "epoch 2 loss: 0.44840842485427856\n",
      "epoch 3 loss: 0.31811511516571045\n",
      "epoch 4 loss: 0.17279662191867828\n",
      "epoch 5 loss: 0.13054771721363068\n",
      "epoch 6 loss: 0.1382262259721756\n",
      "epoch 7 loss: 0.114740289747715\n",
      "epoch 8 loss: 0.07415225356817245\n",
      "epoch 9 loss: 0.08845924586057663\n",
      "epoch 10 loss: 0.10092420876026154\n",
      "epoch 11 loss: 0.08220494538545609\n",
      "epoch 12 loss: 0.06518557667732239\n",
      "epoch 13 loss: 0.0827619656920433\n",
      "epoch 14 loss: 0.06544695049524307\n",
      "epoch 15 loss: 0.07927407324314117\n",
      "epoch 16 loss: 0.07071521133184433\n",
      "epoch 17 loss: 0.05830589681863785\n",
      "epoch 18 loss: 0.08035057038068771\n",
      "epoch 19 loss: 0.06600648909807205\n",
      "epoch 20 loss: 0.0879155769944191\n",
      "epoch 21 loss: 0.05426585674285889\n",
      "epoch 22 loss: 0.06601539999246597\n",
      "epoch 23 loss: 0.06752117723226547\n",
      "epoch 24 loss: 0.07064467668533325\n",
      "epoch 25 loss: 0.05801881104707718\n",
      "epoch 26 loss: 0.07392489910125732\n",
      "epoch 27 loss: 0.05282538756728172\n",
      "epoch 28 loss: 0.05622563511133194\n",
      "epoch 29 loss: 0.061960093677043915\n",
      "epoch 30 loss: 0.05295320227742195\n",
      "19\n",
      "epoch 1 loss: 0.8548455834388733\n",
      "epoch 2 loss: 0.7063071131706238\n",
      "epoch 3 loss: 0.2809695303440094\n",
      "epoch 4 loss: 0.16961055994033813\n",
      "epoch 5 loss: 0.12631215155124664\n",
      "epoch 6 loss: 0.13008344173431396\n",
      "epoch 7 loss: 0.10474163293838501\n",
      "epoch 8 loss: 0.12071854621171951\n",
      "epoch 9 loss: 0.09112668037414551\n",
      "epoch 10 loss: 0.09101331979036331\n",
      "epoch 11 loss: 0.08856723457574844\n",
      "epoch 12 loss: 0.10632510483264923\n",
      "epoch 13 loss: 0.11205596476793289\n",
      "epoch 14 loss: 0.08772946149110794\n",
      "epoch 15 loss: 0.07514141499996185\n",
      "epoch 16 loss: 0.05066496878862381\n",
      "epoch 17 loss: 0.0742742046713829\n",
      "epoch 18 loss: 0.08849863708019257\n",
      "epoch 19 loss: 0.07262616604566574\n",
      "epoch 20 loss: 0.06581747531890869\n",
      "epoch 21 loss: 0.05936455354094505\n",
      "epoch 22 loss: 0.06106838956475258\n",
      "epoch 23 loss: 0.0777541771531105\n",
      "epoch 24 loss: 0.0951455757021904\n",
      "epoch 25 loss: 0.07918430864810944\n",
      "epoch 26 loss: 0.06732913851737976\n",
      "epoch 27 loss: 0.06831090152263641\n",
      "epoch 28 loss: 0.05790894478559494\n",
      "epoch 29 loss: 0.050419680774211884\n",
      "epoch 30 loss: 0.055834267288446426\n",
      "20\n",
      "epoch 1 loss: 0.8040257096290588\n",
      "epoch 2 loss: 0.48811155557632446\n",
      "epoch 3 loss: 0.5557705163955688\n",
      "epoch 4 loss: 0.2773624658584595\n",
      "epoch 5 loss: 0.14128392934799194\n",
      "epoch 6 loss: 0.11894461512565613\n",
      "epoch 7 loss: 0.1067599281668663\n",
      "epoch 8 loss: 0.1309606283903122\n",
      "epoch 9 loss: 0.07732938975095749\n",
      "epoch 10 loss: 0.1317654550075531\n",
      "epoch 11 loss: 0.08416072279214859\n",
      "epoch 12 loss: 0.06887461990118027\n",
      "epoch 13 loss: 0.07735107839107513\n",
      "epoch 14 loss: 0.07987964153289795\n",
      "epoch 15 loss: 0.09463386237621307\n",
      "epoch 16 loss: 0.08515945822000504\n",
      "epoch 17 loss: 0.08262917399406433\n",
      "epoch 18 loss: 0.06272763758897781\n",
      "epoch 19 loss: 0.0704600065946579\n",
      "epoch 20 loss: 0.0806199386715889\n",
      "epoch 21 loss: 0.07057950645685196\n",
      "epoch 22 loss: 0.05155525729060173\n",
      "epoch 23 loss: 0.06966982036828995\n",
      "epoch 24 loss: 0.06867734342813492\n",
      "epoch 25 loss: 0.06202555075287819\n",
      "epoch 26 loss: 0.08472684025764465\n",
      "epoch 27 loss: 0.0696890652179718\n",
      "epoch 28 loss: 0.05651509389281273\n",
      "epoch 29 loss: 0.07285132259130478\n",
      "epoch 30 loss: 0.06577124446630478\n",
      "21\n",
      "epoch 1 loss: 0.7338072657585144\n",
      "epoch 2 loss: 0.567888081073761\n",
      "epoch 3 loss: 0.5278280973434448\n",
      "epoch 4 loss: 0.2188248187303543\n",
      "epoch 5 loss: 0.15891660749912262\n",
      "epoch 6 loss: 0.12156163901090622\n",
      "epoch 7 loss: 0.14098413288593292\n",
      "epoch 8 loss: 0.12010850757360458\n",
      "epoch 9 loss: 0.1061825379729271\n",
      "epoch 10 loss: 0.08493540436029434\n",
      "epoch 11 loss: 0.08943545818328857\n",
      "epoch 12 loss: 0.08021782338619232\n",
      "epoch 13 loss: 0.07251478731632233\n",
      "epoch 14 loss: 0.07078184932470322\n",
      "epoch 15 loss: 0.07758663594722748\n",
      "epoch 16 loss: 0.08575668185949326\n",
      "epoch 17 loss: 0.06595973670482635\n",
      "epoch 18 loss: 0.10650622099637985\n",
      "epoch 19 loss: 0.06568614393472672\n",
      "epoch 20 loss: 0.07142814993858337\n",
      "epoch 21 loss: 0.06324486434459686\n",
      "epoch 22 loss: 0.06600984185934067\n",
      "epoch 23 loss: 0.07486006617546082\n",
      "epoch 24 loss: 0.054295364767313004\n",
      "epoch 25 loss: 0.06582911312580109\n",
      "epoch 26 loss: 0.07468269020318985\n",
      "epoch 27 loss: 0.06723256409168243\n",
      "epoch 28 loss: 0.04213784262537956\n",
      "epoch 29 loss: 0.07713887095451355\n",
      "epoch 30 loss: 0.0608225092291832\n",
      "22\n",
      "epoch 1 loss: 0.7364628314971924\n",
      "epoch 2 loss: 0.43425214290618896\n",
      "epoch 3 loss: 0.5030993223190308\n",
      "epoch 4 loss: 0.2537809908390045\n",
      "epoch 5 loss: 0.1276332437992096\n",
      "epoch 6 loss: 0.12047203630208969\n",
      "epoch 7 loss: 0.08993623405694962\n",
      "epoch 8 loss: 0.11438513547182083\n",
      "epoch 9 loss: 0.1048368364572525\n",
      "epoch 10 loss: 0.12340328097343445\n",
      "epoch 11 loss: 0.07644384354352951\n",
      "epoch 12 loss: 0.09930610656738281\n",
      "epoch 13 loss: 0.07492256909608841\n",
      "epoch 14 loss: 0.07668717205524445\n",
      "epoch 15 loss: 0.08135692775249481\n",
      "epoch 16 loss: 0.0802227035164833\n",
      "epoch 17 loss: 0.05348997935652733\n",
      "epoch 18 loss: 0.07097094506025314\n",
      "epoch 19 loss: 0.05975751578807831\n",
      "epoch 20 loss: 0.05776730552315712\n",
      "epoch 21 loss: 0.057949040085077286\n",
      "epoch 22 loss: 0.06969135254621506\n",
      "epoch 23 loss: 0.0657665804028511\n",
      "epoch 24 loss: 0.06157488748431206\n",
      "epoch 25 loss: 0.06189008802175522\n",
      "epoch 26 loss: 0.062371257692575455\n",
      "epoch 27 loss: 0.07404659688472748\n",
      "epoch 28 loss: 0.062265545129776\n",
      "epoch 29 loss: 0.06292826682329178\n",
      "epoch 30 loss: 0.05677277594804764\n",
      "23\n",
      "epoch 1 loss: 1.0260279178619385\n",
      "epoch 2 loss: 0.5577524304389954\n",
      "epoch 3 loss: 0.20831602811813354\n",
      "epoch 4 loss: 0.16202610731124878\n",
      "epoch 5 loss: 0.12343384325504303\n",
      "epoch 6 loss: 0.14806270599365234\n",
      "epoch 7 loss: 0.10918038338422775\n",
      "epoch 8 loss: 0.14799557626247406\n",
      "epoch 9 loss: 0.09423133730888367\n",
      "epoch 10 loss: 0.11064792424440384\n",
      "epoch 11 loss: 0.08005596697330475\n",
      "epoch 12 loss: 0.1110585555434227\n",
      "epoch 13 loss: 0.1057443842291832\n",
      "epoch 14 loss: 0.09978139400482178\n",
      "epoch 15 loss: 0.058748748153448105\n",
      "epoch 16 loss: 0.07744257152080536\n",
      "epoch 17 loss: 0.07822686433792114\n",
      "epoch 18 loss: 0.0938352420926094\n",
      "epoch 19 loss: 0.10846972465515137\n",
      "epoch 20 loss: 0.07136484235525131\n",
      "epoch 21 loss: 0.06569655239582062\n",
      "epoch 22 loss: 0.05296460911631584\n",
      "epoch 23 loss: 0.06809559464454651\n",
      "epoch 24 loss: 0.0875038355588913\n",
      "epoch 25 loss: 0.06499210000038147\n",
      "epoch 26 loss: 0.06559916585683823\n",
      "epoch 27 loss: 0.06010859087109566\n",
      "epoch 28 loss: 0.04904169961810112\n",
      "epoch 29 loss: 0.04870115965604782\n",
      "epoch 30 loss: 0.0545455738902092\n",
      "24\n",
      "epoch 1 loss: 1.3575483560562134\n",
      "epoch 2 loss: 1.127758264541626\n",
      "epoch 3 loss: 0.5335241556167603\n",
      "epoch 4 loss: 0.41521134972572327\n",
      "epoch 5 loss: 0.21768982708454132\n",
      "epoch 6 loss: 0.1432144045829773\n",
      "epoch 7 loss: 0.13008439540863037\n",
      "epoch 8 loss: 0.1434800624847412\n",
      "epoch 9 loss: 0.12653601169586182\n",
      "epoch 10 loss: 0.11104846000671387\n",
      "epoch 11 loss: 0.10887134820222855\n",
      "epoch 12 loss: 0.08990315347909927\n",
      "epoch 13 loss: 0.1077163815498352\n",
      "epoch 14 loss: 0.08676603436470032\n",
      "epoch 15 loss: 0.10705609619617462\n",
      "epoch 16 loss: 0.07853703200817108\n",
      "epoch 17 loss: 0.06951228529214859\n",
      "epoch 18 loss: 0.08999931067228317\n",
      "epoch 19 loss: 0.06907466799020767\n",
      "epoch 20 loss: 0.07034102082252502\n",
      "epoch 21 loss: 0.06362167000770569\n",
      "epoch 22 loss: 0.06609311699867249\n",
      "epoch 23 loss: 0.06614144146442413\n",
      "epoch 24 loss: 0.0725080668926239\n",
      "epoch 25 loss: 0.059506289660930634\n",
      "epoch 26 loss: 0.07022411376237869\n",
      "epoch 27 loss: 0.06379146128892899\n",
      "epoch 28 loss: 0.08063964545726776\n",
      "epoch 29 loss: 0.05102797597646713\n",
      "epoch 30 loss: 0.06543942540884018\n",
      "25\n",
      "epoch 1 loss: 0.8653264045715332\n",
      "epoch 2 loss: 0.31746822595596313\n",
      "epoch 3 loss: 0.21341395378112793\n",
      "epoch 4 loss: 0.1628810167312622\n",
      "epoch 5 loss: 0.1391269862651825\n",
      "epoch 6 loss: 0.13945430517196655\n",
      "epoch 7 loss: 0.156479611992836\n",
      "epoch 8 loss: 0.12201256304979324\n",
      "epoch 9 loss: 0.09399990737438202\n",
      "epoch 10 loss: 0.08814115822315216\n",
      "epoch 11 loss: 0.08381989598274231\n",
      "epoch 12 loss: 0.11343065649271011\n",
      "epoch 13 loss: 0.083310566842556\n",
      "epoch 14 loss: 0.08364072442054749\n",
      "epoch 15 loss: 0.07472255080938339\n",
      "epoch 16 loss: 0.06613899767398834\n",
      "epoch 17 loss: 0.07660020142793655\n",
      "epoch 18 loss: 0.06855279952287674\n",
      "epoch 19 loss: 0.06726975739002228\n",
      "epoch 20 loss: 0.07319511473178864\n",
      "epoch 21 loss: 0.0633569210767746\n",
      "epoch 22 loss: 0.05952199548482895\n",
      "epoch 23 loss: 0.072761170566082\n",
      "epoch 24 loss: 0.07569694519042969\n",
      "epoch 25 loss: 0.06406692415475845\n",
      "epoch 26 loss: 0.06947040557861328\n",
      "epoch 27 loss: 0.0636172741651535\n",
      "epoch 28 loss: 0.06846900284290314\n",
      "epoch 29 loss: 0.054742589592933655\n",
      "epoch 30 loss: 0.06036496162414551\n",
      "26\n",
      "epoch 1 loss: 0.776111900806427\n",
      "epoch 2 loss: 0.8638659715652466\n",
      "epoch 3 loss: 0.6983384490013123\n",
      "epoch 4 loss: 0.4043399393558502\n",
      "epoch 5 loss: 0.2228282243013382\n",
      "epoch 6 loss: 0.15381623804569244\n",
      "epoch 7 loss: 0.11789565533399582\n",
      "epoch 8 loss: 0.1618785858154297\n",
      "epoch 9 loss: 0.12331034243106842\n",
      "epoch 10 loss: 0.10967230796813965\n",
      "epoch 11 loss: 0.09475458413362503\n",
      "epoch 12 loss: 0.06952349841594696\n",
      "epoch 13 loss: 0.07586348056793213\n",
      "epoch 14 loss: 0.06448506563901901\n",
      "epoch 15 loss: 0.09054221957921982\n",
      "epoch 16 loss: 0.066129170358181\n",
      "epoch 17 loss: 0.07621385902166367\n",
      "epoch 18 loss: 0.061064884066581726\n",
      "epoch 19 loss: 0.06933071464300156\n",
      "epoch 20 loss: 0.06423088908195496\n",
      "epoch 21 loss: 0.07240760326385498\n",
      "epoch 22 loss: 0.06067022681236267\n",
      "epoch 23 loss: 0.05936918780207634\n",
      "epoch 24 loss: 0.05678895115852356\n",
      "epoch 25 loss: 0.06631127744913101\n",
      "epoch 26 loss: 0.06714660674333572\n",
      "epoch 27 loss: 0.05463656410574913\n",
      "epoch 28 loss: 0.06612361967563629\n",
      "epoch 29 loss: 0.06295683234930038\n",
      "epoch 30 loss: 0.0541408471763134\n",
      "27\n",
      "epoch 1 loss: 0.8106091618537903\n",
      "epoch 2 loss: 0.5680383443832397\n",
      "epoch 3 loss: 0.30833351612091064\n",
      "epoch 4 loss: 0.1596221774816513\n",
      "epoch 5 loss: 0.1202147975564003\n",
      "epoch 6 loss: 0.09843027591705322\n",
      "epoch 7 loss: 0.086179718375206\n",
      "epoch 8 loss: 0.09206346422433853\n",
      "epoch 9 loss: 0.08650483191013336\n",
      "epoch 10 loss: 0.08354239165782928\n",
      "epoch 11 loss: 0.05611902475357056\n",
      "epoch 12 loss: 0.06022918224334717\n",
      "epoch 13 loss: 0.06885626912117004\n",
      "epoch 14 loss: 0.10395580530166626\n",
      "epoch 15 loss: 0.09575225412845612\n",
      "epoch 16 loss: 0.08242592960596085\n",
      "epoch 17 loss: 0.06405197829008102\n",
      "epoch 18 loss: 0.06732404977083206\n",
      "epoch 19 loss: 0.06888150423765182\n",
      "epoch 20 loss: 0.06926894187927246\n",
      "epoch 21 loss: 0.06985469162464142\n",
      "epoch 22 loss: 0.07046984881162643\n",
      "epoch 23 loss: 0.06661242991685867\n",
      "epoch 24 loss: 0.05655503273010254\n",
      "epoch 25 loss: 0.06262243539094925\n",
      "epoch 26 loss: 0.05603409186005592\n",
      "epoch 27 loss: 0.06155608594417572\n",
      "epoch 28 loss: 0.05886349081993103\n",
      "epoch 29 loss: 0.05364803969860077\n",
      "epoch 30 loss: 0.06512409448623657\n",
      "28\n",
      "epoch 1 loss: 0.704734742641449\n",
      "epoch 2 loss: 0.46962183713912964\n",
      "epoch 3 loss: 0.2967541217803955\n",
      "epoch 4 loss: 0.17380821704864502\n",
      "epoch 5 loss: 0.12822666764259338\n",
      "epoch 6 loss: 0.1449148803949356\n",
      "epoch 7 loss: 0.10628943890333176\n",
      "epoch 8 loss: 0.10835112631320953\n",
      "epoch 9 loss: 0.13285787403583527\n",
      "epoch 10 loss: 0.11799600720405579\n",
      "epoch 11 loss: 0.11898685246706009\n",
      "epoch 12 loss: 0.08574943989515305\n",
      "epoch 13 loss: 0.12458407133817673\n",
      "epoch 14 loss: 0.0794534981250763\n",
      "epoch 15 loss: 0.11179884523153305\n",
      "epoch 16 loss: 0.09041480720043182\n",
      "epoch 17 loss: 0.11356617510318756\n",
      "epoch 18 loss: 0.07030058652162552\n",
      "epoch 19 loss: 0.07161357253789902\n",
      "epoch 20 loss: 0.06785041838884354\n",
      "epoch 21 loss: 0.06652235984802246\n",
      "epoch 22 loss: 0.09118504822254181\n",
      "epoch 23 loss: 0.0628722682595253\n",
      "epoch 24 loss: 0.10890042036771774\n",
      "epoch 25 loss: 0.0781124159693718\n",
      "epoch 26 loss: 0.06754918396472931\n",
      "epoch 27 loss: 0.061268631368875504\n",
      "epoch 28 loss: 0.09463512152433395\n",
      "epoch 29 loss: 0.0642041489481926\n",
      "epoch 30 loss: 0.05267704278230667\n",
      "29\n",
      "epoch 1 loss: 0.7718409299850464\n",
      "epoch 2 loss: 0.663824200630188\n",
      "epoch 3 loss: 0.23316261172294617\n",
      "epoch 4 loss: 0.19498032331466675\n",
      "epoch 5 loss: 0.15647491812705994\n",
      "epoch 6 loss: 0.14547939598560333\n",
      "epoch 7 loss: 0.11593896895647049\n",
      "epoch 8 loss: 0.1351771354675293\n",
      "epoch 9 loss: 0.10318968445062637\n",
      "epoch 10 loss: 0.10490148514509201\n",
      "epoch 11 loss: 0.06786076724529266\n",
      "epoch 12 loss: 0.08522683382034302\n",
      "epoch 13 loss: 0.07884151488542557\n",
      "epoch 14 loss: 0.0707523301243782\n",
      "epoch 15 loss: 0.1006099209189415\n",
      "epoch 16 loss: 0.08295165747404099\n",
      "epoch 17 loss: 0.08124730736017227\n",
      "epoch 18 loss: 0.08164103329181671\n",
      "epoch 19 loss: 0.07032740116119385\n",
      "epoch 20 loss: 0.05526898801326752\n",
      "epoch 21 loss: 0.05581462383270264\n",
      "epoch 22 loss: 0.07513649016618729\n",
      "epoch 23 loss: 0.08380554616451263\n",
      "epoch 24 loss: 0.0641750693321228\n",
      "epoch 25 loss: 0.06994537264108658\n",
      "epoch 26 loss: 0.08319421857595444\n",
      "epoch 27 loss: 0.07789568603038788\n",
      "epoch 28 loss: 0.06288781017065048\n",
      "epoch 29 loss: 0.057241860777139664\n",
      "epoch 30 loss: 0.051274657249450684\n",
      "30\n",
      "epoch 1 loss: 0.8974304795265198\n",
      "epoch 2 loss: 0.629163384437561\n",
      "epoch 3 loss: 0.3158337473869324\n",
      "epoch 4 loss: 0.18595553934574127\n",
      "epoch 5 loss: 0.14206360280513763\n",
      "epoch 6 loss: 0.11300303786993027\n",
      "epoch 7 loss: 0.13015848398208618\n",
      "epoch 8 loss: 0.09464474767446518\n",
      "epoch 9 loss: 0.11208989471197128\n",
      "epoch 10 loss: 0.09299800544977188\n",
      "epoch 11 loss: 0.09011733531951904\n",
      "epoch 12 loss: 0.07416297495365143\n",
      "epoch 13 loss: 0.06850890070199966\n",
      "epoch 14 loss: 0.07676275074481964\n",
      "epoch 15 loss: 0.06397530436515808\n",
      "epoch 16 loss: 0.08511999994516373\n",
      "epoch 17 loss: 0.05794616416096687\n",
      "epoch 18 loss: 0.07126682996749878\n",
      "epoch 19 loss: 0.06822340935468674\n",
      "epoch 20 loss: 0.07101424038410187\n",
      "epoch 21 loss: 0.06805235147476196\n",
      "epoch 22 loss: 0.06188369169831276\n",
      "epoch 23 loss: 0.061491698026657104\n",
      "epoch 24 loss: 0.05434209108352661\n",
      "epoch 25 loss: 0.05874618887901306\n",
      "epoch 26 loss: 0.052606482058763504\n",
      "epoch 27 loss: 0.05675158649682999\n",
      "epoch 28 loss: 0.06558357924222946\n",
      "epoch 29 loss: 0.056195054203271866\n",
      "epoch 30 loss: 0.05191906914114952\n",
      "31\n",
      "epoch 1 loss: 0.7411758899688721\n",
      "epoch 2 loss: 0.40568727254867554\n",
      "epoch 3 loss: 0.34399545192718506\n",
      "epoch 4 loss: 0.26698824763298035\n",
      "epoch 5 loss: 0.18680796027183533\n",
      "epoch 6 loss: 0.14335235953330994\n",
      "epoch 7 loss: 0.12624289095401764\n",
      "epoch 8 loss: 0.09675966948270798\n",
      "epoch 9 loss: 0.09780298918485641\n",
      "epoch 10 loss: 0.09068215638399124\n",
      "epoch 11 loss: 0.10463590174913406\n",
      "epoch 12 loss: 0.07457665354013443\n",
      "epoch 13 loss: 0.07300546765327454\n",
      "epoch 14 loss: 0.10487518459558487\n",
      "epoch 15 loss: 0.06375467032194138\n",
      "epoch 16 loss: 0.09565885365009308\n",
      "epoch 17 loss: 0.07048498094081879\n",
      "epoch 18 loss: 0.08076395839452744\n",
      "epoch 19 loss: 0.06993310153484344\n",
      "epoch 20 loss: 0.06094588711857796\n",
      "epoch 21 loss: 0.05712982639670372\n",
      "epoch 22 loss: 0.0612361766397953\n",
      "epoch 23 loss: 0.057189181447029114\n",
      "epoch 24 loss: 0.06642366200685501\n",
      "epoch 25 loss: 0.07604587078094482\n",
      "epoch 26 loss: 0.0721917673945427\n",
      "epoch 27 loss: 0.07038579136133194\n",
      "epoch 28 loss: 0.05211105942726135\n",
      "epoch 29 loss: 0.06311492621898651\n",
      "epoch 30 loss: 0.06034635379910469\n",
      "32\n",
      "epoch 1 loss: 0.7172242999076843\n",
      "epoch 2 loss: 0.8644278645515442\n",
      "epoch 3 loss: 0.43615397810935974\n",
      "epoch 4 loss: 0.27513474225997925\n",
      "epoch 5 loss: 0.1724506914615631\n",
      "epoch 6 loss: 0.1523270308971405\n",
      "epoch 7 loss: 0.12060243636369705\n",
      "epoch 8 loss: 0.11579826474189758\n",
      "epoch 9 loss: 0.08989028632640839\n",
      "epoch 10 loss: 0.09260919690132141\n",
      "epoch 11 loss: 0.0730682909488678\n",
      "epoch 12 loss: 0.09629250317811966\n",
      "epoch 13 loss: 0.09853397309780121\n",
      "epoch 14 loss: 0.10004457086324692\n",
      "epoch 15 loss: 0.05879362300038338\n",
      "epoch 16 loss: 0.07065638154745102\n",
      "epoch 17 loss: 0.08343150466680527\n",
      "epoch 18 loss: 0.06198621913790703\n",
      "epoch 19 loss: 0.07684952020645142\n",
      "epoch 20 loss: 0.077356718480587\n",
      "epoch 21 loss: 0.0876997858285904\n",
      "epoch 22 loss: 0.07550369948148727\n",
      "epoch 23 loss: 0.09714572876691818\n",
      "epoch 24 loss: 0.07905132323503494\n",
      "epoch 25 loss: 0.05715322867035866\n",
      "epoch 26 loss: 0.057255420833826065\n",
      "epoch 27 loss: 0.07025030255317688\n",
      "epoch 28 loss: 0.0577564537525177\n",
      "epoch 29 loss: 0.07011790573596954\n",
      "epoch 30 loss: 0.06297049671411514\n",
      "33\n",
      "epoch 1 loss: 0.7578072547912598\n",
      "epoch 2 loss: 0.726762056350708\n",
      "epoch 3 loss: 0.6504915356636047\n",
      "epoch 4 loss: 0.5456222295761108\n",
      "epoch 5 loss: 0.3098284900188446\n",
      "epoch 6 loss: 0.21663200855255127\n",
      "epoch 7 loss: 0.16034440696239471\n",
      "epoch 8 loss: 0.13210640847682953\n",
      "epoch 9 loss: 0.12486926466226578\n",
      "epoch 10 loss: 0.14052733778953552\n",
      "epoch 11 loss: 0.08709273487329483\n",
      "epoch 12 loss: 0.08400740474462509\n",
      "epoch 13 loss: 0.0850549042224884\n",
      "epoch 14 loss: 0.09396757185459137\n",
      "epoch 15 loss: 0.09273458272218704\n",
      "epoch 16 loss: 0.07314258813858032\n",
      "epoch 17 loss: 0.07633896917104721\n",
      "epoch 18 loss: 0.06933563947677612\n",
      "epoch 19 loss: 0.09077445417642593\n",
      "epoch 20 loss: 0.07489845901727676\n",
      "epoch 21 loss: 0.07942336052656174\n",
      "epoch 22 loss: 0.05484846234321594\n",
      "epoch 23 loss: 0.058227427303791046\n",
      "epoch 24 loss: 0.06305702030658722\n",
      "epoch 25 loss: 0.06155114248394966\n",
      "epoch 26 loss: 0.08134343475103378\n",
      "epoch 27 loss: 0.0644637793302536\n",
      "epoch 28 loss: 0.055589709430933\n",
      "epoch 29 loss: 0.05782012268900871\n",
      "epoch 30 loss: 0.06841863691806793\n",
      "34\n",
      "epoch 1 loss: 0.7359796166419983\n",
      "epoch 2 loss: 0.6765422821044922\n",
      "epoch 3 loss: 0.3642614781856537\n",
      "epoch 4 loss: 0.20557594299316406\n",
      "epoch 5 loss: 0.15813902020454407\n",
      "epoch 6 loss: 0.13238871097564697\n",
      "epoch 7 loss: 0.09419810771942139\n",
      "epoch 8 loss: 0.0978739783167839\n",
      "epoch 9 loss: 0.09718716889619827\n",
      "epoch 10 loss: 0.1083901971578598\n",
      "epoch 11 loss: 0.09272615611553192\n",
      "epoch 12 loss: 0.09501366317272186\n",
      "epoch 13 loss: 0.11889821290969849\n",
      "epoch 14 loss: 0.06741861253976822\n",
      "epoch 15 loss: 0.08078105002641678\n",
      "epoch 16 loss: 0.07418450713157654\n",
      "epoch 17 loss: 0.0734456479549408\n",
      "epoch 18 loss: 0.08809918165206909\n",
      "epoch 19 loss: 0.07420700043439865\n",
      "epoch 20 loss: 0.07295617461204529\n",
      "epoch 21 loss: 0.07398887723684311\n",
      "epoch 22 loss: 0.0667821392416954\n",
      "epoch 23 loss: 0.05806193873286247\n",
      "epoch 24 loss: 0.07066444307565689\n",
      "epoch 25 loss: 0.067958302795887\n",
      "epoch 26 loss: 0.060376398265361786\n",
      "epoch 27 loss: 0.06432965397834778\n",
      "epoch 28 loss: 0.05297483131289482\n",
      "epoch 29 loss: 0.04254496097564697\n",
      "epoch 30 loss: 0.05918325483798981\n",
      "35\n",
      "epoch 1 loss: 0.7900627851486206\n",
      "epoch 2 loss: 0.5022230744361877\n",
      "epoch 3 loss: 0.24614010751247406\n",
      "epoch 4 loss: 0.2013980746269226\n",
      "epoch 5 loss: 0.16287283599376678\n",
      "epoch 6 loss: 0.11695162206888199\n",
      "epoch 7 loss: 0.14456579089164734\n",
      "epoch 8 loss: 0.08538760989904404\n",
      "epoch 9 loss: 0.10264739394187927\n",
      "epoch 10 loss: 0.0992257371544838\n",
      "epoch 11 loss: 0.08061252534389496\n",
      "epoch 12 loss: 0.06985130161046982\n",
      "epoch 13 loss: 0.0936836376786232\n",
      "epoch 14 loss: 0.08034496009349823\n",
      "epoch 15 loss: 0.08598393201828003\n",
      "epoch 16 loss: 0.07607346028089523\n",
      "epoch 17 loss: 0.05726146325469017\n",
      "epoch 18 loss: 0.09652947634458542\n",
      "epoch 19 loss: 0.0746755376458168\n",
      "epoch 20 loss: 0.06646955758333206\n",
      "epoch 21 loss: 0.06721443682909012\n",
      "epoch 22 loss: 0.06492288410663605\n",
      "epoch 23 loss: 0.08780457079410553\n",
      "epoch 24 loss: 0.06583939492702484\n",
      "epoch 25 loss: 0.061700452119112015\n",
      "epoch 26 loss: 0.06772346049547195\n",
      "epoch 27 loss: 0.07368793338537216\n",
      "epoch 28 loss: 0.06928770989179611\n",
      "epoch 29 loss: 0.05157197639346123\n",
      "epoch 30 loss: 0.07315994799137115\n",
      "36\n",
      "epoch 1 loss: 0.6719784736633301\n",
      "epoch 2 loss: 1.1499626636505127\n",
      "epoch 3 loss: 0.5108669400215149\n",
      "epoch 4 loss: 0.38078758120536804\n",
      "epoch 5 loss: 0.15705662965774536\n",
      "epoch 6 loss: 0.13108383119106293\n",
      "epoch 7 loss: 0.11070264130830765\n",
      "epoch 8 loss: 0.09270194172859192\n",
      "epoch 9 loss: 0.08956637978553772\n",
      "epoch 10 loss: 0.0809253454208374\n",
      "epoch 11 loss: 0.07388969510793686\n",
      "epoch 12 loss: 0.08429356664419174\n",
      "epoch 13 loss: 0.08076931536197662\n",
      "epoch 14 loss: 0.07331327348947525\n",
      "epoch 15 loss: 0.09505663067102432\n",
      "epoch 16 loss: 0.08427608013153076\n",
      "epoch 17 loss: 0.05037481710314751\n",
      "epoch 18 loss: 0.06924891471862793\n",
      "epoch 19 loss: 0.056102536618709564\n",
      "epoch 20 loss: 0.08220483362674713\n",
      "epoch 21 loss: 0.07296338677406311\n",
      "epoch 22 loss: 0.08094527572393417\n",
      "epoch 23 loss: 0.05681882053613663\n",
      "epoch 24 loss: 0.04715347662568092\n",
      "epoch 25 loss: 0.06664686650037766\n",
      "epoch 26 loss: 0.07001034170389175\n",
      "epoch 27 loss: 0.06299406290054321\n",
      "epoch 28 loss: 0.050534702837467194\n",
      "epoch 29 loss: 0.06506027281284332\n",
      "epoch 30 loss: 0.04749726876616478\n",
      "37\n",
      "epoch 1 loss: 0.6927634477615356\n",
      "epoch 2 loss: 0.4964616298675537\n",
      "epoch 3 loss: 0.1958167850971222\n",
      "epoch 4 loss: 0.16258570551872253\n",
      "epoch 5 loss: 0.15594999492168427\n",
      "epoch 6 loss: 0.15980155766010284\n",
      "epoch 7 loss: 0.07777298986911774\n",
      "epoch 8 loss: 0.07189987599849701\n",
      "epoch 9 loss: 0.08223804086446762\n",
      "epoch 10 loss: 0.06995570659637451\n",
      "epoch 11 loss: 0.07444160431623459\n",
      "epoch 12 loss: 0.09453494101762772\n",
      "epoch 13 loss: 0.0987425148487091\n",
      "epoch 14 loss: 0.07227164506912231\n",
      "epoch 15 loss: 0.07316697388887405\n",
      "epoch 16 loss: 0.06231880933046341\n",
      "epoch 17 loss: 0.11374616622924805\n",
      "epoch 18 loss: 0.08902382105588913\n",
      "epoch 19 loss: 0.0741846039891243\n",
      "epoch 20 loss: 0.06446798145771027\n",
      "epoch 21 loss: 0.08419347554445267\n",
      "epoch 22 loss: 0.06334885954856873\n",
      "epoch 23 loss: 0.0651097521185875\n",
      "epoch 24 loss: 0.07770384848117828\n",
      "epoch 25 loss: 0.06123670935630798\n",
      "epoch 26 loss: 0.057257119566202164\n",
      "epoch 27 loss: 0.06864622235298157\n",
      "epoch 28 loss: 0.053193625062704086\n",
      "epoch 29 loss: 0.05803840979933739\n",
      "epoch 30 loss: 0.04409949854016304\n",
      "38\n",
      "epoch 1 loss: 0.9520838260650635\n",
      "epoch 2 loss: 0.7775167226791382\n",
      "epoch 3 loss: 0.6159830689430237\n",
      "epoch 4 loss: 0.49721238017082214\n",
      "epoch 5 loss: 0.20556657016277313\n",
      "epoch 6 loss: 0.15179885923862457\n",
      "epoch 7 loss: 0.14673452079296112\n",
      "epoch 8 loss: 0.06552591919898987\n",
      "epoch 9 loss: 0.06876350939273834\n",
      "epoch 10 loss: 0.10022488236427307\n",
      "epoch 11 loss: 0.09365013986825943\n",
      "epoch 12 loss: 0.08843468129634857\n",
      "epoch 13 loss: 0.09964633733034134\n",
      "epoch 14 loss: 0.08439738303422928\n",
      "epoch 15 loss: 0.07985284924507141\n",
      "epoch 16 loss: 0.08584792912006378\n",
      "epoch 17 loss: 0.08854680508375168\n",
      "epoch 18 loss: 0.06544084846973419\n",
      "epoch 19 loss: 0.06992116570472717\n",
      "epoch 20 loss: 0.0767337903380394\n",
      "epoch 21 loss: 0.05931395664811134\n",
      "epoch 22 loss: 0.06170523911714554\n",
      "epoch 23 loss: 0.06848561763763428\n",
      "epoch 24 loss: 0.060314394533634186\n",
      "epoch 25 loss: 0.06468883901834488\n",
      "epoch 26 loss: 0.06354158371686935\n",
      "epoch 27 loss: 0.05836847424507141\n",
      "epoch 28 loss: 0.06958988308906555\n",
      "epoch 29 loss: 0.0534997396171093\n",
      "epoch 30 loss: 0.06354925036430359\n",
      "39\n",
      "epoch 1 loss: 0.8075583577156067\n",
      "epoch 2 loss: 0.525231659412384\n",
      "epoch 3 loss: 0.32677537202835083\n",
      "epoch 4 loss: 0.17844821512699127\n",
      "epoch 5 loss: 0.15392491221427917\n",
      "epoch 6 loss: 0.13689489662647247\n",
      "epoch 7 loss: 0.11255238205194473\n",
      "epoch 8 loss: 0.08219268918037415\n",
      "epoch 9 loss: 0.07236254215240479\n",
      "epoch 10 loss: 0.0866423025727272\n",
      "epoch 11 loss: 0.06565994024276733\n",
      "epoch 12 loss: 0.06647472083568573\n",
      "epoch 13 loss: 0.07229562848806381\n",
      "epoch 14 loss: 0.08938269317150116\n",
      "epoch 15 loss: 0.06505724787712097\n",
      "epoch 16 loss: 0.07484441995620728\n",
      "epoch 17 loss: 0.062131546437740326\n",
      "epoch 18 loss: 0.0634901374578476\n",
      "epoch 19 loss: 0.059381622821092606\n",
      "epoch 20 loss: 0.06771480292081833\n",
      "epoch 21 loss: 0.06596503406763077\n",
      "epoch 22 loss: 0.06512217968702316\n",
      "epoch 23 loss: 0.05528891459107399\n",
      "epoch 24 loss: 0.05140150338411331\n",
      "epoch 25 loss: 0.06003566086292267\n",
      "epoch 26 loss: 0.06867586076259613\n",
      "epoch 27 loss: 0.06319248676300049\n",
      "epoch 28 loss: 0.059402864426374435\n",
      "epoch 29 loss: 0.05537082254886627\n",
      "epoch 30 loss: 0.0563330352306366\n",
      "40\n",
      "epoch 1 loss: 0.7200304269790649\n",
      "epoch 2 loss: 0.31966736912727356\n",
      "epoch 3 loss: 0.2108350396156311\n",
      "epoch 4 loss: 0.16980278491973877\n",
      "epoch 5 loss: 0.12140762060880661\n",
      "epoch 6 loss: 0.12325631082057953\n",
      "epoch 7 loss: 0.10434739291667938\n",
      "epoch 8 loss: 0.08049326390028\n",
      "epoch 9 loss: 0.06758351624011993\n",
      "epoch 10 loss: 0.09425186365842819\n",
      "epoch 11 loss: 0.060229260474443436\n",
      "epoch 12 loss: 0.08572521060705185\n",
      "epoch 13 loss: 0.08128797262907028\n",
      "epoch 14 loss: 0.08231501281261444\n",
      "epoch 15 loss: 0.05535643920302391\n",
      "epoch 16 loss: 0.08899740129709244\n",
      "epoch 17 loss: 0.08587872236967087\n",
      "epoch 18 loss: 0.0658905953168869\n",
      "epoch 19 loss: 0.08393225818872452\n",
      "epoch 20 loss: 0.07111645489931107\n",
      "epoch 21 loss: 0.07960514724254608\n",
      "epoch 22 loss: 0.06534430384635925\n",
      "epoch 23 loss: 0.05334354192018509\n",
      "epoch 24 loss: 0.06010795012116432\n",
      "epoch 25 loss: 0.049976006150245667\n",
      "epoch 26 loss: 0.04286690056324005\n",
      "epoch 27 loss: 0.05483591929078102\n",
      "epoch 28 loss: 0.044612184166908264\n",
      "epoch 29 loss: 0.050886549055576324\n",
      "epoch 30 loss: 0.05740707740187645\n",
      "41\n",
      "epoch 1 loss: 0.7318195700645447\n",
      "epoch 2 loss: 0.38785526156425476\n",
      "epoch 3 loss: 0.34421205520629883\n",
      "epoch 4 loss: 0.16259732842445374\n",
      "epoch 5 loss: 0.11607181280851364\n",
      "epoch 6 loss: 0.1316273808479309\n",
      "epoch 7 loss: 0.09793538600206375\n",
      "epoch 8 loss: 0.08059948682785034\n",
      "epoch 9 loss: 0.12158915400505066\n",
      "epoch 10 loss: 0.08769012987613678\n",
      "epoch 11 loss: 0.07067970186471939\n",
      "epoch 12 loss: 0.07317546010017395\n",
      "epoch 13 loss: 0.0610569603741169\n",
      "epoch 14 loss: 0.10378025472164154\n",
      "epoch 15 loss: 0.059905435889959335\n",
      "epoch 16 loss: 0.07264012098312378\n",
      "epoch 17 loss: 0.05154416710138321\n",
      "epoch 18 loss: 0.07451114058494568\n",
      "epoch 19 loss: 0.06928066909313202\n",
      "epoch 20 loss: 0.06474678218364716\n",
      "epoch 21 loss: 0.06443893909454346\n",
      "epoch 22 loss: 0.0728292241692543\n",
      "epoch 23 loss: 0.057087887078523636\n",
      "epoch 24 loss: 0.05916346609592438\n",
      "epoch 25 loss: 0.06567040830850601\n",
      "epoch 26 loss: 0.07036948204040527\n",
      "epoch 27 loss: 0.05694842338562012\n",
      "epoch 28 loss: 0.055619314312934875\n",
      "epoch 29 loss: 0.06544629484415054\n",
      "epoch 30 loss: 0.05500686168670654\n",
      "42\n",
      "epoch 1 loss: 1.0077848434448242\n",
      "epoch 2 loss: 1.0251402854919434\n",
      "epoch 3 loss: 0.5178675651550293\n",
      "epoch 4 loss: 0.5024837851524353\n",
      "epoch 5 loss: 0.33052119612693787\n",
      "epoch 6 loss: 0.19926391541957855\n",
      "epoch 7 loss: 0.23645538091659546\n",
      "epoch 8 loss: 0.11822336167097092\n",
      "epoch 9 loss: 0.11370206624269485\n",
      "epoch 10 loss: 0.10132335871458054\n",
      "epoch 11 loss: 0.09043560177087784\n",
      "epoch 12 loss: 0.07048594951629639\n",
      "epoch 13 loss: 0.07776263356208801\n",
      "epoch 14 loss: 0.07600726187229156\n",
      "epoch 15 loss: 0.07942505925893784\n",
      "epoch 16 loss: 0.06794192641973495\n",
      "epoch 17 loss: 0.09868521243333817\n",
      "epoch 18 loss: 0.07973875850439072\n",
      "epoch 19 loss: 0.06422363966703415\n",
      "epoch 20 loss: 0.06235923618078232\n",
      "epoch 21 loss: 0.08259084075689316\n",
      "epoch 22 loss: 0.06321657449007034\n",
      "epoch 23 loss: 0.056395865976810455\n",
      "epoch 24 loss: 0.0695851519703865\n",
      "epoch 25 loss: 0.06320704519748688\n",
      "epoch 26 loss: 0.05327158421278\n",
      "epoch 27 loss: 0.0705496147274971\n",
      "epoch 28 loss: 0.05955657735466957\n",
      "epoch 29 loss: 0.05155259370803833\n",
      "epoch 30 loss: 0.06063443422317505\n",
      "43\n",
      "epoch 1 loss: 0.853081464767456\n",
      "epoch 2 loss: 0.7120010852813721\n",
      "epoch 3 loss: 0.31365057826042175\n",
      "epoch 4 loss: 0.2133180946111679\n",
      "epoch 5 loss: 0.14521442353725433\n",
      "epoch 6 loss: 0.10675957798957825\n",
      "epoch 7 loss: 0.10387701541185379\n",
      "epoch 8 loss: 0.09544077515602112\n",
      "epoch 9 loss: 0.10338039696216583\n",
      "epoch 10 loss: 0.07285870611667633\n",
      "epoch 11 loss: 0.07524342089891434\n",
      "epoch 12 loss: 0.07169611752033234\n",
      "epoch 13 loss: 0.07731512188911438\n",
      "epoch 14 loss: 0.07459251582622528\n",
      "epoch 15 loss: 0.08832690119743347\n",
      "epoch 16 loss: 0.06048383563756943\n",
      "epoch 17 loss: 0.05747691169381142\n",
      "epoch 18 loss: 0.060545239597558975\n",
      "epoch 19 loss: 0.058472950011491776\n",
      "epoch 20 loss: 0.05638304352760315\n",
      "epoch 21 loss: 0.0871177688241005\n",
      "epoch 22 loss: 0.059209395200014114\n",
      "epoch 23 loss: 0.05669784173369408\n",
      "epoch 24 loss: 0.05142635479569435\n",
      "epoch 25 loss: 0.06346534192562103\n",
      "epoch 26 loss: 0.06895967572927475\n",
      "epoch 27 loss: 0.06236909329891205\n",
      "epoch 28 loss: 0.04732154309749603\n",
      "epoch 29 loss: 0.06733351200819016\n",
      "epoch 30 loss: 0.05532624572515488\n",
      "44\n",
      "epoch 1 loss: 0.8395786285400391\n",
      "epoch 2 loss: 0.8303889036178589\n",
      "epoch 3 loss: 0.5486265420913696\n",
      "epoch 4 loss: 0.510661780834198\n",
      "epoch 5 loss: 0.295596182346344\n",
      "epoch 6 loss: 0.17939668893814087\n",
      "epoch 7 loss: 0.1340542733669281\n",
      "epoch 8 loss: 0.1263859122991562\n",
      "epoch 9 loss: 0.10526245087385178\n",
      "epoch 10 loss: 0.09590795636177063\n",
      "epoch 11 loss: 0.09939149022102356\n",
      "epoch 12 loss: 0.09466436505317688\n",
      "epoch 13 loss: 0.10529825836420059\n",
      "epoch 14 loss: 0.0853632241487503\n",
      "epoch 15 loss: 0.07281391322612762\n",
      "epoch 16 loss: 0.0685872733592987\n",
      "epoch 17 loss: 0.07717841118574142\n",
      "epoch 18 loss: 0.0787685364484787\n",
      "epoch 19 loss: 0.07241132110357285\n",
      "epoch 20 loss: 0.054828789085149765\n",
      "epoch 21 loss: 0.06536702066659927\n",
      "epoch 22 loss: 0.06796032190322876\n",
      "epoch 23 loss: 0.05891907587647438\n",
      "epoch 24 loss: 0.07903292030096054\n",
      "epoch 25 loss: 0.07264159619808197\n",
      "epoch 26 loss: 0.06537354737520218\n",
      "epoch 27 loss: 0.06594187766313553\n",
      "epoch 28 loss: 0.05786306411027908\n",
      "epoch 29 loss: 0.060065560042858124\n",
      "epoch 30 loss: 0.0507299043238163\n",
      "45\n",
      "epoch 1 loss: 0.8059958219528198\n",
      "epoch 2 loss: 0.5840660929679871\n",
      "epoch 3 loss: 0.4422818422317505\n",
      "epoch 4 loss: 0.303707093000412\n",
      "epoch 5 loss: 0.17248864471912384\n",
      "epoch 6 loss: 0.1795325130224228\n",
      "epoch 7 loss: 0.11838191747665405\n",
      "epoch 8 loss: 0.13178366422653198\n",
      "epoch 9 loss: 0.16177360713481903\n",
      "epoch 10 loss: 0.11785559356212616\n",
      "epoch 11 loss: 0.127284973859787\n",
      "epoch 12 loss: 0.09146615117788315\n",
      "epoch 13 loss: 0.09190376847982407\n",
      "epoch 14 loss: 0.08956841379404068\n",
      "epoch 15 loss: 0.08254458010196686\n",
      "epoch 16 loss: 0.10304087400436401\n",
      "epoch 17 loss: 0.05113508924841881\n",
      "epoch 18 loss: 0.06195990741252899\n",
      "epoch 19 loss: 0.07037725299596786\n",
      "epoch 20 loss: 0.07288758456707001\n",
      "epoch 21 loss: 0.08821512013673782\n",
      "epoch 22 loss: 0.06471666693687439\n",
      "epoch 23 loss: 0.06571546941995621\n",
      "epoch 24 loss: 0.06049042567610741\n",
      "epoch 25 loss: 0.06467906385660172\n",
      "epoch 26 loss: 0.05388116464018822\n",
      "epoch 27 loss: 0.05460115522146225\n",
      "epoch 28 loss: 0.06527946144342422\n",
      "epoch 29 loss: 0.04734642803668976\n",
      "epoch 30 loss: 0.05953508988022804\n",
      "46\n",
      "epoch 1 loss: 1.0174517631530762\n",
      "epoch 2 loss: 0.807710587978363\n",
      "epoch 3 loss: 0.2831619679927826\n",
      "epoch 4 loss: 0.24593405425548553\n",
      "epoch 5 loss: 0.17604753375053406\n",
      "epoch 6 loss: 0.1222974881529808\n",
      "epoch 7 loss: 0.10475937277078629\n",
      "epoch 8 loss: 0.09825237840414047\n",
      "epoch 9 loss: 0.13219812512397766\n",
      "epoch 10 loss: 0.07834568619728088\n",
      "epoch 11 loss: 0.07531128078699112\n",
      "epoch 12 loss: 0.09384449571371078\n",
      "epoch 13 loss: 0.08491204679012299\n",
      "epoch 14 loss: 0.07498447597026825\n",
      "epoch 15 loss: 0.06405666470527649\n",
      "epoch 16 loss: 0.07140211015939713\n",
      "epoch 17 loss: 0.07040093839168549\n",
      "epoch 18 loss: 0.06191923841834068\n",
      "epoch 19 loss: 0.054605256766080856\n",
      "epoch 20 loss: 0.06839441508054733\n",
      "epoch 21 loss: 0.07588659226894379\n",
      "epoch 22 loss: 0.06019768863916397\n",
      "epoch 23 loss: 0.09220895171165466\n",
      "epoch 24 loss: 0.06331317126750946\n",
      "epoch 25 loss: 0.05839311704039574\n",
      "epoch 26 loss: 0.04552791640162468\n",
      "epoch 27 loss: 0.05692797154188156\n",
      "epoch 28 loss: 0.0734303668141365\n",
      "epoch 29 loss: 0.05924507603049278\n",
      "epoch 30 loss: 0.078861303627491\n",
      "47\n",
      "epoch 1 loss: 0.7503886222839355\n",
      "epoch 2 loss: 0.8651843070983887\n",
      "epoch 3 loss: 0.5653244256973267\n",
      "epoch 4 loss: 0.7094799876213074\n",
      "epoch 5 loss: 0.4076101779937744\n",
      "epoch 6 loss: 0.1950167566537857\n",
      "epoch 7 loss: 0.134958878159523\n",
      "epoch 8 loss: 0.12226852029561996\n",
      "epoch 9 loss: 0.13280600309371948\n",
      "epoch 10 loss: 0.10637962073087692\n",
      "epoch 11 loss: 0.08037120848894119\n",
      "epoch 12 loss: 0.10132838785648346\n",
      "epoch 13 loss: 0.08007115125656128\n",
      "epoch 14 loss: 0.08398663252592087\n",
      "epoch 15 loss: 0.08835658431053162\n",
      "epoch 16 loss: 0.09165621548891068\n",
      "epoch 17 loss: 0.08543898165225983\n",
      "epoch 18 loss: 0.08783464133739471\n",
      "epoch 19 loss: 0.06497442722320557\n",
      "epoch 20 loss: 0.06430986523628235\n",
      "epoch 21 loss: 0.06437352299690247\n",
      "epoch 22 loss: 0.07028418779373169\n",
      "epoch 23 loss: 0.07054027915000916\n",
      "epoch 24 loss: 0.07154647260904312\n",
      "epoch 25 loss: 0.08293087035417557\n",
      "epoch 26 loss: 0.05114097148180008\n",
      "epoch 27 loss: 0.06465741991996765\n",
      "epoch 28 loss: 0.06566856801509857\n",
      "epoch 29 loss: 0.06682703644037247\n",
      "epoch 30 loss: 0.06833871454000473\n",
      "48\n",
      "epoch 1 loss: 0.9770313501358032\n",
      "epoch 2 loss: 0.607038140296936\n",
      "epoch 3 loss: 0.7427266836166382\n",
      "epoch 4 loss: 0.3240559995174408\n",
      "epoch 5 loss: 0.2057868391275406\n",
      "epoch 6 loss: 0.15880347788333893\n",
      "epoch 7 loss: 0.11484820395708084\n",
      "epoch 8 loss: 0.10134035348892212\n",
      "epoch 9 loss: 0.10953296720981598\n",
      "epoch 10 loss: 0.09479875862598419\n",
      "epoch 11 loss: 0.1017659604549408\n",
      "epoch 12 loss: 0.07153517752885818\n",
      "epoch 13 loss: 0.07189669460058212\n",
      "epoch 14 loss: 0.0828830674290657\n",
      "epoch 15 loss: 0.07470948994159698\n",
      "epoch 16 loss: 0.060656867921352386\n",
      "epoch 17 loss: 0.06989703327417374\n",
      "epoch 18 loss: 0.08132407069206238\n",
      "epoch 19 loss: 0.06353688985109329\n",
      "epoch 20 loss: 0.06367673724889755\n",
      "epoch 21 loss: 0.08020757138729095\n",
      "epoch 22 loss: 0.07826007157564163\n",
      "epoch 23 loss: 0.05809469893574715\n",
      "epoch 24 loss: 0.06632854789495468\n",
      "epoch 25 loss: 0.06631568819284439\n",
      "epoch 26 loss: 0.06542528420686722\n",
      "epoch 27 loss: 0.045145999640226364\n",
      "epoch 28 loss: 0.049544163048267365\n",
      "epoch 29 loss: 0.056823089718818665\n",
      "epoch 30 loss: 0.05045934394001961\n",
      "49\n",
      "epoch 1 loss: 0.9118235111236572\n",
      "epoch 2 loss: 0.534512996673584\n",
      "epoch 3 loss: 0.2842264771461487\n",
      "epoch 4 loss: 0.10745859146118164\n",
      "epoch 5 loss: 0.12825621664524078\n",
      "epoch 6 loss: 0.10577182471752167\n",
      "epoch 7 loss: 0.10506115853786469\n",
      "epoch 8 loss: 0.07459656149148941\n",
      "epoch 9 loss: 0.09371867030858994\n",
      "epoch 10 loss: 0.09765607863664627\n",
      "epoch 11 loss: 0.1007830798625946\n",
      "epoch 12 loss: 0.056492049247026443\n",
      "epoch 13 loss: 0.07911401242017746\n",
      "epoch 14 loss: 0.0914389044046402\n",
      "epoch 15 loss: 0.077082060277462\n",
      "epoch 16 loss: 0.08029535412788391\n",
      "epoch 17 loss: 0.06119956448674202\n",
      "epoch 18 loss: 0.0534750372171402\n",
      "epoch 19 loss: 0.06352356821298599\n",
      "epoch 20 loss: 0.06596129387617111\n",
      "epoch 21 loss: 0.0633435994386673\n",
      "epoch 22 loss: 0.07283660769462585\n",
      "epoch 23 loss: 0.08000557124614716\n",
      "epoch 24 loss: 0.05882905423641205\n",
      "epoch 25 loss: 0.0735405907034874\n",
      "epoch 26 loss: 0.04926763474941254\n",
      "epoch 27 loss: 0.07706384360790253\n",
      "epoch 28 loss: 0.0558990016579628\n",
      "epoch 29 loss: 0.07712370902299881\n",
      "epoch 30 loss: 0.06387332826852798\n",
      "50\n",
      "epoch 1 loss: 0.6773877143859863\n",
      "epoch 2 loss: 0.3832516074180603\n",
      "epoch 3 loss: 0.34687432646751404\n",
      "epoch 4 loss: 0.14747850596904755\n",
      "epoch 5 loss: 0.13942913711071014\n",
      "epoch 6 loss: 0.12439392507076263\n",
      "epoch 7 loss: 0.11539876461029053\n",
      "epoch 8 loss: 0.12368947267532349\n",
      "epoch 9 loss: 0.10174702107906342\n",
      "epoch 10 loss: 0.08390995860099792\n",
      "epoch 11 loss: 0.0772433951497078\n",
      "epoch 12 loss: 0.07755277305841446\n",
      "epoch 13 loss: 0.07286570221185684\n",
      "epoch 14 loss: 0.08616631478071213\n",
      "epoch 15 loss: 0.07198426127433777\n",
      "epoch 16 loss: 0.06905551999807358\n",
      "epoch 17 loss: 0.0939020961523056\n",
      "epoch 18 loss: 0.0693899393081665\n",
      "epoch 19 loss: 0.08718519657850266\n",
      "epoch 20 loss: 0.08794402331113815\n",
      "epoch 21 loss: 0.06836976855993271\n",
      "epoch 22 loss: 0.06606592983007431\n",
      "epoch 23 loss: 0.04828860983252525\n",
      "epoch 24 loss: 0.09696187824010849\n",
      "epoch 25 loss: 0.06399822235107422\n",
      "epoch 26 loss: 0.06202540546655655\n",
      "epoch 27 loss: 0.06690359860658646\n",
      "epoch 28 loss: 0.07264208793640137\n",
      "epoch 29 loss: 0.06524380296468735\n",
      "epoch 30 loss: 0.0632941871881485\n",
      "51\n",
      "epoch 1 loss: 0.6529277563095093\n",
      "epoch 2 loss: 0.812868058681488\n",
      "epoch 3 loss: 0.3578122556209564\n",
      "epoch 4 loss: 0.15917333960533142\n",
      "epoch 5 loss: 0.18459810316562653\n",
      "epoch 6 loss: 0.09399481117725372\n",
      "epoch 7 loss: 0.11071307212114334\n",
      "epoch 8 loss: 0.10373524576425552\n",
      "epoch 9 loss: 0.0760578140616417\n",
      "epoch 10 loss: 0.07246844470500946\n",
      "epoch 11 loss: 0.06755479425191879\n",
      "epoch 12 loss: 0.08108319342136383\n",
      "epoch 13 loss: 0.07361321151256561\n",
      "epoch 14 loss: 0.10945338755846024\n",
      "epoch 15 loss: 0.11524057388305664\n",
      "epoch 16 loss: 0.06285323947668076\n",
      "epoch 17 loss: 0.09304030239582062\n",
      "epoch 18 loss: 0.08727148175239563\n",
      "epoch 19 loss: 0.07772419601678848\n",
      "epoch 20 loss: 0.08842403441667557\n",
      "epoch 21 loss: 0.0750645101070404\n",
      "epoch 22 loss: 0.06501848995685577\n",
      "epoch 23 loss: 0.05610420182347298\n",
      "epoch 24 loss: 0.0584915429353714\n",
      "epoch 25 loss: 0.07252281904220581\n",
      "epoch 26 loss: 0.060695894062519073\n",
      "epoch 27 loss: 0.06553924828767776\n",
      "epoch 28 loss: 0.060630496591329575\n",
      "epoch 29 loss: 0.060746319591999054\n",
      "epoch 30 loss: 0.07007546722888947\n",
      "52\n",
      "epoch 1 loss: 0.940126359462738\n",
      "epoch 2 loss: 0.4007943570613861\n",
      "epoch 3 loss: 0.33681827783584595\n",
      "epoch 4 loss: 0.2325638234615326\n",
      "epoch 5 loss: 0.12705866992473602\n",
      "epoch 6 loss: 0.13691885769367218\n",
      "epoch 7 loss: 0.13876764476299286\n",
      "epoch 8 loss: 0.13342046737670898\n",
      "epoch 9 loss: 0.11694704741239548\n",
      "epoch 10 loss: 0.15228238701820374\n",
      "epoch 11 loss: 0.077549509704113\n",
      "epoch 12 loss: 0.10345683991909027\n",
      "epoch 13 loss: 0.06870768219232559\n",
      "epoch 14 loss: 0.0837806835770607\n",
      "epoch 15 loss: 0.06335452944040298\n",
      "epoch 16 loss: 0.0791342481970787\n",
      "epoch 17 loss: 0.07552462071180344\n",
      "epoch 18 loss: 0.051899973303079605\n",
      "epoch 19 loss: 0.05460511893033981\n",
      "epoch 20 loss: 0.05359266325831413\n",
      "epoch 21 loss: 0.06526512652635574\n",
      "epoch 22 loss: 0.055603913962841034\n",
      "epoch 23 loss: 0.05860791355371475\n",
      "epoch 24 loss: 0.07471078634262085\n",
      "epoch 25 loss: 0.05823585018515587\n",
      "epoch 26 loss: 0.04373767226934433\n",
      "epoch 27 loss: 0.05325978621840477\n",
      "epoch 28 loss: 0.05650372430682182\n",
      "epoch 29 loss: 0.06631232798099518\n",
      "epoch 30 loss: 0.06856178492307663\n",
      "53\n",
      "epoch 1 loss: 0.7155385613441467\n",
      "epoch 2 loss: 0.5339909791946411\n",
      "epoch 3 loss: 0.3049127161502838\n",
      "epoch 4 loss: 0.17405012249946594\n",
      "epoch 5 loss: 0.15087434649467468\n",
      "epoch 6 loss: 0.1434953808784485\n",
      "epoch 7 loss: 0.09650272876024246\n",
      "epoch 8 loss: 0.10709420591592789\n",
      "epoch 9 loss: 0.08713299036026001\n",
      "epoch 10 loss: 0.08330239355564117\n",
      "epoch 11 loss: 0.13657096028327942\n",
      "epoch 12 loss: 0.07508324086666107\n",
      "epoch 13 loss: 0.07536743581295013\n",
      "epoch 14 loss: 0.06628014147281647\n",
      "epoch 15 loss: 0.07094728201627731\n",
      "epoch 16 loss: 0.0759497806429863\n",
      "epoch 17 loss: 0.07002755254507065\n",
      "epoch 18 loss: 0.05578067898750305\n",
      "epoch 19 loss: 0.048957403749227524\n",
      "epoch 20 loss: 0.06059785559773445\n",
      "epoch 21 loss: 0.06389614939689636\n",
      "epoch 22 loss: 0.05383705720305443\n",
      "epoch 23 loss: 0.06387268751859665\n",
      "epoch 24 loss: 0.06776627898216248\n",
      "epoch 25 loss: 0.04941040277481079\n",
      "epoch 26 loss: 0.06113514304161072\n",
      "epoch 27 loss: 0.05609613284468651\n",
      "epoch 28 loss: 0.05886966362595558\n",
      "epoch 29 loss: 0.06309251487255096\n",
      "epoch 30 loss: 0.05691192299127579\n",
      "54\n",
      "epoch 1 loss: 0.9866160750389099\n",
      "epoch 2 loss: 0.4394022822380066\n",
      "epoch 3 loss: 0.22071623802185059\n",
      "epoch 4 loss: 0.1376400887966156\n",
      "epoch 5 loss: 0.14164425432682037\n",
      "epoch 6 loss: 0.11756616085767746\n",
      "epoch 7 loss: 0.11368206888437271\n",
      "epoch 8 loss: 0.09999818354845047\n",
      "epoch 9 loss: 0.09262692183256149\n",
      "epoch 10 loss: 0.11130966246128082\n",
      "epoch 11 loss: 0.08096083998680115\n",
      "epoch 12 loss: 0.07836665958166122\n",
      "epoch 13 loss: 0.074446901679039\n",
      "epoch 14 loss: 0.1048261970281601\n",
      "epoch 15 loss: 0.08864326775074005\n",
      "epoch 16 loss: 0.10641682893037796\n",
      "epoch 17 loss: 0.06339474767446518\n",
      "epoch 18 loss: 0.07323598116636276\n",
      "epoch 19 loss: 0.06392215937376022\n",
      "epoch 20 loss: 0.055975545197725296\n",
      "epoch 21 loss: 0.060820985585451126\n",
      "epoch 22 loss: 0.0727691724896431\n",
      "epoch 23 loss: 0.05154681205749512\n",
      "epoch 24 loss: 0.061563242226839066\n",
      "epoch 25 loss: 0.0719580128788948\n",
      "epoch 26 loss: 0.04954510182142258\n",
      "epoch 27 loss: 0.047207869589328766\n",
      "epoch 28 loss: 0.05509171634912491\n",
      "epoch 29 loss: 0.058740437030792236\n",
      "epoch 30 loss: 0.06266500800848007\n",
      "55\n",
      "epoch 1 loss: 0.83188396692276\n",
      "epoch 2 loss: 0.5269831418991089\n",
      "epoch 3 loss: 0.33605486154556274\n",
      "epoch 4 loss: 0.1669958382844925\n",
      "epoch 5 loss: 0.15757067501544952\n",
      "epoch 6 loss: 0.1217087060213089\n",
      "epoch 7 loss: 0.09476166218519211\n",
      "epoch 8 loss: 0.07002205401659012\n",
      "epoch 9 loss: 0.06362755596637726\n",
      "epoch 10 loss: 0.10604254901409149\n",
      "epoch 11 loss: 0.0859055370092392\n",
      "epoch 12 loss: 0.07107008248567581\n",
      "epoch 13 loss: 0.06922248005867004\n",
      "epoch 14 loss: 0.05297233909368515\n",
      "epoch 15 loss: 0.06458941102027893\n",
      "epoch 16 loss: 0.06802766025066376\n",
      "epoch 17 loss: 0.05194253847002983\n",
      "epoch 18 loss: 0.07080557942390442\n",
      "epoch 19 loss: 0.07658538222312927\n",
      "epoch 20 loss: 0.06472999602556229\n",
      "epoch 21 loss: 0.074293352663517\n",
      "epoch 22 loss: 0.0632338747382164\n",
      "epoch 23 loss: 0.054830681532621384\n",
      "epoch 24 loss: 0.06692399084568024\n",
      "epoch 25 loss: 0.06687803566455841\n",
      "epoch 26 loss: 0.0620453841984272\n",
      "epoch 27 loss: 0.06004142761230469\n",
      "epoch 28 loss: 0.059284090995788574\n",
      "epoch 29 loss: 0.055178478360176086\n",
      "epoch 30 loss: 0.05773020535707474\n",
      "56\n",
      "epoch 1 loss: 0.7480154633522034\n",
      "epoch 2 loss: 0.6357904076576233\n",
      "epoch 3 loss: 0.37549763917922974\n",
      "epoch 4 loss: 0.24015885591506958\n",
      "epoch 5 loss: 0.13641881942749023\n",
      "epoch 6 loss: 0.17853456735610962\n",
      "epoch 7 loss: 0.09770786017179489\n",
      "epoch 8 loss: 0.11397168785333633\n",
      "epoch 9 loss: 0.08400779962539673\n",
      "epoch 10 loss: 0.08996637165546417\n",
      "epoch 11 loss: 0.10779928416013718\n",
      "epoch 12 loss: 0.10960462689399719\n",
      "epoch 13 loss: 0.09409324079751968\n",
      "epoch 14 loss: 0.08218070864677429\n",
      "epoch 15 loss: 0.07303813844919205\n",
      "epoch 16 loss: 0.06728558242321014\n",
      "epoch 17 loss: 0.078546904027462\n",
      "epoch 18 loss: 0.08181946724653244\n",
      "epoch 19 loss: 0.10280968248844147\n",
      "epoch 20 loss: 0.07054737955331802\n",
      "epoch 21 loss: 0.06285680085420609\n",
      "epoch 22 loss: 0.05630502477288246\n",
      "epoch 23 loss: 0.05758063495159149\n",
      "epoch 24 loss: 0.05931352823972702\n",
      "epoch 25 loss: 0.05711578577756882\n",
      "epoch 26 loss: 0.053961146622896194\n",
      "epoch 27 loss: 0.0587383471429348\n",
      "epoch 28 loss: 0.0698990747332573\n",
      "epoch 29 loss: 0.051669228821992874\n",
      "epoch 30 loss: 0.04364526644349098\n",
      "57\n",
      "epoch 1 loss: 1.050121784210205\n",
      "epoch 2 loss: 0.687471330165863\n",
      "epoch 3 loss: 0.5824058651924133\n",
      "epoch 4 loss: 0.3034832775592804\n",
      "epoch 5 loss: 0.13457682728767395\n",
      "epoch 6 loss: 0.1238495409488678\n",
      "epoch 7 loss: 0.14104466140270233\n",
      "epoch 8 loss: 0.11774289608001709\n",
      "epoch 9 loss: 0.09319299459457397\n",
      "epoch 10 loss: 0.06986372172832489\n",
      "epoch 11 loss: 0.08334341645240784\n",
      "epoch 12 loss: 0.07161116600036621\n",
      "epoch 13 loss: 0.08885619789361954\n",
      "epoch 14 loss: 0.11172298341989517\n",
      "epoch 15 loss: 0.0773894265294075\n",
      "epoch 16 loss: 0.07908343523740768\n",
      "epoch 17 loss: 0.08257319778203964\n",
      "epoch 18 loss: 0.06469316780567169\n",
      "epoch 19 loss: 0.08155110478401184\n",
      "epoch 20 loss: 0.07086819410324097\n",
      "epoch 21 loss: 0.06994211673736572\n",
      "epoch 22 loss: 0.06977525353431702\n",
      "epoch 23 loss: 0.057098452001810074\n",
      "epoch 24 loss: 0.08817102015018463\n",
      "epoch 25 loss: 0.06125699728727341\n",
      "epoch 26 loss: 0.05770833417773247\n",
      "epoch 27 loss: 0.0740722045302391\n",
      "epoch 28 loss: 0.08893019706010818\n",
      "epoch 29 loss: 0.06385880708694458\n",
      "epoch 30 loss: 0.0757005512714386\n",
      "58\n",
      "epoch 1 loss: 0.7874342799186707\n",
      "epoch 2 loss: 0.579931378364563\n",
      "epoch 3 loss: 0.406986266374588\n",
      "epoch 4 loss: 0.18418385088443756\n",
      "epoch 5 loss: 0.16368955373764038\n",
      "epoch 6 loss: 0.14648012816905975\n",
      "epoch 7 loss: 0.11046113818883896\n",
      "epoch 8 loss: 0.11235897988080978\n",
      "epoch 9 loss: 0.0873529240489006\n",
      "epoch 10 loss: 0.09539981186389923\n",
      "epoch 11 loss: 0.07596731185913086\n",
      "epoch 12 loss: 0.06297093629837036\n",
      "epoch 13 loss: 0.07955622673034668\n",
      "epoch 14 loss: 0.07318267226219177\n",
      "epoch 15 loss: 0.0808180570602417\n",
      "epoch 16 loss: 0.0677453801035881\n",
      "epoch 17 loss: 0.07310991734266281\n",
      "epoch 18 loss: 0.05156548321247101\n",
      "epoch 19 loss: 0.06498075276613235\n",
      "epoch 20 loss: 0.0840156227350235\n",
      "epoch 21 loss: 0.06103597208857536\n",
      "epoch 22 loss: 0.06519632041454315\n",
      "epoch 23 loss: 0.06333479285240173\n",
      "epoch 24 loss: 0.07555877417325974\n",
      "epoch 25 loss: 0.04805799201130867\n",
      "epoch 26 loss: 0.06090521067380905\n",
      "epoch 27 loss: 0.05667349323630333\n",
      "epoch 28 loss: 0.061386484652757645\n",
      "epoch 29 loss: 0.055654365569353104\n",
      "epoch 30 loss: 0.04790489375591278\n",
      "59\n",
      "epoch 1 loss: 0.7737402319908142\n",
      "epoch 2 loss: 0.7414004802703857\n",
      "epoch 3 loss: 0.3651553690433502\n",
      "epoch 4 loss: 0.2659343183040619\n",
      "epoch 5 loss: 0.1787438541650772\n",
      "epoch 6 loss: 0.11493966728448868\n",
      "epoch 7 loss: 0.11216411739587784\n",
      "epoch 8 loss: 0.10447689145803452\n",
      "epoch 9 loss: 0.08293376117944717\n",
      "epoch 10 loss: 0.09645406156778336\n",
      "epoch 11 loss: 0.08227165788412094\n",
      "epoch 12 loss: 0.08658470213413239\n",
      "epoch 13 loss: 0.07836083322763443\n",
      "epoch 14 loss: 0.09263777732849121\n",
      "epoch 15 loss: 0.08497858047485352\n",
      "epoch 16 loss: 0.09937820583581924\n",
      "epoch 17 loss: 0.06524736434221268\n",
      "epoch 18 loss: 0.06182215362787247\n",
      "epoch 19 loss: 0.07587253302335739\n",
      "epoch 20 loss: 0.07376207411289215\n",
      "epoch 21 loss: 0.07267685979604721\n",
      "epoch 22 loss: 0.06924805790185928\n",
      "epoch 23 loss: 0.05713823065161705\n",
      "epoch 24 loss: 0.06212002411484718\n",
      "epoch 25 loss: 0.0865837037563324\n",
      "epoch 26 loss: 0.0603485144674778\n",
      "epoch 27 loss: 0.05074189603328705\n",
      "epoch 28 loss: 0.06564739346504211\n",
      "epoch 29 loss: 0.056149471551179886\n",
      "epoch 30 loss: 0.05343043804168701\n",
      "60\n",
      "epoch 1 loss: 0.7585675120353699\n",
      "epoch 2 loss: 0.5603671073913574\n",
      "epoch 3 loss: 0.27353015542030334\n",
      "epoch 4 loss: 0.14294081926345825\n",
      "epoch 5 loss: 0.12513571977615356\n",
      "epoch 6 loss: 0.06718623638153076\n",
      "epoch 7 loss: 0.09164410829544067\n",
      "epoch 8 loss: 0.07645495235919952\n",
      "epoch 9 loss: 0.09405755251646042\n",
      "epoch 10 loss: 0.05881272628903389\n",
      "epoch 11 loss: 0.07130715250968933\n",
      "epoch 12 loss: 0.06927944719791412\n",
      "epoch 13 loss: 0.09002330899238586\n",
      "epoch 14 loss: 0.0636177659034729\n",
      "epoch 15 loss: 0.06058482825756073\n",
      "epoch 16 loss: 0.07335531711578369\n",
      "epoch 17 loss: 0.07258573174476624\n",
      "epoch 18 loss: 0.07039880007505417\n",
      "epoch 19 loss: 0.07686182856559753\n",
      "epoch 20 loss: 0.0629785880446434\n",
      "epoch 21 loss: 0.06059519946575165\n",
      "epoch 22 loss: 0.06989523023366928\n",
      "epoch 23 loss: 0.06763086467981339\n",
      "epoch 24 loss: 0.06543054431676865\n",
      "epoch 25 loss: 0.07132730633020401\n",
      "epoch 26 loss: 0.05200442299246788\n",
      "epoch 27 loss: 0.06073529273271561\n",
      "epoch 28 loss: 0.06238432228565216\n",
      "epoch 29 loss: 0.051793958991765976\n",
      "epoch 30 loss: 0.06137611344456673\n",
      "61\n",
      "epoch 1 loss: 0.6811569929122925\n",
      "epoch 2 loss: 0.5344392657279968\n",
      "epoch 3 loss: 0.24258090555667877\n",
      "epoch 4 loss: 0.14614203572273254\n",
      "epoch 5 loss: 0.12834793329238892\n",
      "epoch 6 loss: 0.11297091841697693\n",
      "epoch 7 loss: 0.10889936238527298\n",
      "epoch 8 loss: 0.11431805044412613\n",
      "epoch 9 loss: 0.09159569442272186\n",
      "epoch 10 loss: 0.07072649151086807\n",
      "epoch 11 loss: 0.07629808038473129\n",
      "epoch 12 loss: 0.1103518083691597\n",
      "epoch 13 loss: 0.06593968719244003\n",
      "epoch 14 loss: 0.08280222862958908\n",
      "epoch 15 loss: 0.08243905752897263\n",
      "epoch 16 loss: 0.08008180558681488\n",
      "epoch 17 loss: 0.0760406032204628\n",
      "epoch 18 loss: 0.08169325441122055\n",
      "epoch 19 loss: 0.06712976843118668\n",
      "epoch 20 loss: 0.06346717476844788\n",
      "epoch 21 loss: 0.061554767191410065\n",
      "epoch 22 loss: 0.06515847146511078\n",
      "epoch 23 loss: 0.05777470022439957\n",
      "epoch 24 loss: 0.06337125599384308\n",
      "epoch 25 loss: 0.07109715044498444\n",
      "epoch 26 loss: 0.054338570684194565\n",
      "epoch 27 loss: 0.06477680057287216\n",
      "epoch 28 loss: 0.061213504523038864\n",
      "epoch 29 loss: 0.06352894008159637\n",
      "epoch 30 loss: 0.05583023279905319\n",
      "62\n",
      "epoch 1 loss: 0.6699751615524292\n",
      "epoch 2 loss: 0.7880367636680603\n",
      "epoch 3 loss: 0.37376531958580017\n",
      "epoch 4 loss: 0.18612141907215118\n",
      "epoch 5 loss: 0.1550132930278778\n",
      "epoch 6 loss: 0.10762146860361099\n",
      "epoch 7 loss: 0.11517177522182465\n",
      "epoch 8 loss: 0.08690445870161057\n",
      "epoch 9 loss: 0.1012786403298378\n",
      "epoch 10 loss: 0.08034560084342957\n",
      "epoch 11 loss: 0.09646306931972504\n",
      "epoch 12 loss: 0.07224591076374054\n",
      "epoch 13 loss: 0.06522060185670853\n",
      "epoch 14 loss: 0.07563362270593643\n",
      "epoch 15 loss: 0.06280732154846191\n",
      "epoch 16 loss: 0.07718018442392349\n",
      "epoch 17 loss: 0.06400568038225174\n",
      "epoch 18 loss: 0.0664101168513298\n",
      "epoch 19 loss: 0.0578470416367054\n",
      "epoch 20 loss: 0.07139594107866287\n",
      "epoch 21 loss: 0.06415506452322006\n",
      "epoch 22 loss: 0.06672336906194687\n",
      "epoch 23 loss: 0.0700707733631134\n",
      "epoch 24 loss: 0.06766793131828308\n",
      "epoch 25 loss: 0.06077627092599869\n",
      "epoch 26 loss: 0.053950872272253036\n",
      "epoch 27 loss: 0.04747578129172325\n",
      "epoch 28 loss: 0.0495571605861187\n",
      "epoch 29 loss: 0.07278916984796524\n",
      "epoch 30 loss: 0.05690331757068634\n",
      "63\n",
      "epoch 1 loss: 0.8044430613517761\n",
      "epoch 2 loss: 0.703299343585968\n",
      "epoch 3 loss: 0.41637054085731506\n",
      "epoch 4 loss: 0.27432021498680115\n",
      "epoch 5 loss: 0.10035090148448944\n",
      "epoch 6 loss: 0.12322785705327988\n",
      "epoch 7 loss: 0.11245550960302353\n",
      "epoch 8 loss: 0.11802992224693298\n",
      "epoch 9 loss: 0.075309619307518\n",
      "epoch 10 loss: 0.08316893130540848\n",
      "epoch 11 loss: 0.07000420242547989\n",
      "epoch 12 loss: 0.0847717672586441\n",
      "epoch 13 loss: 0.06499923765659332\n",
      "epoch 14 loss: 0.0738818347454071\n",
      "epoch 15 loss: 0.08180323243141174\n",
      "epoch 16 loss: 0.06538141518831253\n",
      "epoch 17 loss: 0.05779479816555977\n",
      "epoch 18 loss: 0.058598969131708145\n",
      "epoch 19 loss: 0.09115602821111679\n",
      "epoch 20 loss: 0.06498514860868454\n",
      "epoch 21 loss: 0.06044505909085274\n",
      "epoch 22 loss: 0.087334543466568\n",
      "epoch 23 loss: 0.06944581121206284\n",
      "epoch 24 loss: 0.06814170628786087\n",
      "epoch 25 loss: 0.07249319553375244\n",
      "epoch 26 loss: 0.05572301149368286\n",
      "epoch 27 loss: 0.05570559576153755\n",
      "epoch 28 loss: 0.056985024362802505\n",
      "epoch 29 loss: 0.07165931165218353\n",
      "epoch 30 loss: 0.055406782776117325\n",
      "64\n",
      "epoch 1 loss: 0.900037944316864\n",
      "epoch 2 loss: 0.841124951839447\n",
      "epoch 3 loss: 0.47465234994888306\n",
      "epoch 4 loss: 0.29512831568717957\n",
      "epoch 5 loss: 0.1648445725440979\n",
      "epoch 6 loss: 0.12566673755645752\n",
      "epoch 7 loss: 0.11203812807798386\n",
      "epoch 8 loss: 0.10963097959756851\n",
      "epoch 9 loss: 0.09203372150659561\n",
      "epoch 10 loss: 0.09102578461170197\n",
      "epoch 11 loss: 0.08708401769399643\n",
      "epoch 12 loss: 0.06341022253036499\n",
      "epoch 13 loss: 0.08711216598749161\n",
      "epoch 14 loss: 0.10174959152936935\n",
      "epoch 15 loss: 0.06553898751735687\n",
      "epoch 16 loss: 0.12228844314813614\n",
      "epoch 17 loss: 0.0777733102440834\n",
      "epoch 18 loss: 0.08997109532356262\n",
      "epoch 19 loss: 0.057121485471725464\n",
      "epoch 20 loss: 0.07771290838718414\n",
      "epoch 21 loss: 0.06630732864141464\n",
      "epoch 22 loss: 0.07131286710500717\n",
      "epoch 23 loss: 0.06006227806210518\n",
      "epoch 24 loss: 0.06482301652431488\n",
      "epoch 25 loss: 0.05912843719124794\n",
      "epoch 26 loss: 0.07472491264343262\n",
      "epoch 27 loss: 0.07395688444375992\n",
      "epoch 28 loss: 0.0700862780213356\n",
      "epoch 29 loss: 0.06703832745552063\n",
      "epoch 30 loss: 0.05995055288076401\n",
      "65\n",
      "epoch 1 loss: 0.7905824184417725\n",
      "epoch 2 loss: 0.5020278692245483\n",
      "epoch 3 loss: 0.2350296676158905\n",
      "epoch 4 loss: 0.16222287714481354\n",
      "epoch 5 loss: 0.16167780756950378\n",
      "epoch 6 loss: 0.10043082386255264\n",
      "epoch 7 loss: 0.08617312461137772\n",
      "epoch 8 loss: 0.10596352815628052\n",
      "epoch 9 loss: 0.10923545807600021\n",
      "epoch 10 loss: 0.08404052257537842\n",
      "epoch 11 loss: 0.07878664135932922\n",
      "epoch 12 loss: 0.06969331949949265\n",
      "epoch 13 loss: 0.066266268491745\n",
      "epoch 14 loss: 0.07847358286380768\n",
      "epoch 15 loss: 0.07202532887458801\n",
      "epoch 16 loss: 0.06624900549650192\n",
      "epoch 17 loss: 0.05597243458032608\n",
      "epoch 18 loss: 0.08431674540042877\n",
      "epoch 19 loss: 0.08413883298635483\n",
      "epoch 20 loss: 0.09526869654655457\n",
      "epoch 21 loss: 0.0620400533080101\n",
      "epoch 22 loss: 0.04832792654633522\n",
      "epoch 23 loss: 0.06213035434484482\n",
      "epoch 24 loss: 0.07599923759698868\n",
      "epoch 25 loss: 0.059002120047807693\n",
      "epoch 26 loss: 0.05569498613476753\n",
      "epoch 27 loss: 0.0649581253528595\n",
      "epoch 28 loss: 0.06212283670902252\n",
      "epoch 29 loss: 0.055709358304739\n",
      "epoch 30 loss: 0.07004515826702118\n",
      "66\n",
      "epoch 1 loss: 0.6765541434288025\n",
      "epoch 2 loss: 0.49454012513160706\n",
      "epoch 3 loss: 0.41459208726882935\n",
      "epoch 4 loss: 0.2016550451517105\n",
      "epoch 5 loss: 0.1730266660451889\n",
      "epoch 6 loss: 0.12227753549814224\n",
      "epoch 7 loss: 0.12484568357467651\n",
      "epoch 8 loss: 0.0891471654176712\n",
      "epoch 9 loss: 0.08551783114671707\n",
      "epoch 10 loss: 0.10031292587518692\n",
      "epoch 11 loss: 0.1212085634469986\n",
      "epoch 12 loss: 0.08478996157646179\n",
      "epoch 13 loss: 0.06733004748821259\n",
      "epoch 14 loss: 0.09427714347839355\n",
      "epoch 15 loss: 0.07371241599321365\n",
      "epoch 16 loss: 0.07157174497842789\n",
      "epoch 17 loss: 0.0779709666967392\n",
      "epoch 18 loss: 0.10662633925676346\n",
      "epoch 19 loss: 0.08782520145177841\n",
      "epoch 20 loss: 0.07895924150943756\n",
      "epoch 21 loss: 0.06440158933401108\n",
      "epoch 22 loss: 0.06772472709417343\n",
      "epoch 23 loss: 0.05870218575000763\n",
      "epoch 24 loss: 0.06415237486362457\n",
      "epoch 25 loss: 0.05822055786848068\n",
      "epoch 26 loss: 0.06953728944063187\n",
      "epoch 27 loss: 0.08052575588226318\n",
      "epoch 28 loss: 0.0561361089348793\n",
      "epoch 29 loss: 0.0737864151597023\n",
      "epoch 30 loss: 0.06434953957796097\n",
      "67\n",
      "epoch 1 loss: 0.6652757525444031\n",
      "epoch 2 loss: 0.40041401982307434\n",
      "epoch 3 loss: 0.25189661979675293\n",
      "epoch 4 loss: 0.11987824738025665\n",
      "epoch 5 loss: 0.12274007499217987\n",
      "epoch 6 loss: 0.10251445323228836\n",
      "epoch 7 loss: 0.09360802918672562\n",
      "epoch 8 loss: 0.09205908328294754\n",
      "epoch 9 loss: 0.0798797607421875\n",
      "epoch 10 loss: 0.0792320966720581\n",
      "epoch 11 loss: 0.06822491437196732\n",
      "epoch 12 loss: 0.0728190466761589\n",
      "epoch 13 loss: 0.08667699247598648\n",
      "epoch 14 loss: 0.06727701425552368\n",
      "epoch 15 loss: 0.06269221752882004\n",
      "epoch 16 loss: 0.06368613243103027\n",
      "epoch 17 loss: 0.07096827030181885\n",
      "epoch 18 loss: 0.06112408638000488\n",
      "epoch 19 loss: 0.07806319743394852\n",
      "epoch 20 loss: 0.10780347883701324\n",
      "epoch 21 loss: 0.0464341826736927\n",
      "epoch 22 loss: 0.05922896787524223\n",
      "epoch 23 loss: 0.058513425290584564\n",
      "epoch 24 loss: 0.0689677745103836\n",
      "epoch 25 loss: 0.06577993184328079\n",
      "epoch 26 loss: 0.059480056166648865\n",
      "epoch 27 loss: 0.0641583502292633\n",
      "epoch 28 loss: 0.06986018270254135\n",
      "epoch 29 loss: 0.06625448167324066\n",
      "epoch 30 loss: 0.055008240044116974\n",
      "68\n",
      "epoch 1 loss: 0.860089898109436\n",
      "epoch 2 loss: 0.6183095574378967\n",
      "epoch 3 loss: 0.2422567903995514\n",
      "epoch 4 loss: 0.1899803727865219\n",
      "epoch 5 loss: 0.15374435484409332\n",
      "epoch 6 loss: 0.10937289893627167\n",
      "epoch 7 loss: 0.09421738237142563\n",
      "epoch 8 loss: 0.08224327862262726\n",
      "epoch 9 loss: 0.0805688351392746\n",
      "epoch 10 loss: 0.07300189137458801\n",
      "epoch 11 loss: 0.06487518548965454\n",
      "epoch 12 loss: 0.06489166617393494\n",
      "epoch 13 loss: 0.07455240190029144\n",
      "epoch 14 loss: 0.07891865819692612\n",
      "epoch 15 loss: 0.07835186272859573\n",
      "epoch 16 loss: 0.07024174183607101\n",
      "epoch 17 loss: 0.06602878123521805\n",
      "epoch 18 loss: 0.08392013609409332\n",
      "epoch 19 loss: 0.05683997645974159\n",
      "epoch 20 loss: 0.0820002406835556\n",
      "epoch 21 loss: 0.06662546098232269\n",
      "epoch 22 loss: 0.07078016549348831\n",
      "epoch 23 loss: 0.06755167245864868\n",
      "epoch 24 loss: 0.062391068786382675\n",
      "epoch 25 loss: 0.04375611990690231\n",
      "epoch 26 loss: 0.05877441167831421\n",
      "epoch 27 loss: 0.06115744262933731\n",
      "epoch 28 loss: 0.06535199284553528\n",
      "epoch 29 loss: 0.0535653680562973\n",
      "epoch 30 loss: 0.046352311968803406\n",
      "69\n",
      "epoch 1 loss: 0.8999282121658325\n",
      "epoch 2 loss: 0.5202972292900085\n",
      "epoch 3 loss: 0.27315619587898254\n",
      "epoch 4 loss: 0.1843426376581192\n",
      "epoch 5 loss: 0.1310349404811859\n",
      "epoch 6 loss: 0.14266890287399292\n",
      "epoch 7 loss: 0.09725964814424515\n",
      "epoch 8 loss: 0.12090656161308289\n",
      "epoch 9 loss: 0.09793835133314133\n",
      "epoch 10 loss: 0.09339252859354019\n",
      "epoch 11 loss: 0.0817403569817543\n",
      "epoch 12 loss: 0.062468577176332474\n",
      "epoch 13 loss: 0.07704706490039825\n",
      "epoch 14 loss: 0.06815510988235474\n",
      "epoch 15 loss: 0.06696151942014694\n",
      "epoch 16 loss: 0.07290142774581909\n",
      "epoch 17 loss: 0.06521669030189514\n",
      "epoch 18 loss: 0.06961621344089508\n",
      "epoch 19 loss: 0.07357151061296463\n",
      "epoch 20 loss: 0.0648168995976448\n",
      "epoch 21 loss: 0.08725636452436447\n",
      "epoch 22 loss: 0.07381454855203629\n",
      "epoch 23 loss: 0.07462291419506073\n",
      "epoch 24 loss: 0.05980294570326805\n",
      "epoch 25 loss: 0.05287123844027519\n",
      "epoch 26 loss: 0.061087656766176224\n",
      "epoch 27 loss: 0.08055564761161804\n",
      "epoch 28 loss: 0.04950365424156189\n",
      "epoch 29 loss: 0.06434252858161926\n",
      "epoch 30 loss: 0.07071725279092789\n",
      "70\n",
      "epoch 1 loss: 0.7961811423301697\n",
      "epoch 2 loss: 0.583690881729126\n",
      "epoch 3 loss: 0.3147151470184326\n",
      "epoch 4 loss: 0.2134028971195221\n",
      "epoch 5 loss: 0.15834294259548187\n",
      "epoch 6 loss: 0.1398847997188568\n",
      "epoch 7 loss: 0.12432273477315903\n",
      "epoch 8 loss: 0.11732790619134903\n",
      "epoch 9 loss: 0.10220076888799667\n",
      "epoch 10 loss: 0.08727093040943146\n",
      "epoch 11 loss: 0.07936376333236694\n",
      "epoch 12 loss: 0.09534832835197449\n",
      "epoch 13 loss: 0.08839315176010132\n",
      "epoch 14 loss: 0.07988059520721436\n",
      "epoch 15 loss: 0.08877252787351608\n",
      "epoch 16 loss: 0.08212641626596451\n",
      "epoch 17 loss: 0.09396817535161972\n",
      "epoch 18 loss: 0.06346578896045685\n",
      "epoch 19 loss: 0.06900417059659958\n",
      "epoch 20 loss: 0.07038462162017822\n",
      "epoch 21 loss: 0.0671435073018074\n",
      "epoch 22 loss: 0.06626244634389877\n",
      "epoch 23 loss: 0.06708749383687973\n",
      "epoch 24 loss: 0.07826490700244904\n",
      "epoch 25 loss: 0.05959630757570267\n",
      "epoch 26 loss: 0.058479152619838715\n",
      "epoch 27 loss: 0.055297091603279114\n",
      "epoch 28 loss: 0.06695735454559326\n",
      "epoch 29 loss: 0.06931420415639877\n",
      "epoch 30 loss: 0.06100214272737503\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "5213cfe5-3065-40c2-8f0a-c36d9e0d7380",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier vector (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "57c81264-58cc-4abe-b8ae-3dcc4ecd8e02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T17:10:20.958159Z",
     "start_time": "2025-10-03T16:03:54.940273Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"vector\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w = pd.concat([results_aep_fourier_w, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w.to_csv(out_dir + '/results_aep_fourier_w.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:921: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {ep+1} loss: {float(loss):.4f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7756\n",
      "epoch 2 loss: 0.8179\n",
      "epoch 3 loss: 0.5464\n",
      "epoch 4 loss: 0.6245\n",
      "epoch 5 loss: 0.4803\n",
      "epoch 6 loss: 0.4608\n",
      "epoch 7 loss: 0.3190\n",
      "epoch 8 loss: 0.2122\n",
      "epoch 9 loss: 0.1944\n",
      "epoch 10 loss: 0.1791\n",
      "epoch 11 loss: 0.1082\n",
      "epoch 12 loss: 0.1191\n",
      "epoch 13 loss: 0.1384\n",
      "epoch 14 loss: 0.1034\n",
      "epoch 15 loss: 0.1078\n",
      "epoch 16 loss: 0.0844\n",
      "epoch 17 loss: 0.0896\n",
      "epoch 18 loss: 0.0931\n",
      "epoch 19 loss: 0.1043\n",
      "epoch 20 loss: 0.1207\n",
      "epoch 21 loss: 0.1167\n",
      "epoch 22 loss: 0.0946\n",
      "epoch 23 loss: 0.0688\n",
      "epoch 24 loss: 0.0654\n",
      "epoch 25 loss: 0.0778\n",
      "epoch 26 loss: 0.0949\n",
      "epoch 27 loss: 0.0735\n",
      "epoch 28 loss: 0.0803\n",
      "epoch 29 loss: 0.0945\n",
      "epoch 30 loss: 0.0833\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_70708/4267778447.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_fourier_w = pd.concat([results_aep_fourier_w, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6065\n",
      "epoch 2 loss: 0.5725\n",
      "epoch 3 loss: 0.3128\n",
      "epoch 4 loss: 0.3577\n",
      "epoch 5 loss: 0.2434\n",
      "epoch 6 loss: 0.1692\n",
      "epoch 7 loss: 0.1034\n",
      "epoch 8 loss: 0.1557\n",
      "epoch 9 loss: 0.0917\n",
      "epoch 10 loss: 0.1231\n",
      "epoch 11 loss: 0.1004\n",
      "epoch 12 loss: 0.1010\n",
      "epoch 13 loss: 0.0746\n",
      "epoch 14 loss: 0.0788\n",
      "epoch 15 loss: 0.0758\n",
      "epoch 16 loss: 0.0782\n",
      "epoch 17 loss: 0.0670\n",
      "epoch 18 loss: 0.0795\n",
      "epoch 19 loss: 0.0749\n",
      "epoch 20 loss: 0.0618\n",
      "epoch 21 loss: 0.0522\n",
      "epoch 22 loss: 0.0788\n",
      "epoch 23 loss: 0.0701\n",
      "epoch 24 loss: 0.0471\n",
      "epoch 25 loss: 0.0750\n",
      "epoch 26 loss: 0.0759\n",
      "epoch 27 loss: 0.0639\n",
      "epoch 28 loss: 0.0513\n",
      "epoch 29 loss: 0.0496\n",
      "epoch 30 loss: 0.1086\n",
      "3\n",
      "epoch 1 loss: 0.7695\n",
      "epoch 2 loss: 0.6359\n",
      "epoch 3 loss: 0.6801\n",
      "epoch 4 loss: 0.5313\n",
      "epoch 5 loss: 0.4580\n",
      "epoch 6 loss: 0.4784\n",
      "epoch 7 loss: 0.2628\n",
      "epoch 8 loss: 0.2028\n",
      "epoch 9 loss: 0.1803\n",
      "epoch 10 loss: 0.1816\n",
      "epoch 11 loss: 0.2023\n",
      "epoch 12 loss: 0.2003\n",
      "epoch 13 loss: 0.1987\n",
      "epoch 14 loss: 0.2012\n",
      "epoch 15 loss: 0.1991\n",
      "epoch 16 loss: 0.2043\n",
      "epoch 17 loss: 0.1685\n",
      "epoch 18 loss: 0.1519\n",
      "epoch 19 loss: 0.1116\n",
      "epoch 20 loss: 0.1087\n",
      "epoch 21 loss: 0.1392\n",
      "epoch 22 loss: 0.1057\n",
      "epoch 23 loss: 0.1136\n",
      "epoch 24 loss: 0.1313\n",
      "epoch 25 loss: 0.1550\n",
      "epoch 26 loss: 0.1169\n",
      "epoch 27 loss: 0.1440\n",
      "epoch 28 loss: 0.1253\n",
      "epoch 29 loss: 0.1055\n",
      "epoch 30 loss: 0.1265\n",
      "4\n",
      "epoch 1 loss: 1.0146\n",
      "epoch 2 loss: 0.5942\n",
      "epoch 3 loss: 0.5713\n",
      "epoch 4 loss: 0.2471\n",
      "epoch 5 loss: 0.1589\n",
      "epoch 6 loss: 0.1666\n",
      "epoch 7 loss: 0.1746\n",
      "epoch 8 loss: 0.1773\n",
      "epoch 9 loss: 0.1617\n",
      "epoch 10 loss: 0.1428\n",
      "epoch 11 loss: 0.1385\n",
      "epoch 12 loss: 0.1280\n",
      "epoch 13 loss: 0.1213\n",
      "epoch 14 loss: 0.1097\n",
      "epoch 15 loss: 0.1339\n",
      "epoch 16 loss: 0.1229\n",
      "epoch 17 loss: 0.0921\n",
      "epoch 18 loss: 0.0938\n",
      "epoch 19 loss: 0.0849\n",
      "epoch 20 loss: 0.0743\n",
      "epoch 21 loss: 0.0652\n",
      "epoch 22 loss: 0.0736\n",
      "epoch 23 loss: 0.0552\n",
      "epoch 24 loss: 0.0641\n",
      "epoch 25 loss: 0.0750\n",
      "epoch 26 loss: 0.0814\n",
      "epoch 27 loss: 0.1123\n",
      "epoch 28 loss: 0.0673\n",
      "epoch 29 loss: 0.0593\n",
      "epoch 30 loss: 0.0748\n",
      "5\n",
      "epoch 1 loss: 0.7959\n",
      "epoch 2 loss: 0.7430\n",
      "epoch 3 loss: 0.5262\n",
      "epoch 4 loss: 0.7712\n",
      "epoch 5 loss: 0.5692\n",
      "epoch 6 loss: 0.3897\n",
      "epoch 7 loss: 0.2148\n",
      "epoch 8 loss: 0.1334\n",
      "epoch 9 loss: 0.1500\n",
      "epoch 10 loss: 0.1279\n",
      "epoch 11 loss: 0.1169\n",
      "epoch 12 loss: 0.0894\n",
      "epoch 13 loss: 0.0783\n",
      "epoch 14 loss: 0.1134\n",
      "epoch 15 loss: 0.0776\n",
      "epoch 16 loss: 0.0797\n",
      "epoch 17 loss: 0.0848\n",
      "epoch 18 loss: 0.1040\n",
      "epoch 19 loss: 0.0672\n",
      "epoch 20 loss: 0.1039\n",
      "epoch 21 loss: 0.1019\n",
      "epoch 22 loss: 0.0960\n",
      "epoch 23 loss: 0.0754\n",
      "epoch 24 loss: 0.0592\n",
      "epoch 25 loss: 0.0946\n",
      "epoch 26 loss: 0.0710\n",
      "epoch 27 loss: 0.0708\n",
      "epoch 28 loss: 0.0736\n",
      "epoch 29 loss: 0.0802\n",
      "epoch 30 loss: 0.0701\n",
      "6\n",
      "epoch 1 loss: 0.7827\n",
      "epoch 2 loss: 0.6787\n",
      "epoch 3 loss: 0.6055\n",
      "epoch 4 loss: 0.4676\n",
      "epoch 5 loss: 0.2462\n",
      "epoch 6 loss: 0.1764\n",
      "epoch 7 loss: 0.1453\n",
      "epoch 8 loss: 0.1158\n",
      "epoch 9 loss: 0.0771\n",
      "epoch 10 loss: 0.1126\n",
      "epoch 11 loss: 0.1066\n",
      "epoch 12 loss: 0.1015\n",
      "epoch 13 loss: 0.0797\n",
      "epoch 14 loss: 0.1070\n",
      "epoch 15 loss: 0.0958\n",
      "epoch 16 loss: 0.0998\n",
      "epoch 17 loss: 0.0858\n",
      "epoch 18 loss: 0.0688\n",
      "epoch 19 loss: 0.0695\n",
      "epoch 20 loss: 0.0723\n",
      "epoch 21 loss: 0.0676\n",
      "epoch 22 loss: 0.0777\n",
      "epoch 23 loss: 0.0855\n",
      "epoch 24 loss: 0.0585\n",
      "epoch 25 loss: 0.0624\n",
      "epoch 26 loss: 0.0620\n",
      "epoch 27 loss: 0.0619\n",
      "epoch 28 loss: 0.0470\n",
      "epoch 29 loss: 0.0468\n",
      "epoch 30 loss: 0.0473\n",
      "7\n",
      "epoch 1 loss: 1.0659\n",
      "epoch 2 loss: 0.7357\n",
      "epoch 3 loss: 0.5692\n",
      "epoch 4 loss: 0.2850\n",
      "epoch 5 loss: 0.2649\n",
      "epoch 6 loss: 0.1822\n",
      "epoch 7 loss: 0.1414\n",
      "epoch 8 loss: 0.1329\n",
      "epoch 9 loss: 0.1295\n",
      "epoch 10 loss: 0.1317\n",
      "epoch 11 loss: 0.1254\n",
      "epoch 12 loss: 0.1163\n",
      "epoch 13 loss: 0.0922\n",
      "epoch 14 loss: 0.1008\n",
      "epoch 15 loss: 0.0742\n",
      "epoch 16 loss: 0.0767\n",
      "epoch 17 loss: 0.0608\n",
      "epoch 18 loss: 0.0893\n",
      "epoch 19 loss: 0.0796\n",
      "epoch 20 loss: 0.0644\n",
      "epoch 21 loss: 0.0824\n",
      "epoch 22 loss: 0.0560\n",
      "epoch 23 loss: 0.0896\n",
      "epoch 24 loss: 0.0737\n",
      "epoch 25 loss: 0.0539\n",
      "epoch 26 loss: 0.0669\n",
      "epoch 27 loss: 0.0722\n",
      "epoch 28 loss: 0.0750\n",
      "epoch 29 loss: 0.0544\n",
      "epoch 30 loss: 0.0818\n",
      "8\n",
      "epoch 1 loss: 0.7714\n",
      "epoch 2 loss: 0.5794\n",
      "epoch 3 loss: 0.7129\n",
      "epoch 4 loss: 0.4373\n",
      "epoch 5 loss: 0.2831\n",
      "epoch 6 loss: 0.1969\n",
      "epoch 7 loss: 0.1977\n",
      "epoch 8 loss: 0.1770\n",
      "epoch 9 loss: 0.1386\n",
      "epoch 10 loss: 0.1218\n",
      "epoch 11 loss: 0.1234\n",
      "epoch 12 loss: 0.1033\n",
      "epoch 13 loss: 0.1024\n",
      "epoch 14 loss: 0.1161\n",
      "epoch 15 loss: 0.1048\n",
      "epoch 16 loss: 0.0746\n",
      "epoch 17 loss: 0.0944\n",
      "epoch 18 loss: 0.0825\n",
      "epoch 19 loss: 0.1250\n",
      "epoch 20 loss: 0.0906\n",
      "epoch 21 loss: 0.0810\n",
      "epoch 22 loss: 0.0766\n",
      "epoch 23 loss: 0.0811\n",
      "epoch 24 loss: 0.0739\n",
      "epoch 25 loss: 0.0607\n",
      "epoch 26 loss: 0.0684\n",
      "epoch 27 loss: 0.0688\n",
      "epoch 28 loss: 0.0636\n",
      "epoch 29 loss: 0.0594\n",
      "epoch 30 loss: 0.0582\n",
      "9\n",
      "epoch 1 loss: 0.8487\n",
      "epoch 2 loss: 0.7915\n",
      "epoch 3 loss: 0.6198\n",
      "epoch 4 loss: 0.4176\n",
      "epoch 5 loss: 0.4860\n",
      "epoch 6 loss: 0.3124\n",
      "epoch 7 loss: 0.2604\n",
      "epoch 8 loss: 0.1293\n",
      "epoch 9 loss: 0.1492\n",
      "epoch 10 loss: 0.1322\n",
      "epoch 11 loss: 0.1316\n",
      "epoch 12 loss: 0.0915\n",
      "epoch 13 loss: 0.1297\n",
      "epoch 14 loss: 0.1230\n",
      "epoch 15 loss: 0.0832\n",
      "epoch 16 loss: 0.0894\n",
      "epoch 17 loss: 0.0721\n",
      "epoch 18 loss: 0.0855\n",
      "epoch 19 loss: 0.0821\n",
      "epoch 20 loss: 0.0700\n",
      "epoch 21 loss: 0.0623\n",
      "epoch 22 loss: 0.0801\n",
      "epoch 23 loss: 0.1032\n",
      "epoch 24 loss: 0.0701\n",
      "epoch 25 loss: 0.1002\n",
      "epoch 26 loss: 0.1024\n",
      "epoch 27 loss: 0.0782\n",
      "epoch 28 loss: 0.0637\n",
      "epoch 29 loss: 0.0860\n",
      "epoch 30 loss: 0.0721\n",
      "10\n",
      "epoch 1 loss: 0.7906\n",
      "epoch 2 loss: 0.6811\n",
      "epoch 3 loss: 0.4173\n",
      "epoch 4 loss: 0.2765\n",
      "epoch 5 loss: 0.1990\n",
      "epoch 6 loss: 0.1764\n",
      "epoch 7 loss: 0.1092\n",
      "epoch 8 loss: 0.1448\n",
      "epoch 9 loss: 0.1296\n",
      "epoch 10 loss: 0.1175\n",
      "epoch 11 loss: 0.0931\n",
      "epoch 12 loss: 0.0948\n",
      "epoch 13 loss: 0.1395\n",
      "epoch 14 loss: 0.0835\n",
      "epoch 15 loss: 0.0873\n",
      "epoch 16 loss: 0.0975\n",
      "epoch 17 loss: 0.0711\n",
      "epoch 18 loss: 0.1163\n",
      "epoch 19 loss: 0.0823\n",
      "epoch 20 loss: 0.0946\n",
      "epoch 21 loss: 0.1044\n",
      "epoch 22 loss: 0.0450\n",
      "epoch 23 loss: 0.0827\n",
      "epoch 24 loss: 0.0956\n",
      "epoch 25 loss: 0.0634\n",
      "epoch 26 loss: 0.0596\n",
      "epoch 27 loss: 0.0743\n",
      "epoch 28 loss: 0.0587\n",
      "epoch 29 loss: 0.0823\n",
      "epoch 30 loss: 0.0839\n",
      "11\n",
      "epoch 1 loss: 1.0341\n",
      "epoch 2 loss: 0.5931\n",
      "epoch 3 loss: 0.5784\n",
      "epoch 4 loss: 0.3057\n",
      "epoch 5 loss: 0.3033\n",
      "epoch 6 loss: 0.2213\n",
      "epoch 7 loss: 0.2157\n",
      "epoch 8 loss: 0.1533\n",
      "epoch 9 loss: 0.1252\n",
      "epoch 10 loss: 0.1057\n",
      "epoch 11 loss: 0.1266\n",
      "epoch 12 loss: 0.1254\n",
      "epoch 13 loss: 0.1241\n",
      "epoch 14 loss: 0.1963\n",
      "epoch 15 loss: 0.0891\n",
      "epoch 16 loss: 0.0901\n",
      "epoch 17 loss: 0.0811\n",
      "epoch 18 loss: 0.1020\n",
      "epoch 19 loss: 0.1074\n",
      "epoch 20 loss: 0.1090\n",
      "epoch 21 loss: 0.0625\n",
      "epoch 22 loss: 0.0905\n",
      "epoch 23 loss: 0.0841\n",
      "epoch 24 loss: 0.0845\n",
      "epoch 25 loss: 0.0596\n",
      "epoch 26 loss: 0.0655\n",
      "epoch 27 loss: 0.0712\n",
      "epoch 28 loss: 0.0780\n",
      "epoch 29 loss: 0.0690\n",
      "epoch 30 loss: 0.0662\n",
      "12\n",
      "epoch 1 loss: 0.9820\n",
      "epoch 2 loss: 0.6387\n",
      "epoch 3 loss: 0.4953\n",
      "epoch 4 loss: 0.4593\n",
      "epoch 5 loss: 0.3291\n",
      "epoch 6 loss: 0.2987\n",
      "epoch 7 loss: 0.2122\n",
      "epoch 8 loss: 0.1442\n",
      "epoch 9 loss: 0.1473\n",
      "epoch 10 loss: 0.1251\n",
      "epoch 11 loss: 0.1242\n",
      "epoch 12 loss: 0.1075\n",
      "epoch 13 loss: 0.1108\n",
      "epoch 14 loss: 0.1000\n",
      "epoch 15 loss: 0.1247\n",
      "epoch 16 loss: 0.1106\n",
      "epoch 17 loss: 0.1125\n",
      "epoch 18 loss: 0.0833\n",
      "epoch 19 loss: 0.1134\n",
      "epoch 20 loss: 0.1030\n",
      "epoch 21 loss: 0.0973\n",
      "epoch 22 loss: 0.0625\n",
      "epoch 23 loss: 0.0728\n",
      "epoch 24 loss: 0.0942\n",
      "epoch 25 loss: 0.0841\n",
      "epoch 26 loss: 0.0906\n",
      "epoch 27 loss: 0.1497\n",
      "epoch 28 loss: 0.0563\n",
      "epoch 29 loss: 0.0833\n",
      "epoch 30 loss: 0.0708\n",
      "13\n",
      "epoch 1 loss: 0.8792\n",
      "epoch 2 loss: 0.8179\n",
      "epoch 3 loss: 0.5679\n",
      "epoch 4 loss: 0.5589\n",
      "epoch 5 loss: 0.2861\n",
      "epoch 6 loss: 0.1615\n",
      "epoch 7 loss: 0.1235\n",
      "epoch 8 loss: 0.1644\n",
      "epoch 9 loss: 0.1040\n",
      "epoch 10 loss: 0.0886\n",
      "epoch 11 loss: 0.0739\n",
      "epoch 12 loss: 0.0775\n",
      "epoch 13 loss: 0.0913\n",
      "epoch 14 loss: 0.0654\n",
      "epoch 15 loss: 0.0753\n",
      "epoch 16 loss: 0.0665\n",
      "epoch 17 loss: 0.0698\n",
      "epoch 18 loss: 0.0941\n",
      "epoch 19 loss: 0.0773\n",
      "epoch 20 loss: 0.0636\n",
      "epoch 21 loss: 0.0668\n",
      "epoch 22 loss: 0.0634\n",
      "epoch 23 loss: 0.0580\n",
      "epoch 24 loss: 0.0661\n",
      "epoch 25 loss: 0.0468\n",
      "epoch 26 loss: 0.0658\n",
      "epoch 27 loss: 0.0581\n",
      "epoch 28 loss: 0.0431\n",
      "epoch 29 loss: 0.0536\n",
      "epoch 30 loss: 0.0609\n",
      "14\n",
      "epoch 1 loss: 1.0263\n",
      "epoch 2 loss: 0.5009\n",
      "epoch 3 loss: 0.5241\n",
      "epoch 4 loss: 0.3141\n",
      "epoch 5 loss: 0.3717\n",
      "epoch 6 loss: 0.1698\n",
      "epoch 7 loss: 0.1244\n",
      "epoch 8 loss: 0.1270\n",
      "epoch 9 loss: 0.1289\n",
      "epoch 10 loss: 0.1256\n",
      "epoch 11 loss: 0.0944\n",
      "epoch 12 loss: 0.1072\n",
      "epoch 13 loss: 0.1384\n",
      "epoch 14 loss: 0.1166\n",
      "epoch 15 loss: 0.0979\n",
      "epoch 16 loss: 0.0967\n",
      "epoch 17 loss: 0.0861\n",
      "epoch 18 loss: 0.0976\n",
      "epoch 19 loss: 0.0821\n",
      "epoch 20 loss: 0.0650\n",
      "epoch 21 loss: 0.0927\n",
      "epoch 22 loss: 0.1416\n",
      "epoch 23 loss: 0.0913\n",
      "epoch 24 loss: 0.0859\n",
      "epoch 25 loss: 0.0700\n",
      "epoch 26 loss: 0.0927\n",
      "epoch 27 loss: 0.0777\n",
      "epoch 28 loss: 0.0714\n",
      "epoch 29 loss: 0.0697\n",
      "epoch 30 loss: 0.0644\n",
      "15\n",
      "epoch 1 loss: 0.6032\n",
      "epoch 2 loss: 0.8858\n",
      "epoch 3 loss: 0.7807\n",
      "epoch 4 loss: 1.0796\n",
      "epoch 5 loss: 0.9399\n",
      "epoch 6 loss: 0.4618\n",
      "epoch 7 loss: 0.2738\n",
      "epoch 8 loss: 0.1834\n",
      "epoch 9 loss: 0.1585\n",
      "epoch 10 loss: 0.1268\n",
      "epoch 11 loss: 0.1226\n",
      "epoch 12 loss: 0.1064\n",
      "epoch 13 loss: 0.0913\n",
      "epoch 14 loss: 0.1304\n",
      "epoch 15 loss: 0.1198\n",
      "epoch 16 loss: 0.0779\n",
      "epoch 17 loss: 0.0966\n",
      "epoch 18 loss: 0.0684\n",
      "epoch 19 loss: 0.0513\n",
      "epoch 20 loss: 0.0584\n",
      "epoch 21 loss: 0.0698\n",
      "epoch 22 loss: 0.0638\n",
      "epoch 23 loss: 0.0740\n",
      "epoch 24 loss: 0.0667\n",
      "epoch 25 loss: 0.0824\n",
      "epoch 26 loss: 0.0674\n",
      "epoch 27 loss: 0.0769\n",
      "epoch 28 loss: 0.0838\n",
      "epoch 29 loss: 0.0457\n",
      "epoch 30 loss: 0.0599\n",
      "16\n",
      "epoch 1 loss: 0.8680\n",
      "epoch 2 loss: 0.5360\n",
      "epoch 3 loss: 0.4525\n",
      "epoch 4 loss: 0.5070\n",
      "epoch 5 loss: 0.3149\n",
      "epoch 6 loss: 0.2394\n",
      "epoch 7 loss: 0.1591\n",
      "epoch 8 loss: 0.1712\n",
      "epoch 9 loss: 0.1399\n",
      "epoch 10 loss: 0.1065\n",
      "epoch 11 loss: 0.1243\n",
      "epoch 12 loss: 0.1370\n",
      "epoch 13 loss: 0.0942\n",
      "epoch 14 loss: 0.2030\n",
      "epoch 15 loss: 0.1428\n",
      "epoch 16 loss: 0.1054\n",
      "epoch 17 loss: 0.0961\n",
      "epoch 18 loss: 0.0837\n",
      "epoch 19 loss: 0.1137\n",
      "epoch 20 loss: 0.0859\n",
      "epoch 21 loss: 0.0741\n",
      "epoch 22 loss: 0.0711\n",
      "epoch 23 loss: 0.0611\n",
      "epoch 24 loss: 0.0750\n",
      "epoch 25 loss: 0.0831\n",
      "epoch 26 loss: 0.0621\n",
      "epoch 27 loss: 0.1023\n",
      "epoch 28 loss: 0.0632\n",
      "epoch 29 loss: 0.0699\n",
      "epoch 30 loss: 0.0669\n",
      "17\n",
      "epoch 1 loss: 0.8568\n",
      "epoch 2 loss: 0.7296\n",
      "epoch 3 loss: 0.8058\n",
      "epoch 4 loss: 0.5115\n",
      "epoch 5 loss: 0.6564\n",
      "epoch 6 loss: 0.5433\n",
      "epoch 7 loss: 0.3162\n",
      "epoch 8 loss: 0.1386\n",
      "epoch 9 loss: 0.1291\n",
      "epoch 10 loss: 0.1194\n",
      "epoch 11 loss: 0.1052\n",
      "epoch 12 loss: 0.1743\n",
      "epoch 13 loss: 0.0859\n",
      "epoch 14 loss: 0.0745\n",
      "epoch 15 loss: 0.0995\n",
      "epoch 16 loss: 0.1551\n",
      "epoch 17 loss: 0.0699\n",
      "epoch 18 loss: 0.0652\n",
      "epoch 19 loss: 0.1024\n",
      "epoch 20 loss: 0.0699\n",
      "epoch 21 loss: 0.0772\n",
      "epoch 22 loss: 0.0765\n",
      "epoch 23 loss: 0.0834\n",
      "epoch 24 loss: 0.0586\n",
      "epoch 25 loss: 0.0717\n",
      "epoch 26 loss: 0.0691\n",
      "epoch 27 loss: 0.0663\n",
      "epoch 28 loss: 0.0559\n",
      "epoch 29 loss: 0.0880\n",
      "epoch 30 loss: 0.0620\n",
      "18\n",
      "epoch 1 loss: 0.7942\n",
      "epoch 2 loss: 0.7493\n",
      "epoch 3 loss: 0.7415\n",
      "epoch 4 loss: 0.3767\n",
      "epoch 5 loss: 0.3545\n",
      "epoch 6 loss: 0.2385\n",
      "epoch 7 loss: 0.2087\n",
      "epoch 8 loss: 0.1669\n",
      "epoch 9 loss: 0.1682\n",
      "epoch 10 loss: 0.1171\n",
      "epoch 11 loss: 0.1263\n",
      "epoch 12 loss: 0.1406\n",
      "epoch 13 loss: 0.1544\n",
      "epoch 14 loss: 0.1244\n",
      "epoch 15 loss: 0.1368\n",
      "epoch 16 loss: 0.1145\n",
      "epoch 17 loss: 0.1596\n",
      "epoch 18 loss: 0.0794\n",
      "epoch 19 loss: 0.1145\n",
      "epoch 20 loss: 0.1393\n",
      "epoch 21 loss: 0.1092\n",
      "epoch 22 loss: 0.1825\n",
      "epoch 23 loss: 0.1021\n",
      "epoch 24 loss: 0.0749\n",
      "epoch 25 loss: 0.0719\n",
      "epoch 26 loss: 0.1081\n",
      "epoch 27 loss: 0.0862\n",
      "epoch 28 loss: 0.0922\n",
      "epoch 29 loss: 0.0888\n",
      "epoch 30 loss: 0.0775\n",
      "19\n",
      "epoch 1 loss: 0.7311\n",
      "epoch 2 loss: 0.6253\n",
      "epoch 3 loss: 0.4809\n",
      "epoch 4 loss: 0.2717\n",
      "epoch 5 loss: 0.1501\n",
      "epoch 6 loss: 0.1697\n",
      "epoch 7 loss: 0.1347\n",
      "epoch 8 loss: 0.1037\n",
      "epoch 9 loss: 0.1147\n",
      "epoch 10 loss: 0.1238\n",
      "epoch 11 loss: 0.1217\n",
      "epoch 12 loss: 0.0731\n",
      "epoch 13 loss: 0.0752\n",
      "epoch 14 loss: 0.0632\n",
      "epoch 15 loss: 0.0738\n",
      "epoch 16 loss: 0.0934\n",
      "epoch 17 loss: 0.0903\n",
      "epoch 18 loss: 0.0656\n",
      "epoch 19 loss: 0.1069\n",
      "epoch 20 loss: 0.0946\n",
      "epoch 21 loss: 0.0855\n",
      "epoch 22 loss: 0.0701\n",
      "epoch 23 loss: 0.0669\n",
      "epoch 24 loss: 0.0721\n",
      "epoch 25 loss: 0.0546\n",
      "epoch 26 loss: 0.0535\n",
      "epoch 27 loss: 0.0761\n",
      "epoch 28 loss: 0.0692\n",
      "epoch 29 loss: 0.0532\n",
      "epoch 30 loss: 0.0739\n",
      "20\n",
      "epoch 1 loss: 1.3015\n",
      "epoch 2 loss: 0.8096\n",
      "epoch 3 loss: 0.9799\n",
      "epoch 4 loss: 0.4506\n",
      "epoch 5 loss: 0.1905\n",
      "epoch 6 loss: 0.1572\n",
      "epoch 7 loss: 0.1567\n",
      "epoch 8 loss: 0.1361\n",
      "epoch 9 loss: 0.1650\n",
      "epoch 10 loss: 0.1467\n",
      "epoch 11 loss: 0.1307\n",
      "epoch 12 loss: 0.1187\n",
      "epoch 13 loss: 0.0876\n",
      "epoch 14 loss: 0.1081\n",
      "epoch 15 loss: 0.0959\n",
      "epoch 16 loss: 0.1038\n",
      "epoch 17 loss: 0.0806\n",
      "epoch 18 loss: 0.1124\n",
      "epoch 19 loss: 0.0687\n",
      "epoch 20 loss: 0.0859\n",
      "epoch 21 loss: 0.1227\n",
      "epoch 22 loss: 0.0699\n",
      "epoch 23 loss: 0.0866\n",
      "epoch 24 loss: 0.0795\n",
      "epoch 25 loss: 0.0613\n",
      "epoch 26 loss: 0.0526\n",
      "epoch 27 loss: 0.0748\n",
      "epoch 28 loss: 0.0646\n",
      "epoch 29 loss: 0.0729\n",
      "epoch 30 loss: 0.0771\n",
      "21\n",
      "epoch 1 loss: 0.6601\n",
      "epoch 2 loss: 0.7468\n",
      "epoch 3 loss: 0.6587\n",
      "epoch 4 loss: 0.4775\n",
      "epoch 5 loss: 0.3835\n",
      "epoch 6 loss: 0.2235\n",
      "epoch 7 loss: 0.1523\n",
      "epoch 8 loss: 0.1727\n",
      "epoch 9 loss: 0.1552\n",
      "epoch 10 loss: 0.1455\n",
      "epoch 11 loss: 0.1146\n",
      "epoch 12 loss: 0.1203\n",
      "epoch 13 loss: 0.1279\n",
      "epoch 14 loss: 0.1043\n",
      "epoch 15 loss: 0.1241\n",
      "epoch 16 loss: 0.1145\n",
      "epoch 17 loss: 0.1053\n",
      "epoch 18 loss: 0.0865\n",
      "epoch 19 loss: 0.0730\n",
      "epoch 20 loss: 0.0812\n",
      "epoch 21 loss: 0.0692\n",
      "epoch 22 loss: 0.0885\n",
      "epoch 23 loss: 0.0875\n",
      "epoch 24 loss: 0.0774\n",
      "epoch 25 loss: 0.0704\n",
      "epoch 26 loss: 0.0728\n",
      "epoch 27 loss: 0.0531\n",
      "epoch 28 loss: 0.0876\n",
      "epoch 29 loss: 0.0769\n",
      "epoch 30 loss: 0.0770\n",
      "22\n",
      "epoch 1 loss: 0.7042\n",
      "epoch 2 loss: 0.6336\n",
      "epoch 3 loss: 0.4672\n",
      "epoch 4 loss: 0.4719\n",
      "epoch 5 loss: 0.2688\n",
      "epoch 6 loss: 0.1668\n",
      "epoch 7 loss: 0.1761\n",
      "epoch 8 loss: 0.1142\n",
      "epoch 9 loss: 0.1244\n",
      "epoch 10 loss: 0.1012\n",
      "epoch 11 loss: 0.1282\n",
      "epoch 12 loss: 0.1176\n",
      "epoch 13 loss: 0.0756\n",
      "epoch 14 loss: 0.1199\n",
      "epoch 15 loss: 0.1248\n",
      "epoch 16 loss: 0.0683\n",
      "epoch 17 loss: 0.0858\n",
      "epoch 18 loss: 0.0971\n",
      "epoch 19 loss: 0.0689\n",
      "epoch 20 loss: 0.0731\n",
      "epoch 21 loss: 0.0567\n",
      "epoch 22 loss: 0.0749\n",
      "epoch 23 loss: 0.0774\n",
      "epoch 24 loss: 0.0887\n",
      "epoch 25 loss: 0.0816\n",
      "epoch 26 loss: 0.1146\n",
      "epoch 27 loss: 0.0639\n",
      "epoch 28 loss: 0.0713\n",
      "epoch 29 loss: 0.0986\n",
      "epoch 30 loss: 0.0850\n",
      "23\n",
      "epoch 1 loss: 1.0616\n",
      "epoch 2 loss: 0.7065\n",
      "epoch 3 loss: 0.4006\n",
      "epoch 4 loss: 0.5202\n",
      "epoch 5 loss: 0.2933\n",
      "epoch 6 loss: 0.3617\n",
      "epoch 7 loss: 0.2110\n",
      "epoch 8 loss: 0.1722\n",
      "epoch 9 loss: 0.1269\n",
      "epoch 10 loss: 0.1175\n",
      "epoch 11 loss: 0.0885\n",
      "epoch 12 loss: 0.1112\n",
      "epoch 13 loss: 0.1417\n",
      "epoch 14 loss: 0.1027\n",
      "epoch 15 loss: 0.1097\n",
      "epoch 16 loss: 0.0876\n",
      "epoch 17 loss: 0.0947\n",
      "epoch 18 loss: 0.0755\n",
      "epoch 19 loss: 0.1121\n",
      "epoch 20 loss: 0.0821\n",
      "epoch 21 loss: 0.0714\n",
      "epoch 22 loss: 0.0873\n",
      "epoch 23 loss: 0.1184\n",
      "epoch 24 loss: 0.0802\n",
      "epoch 25 loss: 0.0749\n",
      "epoch 26 loss: 0.0785\n",
      "epoch 27 loss: 0.0658\n",
      "epoch 28 loss: 0.0871\n",
      "epoch 29 loss: 0.0705\n",
      "epoch 30 loss: 0.0868\n",
      "24\n",
      "epoch 1 loss: 0.8812\n",
      "epoch 2 loss: 0.5315\n",
      "epoch 3 loss: 0.5317\n",
      "epoch 4 loss: 0.3040\n",
      "epoch 5 loss: 0.2207\n",
      "epoch 6 loss: 0.1117\n",
      "epoch 7 loss: 0.1492\n",
      "epoch 8 loss: 0.1247\n",
      "epoch 9 loss: 0.0859\n",
      "epoch 10 loss: 0.1295\n",
      "epoch 11 loss: 0.1211\n",
      "epoch 12 loss: 0.1076\n",
      "epoch 13 loss: 0.0914\n",
      "epoch 14 loss: 0.0978\n",
      "epoch 15 loss: 0.1051\n",
      "epoch 16 loss: 0.0643\n",
      "epoch 17 loss: 0.0767\n",
      "epoch 18 loss: 0.0694\n",
      "epoch 19 loss: 0.0865\n",
      "epoch 20 loss: 0.0755\n",
      "epoch 21 loss: 0.1362\n",
      "epoch 22 loss: 0.0916\n",
      "epoch 23 loss: 0.0615\n",
      "epoch 24 loss: 0.0569\n",
      "epoch 25 loss: 0.0750\n",
      "epoch 26 loss: 0.0677\n",
      "epoch 27 loss: 0.0878\n",
      "epoch 28 loss: 0.0725\n",
      "epoch 29 loss: 0.0781\n",
      "epoch 30 loss: 0.0606\n",
      "25\n",
      "epoch 1 loss: 0.7751\n",
      "epoch 2 loss: 0.5829\n",
      "epoch 3 loss: 0.5131\n",
      "epoch 4 loss: 0.5137\n",
      "epoch 5 loss: 0.8060\n",
      "epoch 6 loss: 0.4994\n",
      "epoch 7 loss: 0.4693\n",
      "epoch 8 loss: 0.5480\n",
      "epoch 9 loss: 0.4725\n",
      "epoch 10 loss: 0.4149\n",
      "epoch 11 loss: 0.2378\n",
      "epoch 12 loss: 0.1537\n",
      "epoch 13 loss: 0.1270\n",
      "epoch 14 loss: 0.1292\n",
      "epoch 15 loss: 0.1145\n",
      "epoch 16 loss: 0.0959\n",
      "epoch 17 loss: 0.1184\n",
      "epoch 18 loss: 0.1202\n",
      "epoch 19 loss: 0.0825\n",
      "epoch 20 loss: 0.0875\n",
      "epoch 21 loss: 0.0949\n",
      "epoch 22 loss: 0.0676\n",
      "epoch 23 loss: 0.0711\n",
      "epoch 24 loss: 0.0777\n",
      "epoch 25 loss: 0.0507\n",
      "epoch 26 loss: 0.0726\n",
      "epoch 27 loss: 0.0783\n",
      "epoch 28 loss: 0.0762\n",
      "epoch 29 loss: 0.0683\n",
      "epoch 30 loss: 0.0635\n",
      "26\n",
      "epoch 1 loss: 0.5955\n",
      "epoch 2 loss: 0.6290\n",
      "epoch 3 loss: 0.4185\n",
      "epoch 4 loss: 0.4262\n",
      "epoch 5 loss: 0.3268\n",
      "epoch 6 loss: 0.2119\n",
      "epoch 7 loss: 0.1291\n",
      "epoch 8 loss: 0.1066\n",
      "epoch 9 loss: 0.1111\n",
      "epoch 10 loss: 0.1100\n",
      "epoch 11 loss: 0.1016\n",
      "epoch 12 loss: 0.1123\n",
      "epoch 13 loss: 0.0863\n",
      "epoch 14 loss: 0.1176\n",
      "epoch 15 loss: 0.0950\n",
      "epoch 16 loss: 0.1103\n",
      "epoch 17 loss: 0.0739\n",
      "epoch 18 loss: 0.0708\n",
      "epoch 19 loss: 0.0725\n",
      "epoch 20 loss: 0.0795\n",
      "epoch 21 loss: 0.0694\n",
      "epoch 22 loss: 0.0709\n",
      "epoch 23 loss: 0.0910\n",
      "epoch 24 loss: 0.0708\n",
      "epoch 25 loss: 0.0934\n",
      "epoch 26 loss: 0.0904\n",
      "epoch 27 loss: 0.0732\n",
      "epoch 28 loss: 0.0601\n",
      "epoch 29 loss: 0.1104\n",
      "epoch 30 loss: 0.0703\n",
      "27\n",
      "epoch 1 loss: 0.8517\n",
      "epoch 2 loss: 0.7828\n",
      "epoch 3 loss: 0.6470\n",
      "epoch 4 loss: 0.6443\n",
      "epoch 5 loss: 0.4678\n",
      "epoch 6 loss: 0.4448\n",
      "epoch 7 loss: 0.2602\n",
      "epoch 8 loss: 0.1673\n",
      "epoch 9 loss: 0.1621\n",
      "epoch 10 loss: 0.1275\n",
      "epoch 11 loss: 0.1266\n",
      "epoch 12 loss: 0.1232\n",
      "epoch 13 loss: 0.0883\n",
      "epoch 14 loss: 0.1100\n",
      "epoch 15 loss: 0.1143\n",
      "epoch 16 loss: 0.0833\n",
      "epoch 17 loss: 0.0850\n",
      "epoch 18 loss: 0.0734\n",
      "epoch 19 loss: 0.0726\n",
      "epoch 20 loss: 0.0800\n",
      "epoch 21 loss: 0.0671\n",
      "epoch 22 loss: 0.0826\n",
      "epoch 23 loss: 0.0562\n",
      "epoch 24 loss: 0.0639\n",
      "epoch 25 loss: 0.0880\n",
      "epoch 26 loss: 0.0678\n",
      "epoch 27 loss: 0.0698\n",
      "epoch 28 loss: 0.0647\n",
      "epoch 29 loss: 0.0430\n",
      "epoch 30 loss: 0.0759\n",
      "28\n",
      "epoch 1 loss: 0.8088\n",
      "epoch 2 loss: 0.7188\n",
      "epoch 3 loss: 0.4397\n",
      "epoch 4 loss: 0.6262\n",
      "epoch 5 loss: 0.3118\n",
      "epoch 6 loss: 0.2319\n",
      "epoch 7 loss: 0.1466\n",
      "epoch 8 loss: 0.1141\n",
      "epoch 9 loss: 0.0916\n",
      "epoch 10 loss: 0.1006\n",
      "epoch 11 loss: 0.1033\n",
      "epoch 12 loss: 0.0704\n",
      "epoch 13 loss: 0.0757\n",
      "epoch 14 loss: 0.0704\n",
      "epoch 15 loss: 0.0947\n",
      "epoch 16 loss: 0.0709\n",
      "epoch 17 loss: 0.1208\n",
      "epoch 18 loss: 0.0692\n",
      "epoch 19 loss: 0.0620\n",
      "epoch 20 loss: 0.0699\n",
      "epoch 21 loss: 0.0930\n",
      "epoch 22 loss: 0.0695\n",
      "epoch 23 loss: 0.0594\n",
      "epoch 24 loss: 0.0825\n",
      "epoch 25 loss: 0.0719\n",
      "epoch 26 loss: 0.0634\n",
      "epoch 27 loss: 0.0754\n",
      "epoch 28 loss: 0.0731\n",
      "epoch 29 loss: 0.0601\n",
      "epoch 30 loss: 0.0643\n",
      "29\n",
      "epoch 1 loss: 0.9816\n",
      "epoch 2 loss: 0.7066\n",
      "epoch 3 loss: 0.7278\n",
      "epoch 4 loss: 0.4371\n",
      "epoch 5 loss: 0.3231\n",
      "epoch 6 loss: 0.2386\n",
      "epoch 7 loss: 0.1801\n",
      "epoch 8 loss: 0.1931\n",
      "epoch 9 loss: 0.1272\n",
      "epoch 10 loss: 0.1388\n",
      "epoch 11 loss: 0.1188\n",
      "epoch 12 loss: 0.1258\n",
      "epoch 13 loss: 0.1239\n",
      "epoch 14 loss: 0.1088\n",
      "epoch 15 loss: 0.1256\n",
      "epoch 16 loss: 0.1529\n",
      "epoch 17 loss: 0.1283\n",
      "epoch 18 loss: 0.1315\n",
      "epoch 19 loss: 0.1312\n",
      "epoch 20 loss: 0.1031\n",
      "epoch 21 loss: 0.1435\n",
      "epoch 22 loss: 0.0921\n",
      "epoch 23 loss: 0.1110\n",
      "epoch 24 loss: 0.0769\n",
      "epoch 25 loss: 0.0909\n",
      "epoch 26 loss: 0.0984\n",
      "epoch 27 loss: 0.1034\n",
      "epoch 28 loss: 0.0734\n",
      "epoch 29 loss: 0.0703\n",
      "epoch 30 loss: 0.0924\n",
      "30\n",
      "epoch 1 loss: 0.7850\n",
      "epoch 2 loss: 0.4210\n",
      "epoch 3 loss: 0.5575\n",
      "epoch 4 loss: 0.2879\n",
      "epoch 5 loss: 0.2067\n",
      "epoch 6 loss: 0.1571\n",
      "epoch 7 loss: 0.1638\n",
      "epoch 8 loss: 0.1221\n",
      "epoch 9 loss: 0.1166\n",
      "epoch 10 loss: 0.1268\n",
      "epoch 11 loss: 0.1205\n",
      "epoch 12 loss: 0.0950\n",
      "epoch 13 loss: 0.0990\n",
      "epoch 14 loss: 0.0987\n",
      "epoch 15 loss: 0.0896\n",
      "epoch 16 loss: 0.0864\n",
      "epoch 17 loss: 0.1096\n",
      "epoch 18 loss: 0.0702\n",
      "epoch 19 loss: 0.0913\n",
      "epoch 20 loss: 0.0926\n",
      "epoch 21 loss: 0.1050\n",
      "epoch 22 loss: 0.0808\n",
      "epoch 23 loss: 0.0600\n",
      "epoch 24 loss: 0.0620\n",
      "epoch 25 loss: 0.0621\n",
      "epoch 26 loss: 0.0642\n",
      "epoch 27 loss: 0.0606\n",
      "epoch 28 loss: 0.0800\n",
      "epoch 29 loss: 0.0968\n",
      "epoch 30 loss: 0.0754\n",
      "31\n",
      "epoch 1 loss: 1.1508\n",
      "epoch 2 loss: 0.8578\n",
      "epoch 3 loss: 0.4974\n",
      "epoch 4 loss: 0.2495\n",
      "epoch 5 loss: 0.2095\n",
      "epoch 6 loss: 0.2073\n",
      "epoch 7 loss: 0.1898\n",
      "epoch 8 loss: 0.1441\n",
      "epoch 9 loss: 0.1129\n",
      "epoch 10 loss: 0.1416\n",
      "epoch 11 loss: 0.1411\n",
      "epoch 12 loss: 0.1269\n",
      "epoch 13 loss: 0.1311\n",
      "epoch 14 loss: 0.1159\n",
      "epoch 15 loss: 0.1134\n",
      "epoch 16 loss: 0.1144\n",
      "epoch 17 loss: 0.1015\n",
      "epoch 18 loss: 0.0903\n",
      "epoch 19 loss: 0.0808\n",
      "epoch 20 loss: 0.0849\n",
      "epoch 21 loss: 0.0693\n",
      "epoch 22 loss: 0.0573\n",
      "epoch 23 loss: 0.0760\n",
      "epoch 24 loss: 0.0796\n",
      "epoch 25 loss: 0.0699\n",
      "epoch 26 loss: 0.0828\n",
      "epoch 27 loss: 0.0840\n",
      "epoch 28 loss: 0.0425\n",
      "epoch 29 loss: 0.0817\n",
      "epoch 30 loss: 0.0909\n",
      "32\n",
      "epoch 1 loss: 0.6665\n",
      "epoch 2 loss: 0.6913\n",
      "epoch 3 loss: 0.4121\n",
      "epoch 4 loss: 0.2627\n",
      "epoch 5 loss: 0.2163\n",
      "epoch 6 loss: 0.2187\n",
      "epoch 7 loss: 0.1647\n",
      "epoch 8 loss: 0.1525\n",
      "epoch 9 loss: 0.1471\n",
      "epoch 10 loss: 0.1013\n",
      "epoch 11 loss: 0.1064\n",
      "epoch 12 loss: 0.0965\n",
      "epoch 13 loss: 0.0841\n",
      "epoch 14 loss: 0.0845\n",
      "epoch 15 loss: 0.1054\n",
      "epoch 16 loss: 0.0855\n",
      "epoch 17 loss: 0.0704\n",
      "epoch 18 loss: 0.0979\n",
      "epoch 19 loss: 0.0751\n",
      "epoch 20 loss: 0.1283\n",
      "epoch 21 loss: 0.0468\n",
      "epoch 22 loss: 0.0694\n",
      "epoch 23 loss: 0.0715\n",
      "epoch 24 loss: 0.0636\n",
      "epoch 25 loss: 0.0585\n",
      "epoch 26 loss: 0.0624\n",
      "epoch 27 loss: 0.0603\n",
      "epoch 28 loss: 0.0460\n",
      "epoch 29 loss: 0.0527\n",
      "epoch 30 loss: 0.0642\n",
      "33\n",
      "epoch 1 loss: 1.0907\n",
      "epoch 2 loss: 0.7277\n",
      "epoch 3 loss: 0.7562\n",
      "epoch 4 loss: 0.3964\n",
      "epoch 5 loss: 0.2624\n",
      "epoch 6 loss: 0.1987\n",
      "epoch 7 loss: 0.1671\n",
      "epoch 8 loss: 0.1696\n",
      "epoch 9 loss: 0.1436\n",
      "epoch 10 loss: 0.1521\n",
      "epoch 11 loss: 0.1480\n",
      "epoch 12 loss: 0.1376\n",
      "epoch 13 loss: 0.1120\n",
      "epoch 14 loss: 0.1255\n",
      "epoch 15 loss: 0.1263\n",
      "epoch 16 loss: 0.1169\n",
      "epoch 17 loss: 0.0833\n",
      "epoch 18 loss: 0.1271\n",
      "epoch 19 loss: 0.1458\n",
      "epoch 20 loss: 0.1543\n",
      "epoch 21 loss: 0.0845\n",
      "epoch 22 loss: 0.0974\n",
      "epoch 23 loss: 0.0664\n",
      "epoch 24 loss: 0.0687\n",
      "epoch 25 loss: 0.0713\n",
      "epoch 26 loss: 0.0858\n",
      "epoch 27 loss: 0.0894\n",
      "epoch 28 loss: 0.0711\n",
      "epoch 29 loss: 0.0918\n",
      "epoch 30 loss: 0.0852\n",
      "34\n",
      "epoch 1 loss: 1.2432\n",
      "epoch 2 loss: 0.6594\n",
      "epoch 3 loss: 0.4345\n",
      "epoch 4 loss: 0.3821\n",
      "epoch 5 loss: 0.2173\n",
      "epoch 6 loss: 0.1557\n",
      "epoch 7 loss: 0.1249\n",
      "epoch 8 loss: 0.1162\n",
      "epoch 9 loss: 0.1235\n",
      "epoch 10 loss: 0.0836\n",
      "epoch 11 loss: 0.0794\n",
      "epoch 12 loss: 0.0922\n",
      "epoch 13 loss: 0.1028\n",
      "epoch 14 loss: 0.0736\n",
      "epoch 15 loss: 0.0699\n",
      "epoch 16 loss: 0.0862\n",
      "epoch 17 loss: 0.1016\n",
      "epoch 18 loss: 0.0825\n",
      "epoch 19 loss: 0.0757\n",
      "epoch 20 loss: 0.0681\n",
      "epoch 21 loss: 0.0728\n",
      "epoch 22 loss: 0.0518\n",
      "epoch 23 loss: 0.0675\n",
      "epoch 24 loss: 0.0742\n",
      "epoch 25 loss: 0.0660\n",
      "epoch 26 loss: 0.0631\n",
      "epoch 27 loss: 0.0614\n",
      "epoch 28 loss: 0.0548\n",
      "epoch 29 loss: 0.0495\n",
      "epoch 30 loss: 0.0635\n",
      "35\n",
      "epoch 1 loss: 0.8288\n",
      "epoch 2 loss: 0.6145\n",
      "epoch 3 loss: 0.6099\n",
      "epoch 4 loss: 0.3756\n",
      "epoch 5 loss: 0.4388\n",
      "epoch 6 loss: 0.2287\n",
      "epoch 7 loss: 0.2155\n",
      "epoch 8 loss: 0.1973\n",
      "epoch 9 loss: 0.2121\n",
      "epoch 10 loss: 0.1418\n",
      "epoch 11 loss: 0.1510\n",
      "epoch 12 loss: 0.1510\n",
      "epoch 13 loss: 0.1234\n",
      "epoch 14 loss: 0.1310\n",
      "epoch 15 loss: 0.1228\n",
      "epoch 16 loss: 0.1178\n",
      "epoch 17 loss: 0.1273\n",
      "epoch 18 loss: 0.1184\n",
      "epoch 19 loss: 0.1177\n",
      "epoch 20 loss: 0.1079\n",
      "epoch 21 loss: 0.1070\n",
      "epoch 22 loss: 0.1118\n",
      "epoch 23 loss: 0.0980\n",
      "epoch 24 loss: 0.0794\n",
      "epoch 25 loss: 0.1124\n",
      "epoch 26 loss: 0.0978\n",
      "epoch 27 loss: 0.0711\n",
      "epoch 28 loss: 0.0813\n",
      "epoch 29 loss: 0.0735\n",
      "epoch 30 loss: 0.0920\n",
      "36\n",
      "epoch 1 loss: 0.9829\n",
      "epoch 2 loss: 0.7596\n",
      "epoch 3 loss: 0.7719\n",
      "epoch 4 loss: 0.5625\n",
      "epoch 5 loss: 0.3925\n",
      "epoch 6 loss: 0.2648\n",
      "epoch 7 loss: 0.1817\n",
      "epoch 8 loss: 0.1401\n",
      "epoch 9 loss: 0.1539\n",
      "epoch 10 loss: 0.1336\n",
      "epoch 11 loss: 0.1076\n",
      "epoch 12 loss: 0.1270\n",
      "epoch 13 loss: 0.1256\n",
      "epoch 14 loss: 0.1618\n",
      "epoch 15 loss: 0.0881\n",
      "epoch 16 loss: 0.0797\n",
      "epoch 17 loss: 0.1280\n",
      "epoch 18 loss: 0.1185\n",
      "epoch 19 loss: 0.0999\n",
      "epoch 20 loss: 0.0783\n",
      "epoch 21 loss: 0.0703\n",
      "epoch 22 loss: 0.0966\n",
      "epoch 23 loss: 0.0790\n",
      "epoch 24 loss: 0.0759\n",
      "epoch 25 loss: 0.1284\n",
      "epoch 26 loss: 0.0761\n",
      "epoch 27 loss: 0.1123\n",
      "epoch 28 loss: 0.0914\n",
      "epoch 29 loss: 0.1090\n",
      "epoch 30 loss: 0.1138\n",
      "37\n",
      "epoch 1 loss: 0.8789\n",
      "epoch 2 loss: 0.4795\n",
      "epoch 3 loss: 0.9251\n",
      "epoch 4 loss: 0.3958\n",
      "epoch 5 loss: 0.2338\n",
      "epoch 6 loss: 0.1431\n",
      "epoch 7 loss: 0.1431\n",
      "epoch 8 loss: 0.1061\n",
      "epoch 9 loss: 0.1380\n",
      "epoch 10 loss: 0.0992\n",
      "epoch 11 loss: 0.0882\n",
      "epoch 12 loss: 0.0885\n",
      "epoch 13 loss: 0.0853\n",
      "epoch 14 loss: 0.0839\n",
      "epoch 15 loss: 0.0902\n",
      "epoch 16 loss: 0.0744\n",
      "epoch 17 loss: 0.0652\n",
      "epoch 18 loss: 0.0626\n",
      "epoch 19 loss: 0.0751\n",
      "epoch 20 loss: 0.0659\n",
      "epoch 21 loss: 0.0728\n",
      "epoch 22 loss: 0.0775\n",
      "epoch 23 loss: 0.0880\n",
      "epoch 24 loss: 0.0752\n",
      "epoch 25 loss: 0.0692\n",
      "epoch 26 loss: 0.0786\n",
      "epoch 27 loss: 0.0704\n",
      "epoch 28 loss: 0.0662\n",
      "epoch 29 loss: 0.0696\n",
      "epoch 30 loss: 0.0756\n",
      "38\n",
      "epoch 1 loss: 1.3158\n",
      "epoch 2 loss: 0.6781\n",
      "epoch 3 loss: 0.5944\n",
      "epoch 4 loss: 0.7819\n",
      "epoch 5 loss: 0.3135\n",
      "epoch 6 loss: 0.2250\n",
      "epoch 7 loss: 0.1691\n",
      "epoch 8 loss: 0.1500\n",
      "epoch 9 loss: 0.1441\n",
      "epoch 10 loss: 0.1442\n",
      "epoch 11 loss: 0.1482\n",
      "epoch 12 loss: 0.1909\n",
      "epoch 13 loss: 0.1570\n",
      "epoch 14 loss: 0.1370\n",
      "epoch 15 loss: 0.1010\n",
      "epoch 16 loss: 0.0975\n",
      "epoch 17 loss: 0.1048\n",
      "epoch 18 loss: 0.1336\n",
      "epoch 19 loss: 0.0755\n",
      "epoch 20 loss: 0.1098\n",
      "epoch 21 loss: 0.0845\n",
      "epoch 22 loss: 0.0757\n",
      "epoch 23 loss: 0.0727\n",
      "epoch 24 loss: 0.1652\n",
      "epoch 25 loss: 0.0886\n",
      "epoch 26 loss: 0.0989\n",
      "epoch 27 loss: 0.0748\n",
      "epoch 28 loss: 0.0852\n",
      "epoch 29 loss: 0.0672\n",
      "epoch 30 loss: 0.0654\n",
      "39\n",
      "epoch 1 loss: 0.7983\n",
      "epoch 2 loss: 0.6087\n",
      "epoch 3 loss: 0.4737\n",
      "epoch 4 loss: 0.3084\n",
      "epoch 5 loss: 0.2646\n",
      "epoch 6 loss: 0.1329\n",
      "epoch 7 loss: 0.1479\n",
      "epoch 8 loss: 0.1692\n",
      "epoch 9 loss: 0.1380\n",
      "epoch 10 loss: 0.0851\n",
      "epoch 11 loss: 0.0904\n",
      "epoch 12 loss: 0.1028\n",
      "epoch 13 loss: 0.1063\n",
      "epoch 14 loss: 0.1093\n",
      "epoch 15 loss: 0.0737\n",
      "epoch 16 loss: 0.0861\n",
      "epoch 17 loss: 0.0946\n",
      "epoch 18 loss: 0.0647\n",
      "epoch 19 loss: 0.0734\n",
      "epoch 20 loss: 0.0690\n",
      "epoch 21 loss: 0.0588\n",
      "epoch 22 loss: 0.0636\n",
      "epoch 23 loss: 0.0562\n",
      "epoch 24 loss: 0.0656\n",
      "epoch 25 loss: 0.0618\n",
      "epoch 26 loss: 0.0772\n",
      "epoch 27 loss: 0.0780\n",
      "epoch 28 loss: 0.0642\n",
      "epoch 29 loss: 0.0863\n",
      "epoch 30 loss: 0.0651\n",
      "40\n",
      "epoch 1 loss: 1.1669\n",
      "epoch 2 loss: 0.6005\n",
      "epoch 3 loss: 0.4436\n",
      "epoch 4 loss: 0.6628\n",
      "epoch 5 loss: 0.3421\n",
      "epoch 6 loss: 0.2509\n",
      "epoch 7 loss: 0.1877\n",
      "epoch 8 loss: 0.1558\n",
      "epoch 9 loss: 0.1263\n",
      "epoch 10 loss: 0.1347\n",
      "epoch 11 loss: 0.1147\n",
      "epoch 12 loss: 0.1056\n",
      "epoch 13 loss: 0.1214\n",
      "epoch 14 loss: 0.1139\n",
      "epoch 15 loss: 0.0922\n",
      "epoch 16 loss: 0.0873\n",
      "epoch 17 loss: 0.0859\n",
      "epoch 18 loss: 0.0973\n",
      "epoch 19 loss: 0.0814\n",
      "epoch 20 loss: 0.0631\n",
      "epoch 21 loss: 0.0909\n",
      "epoch 22 loss: 0.0908\n",
      "epoch 23 loss: 0.0655\n",
      "epoch 24 loss: 0.0646\n",
      "epoch 25 loss: 0.0648\n",
      "epoch 26 loss: 0.0801\n",
      "epoch 27 loss: 0.0579\n",
      "epoch 28 loss: 0.0638\n",
      "epoch 29 loss: 0.0512\n",
      "epoch 30 loss: 0.0580\n",
      "41\n",
      "epoch 1 loss: 0.7875\n",
      "epoch 2 loss: 0.4229\n",
      "epoch 3 loss: 0.5121\n",
      "epoch 4 loss: 0.3199\n",
      "epoch 5 loss: 0.1919\n",
      "epoch 6 loss: 0.1692\n",
      "epoch 7 loss: 0.1098\n",
      "epoch 8 loss: 0.1316\n",
      "epoch 9 loss: 0.1378\n",
      "epoch 10 loss: 0.1063\n",
      "epoch 11 loss: 0.1368\n",
      "epoch 12 loss: 0.1449\n",
      "epoch 13 loss: 0.1165\n",
      "epoch 14 loss: 0.0815\n",
      "epoch 15 loss: 0.1071\n",
      "epoch 16 loss: 0.0776\n",
      "epoch 17 loss: 0.0760\n",
      "epoch 18 loss: 0.0637\n",
      "epoch 19 loss: 0.0824\n",
      "epoch 20 loss: 0.0740\n",
      "epoch 21 loss: 0.0824\n",
      "epoch 22 loss: 0.0515\n",
      "epoch 23 loss: 0.0714\n",
      "epoch 24 loss: 0.0711\n",
      "epoch 25 loss: 0.0618\n",
      "epoch 26 loss: 0.0864\n",
      "epoch 27 loss: 0.0571\n",
      "epoch 28 loss: 0.0777\n",
      "epoch 29 loss: 0.0727\n",
      "epoch 30 loss: 0.0814\n",
      "42\n",
      "epoch 1 loss: 0.6893\n",
      "epoch 2 loss: 0.6222\n",
      "epoch 3 loss: 0.6343\n",
      "epoch 4 loss: 0.4533\n",
      "epoch 5 loss: 0.2653\n",
      "epoch 6 loss: 0.1494\n",
      "epoch 7 loss: 0.1370\n",
      "epoch 8 loss: 0.1103\n",
      "epoch 9 loss: 0.0983\n",
      "epoch 10 loss: 0.0874\n",
      "epoch 11 loss: 0.1030\n",
      "epoch 12 loss: 0.1476\n",
      "epoch 13 loss: 0.0697\n",
      "epoch 14 loss: 0.0588\n",
      "epoch 15 loss: 0.0632\n",
      "epoch 16 loss: 0.0641\n",
      "epoch 17 loss: 0.0800\n",
      "epoch 18 loss: 0.0593\n",
      "epoch 19 loss: 0.0707\n",
      "epoch 20 loss: 0.0654\n",
      "epoch 21 loss: 0.0542\n",
      "epoch 22 loss: 0.0703\n",
      "epoch 23 loss: 0.0583\n",
      "epoch 24 loss: 0.0747\n",
      "epoch 25 loss: 0.0638\n",
      "epoch 26 loss: 0.0751\n",
      "epoch 27 loss: 0.0594\n",
      "epoch 28 loss: 0.0627\n",
      "epoch 29 loss: 0.0577\n",
      "epoch 30 loss: 0.0710\n",
      "43\n",
      "epoch 1 loss: 1.2879\n",
      "epoch 2 loss: 0.6708\n",
      "epoch 3 loss: 1.0887\n",
      "epoch 4 loss: 0.5666\n",
      "epoch 5 loss: 0.3662\n",
      "epoch 6 loss: 0.2049\n",
      "epoch 7 loss: 0.1565\n",
      "epoch 8 loss: 0.1582\n",
      "epoch 9 loss: 0.1305\n",
      "epoch 10 loss: 0.1113\n",
      "epoch 11 loss: 0.1207\n",
      "epoch 12 loss: 0.1385\n",
      "epoch 13 loss: 0.1109\n",
      "epoch 14 loss: 0.1180\n",
      "epoch 15 loss: 0.1182\n",
      "epoch 16 loss: 0.0963\n",
      "epoch 17 loss: 0.1641\n",
      "epoch 18 loss: 0.0668\n",
      "epoch 19 loss: 0.0561\n",
      "epoch 20 loss: 0.0858\n",
      "epoch 21 loss: 0.0666\n",
      "epoch 22 loss: 0.0649\n",
      "epoch 23 loss: 0.0726\n",
      "epoch 24 loss: 0.1334\n",
      "epoch 25 loss: 0.0737\n",
      "epoch 26 loss: 0.0932\n",
      "epoch 27 loss: 0.0651\n",
      "epoch 28 loss: 0.1046\n",
      "epoch 29 loss: 0.0608\n",
      "epoch 30 loss: 0.0670\n",
      "44\n",
      "epoch 1 loss: 0.6639\n",
      "epoch 2 loss: 0.6694\n",
      "epoch 3 loss: 0.5316\n",
      "epoch 4 loss: 0.3605\n",
      "epoch 5 loss: 0.1686\n",
      "epoch 6 loss: 0.1377\n",
      "epoch 7 loss: 0.1223\n",
      "epoch 8 loss: 0.0920\n",
      "epoch 9 loss: 0.1366\n",
      "epoch 10 loss: 0.1083\n",
      "epoch 11 loss: 0.1028\n",
      "epoch 12 loss: 0.0725\n",
      "epoch 13 loss: 0.1073\n",
      "epoch 14 loss: 0.0628\n",
      "epoch 15 loss: 0.0713\n",
      "epoch 16 loss: 0.0712\n",
      "epoch 17 loss: 0.0606\n",
      "epoch 18 loss: 0.0645\n",
      "epoch 19 loss: 0.0730\n",
      "epoch 20 loss: 0.0821\n",
      "epoch 21 loss: 0.0836\n",
      "epoch 22 loss: 0.0710\n",
      "epoch 23 loss: 0.0633\n",
      "epoch 24 loss: 0.0647\n",
      "epoch 25 loss: 0.0500\n",
      "epoch 26 loss: 0.0600\n",
      "epoch 27 loss: 0.0589\n",
      "epoch 28 loss: 0.0519\n",
      "epoch 29 loss: 0.0730\n",
      "epoch 30 loss: 0.0589\n",
      "45\n",
      "epoch 1 loss: 0.9800\n",
      "epoch 2 loss: 0.6608\n",
      "epoch 3 loss: 0.4838\n",
      "epoch 4 loss: 0.2600\n",
      "epoch 5 loss: 0.2292\n",
      "epoch 6 loss: 0.1657\n",
      "epoch 7 loss: 0.1130\n",
      "epoch 8 loss: 0.1489\n",
      "epoch 9 loss: 0.1304\n",
      "epoch 10 loss: 0.1285\n",
      "epoch 11 loss: 0.0957\n",
      "epoch 12 loss: 0.1147\n",
      "epoch 13 loss: 0.0871\n",
      "epoch 14 loss: 0.0826\n",
      "epoch 15 loss: 0.0845\n",
      "epoch 16 loss: 0.0969\n",
      "epoch 17 loss: 0.0975\n",
      "epoch 18 loss: 0.1117\n",
      "epoch 19 loss: 0.0784\n",
      "epoch 20 loss: 0.0641\n",
      "epoch 21 loss: 0.1060\n",
      "epoch 22 loss: 0.0753\n",
      "epoch 23 loss: 0.1029\n",
      "epoch 24 loss: 0.0664\n",
      "epoch 25 loss: 0.0504\n",
      "epoch 26 loss: 0.0803\n",
      "epoch 27 loss: 0.0644\n",
      "epoch 28 loss: 0.0788\n",
      "epoch 29 loss: 0.0765\n",
      "epoch 30 loss: 0.0672\n",
      "46\n",
      "epoch 1 loss: 0.6860\n",
      "epoch 2 loss: 0.6988\n",
      "epoch 3 loss: 0.4345\n",
      "epoch 4 loss: 0.2109\n",
      "epoch 5 loss: 0.1710\n",
      "epoch 6 loss: 0.1464\n",
      "epoch 7 loss: 0.1462\n",
      "epoch 8 loss: 0.1544\n",
      "epoch 9 loss: 0.1823\n",
      "epoch 10 loss: 0.1475\n",
      "epoch 11 loss: 0.1283\n",
      "epoch 12 loss: 0.1269\n",
      "epoch 13 loss: 0.1134\n",
      "epoch 14 loss: 0.1218\n",
      "epoch 15 loss: 0.0705\n",
      "epoch 16 loss: 0.0900\n",
      "epoch 17 loss: 0.1056\n",
      "epoch 18 loss: 0.0828\n",
      "epoch 19 loss: 0.0730\n",
      "epoch 20 loss: 0.0833\n",
      "epoch 21 loss: 0.0733\n",
      "epoch 22 loss: 0.0925\n",
      "epoch 23 loss: 0.0586\n",
      "epoch 24 loss: 0.0510\n",
      "epoch 25 loss: 0.0725\n",
      "epoch 26 loss: 0.0675\n",
      "epoch 27 loss: 0.0554\n",
      "epoch 28 loss: 0.0525\n",
      "epoch 29 loss: 0.0550\n",
      "epoch 30 loss: 0.0743\n",
      "47\n",
      "epoch 1 loss: 0.5834\n",
      "epoch 2 loss: 0.6020\n",
      "epoch 3 loss: 0.4770\n",
      "epoch 4 loss: 0.2159\n",
      "epoch 5 loss: 0.1893\n",
      "epoch 6 loss: 0.1358\n",
      "epoch 7 loss: 0.1418\n",
      "epoch 8 loss: 0.1230\n",
      "epoch 9 loss: 0.1167\n",
      "epoch 10 loss: 0.1316\n",
      "epoch 11 loss: 0.0942\n",
      "epoch 12 loss: 0.0769\n",
      "epoch 13 loss: 0.0782\n",
      "epoch 14 loss: 0.1091\n",
      "epoch 15 loss: 0.0862\n",
      "epoch 16 loss: 0.0871\n",
      "epoch 17 loss: 0.0998\n",
      "epoch 18 loss: 0.1037\n",
      "epoch 19 loss: 0.1132\n",
      "epoch 20 loss: 0.0794\n",
      "epoch 21 loss: 0.0864\n",
      "epoch 22 loss: 0.0626\n",
      "epoch 23 loss: 0.0848\n",
      "epoch 24 loss: 0.0675\n",
      "epoch 25 loss: 0.0738\n",
      "epoch 26 loss: 0.0602\n",
      "epoch 27 loss: 0.0771\n",
      "epoch 28 loss: 0.0656\n",
      "epoch 29 loss: 0.0624\n",
      "epoch 30 loss: 0.0613\n",
      "48\n",
      "epoch 1 loss: 0.8572\n",
      "epoch 2 loss: 0.7397\n",
      "epoch 3 loss: 0.2601\n",
      "epoch 4 loss: 0.1588\n",
      "epoch 5 loss: 0.1841\n",
      "epoch 6 loss: 0.1795\n",
      "epoch 7 loss: 0.1329\n",
      "epoch 8 loss: 0.1585\n",
      "epoch 9 loss: 0.1211\n",
      "epoch 10 loss: 0.0994\n",
      "epoch 11 loss: 0.1140\n",
      "epoch 12 loss: 0.0732\n",
      "epoch 13 loss: 0.0689\n",
      "epoch 14 loss: 0.0759\n",
      "epoch 15 loss: 0.0827\n",
      "epoch 16 loss: 0.0654\n",
      "epoch 17 loss: 0.0664\n",
      "epoch 18 loss: 0.0888\n",
      "epoch 19 loss: 0.0736\n",
      "epoch 20 loss: 0.0735\n",
      "epoch 21 loss: 0.0825\n",
      "epoch 22 loss: 0.0761\n",
      "epoch 23 loss: 0.0642\n",
      "epoch 24 loss: 0.0530\n",
      "epoch 25 loss: 0.0798\n",
      "epoch 26 loss: 0.0653\n",
      "epoch 27 loss: 0.0520\n",
      "epoch 28 loss: 0.0657\n",
      "epoch 29 loss: 0.0583\n",
      "epoch 30 loss: 0.0536\n",
      "49\n",
      "epoch 1 loss: 0.7074\n",
      "epoch 2 loss: 0.5535\n",
      "epoch 3 loss: 0.8843\n",
      "epoch 4 loss: 0.4954\n",
      "epoch 5 loss: 0.6290\n",
      "epoch 6 loss: 0.6222\n",
      "epoch 7 loss: 0.4913\n",
      "epoch 8 loss: 0.2415\n",
      "epoch 9 loss: 0.1457\n",
      "epoch 10 loss: 0.1134\n",
      "epoch 11 loss: 0.1206\n",
      "epoch 12 loss: 0.1152\n",
      "epoch 13 loss: 0.0725\n",
      "epoch 14 loss: 0.0958\n",
      "epoch 15 loss: 0.0861\n",
      "epoch 16 loss: 0.0831\n",
      "epoch 17 loss: 0.0871\n",
      "epoch 18 loss: 0.0708\n",
      "epoch 19 loss: 0.0632\n",
      "epoch 20 loss: 0.0761\n",
      "epoch 21 loss: 0.0742\n",
      "epoch 22 loss: 0.0762\n",
      "epoch 23 loss: 0.0970\n",
      "epoch 24 loss: 0.0737\n",
      "epoch 25 loss: 0.0735\n",
      "epoch 26 loss: 0.0575\n",
      "epoch 27 loss: 0.0660\n",
      "epoch 28 loss: 0.0572\n",
      "epoch 29 loss: 0.0584\n",
      "epoch 30 loss: 0.0562\n",
      "50\n",
      "epoch 1 loss: 1.0905\n",
      "epoch 2 loss: 0.7259\n",
      "epoch 3 loss: 0.4759\n",
      "epoch 4 loss: 0.2739\n",
      "epoch 5 loss: 0.1893\n",
      "epoch 6 loss: 0.1537\n",
      "epoch 7 loss: 0.1685\n",
      "epoch 8 loss: 0.1225\n",
      "epoch 9 loss: 0.1317\n",
      "epoch 10 loss: 0.1111\n",
      "epoch 11 loss: 0.1003\n",
      "epoch 12 loss: 0.1404\n",
      "epoch 13 loss: 0.0986\n",
      "epoch 14 loss: 0.0939\n",
      "epoch 15 loss: 0.0745\n",
      "epoch 16 loss: 0.0882\n",
      "epoch 17 loss: 0.0752\n",
      "epoch 18 loss: 0.0762\n",
      "epoch 19 loss: 0.0731\n",
      "epoch 20 loss: 0.0776\n",
      "epoch 21 loss: 0.0858\n",
      "epoch 22 loss: 0.0824\n",
      "epoch 23 loss: 0.0698\n",
      "epoch 24 loss: 0.0871\n",
      "epoch 25 loss: 0.0819\n",
      "epoch 26 loss: 0.0811\n",
      "epoch 27 loss: 0.0758\n",
      "epoch 28 loss: 0.0582\n",
      "epoch 29 loss: 0.0663\n",
      "epoch 30 loss: 0.0664\n",
      "51\n",
      "epoch 1 loss: 0.8477\n",
      "epoch 2 loss: 0.6238\n",
      "epoch 3 loss: 0.4813\n",
      "epoch 4 loss: 0.3096\n",
      "epoch 5 loss: 0.1593\n",
      "epoch 6 loss: 0.1426\n",
      "epoch 7 loss: 0.1232\n",
      "epoch 8 loss: 0.1223\n",
      "epoch 9 loss: 0.1236\n",
      "epoch 10 loss: 0.1170\n",
      "epoch 11 loss: 0.1163\n",
      "epoch 12 loss: 0.1268\n",
      "epoch 13 loss: 0.0989\n",
      "epoch 14 loss: 0.1111\n",
      "epoch 15 loss: 0.0761\n",
      "epoch 16 loss: 0.0790\n",
      "epoch 17 loss: 0.0747\n",
      "epoch 18 loss: 0.0621\n",
      "epoch 19 loss: 0.0569\n",
      "epoch 20 loss: 0.1000\n",
      "epoch 21 loss: 0.0618\n",
      "epoch 22 loss: 0.0619\n",
      "epoch 23 loss: 0.0561\n",
      "epoch 24 loss: 0.0889\n",
      "epoch 25 loss: 0.0564\n",
      "epoch 26 loss: 0.0767\n",
      "epoch 27 loss: 0.0562\n",
      "epoch 28 loss: 0.0504\n",
      "epoch 29 loss: 0.0638\n",
      "epoch 30 loss: 0.0552\n",
      "52\n",
      "epoch 1 loss: 0.7923\n",
      "epoch 2 loss: 0.6399\n",
      "epoch 3 loss: 0.5481\n",
      "epoch 4 loss: 0.4214\n",
      "epoch 5 loss: 0.2544\n",
      "epoch 6 loss: 0.2854\n",
      "epoch 7 loss: 0.1741\n",
      "epoch 8 loss: 0.1559\n",
      "epoch 9 loss: 0.1603\n",
      "epoch 10 loss: 0.1368\n",
      "epoch 11 loss: 0.1218\n",
      "epoch 12 loss: 0.1414\n",
      "epoch 13 loss: 0.1149\n",
      "epoch 14 loss: 0.1377\n",
      "epoch 15 loss: 0.1013\n",
      "epoch 16 loss: 0.0902\n",
      "epoch 17 loss: 0.0948\n",
      "epoch 18 loss: 0.1207\n",
      "epoch 19 loss: 0.0924\n",
      "epoch 20 loss: 0.0864\n",
      "epoch 21 loss: 0.0703\n",
      "epoch 22 loss: 0.0719\n",
      "epoch 23 loss: 0.0804\n",
      "epoch 24 loss: 0.0776\n",
      "epoch 25 loss: 0.0686\n",
      "epoch 26 loss: 0.0587\n",
      "epoch 27 loss: 0.1018\n",
      "epoch 28 loss: 0.0778\n",
      "epoch 29 loss: 0.0792\n",
      "epoch 30 loss: 0.0558\n",
      "53\n",
      "epoch 1 loss: 0.8682\n",
      "epoch 2 loss: 0.5555\n",
      "epoch 3 loss: 0.4897\n",
      "epoch 4 loss: 0.3152\n",
      "epoch 5 loss: 0.2145\n",
      "epoch 6 loss: 0.1432\n",
      "epoch 7 loss: 0.1087\n",
      "epoch 8 loss: 0.1139\n",
      "epoch 9 loss: 0.1442\n",
      "epoch 10 loss: 0.0815\n",
      "epoch 11 loss: 0.0960\n",
      "epoch 12 loss: 0.0874\n",
      "epoch 13 loss: 0.0812\n",
      "epoch 14 loss: 0.0809\n",
      "epoch 15 loss: 0.0790\n",
      "epoch 16 loss: 0.0558\n",
      "epoch 17 loss: 0.0871\n",
      "epoch 18 loss: 0.0713\n",
      "epoch 19 loss: 0.0717\n",
      "epoch 20 loss: 0.0733\n",
      "epoch 21 loss: 0.1506\n",
      "epoch 22 loss: 0.0725\n",
      "epoch 23 loss: 0.0711\n",
      "epoch 24 loss: 0.0635\n",
      "epoch 25 loss: 0.0732\n",
      "epoch 26 loss: 0.0619\n",
      "epoch 27 loss: 0.0696\n",
      "epoch 28 loss: 0.0665\n",
      "epoch 29 loss: 0.0657\n",
      "epoch 30 loss: 0.1208\n",
      "54\n",
      "epoch 1 loss: 0.8684\n",
      "epoch 2 loss: 0.8794\n",
      "epoch 3 loss: 0.6904\n",
      "epoch 4 loss: 0.6928\n",
      "epoch 5 loss: 1.5267\n",
      "epoch 6 loss: 0.6530\n",
      "epoch 7 loss: 0.4772\n",
      "epoch 8 loss: 0.8625\n",
      "epoch 9 loss: 0.6322\n",
      "epoch 10 loss: 0.3566\n",
      "epoch 11 loss: 0.2023\n",
      "epoch 12 loss: 0.1826\n",
      "epoch 13 loss: 0.1327\n",
      "epoch 14 loss: 0.1373\n",
      "epoch 15 loss: 0.1149\n",
      "epoch 16 loss: 0.1065\n",
      "epoch 17 loss: 0.0988\n",
      "epoch 18 loss: 0.0918\n",
      "epoch 19 loss: 0.1031\n",
      "epoch 20 loss: 0.0822\n",
      "epoch 21 loss: 0.0819\n",
      "epoch 22 loss: 0.0899\n",
      "epoch 23 loss: 0.1012\n",
      "epoch 24 loss: 0.0694\n",
      "epoch 25 loss: 0.0551\n",
      "epoch 26 loss: 0.0545\n",
      "epoch 27 loss: 0.0663\n",
      "epoch 28 loss: 0.0865\n",
      "epoch 29 loss: 0.0603\n",
      "epoch 30 loss: 0.0798\n",
      "55\n",
      "epoch 1 loss: 0.6553\n",
      "epoch 2 loss: 0.6535\n",
      "epoch 3 loss: 0.6841\n",
      "epoch 4 loss: 0.4320\n",
      "epoch 5 loss: 0.3989\n",
      "epoch 6 loss: 0.2426\n",
      "epoch 7 loss: 0.1792\n",
      "epoch 8 loss: 0.1040\n",
      "epoch 9 loss: 0.1168\n",
      "epoch 10 loss: 0.1009\n",
      "epoch 11 loss: 0.0774\n",
      "epoch 12 loss: 0.0783\n",
      "epoch 13 loss: 0.1328\n",
      "epoch 14 loss: 0.1153\n",
      "epoch 15 loss: 0.1131\n",
      "epoch 16 loss: 0.0912\n",
      "epoch 17 loss: 0.0929\n",
      "epoch 18 loss: 0.0583\n",
      "epoch 19 loss: 0.0869\n",
      "epoch 20 loss: 0.0706\n",
      "epoch 21 loss: 0.0813\n",
      "epoch 22 loss: 0.0887\n",
      "epoch 23 loss: 0.0914\n",
      "epoch 24 loss: 0.0776\n",
      "epoch 25 loss: 0.0601\n",
      "epoch 26 loss: 0.0930\n",
      "epoch 27 loss: 0.0596\n",
      "epoch 28 loss: 0.0801\n",
      "epoch 29 loss: 0.0818\n",
      "epoch 30 loss: 0.0646\n",
      "56\n",
      "epoch 1 loss: 0.8287\n",
      "epoch 2 loss: 0.8473\n",
      "epoch 3 loss: 0.6013\n",
      "epoch 4 loss: 0.6475\n",
      "epoch 5 loss: 0.2911\n",
      "epoch 6 loss: 0.2808\n",
      "epoch 7 loss: 0.2956\n",
      "epoch 8 loss: 0.2088\n",
      "epoch 9 loss: 0.2328\n",
      "epoch 10 loss: 0.2449\n",
      "epoch 11 loss: 0.1697\n",
      "epoch 12 loss: 0.1754\n",
      "epoch 13 loss: 0.1411\n",
      "epoch 14 loss: 0.1721\n",
      "epoch 15 loss: 0.1147\n",
      "epoch 16 loss: 0.1143\n",
      "epoch 17 loss: 0.1423\n",
      "epoch 18 loss: 0.1711\n",
      "epoch 19 loss: 0.0963\n",
      "epoch 20 loss: 0.1469\n",
      "epoch 21 loss: 0.1212\n",
      "epoch 22 loss: 0.1048\n",
      "epoch 23 loss: 0.1052\n",
      "epoch 24 loss: 0.1030\n",
      "epoch 25 loss: 0.1455\n",
      "epoch 26 loss: 0.1014\n",
      "epoch 27 loss: 0.1001\n",
      "epoch 28 loss: 0.0864\n",
      "epoch 29 loss: 0.1106\n",
      "epoch 30 loss: 0.1094\n",
      "57\n",
      "epoch 1 loss: 0.9223\n",
      "epoch 2 loss: 0.5986\n",
      "epoch 3 loss: 0.5523\n",
      "epoch 4 loss: 0.2543\n",
      "epoch 5 loss: 0.2164\n",
      "epoch 6 loss: 0.1864\n",
      "epoch 7 loss: 0.1460\n",
      "epoch 8 loss: 0.1577\n",
      "epoch 9 loss: 0.1498\n",
      "epoch 10 loss: 0.1294\n",
      "epoch 11 loss: 0.1167\n",
      "epoch 12 loss: 0.1088\n",
      "epoch 13 loss: 0.0961\n",
      "epoch 14 loss: 0.1000\n",
      "epoch 15 loss: 0.0911\n",
      "epoch 16 loss: 0.1162\n",
      "epoch 17 loss: 0.1121\n",
      "epoch 18 loss: 0.0736\n",
      "epoch 19 loss: 0.0997\n",
      "epoch 20 loss: 0.0766\n",
      "epoch 21 loss: 0.0696\n",
      "epoch 22 loss: 0.0768\n",
      "epoch 23 loss: 0.0844\n",
      "epoch 24 loss: 0.0819\n",
      "epoch 25 loss: 0.0549\n",
      "epoch 26 loss: 0.0666\n",
      "epoch 27 loss: 0.0947\n",
      "epoch 28 loss: 0.0774\n",
      "epoch 29 loss: 0.0805\n",
      "epoch 30 loss: 0.0715\n",
      "58\n",
      "epoch 1 loss: 0.9929\n",
      "epoch 2 loss: 0.8475\n",
      "epoch 3 loss: 0.3785\n",
      "epoch 4 loss: 0.2929\n",
      "epoch 5 loss: 0.1994\n",
      "epoch 6 loss: 0.1725\n",
      "epoch 7 loss: 0.1392\n",
      "epoch 8 loss: 0.1040\n",
      "epoch 9 loss: 0.1072\n",
      "epoch 10 loss: 0.1108\n",
      "epoch 11 loss: 0.0949\n",
      "epoch 12 loss: 0.1079\n",
      "epoch 13 loss: 0.0988\n",
      "epoch 14 loss: 0.0711\n",
      "epoch 15 loss: 0.1090\n",
      "epoch 16 loss: 0.0849\n",
      "epoch 17 loss: 0.1244\n",
      "epoch 18 loss: 0.0766\n",
      "epoch 19 loss: 0.0778\n",
      "epoch 20 loss: 0.0854\n",
      "epoch 21 loss: 0.0835\n",
      "epoch 22 loss: 0.0947\n",
      "epoch 23 loss: 0.1256\n",
      "epoch 24 loss: 0.0670\n",
      "epoch 25 loss: 0.0927\n",
      "epoch 26 loss: 0.0705\n",
      "epoch 27 loss: 0.0685\n",
      "epoch 28 loss: 0.0811\n",
      "epoch 29 loss: 0.0827\n",
      "epoch 30 loss: 0.0469\n",
      "59\n",
      "epoch 1 loss: 0.6271\n",
      "epoch 2 loss: 0.5673\n",
      "epoch 3 loss: 0.4761\n",
      "epoch 4 loss: 0.2916\n",
      "epoch 5 loss: 0.2677\n",
      "epoch 6 loss: 0.1608\n",
      "epoch 7 loss: 0.1223\n",
      "epoch 8 loss: 0.1380\n",
      "epoch 9 loss: 0.1194\n",
      "epoch 10 loss: 0.0970\n",
      "epoch 11 loss: 0.1016\n",
      "epoch 12 loss: 0.0900\n",
      "epoch 13 loss: 0.0842\n",
      "epoch 14 loss: 0.0873\n",
      "epoch 15 loss: 0.0892\n",
      "epoch 16 loss: 0.1038\n",
      "epoch 17 loss: 0.0691\n",
      "epoch 18 loss: 0.0658\n",
      "epoch 19 loss: 0.0694\n",
      "epoch 20 loss: 0.0704\n",
      "epoch 21 loss: 0.0716\n",
      "epoch 22 loss: 0.0646\n",
      "epoch 23 loss: 0.0623\n",
      "epoch 24 loss: 0.0572\n",
      "epoch 25 loss: 0.0584\n",
      "epoch 26 loss: 0.0714\n",
      "epoch 27 loss: 0.0729\n",
      "epoch 28 loss: 0.0663\n",
      "epoch 29 loss: 0.0543\n",
      "epoch 30 loss: 0.0548\n",
      "60\n",
      "epoch 1 loss: 0.8441\n",
      "epoch 2 loss: 0.7064\n",
      "epoch 3 loss: 0.6287\n",
      "epoch 4 loss: 0.3879\n",
      "epoch 5 loss: 0.2260\n",
      "epoch 6 loss: 0.1626\n",
      "epoch 7 loss: 0.1596\n",
      "epoch 8 loss: 0.1255\n",
      "epoch 9 loss: 0.1424\n",
      "epoch 10 loss: 0.1374\n",
      "epoch 11 loss: 0.1341\n",
      "epoch 12 loss: 0.1062\n",
      "epoch 13 loss: 0.1017\n",
      "epoch 14 loss: 0.1129\n",
      "epoch 15 loss: 0.0849\n",
      "epoch 16 loss: 0.0768\n",
      "epoch 17 loss: 0.0798\n",
      "epoch 18 loss: 0.1116\n",
      "epoch 19 loss: 0.0794\n",
      "epoch 20 loss: 0.1030\n",
      "epoch 21 loss: 0.1013\n",
      "epoch 22 loss: 0.0892\n",
      "epoch 23 loss: 0.0842\n",
      "epoch 24 loss: 0.0735\n",
      "epoch 25 loss: 0.0821\n",
      "epoch 26 loss: 0.1028\n",
      "epoch 27 loss: 0.0798\n",
      "epoch 28 loss: 0.0668\n",
      "epoch 29 loss: 0.0870\n",
      "epoch 30 loss: 0.0829\n",
      "61\n",
      "epoch 1 loss: 0.7879\n",
      "epoch 2 loss: 0.6025\n",
      "epoch 3 loss: 0.4797\n",
      "epoch 4 loss: 0.5739\n",
      "epoch 5 loss: 0.4857\n",
      "epoch 6 loss: 0.4114\n",
      "epoch 7 loss: 0.3784\n",
      "epoch 8 loss: 0.6997\n",
      "epoch 9 loss: 0.3425\n",
      "epoch 10 loss: 0.1583\n",
      "epoch 11 loss: 0.1534\n",
      "epoch 12 loss: 0.1437\n",
      "epoch 13 loss: 0.1016\n",
      "epoch 14 loss: 0.1009\n",
      "epoch 15 loss: 0.1099\n",
      "epoch 16 loss: 0.0820\n",
      "epoch 17 loss: 0.0945\n",
      "epoch 18 loss: 0.0814\n",
      "epoch 19 loss: 0.0690\n",
      "epoch 20 loss: 0.0746\n",
      "epoch 21 loss: 0.0770\n",
      "epoch 22 loss: 0.0623\n",
      "epoch 23 loss: 0.0653\n",
      "epoch 24 loss: 0.0997\n",
      "epoch 25 loss: 0.0681\n",
      "epoch 26 loss: 0.0701\n",
      "epoch 27 loss: 0.0637\n",
      "epoch 28 loss: 0.0594\n",
      "epoch 29 loss: 0.0606\n",
      "epoch 30 loss: 0.0646\n",
      "62\n",
      "epoch 1 loss: 0.6041\n",
      "epoch 2 loss: 0.8573\n",
      "epoch 3 loss: 0.8071\n",
      "epoch 4 loss: 0.6174\n",
      "epoch 5 loss: 0.3669\n",
      "epoch 6 loss: 0.2948\n",
      "epoch 7 loss: 0.1877\n",
      "epoch 8 loss: 0.1296\n",
      "epoch 9 loss: 0.1227\n",
      "epoch 10 loss: 0.1040\n",
      "epoch 11 loss: 0.1132\n",
      "epoch 12 loss: 0.0908\n",
      "epoch 13 loss: 0.0900\n",
      "epoch 14 loss: 0.0931\n",
      "epoch 15 loss: 0.0944\n",
      "epoch 16 loss: 0.0872\n",
      "epoch 17 loss: 0.0825\n",
      "epoch 18 loss: 0.0745\n",
      "epoch 19 loss: 0.0586\n",
      "epoch 20 loss: 0.0711\n",
      "epoch 21 loss: 0.0786\n",
      "epoch 22 loss: 0.0619\n",
      "epoch 23 loss: 0.0798\n",
      "epoch 24 loss: 0.0586\n",
      "epoch 25 loss: 0.0610\n",
      "epoch 26 loss: 0.0596\n",
      "epoch 27 loss: 0.0582\n",
      "epoch 28 loss: 0.0614\n",
      "epoch 29 loss: 0.0648\n",
      "epoch 30 loss: 0.0869\n",
      "63\n",
      "epoch 1 loss: 0.9214\n",
      "epoch 2 loss: 0.7829\n",
      "epoch 3 loss: 0.5768\n",
      "epoch 4 loss: 0.3639\n",
      "epoch 5 loss: 0.2865\n",
      "epoch 6 loss: 0.1684\n",
      "epoch 7 loss: 0.1386\n",
      "epoch 8 loss: 0.1141\n",
      "epoch 9 loss: 0.1248\n",
      "epoch 10 loss: 0.1276\n",
      "epoch 11 loss: 0.1157\n",
      "epoch 12 loss: 0.1462\n",
      "epoch 13 loss: 0.1054\n",
      "epoch 14 loss: 0.1069\n",
      "epoch 15 loss: 0.1097\n",
      "epoch 16 loss: 0.1393\n",
      "epoch 17 loss: 0.0978\n",
      "epoch 18 loss: 0.0918\n",
      "epoch 19 loss: 0.1010\n",
      "epoch 20 loss: 0.0787\n",
      "epoch 21 loss: 0.0699\n",
      "epoch 22 loss: 0.0799\n",
      "epoch 23 loss: 0.0593\n",
      "epoch 24 loss: 0.0657\n",
      "epoch 25 loss: 0.0718\n",
      "epoch 26 loss: 0.0788\n",
      "epoch 27 loss: 0.0706\n",
      "epoch 28 loss: 0.0742\n",
      "epoch 29 loss: 0.0626\n",
      "epoch 30 loss: 0.0774\n",
      "64\n",
      "epoch 1 loss: 0.8414\n",
      "epoch 2 loss: 0.7827\n",
      "epoch 3 loss: 0.6248\n",
      "epoch 4 loss: 0.4898\n",
      "epoch 5 loss: 0.2370\n",
      "epoch 6 loss: 0.1718\n",
      "epoch 7 loss: 0.1329\n",
      "epoch 8 loss: 0.1385\n",
      "epoch 9 loss: 0.1313\n",
      "epoch 10 loss: 0.0872\n",
      "epoch 11 loss: 0.0939\n",
      "epoch 12 loss: 0.0944\n",
      "epoch 13 loss: 0.1029\n",
      "epoch 14 loss: 0.0955\n",
      "epoch 15 loss: 0.1117\n",
      "epoch 16 loss: 0.0816\n",
      "epoch 17 loss: 0.0775\n",
      "epoch 18 loss: 0.0709\n",
      "epoch 19 loss: 0.0835\n",
      "epoch 20 loss: 0.0782\n",
      "epoch 21 loss: 0.0614\n",
      "epoch 22 loss: 0.0630\n",
      "epoch 23 loss: 0.0668\n",
      "epoch 24 loss: 0.0721\n",
      "epoch 25 loss: 0.0596\n",
      "epoch 26 loss: 0.0626\n",
      "epoch 27 loss: 0.0515\n",
      "epoch 28 loss: 0.0545\n",
      "epoch 29 loss: 0.0508\n",
      "epoch 30 loss: 0.0691\n",
      "65\n",
      "epoch 1 loss: 0.6470\n",
      "epoch 2 loss: 0.6729\n",
      "epoch 3 loss: 0.5681\n",
      "epoch 4 loss: 0.4426\n",
      "epoch 5 loss: 0.3982\n",
      "epoch 6 loss: 0.3313\n",
      "epoch 7 loss: 0.2554\n",
      "epoch 8 loss: 0.1454\n",
      "epoch 9 loss: 0.1583\n",
      "epoch 10 loss: 0.1198\n",
      "epoch 11 loss: 0.1066\n",
      "epoch 12 loss: 0.1174\n",
      "epoch 13 loss: 0.1118\n",
      "epoch 14 loss: 0.1684\n",
      "epoch 15 loss: 0.1295\n",
      "epoch 16 loss: 0.0804\n",
      "epoch 17 loss: 0.0867\n",
      "epoch 18 loss: 0.0826\n",
      "epoch 19 loss: 0.0679\n",
      "epoch 20 loss: 0.0619\n",
      "epoch 21 loss: 0.0761\n",
      "epoch 22 loss: 0.1184\n",
      "epoch 23 loss: 0.0670\n",
      "epoch 24 loss: 0.0666\n",
      "epoch 25 loss: 0.0672\n",
      "epoch 26 loss: 0.0925\n",
      "epoch 27 loss: 0.0730\n",
      "epoch 28 loss: 0.0607\n",
      "epoch 29 loss: 0.1159\n",
      "epoch 30 loss: 0.0819\n",
      "66\n",
      "epoch 1 loss: 0.7612\n",
      "epoch 2 loss: 0.6902\n",
      "epoch 3 loss: 0.3234\n",
      "epoch 4 loss: 0.4940\n",
      "epoch 5 loss: 0.4450\n",
      "epoch 6 loss: 0.2344\n",
      "epoch 7 loss: 0.2302\n",
      "epoch 8 loss: 0.1712\n",
      "epoch 9 loss: 0.1838\n",
      "epoch 10 loss: 0.1254\n",
      "epoch 11 loss: 0.1680\n",
      "epoch 12 loss: 0.1108\n",
      "epoch 13 loss: 0.1280\n",
      "epoch 14 loss: 0.1038\n",
      "epoch 15 loss: 0.1133\n",
      "epoch 16 loss: 0.0745\n",
      "epoch 17 loss: 0.0878\n",
      "epoch 18 loss: 0.0692\n",
      "epoch 19 loss: 0.1148\n",
      "epoch 20 loss: 0.0930\n",
      "epoch 21 loss: 0.0836\n",
      "epoch 22 loss: 0.0802\n",
      "epoch 23 loss: 0.0873\n",
      "epoch 24 loss: 0.0795\n",
      "epoch 25 loss: 0.0613\n",
      "epoch 26 loss: 0.0727\n",
      "epoch 27 loss: 0.0699\n",
      "epoch 28 loss: 0.0725\n",
      "epoch 29 loss: 0.0871\n",
      "epoch 30 loss: 0.0988\n",
      "67\n",
      "epoch 1 loss: 0.8624\n",
      "epoch 2 loss: 0.7415\n",
      "epoch 3 loss: 0.3919\n",
      "epoch 4 loss: 0.4548\n",
      "epoch 5 loss: 0.2776\n",
      "epoch 6 loss: 0.2100\n",
      "epoch 7 loss: 0.1652\n",
      "epoch 8 loss: 0.1167\n",
      "epoch 9 loss: 0.1065\n",
      "epoch 10 loss: 0.1513\n",
      "epoch 11 loss: 0.1291\n",
      "epoch 12 loss: 0.0864\n",
      "epoch 13 loss: 0.0771\n",
      "epoch 14 loss: 0.0726\n",
      "epoch 15 loss: 0.0617\n",
      "epoch 16 loss: 0.1102\n",
      "epoch 17 loss: 0.0725\n",
      "epoch 18 loss: 0.0963\n",
      "epoch 19 loss: 0.0751\n",
      "epoch 20 loss: 0.0903\n",
      "epoch 21 loss: 0.0807\n",
      "epoch 22 loss: 0.0957\n",
      "epoch 23 loss: 0.0604\n",
      "epoch 24 loss: 0.0609\n",
      "epoch 25 loss: 0.0841\n",
      "epoch 26 loss: 0.0657\n",
      "epoch 27 loss: 0.0773\n",
      "epoch 28 loss: 0.0490\n",
      "epoch 29 loss: 0.0717\n",
      "epoch 30 loss: 0.0596\n",
      "68\n",
      "epoch 1 loss: 0.7261\n",
      "epoch 2 loss: 0.5332\n",
      "epoch 3 loss: 0.8342\n",
      "epoch 4 loss: 0.3841\n",
      "epoch 5 loss: 0.2230\n",
      "epoch 6 loss: 0.1626\n",
      "epoch 7 loss: 0.1437\n",
      "epoch 8 loss: 0.1019\n",
      "epoch 9 loss: 0.1129\n",
      "epoch 10 loss: 0.0889\n",
      "epoch 11 loss: 0.1143\n",
      "epoch 12 loss: 0.1056\n",
      "epoch 13 loss: 0.1143\n",
      "epoch 14 loss: 0.0843\n",
      "epoch 15 loss: 0.1063\n",
      "epoch 16 loss: 0.0707\n",
      "epoch 17 loss: 0.0588\n",
      "epoch 18 loss: 0.0740\n",
      "epoch 19 loss: 0.0724\n",
      "epoch 20 loss: 0.0989\n",
      "epoch 21 loss: 0.0682\n",
      "epoch 22 loss: 0.0714\n",
      "epoch 23 loss: 0.0795\n",
      "epoch 24 loss: 0.0700\n",
      "epoch 25 loss: 0.0646\n",
      "epoch 26 loss: 0.0613\n",
      "epoch 27 loss: 0.0614\n",
      "epoch 28 loss: 0.0631\n",
      "epoch 29 loss: 0.0550\n",
      "epoch 30 loss: 0.0651\n",
      "69\n",
      "epoch 1 loss: 0.9163\n",
      "epoch 2 loss: 0.7930\n",
      "epoch 3 loss: 0.4962\n",
      "epoch 4 loss: 0.2843\n",
      "epoch 5 loss: 0.2243\n",
      "epoch 6 loss: 0.1601\n",
      "epoch 7 loss: 0.1625\n",
      "epoch 8 loss: 0.1536\n",
      "epoch 9 loss: 0.1457\n",
      "epoch 10 loss: 0.1659\n",
      "epoch 11 loss: 0.1638\n",
      "epoch 12 loss: 0.1262\n",
      "epoch 13 loss: 0.1150\n",
      "epoch 14 loss: 0.1350\n",
      "epoch 15 loss: 0.1025\n",
      "epoch 16 loss: 0.0938\n",
      "epoch 17 loss: 0.1003\n",
      "epoch 18 loss: 0.0781\n",
      "epoch 19 loss: 0.0984\n",
      "epoch 20 loss: 0.1205\n",
      "epoch 21 loss: 0.0744\n",
      "epoch 22 loss: 0.0716\n",
      "epoch 23 loss: 0.0753\n",
      "epoch 24 loss: 0.0788\n",
      "epoch 25 loss: 0.0848\n",
      "epoch 26 loss: 0.0964\n",
      "epoch 27 loss: 0.0722\n",
      "epoch 28 loss: 0.0776\n",
      "epoch 29 loss: 0.0698\n",
      "epoch 30 loss: 0.0839\n",
      "70\n",
      "epoch 1 loss: 1.0619\n",
      "epoch 2 loss: 0.5710\n",
      "epoch 3 loss: 0.4469\n",
      "epoch 4 loss: 0.2803\n",
      "epoch 5 loss: 0.2232\n",
      "epoch 6 loss: 0.1477\n",
      "epoch 7 loss: 0.1147\n",
      "epoch 8 loss: 0.1619\n",
      "epoch 9 loss: 0.1177\n",
      "epoch 10 loss: 0.1063\n",
      "epoch 11 loss: 0.1108\n",
      "epoch 12 loss: 0.0953\n",
      "epoch 13 loss: 0.1105\n",
      "epoch 14 loss: 0.1003\n",
      "epoch 15 loss: 0.1160\n",
      "epoch 16 loss: 0.0967\n",
      "epoch 17 loss: 0.0904\n",
      "epoch 18 loss: 0.0892\n",
      "epoch 19 loss: 0.1051\n",
      "epoch 20 loss: 0.0653\n",
      "epoch 21 loss: 0.1004\n",
      "epoch 22 loss: 0.1001\n",
      "epoch 23 loss: 0.0674\n",
      "epoch 24 loss: 0.0851\n",
      "epoch 25 loss: 0.0882\n",
      "epoch 26 loss: 0.0644\n",
      "epoch 27 loss: 0.0692\n",
      "epoch 28 loss: 0.1237\n",
      "epoch 29 loss: 0.1055\n",
      "epoch 30 loss: 0.0706\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "30cf4e2e-c31d-4a79-991a-8749f4801426",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier matrix (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee279949-a82f-452f-901e-03c15a84f6dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T19:16:10.166169Z",
     "start_time": "2025-10-03T18:11:19.523040Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_w_matrix.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:921: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {ep+1} loss: {float(loss):.4f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6016\n",
      "epoch 2 loss: 0.6518\n",
      "epoch 3 loss: 0.6378\n",
      "epoch 4 loss: 0.4070\n",
      "epoch 5 loss: 0.5423\n",
      "epoch 6 loss: 0.5118\n",
      "epoch 7 loss: 0.2526\n",
      "epoch 8 loss: 0.1710\n",
      "epoch 9 loss: 0.1503\n",
      "epoch 10 loss: 0.1233\n",
      "epoch 11 loss: 0.1166\n",
      "epoch 12 loss: 0.0804\n",
      "epoch 13 loss: 0.1033\n",
      "epoch 14 loss: 0.0790\n",
      "epoch 15 loss: 0.0711\n",
      "epoch 16 loss: 0.0638\n",
      "epoch 17 loss: 0.0647\n",
      "epoch 18 loss: 0.0517\n",
      "epoch 19 loss: 0.0681\n",
      "epoch 20 loss: 0.0623\n",
      "epoch 21 loss: 0.0598\n",
      "epoch 22 loss: 0.0438\n",
      "epoch 23 loss: 0.0534\n",
      "epoch 24 loss: 0.0766\n",
      "epoch 25 loss: 0.0634\n",
      "epoch 26 loss: 0.0605\n",
      "epoch 27 loss: 0.0719\n",
      "epoch 28 loss: 0.0507\n",
      "epoch 29 loss: 0.0421\n",
      "epoch 30 loss: 0.0519\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_73156/2516605468.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.8241\n",
      "epoch 2 loss: 0.6998\n",
      "epoch 3 loss: 0.4530\n",
      "epoch 4 loss: 0.4092\n",
      "epoch 5 loss: 0.2103\n",
      "epoch 6 loss: 0.1481\n",
      "epoch 7 loss: 0.1401\n",
      "epoch 8 loss: 0.1049\n",
      "epoch 9 loss: 0.0946\n",
      "epoch 10 loss: 0.1266\n",
      "epoch 11 loss: 0.1329\n",
      "epoch 12 loss: 0.0940\n",
      "epoch 13 loss: 0.1410\n",
      "epoch 14 loss: 0.0698\n",
      "epoch 15 loss: 0.0900\n",
      "epoch 16 loss: 0.0963\n",
      "epoch 17 loss: 0.0477\n",
      "epoch 18 loss: 0.1011\n",
      "epoch 19 loss: 0.0814\n",
      "epoch 20 loss: 0.0708\n",
      "epoch 21 loss: 0.0641\n",
      "epoch 22 loss: 0.0814\n",
      "epoch 23 loss: 0.0809\n",
      "epoch 24 loss: 0.0621\n",
      "epoch 25 loss: 0.0817\n",
      "epoch 26 loss: 0.1255\n",
      "epoch 27 loss: 0.1574\n",
      "epoch 28 loss: 0.0770\n",
      "epoch 29 loss: 0.0785\n",
      "epoch 30 loss: 0.0611\n",
      "3\n",
      "epoch 1 loss: 0.7749\n",
      "epoch 2 loss: 0.7894\n",
      "epoch 3 loss: 0.4179\n",
      "epoch 4 loss: 0.3142\n",
      "epoch 5 loss: 0.1596\n",
      "epoch 6 loss: 0.1598\n",
      "epoch 7 loss: 0.1232\n",
      "epoch 8 loss: 0.1307\n",
      "epoch 9 loss: 0.1361\n",
      "epoch 10 loss: 0.0895\n",
      "epoch 11 loss: 0.0861\n",
      "epoch 12 loss: 0.0704\n",
      "epoch 13 loss: 0.1311\n",
      "epoch 14 loss: 0.0850\n",
      "epoch 15 loss: 0.1124\n",
      "epoch 16 loss: 0.0803\n",
      "epoch 17 loss: 0.0887\n",
      "epoch 18 loss: 0.0921\n",
      "epoch 19 loss: 0.0735\n",
      "epoch 20 loss: 0.0592\n",
      "epoch 21 loss: 0.0606\n",
      "epoch 22 loss: 0.1026\n",
      "epoch 23 loss: 0.0767\n",
      "epoch 24 loss: 0.0560\n",
      "epoch 25 loss: 0.0532\n",
      "epoch 26 loss: 0.0738\n",
      "epoch 27 loss: 0.0619\n",
      "epoch 28 loss: 0.0605\n",
      "epoch 29 loss: 0.0771\n",
      "epoch 30 loss: 0.0573\n",
      "4\n",
      "epoch 1 loss: 1.1425\n",
      "epoch 2 loss: 0.8415\n",
      "epoch 3 loss: 0.6552\n",
      "epoch 4 loss: 0.3642\n",
      "epoch 5 loss: 0.4142\n",
      "epoch 6 loss: 0.2700\n",
      "epoch 7 loss: 0.2010\n",
      "epoch 8 loss: 0.1796\n",
      "epoch 9 loss: 0.1403\n",
      "epoch 10 loss: 0.1335\n",
      "epoch 11 loss: 0.0965\n",
      "epoch 12 loss: 0.1146\n",
      "epoch 13 loss: 0.1085\n",
      "epoch 14 loss: 0.1175\n",
      "epoch 15 loss: 0.0788\n",
      "epoch 16 loss: 0.0950\n",
      "epoch 17 loss: 0.0670\n",
      "epoch 18 loss: 0.1127\n",
      "epoch 19 loss: 0.0946\n",
      "epoch 20 loss: 0.0920\n",
      "epoch 21 loss: 0.0877\n",
      "epoch 22 loss: 0.0700\n",
      "epoch 23 loss: 0.1111\n",
      "epoch 24 loss: 0.0797\n",
      "epoch 25 loss: 0.0676\n",
      "epoch 26 loss: 0.0785\n",
      "epoch 27 loss: 0.0823\n",
      "epoch 28 loss: 0.0886\n",
      "epoch 29 loss: 0.0675\n",
      "epoch 30 loss: 0.0670\n",
      "5\n",
      "epoch 1 loss: 0.7758\n",
      "epoch 2 loss: 0.6364\n",
      "epoch 3 loss: 0.5682\n",
      "epoch 4 loss: 0.4101\n",
      "epoch 5 loss: 0.2575\n",
      "epoch 6 loss: 0.1741\n",
      "epoch 7 loss: 0.1284\n",
      "epoch 8 loss: 0.0951\n",
      "epoch 9 loss: 0.1064\n",
      "epoch 10 loss: 0.1115\n",
      "epoch 11 loss: 0.1060\n",
      "epoch 12 loss: 0.0906\n",
      "epoch 13 loss: 0.0863\n",
      "epoch 14 loss: 0.0690\n",
      "epoch 15 loss: 0.0755\n",
      "epoch 16 loss: 0.0885\n",
      "epoch 17 loss: 0.0855\n",
      "epoch 18 loss: 0.0790\n",
      "epoch 19 loss: 0.0673\n",
      "epoch 20 loss: 0.0628\n",
      "epoch 21 loss: 0.0722\n",
      "epoch 22 loss: 0.0830\n",
      "epoch 23 loss: 0.0741\n",
      "epoch 24 loss: 0.0693\n",
      "epoch 25 loss: 0.0691\n",
      "epoch 26 loss: 0.0610\n",
      "epoch 27 loss: 0.0564\n",
      "epoch 28 loss: 0.0866\n",
      "epoch 29 loss: 0.0534\n",
      "epoch 30 loss: 0.0616\n",
      "6\n",
      "epoch 1 loss: 0.6926\n",
      "epoch 2 loss: 0.5479\n",
      "epoch 3 loss: 0.5673\n",
      "epoch 4 loss: 0.3158\n",
      "epoch 5 loss: 0.2622\n",
      "epoch 6 loss: 0.1684\n",
      "epoch 7 loss: 0.1725\n",
      "epoch 8 loss: 0.1391\n",
      "epoch 9 loss: 0.0975\n",
      "epoch 10 loss: 0.1326\n",
      "epoch 11 loss: 0.1218\n",
      "epoch 12 loss: 0.0839\n",
      "epoch 13 loss: 0.0637\n",
      "epoch 14 loss: 0.0825\n",
      "epoch 15 loss: 0.0740\n",
      "epoch 16 loss: 0.0929\n",
      "epoch 17 loss: 0.0638\n",
      "epoch 18 loss: 0.0691\n",
      "epoch 19 loss: 0.0848\n",
      "epoch 20 loss: 0.0652\n",
      "epoch 21 loss: 0.0761\n",
      "epoch 22 loss: 0.0613\n",
      "epoch 23 loss: 0.0664\n",
      "epoch 24 loss: 0.0721\n",
      "epoch 25 loss: 0.0896\n",
      "epoch 26 loss: 0.0624\n",
      "epoch 27 loss: 0.0585\n",
      "epoch 28 loss: 0.0489\n",
      "epoch 29 loss: 0.0756\n",
      "epoch 30 loss: 0.0841\n",
      "7\n",
      "epoch 1 loss: 0.8014\n",
      "epoch 2 loss: 0.5739\n",
      "epoch 3 loss: 0.7582\n",
      "epoch 4 loss: 0.2510\n",
      "epoch 5 loss: 0.2348\n",
      "epoch 6 loss: 0.1640\n",
      "epoch 7 loss: 0.1793\n",
      "epoch 8 loss: 0.1620\n",
      "epoch 9 loss: 0.1584\n",
      "epoch 10 loss: 0.1265\n",
      "epoch 11 loss: 0.1035\n",
      "epoch 12 loss: 0.1123\n",
      "epoch 13 loss: 0.1220\n",
      "epoch 14 loss: 0.1148\n",
      "epoch 15 loss: 0.0877\n",
      "epoch 16 loss: 0.1272\n",
      "epoch 17 loss: 0.0958\n",
      "epoch 18 loss: 0.0875\n",
      "epoch 19 loss: 0.0696\n",
      "epoch 20 loss: 0.0783\n",
      "epoch 21 loss: 0.0875\n",
      "epoch 22 loss: 0.0749\n",
      "epoch 23 loss: 0.0882\n",
      "epoch 24 loss: 0.1239\n",
      "epoch 25 loss: 0.0810\n",
      "epoch 26 loss: 0.0678\n",
      "epoch 27 loss: 0.0639\n",
      "epoch 28 loss: 0.0820\n",
      "epoch 29 loss: 0.0737\n",
      "epoch 30 loss: 0.0705\n",
      "8\n",
      "epoch 1 loss: 0.7636\n",
      "epoch 2 loss: 0.5005\n",
      "epoch 3 loss: 0.8817\n",
      "epoch 4 loss: 0.3299\n",
      "epoch 5 loss: 0.3726\n",
      "epoch 6 loss: 0.2203\n",
      "epoch 7 loss: 0.2266\n",
      "epoch 8 loss: 0.1707\n",
      "epoch 9 loss: 0.1420\n",
      "epoch 10 loss: 0.1630\n",
      "epoch 11 loss: 0.1223\n",
      "epoch 12 loss: 0.0995\n",
      "epoch 13 loss: 0.1140\n",
      "epoch 14 loss: 0.1302\n",
      "epoch 15 loss: 0.1690\n",
      "epoch 16 loss: 0.1420\n",
      "epoch 17 loss: 0.1635\n",
      "epoch 18 loss: 0.1164\n",
      "epoch 19 loss: 0.1768\n",
      "epoch 20 loss: 0.0682\n",
      "epoch 21 loss: 0.1241\n",
      "epoch 22 loss: 0.0974\n",
      "epoch 23 loss: 0.0893\n",
      "epoch 24 loss: 0.0838\n",
      "epoch 25 loss: 0.0804\n",
      "epoch 26 loss: 0.0891\n",
      "epoch 27 loss: 0.0788\n",
      "epoch 28 loss: 0.0739\n",
      "epoch 29 loss: 0.1178\n",
      "epoch 30 loss: 0.0834\n",
      "9\n",
      "epoch 1 loss: 0.8757\n",
      "epoch 2 loss: 0.7171\n",
      "epoch 3 loss: 0.6482\n",
      "epoch 4 loss: 0.7535\n",
      "epoch 5 loss: 0.4491\n",
      "epoch 6 loss: 0.2355\n",
      "epoch 7 loss: 0.1818\n",
      "epoch 8 loss: 0.1679\n",
      "epoch 9 loss: 0.1642\n",
      "epoch 10 loss: 0.1388\n",
      "epoch 11 loss: 0.1507\n",
      "epoch 12 loss: 0.0818\n",
      "epoch 13 loss: 0.1041\n",
      "epoch 14 loss: 0.1190\n",
      "epoch 15 loss: 0.1160\n",
      "epoch 16 loss: 0.0821\n",
      "epoch 17 loss: 0.1225\n",
      "epoch 18 loss: 0.1078\n",
      "epoch 19 loss: 0.1065\n",
      "epoch 20 loss: 0.0994\n",
      "epoch 21 loss: 0.1099\n",
      "epoch 22 loss: 0.0812\n",
      "epoch 23 loss: 0.1292\n",
      "epoch 24 loss: 0.0952\n",
      "epoch 25 loss: 0.0793\n",
      "epoch 26 loss: 0.1053\n",
      "epoch 27 loss: 0.0917\n",
      "epoch 28 loss: 0.0806\n",
      "epoch 29 loss: 0.0710\n",
      "epoch 30 loss: 0.0787\n",
      "10\n",
      "epoch 1 loss: 1.1476\n",
      "epoch 2 loss: 0.9790\n",
      "epoch 3 loss: 0.5954\n",
      "epoch 4 loss: 0.4678\n",
      "epoch 5 loss: 0.4450\n",
      "epoch 6 loss: 0.2928\n",
      "epoch 7 loss: 0.2049\n",
      "epoch 8 loss: 0.2359\n",
      "epoch 9 loss: 0.1969\n",
      "epoch 10 loss: 0.1935\n",
      "epoch 11 loss: 0.1478\n",
      "epoch 12 loss: 0.1379\n",
      "epoch 13 loss: 0.1408\n",
      "epoch 14 loss: 0.0997\n",
      "epoch 15 loss: 0.1221\n",
      "epoch 16 loss: 0.0957\n",
      "epoch 17 loss: 0.1059\n",
      "epoch 18 loss: 0.0916\n",
      "epoch 19 loss: 0.0902\n",
      "epoch 20 loss: 0.1091\n",
      "epoch 21 loss: 0.1526\n",
      "epoch 22 loss: 0.1128\n",
      "epoch 23 loss: 0.0872\n",
      "epoch 24 loss: 0.0993\n",
      "epoch 25 loss: 0.0621\n",
      "epoch 26 loss: 0.0838\n",
      "epoch 27 loss: 0.0571\n",
      "epoch 28 loss: 0.0677\n",
      "epoch 29 loss: 0.1086\n",
      "epoch 30 loss: 0.0715\n",
      "11\n",
      "epoch 1 loss: 1.1959\n",
      "epoch 2 loss: 0.5672\n",
      "epoch 3 loss: 0.4193\n",
      "epoch 4 loss: 0.3324\n",
      "epoch 5 loss: 0.3159\n",
      "epoch 6 loss: 0.1942\n",
      "epoch 7 loss: 0.1728\n",
      "epoch 8 loss: 0.1074\n",
      "epoch 9 loss: 0.1287\n",
      "epoch 10 loss: 0.1119\n",
      "epoch 11 loss: 0.1077\n",
      "epoch 12 loss: 0.0974\n",
      "epoch 13 loss: 0.0860\n",
      "epoch 14 loss: 0.0747\n",
      "epoch 15 loss: 0.0709\n",
      "epoch 16 loss: 0.0955\n",
      "epoch 17 loss: 0.0712\n",
      "epoch 18 loss: 0.0866\n",
      "epoch 19 loss: 0.0594\n",
      "epoch 20 loss: 0.0783\n",
      "epoch 21 loss: 0.0509\n",
      "epoch 22 loss: 0.0731\n",
      "epoch 23 loss: 0.0691\n",
      "epoch 24 loss: 0.0734\n",
      "epoch 25 loss: 0.0642\n",
      "epoch 26 loss: 0.0719\n",
      "epoch 27 loss: 0.0698\n",
      "epoch 28 loss: 0.0619\n",
      "epoch 29 loss: 0.0757\n",
      "epoch 30 loss: 0.0720\n",
      "12\n",
      "epoch 1 loss: 1.0078\n",
      "epoch 2 loss: 0.6397\n",
      "epoch 3 loss: 0.3750\n",
      "epoch 4 loss: 0.2062\n",
      "epoch 5 loss: 0.1664\n",
      "epoch 6 loss: 0.0883\n",
      "epoch 7 loss: 0.1164\n",
      "epoch 8 loss: 0.1334\n",
      "epoch 9 loss: 0.1329\n",
      "epoch 10 loss: 0.1052\n",
      "epoch 11 loss: 0.1073\n",
      "epoch 12 loss: 0.0906\n",
      "epoch 13 loss: 0.1043\n",
      "epoch 14 loss: 0.0828\n",
      "epoch 15 loss: 0.0798\n",
      "epoch 16 loss: 0.0777\n",
      "epoch 17 loss: 0.0884\n",
      "epoch 18 loss: 0.0862\n",
      "epoch 19 loss: 0.0700\n",
      "epoch 20 loss: 0.0701\n",
      "epoch 21 loss: 0.0684\n",
      "epoch 22 loss: 0.0736\n",
      "epoch 23 loss: 0.0676\n",
      "epoch 24 loss: 0.0792\n",
      "epoch 25 loss: 0.0632\n",
      "epoch 26 loss: 0.0693\n",
      "epoch 27 loss: 0.0634\n",
      "epoch 28 loss: 0.0663\n",
      "epoch 29 loss: 0.0653\n",
      "epoch 30 loss: 0.0610\n",
      "13\n",
      "epoch 1 loss: 1.1577\n",
      "epoch 2 loss: 0.9396\n",
      "epoch 3 loss: 0.5139\n",
      "epoch 4 loss: 0.6719\n",
      "epoch 5 loss: 0.3385\n",
      "epoch 6 loss: 0.3060\n",
      "epoch 7 loss: 0.1935\n",
      "epoch 8 loss: 0.1353\n",
      "epoch 9 loss: 0.1218\n",
      "epoch 10 loss: 0.1545\n",
      "epoch 11 loss: 0.1107\n",
      "epoch 12 loss: 0.0903\n",
      "epoch 13 loss: 0.1599\n",
      "epoch 14 loss: 0.0980\n",
      "epoch 15 loss: 0.1173\n",
      "epoch 16 loss: 0.1230\n",
      "epoch 17 loss: 0.0870\n",
      "epoch 18 loss: 0.0741\n",
      "epoch 19 loss: 0.1005\n",
      "epoch 20 loss: 0.1010\n",
      "epoch 21 loss: 0.1358\n",
      "epoch 22 loss: 0.0677\n",
      "epoch 23 loss: 0.0700\n",
      "epoch 24 loss: 0.0679\n",
      "epoch 25 loss: 0.0848\n",
      "epoch 26 loss: 0.0840\n",
      "epoch 27 loss: 0.0922\n",
      "epoch 28 loss: 0.0886\n",
      "epoch 29 loss: 0.0693\n",
      "epoch 30 loss: 0.0735\n",
      "14\n",
      "epoch 1 loss: 0.9893\n",
      "epoch 2 loss: 0.7907\n",
      "epoch 3 loss: 0.5471\n",
      "epoch 4 loss: 0.3918\n",
      "epoch 5 loss: 0.2663\n",
      "epoch 6 loss: 0.1825\n",
      "epoch 7 loss: 0.1635\n",
      "epoch 8 loss: 0.1252\n",
      "epoch 9 loss: 0.1404\n",
      "epoch 10 loss: 0.1203\n",
      "epoch 11 loss: 0.1000\n",
      "epoch 12 loss: 0.0900\n",
      "epoch 13 loss: 0.1362\n",
      "epoch 14 loss: 0.0774\n",
      "epoch 15 loss: 0.0938\n",
      "epoch 16 loss: 0.1205\n",
      "epoch 17 loss: 0.0852\n",
      "epoch 18 loss: 0.0896\n",
      "epoch 19 loss: 0.0915\n",
      "epoch 20 loss: 0.0692\n",
      "epoch 21 loss: 0.0925\n",
      "epoch 22 loss: 0.0809\n",
      "epoch 23 loss: 0.0761\n",
      "epoch 24 loss: 0.0724\n",
      "epoch 25 loss: 0.0685\n",
      "epoch 26 loss: 0.0649\n",
      "epoch 27 loss: 0.0697\n",
      "epoch 28 loss: 0.0729\n",
      "epoch 29 loss: 0.0763\n",
      "epoch 30 loss: 0.0775\n",
      "15\n",
      "epoch 1 loss: 0.8427\n",
      "epoch 2 loss: 0.7100\n",
      "epoch 3 loss: 0.3766\n",
      "epoch 4 loss: 0.2535\n",
      "epoch 5 loss: 0.1607\n",
      "epoch 6 loss: 0.1409\n",
      "epoch 7 loss: 0.1006\n",
      "epoch 8 loss: 0.1075\n",
      "epoch 9 loss: 0.1093\n",
      "epoch 10 loss: 0.2047\n",
      "epoch 11 loss: 0.0796\n",
      "epoch 12 loss: 0.0796\n",
      "epoch 13 loss: 0.0791\n",
      "epoch 14 loss: 0.0817\n",
      "epoch 15 loss: 0.1017\n",
      "epoch 16 loss: 0.0876\n",
      "epoch 17 loss: 0.0801\n",
      "epoch 18 loss: 0.0996\n",
      "epoch 19 loss: 0.0705\n",
      "epoch 20 loss: 0.0572\n",
      "epoch 21 loss: 0.0726\n",
      "epoch 22 loss: 0.0695\n",
      "epoch 23 loss: 0.0656\n",
      "epoch 24 loss: 0.0633\n",
      "epoch 25 loss: 0.0555\n",
      "epoch 26 loss: 0.0615\n",
      "epoch 27 loss: 0.0529\n",
      "epoch 28 loss: 0.0747\n",
      "epoch 29 loss: 0.0631\n",
      "epoch 30 loss: 0.0541\n",
      "16\n",
      "epoch 1 loss: 1.0574\n",
      "epoch 2 loss: 0.6415\n",
      "epoch 3 loss: 0.5326\n",
      "epoch 4 loss: 0.4209\n",
      "epoch 5 loss: 0.2631\n",
      "epoch 6 loss: 0.1953\n",
      "epoch 7 loss: 0.1631\n",
      "epoch 8 loss: 0.1289\n",
      "epoch 9 loss: 0.1193\n",
      "epoch 10 loss: 0.1196\n",
      "epoch 11 loss: 0.0899\n",
      "epoch 12 loss: 0.1185\n",
      "epoch 13 loss: 0.0724\n",
      "epoch 14 loss: 0.0813\n",
      "epoch 15 loss: 0.1085\n",
      "epoch 16 loss: 0.1030\n",
      "epoch 17 loss: 0.0852\n",
      "epoch 18 loss: 0.0615\n",
      "epoch 19 loss: 0.0672\n",
      "epoch 20 loss: 0.0725\n",
      "epoch 21 loss: 0.0785\n",
      "epoch 22 loss: 0.0823\n",
      "epoch 23 loss: 0.0729\n",
      "epoch 24 loss: 0.0599\n",
      "epoch 25 loss: 0.0621\n",
      "epoch 26 loss: 0.0692\n",
      "epoch 27 loss: 0.0634\n",
      "epoch 28 loss: 0.0556\n",
      "epoch 29 loss: 0.0496\n",
      "epoch 30 loss: 0.0510\n",
      "17\n",
      "epoch 1 loss: 1.1224\n",
      "epoch 2 loss: 0.7789\n",
      "epoch 3 loss: 0.5926\n",
      "epoch 4 loss: 0.8952\n",
      "epoch 5 loss: 0.5691\n",
      "epoch 6 loss: 0.4850\n",
      "epoch 7 loss: 0.3393\n",
      "epoch 8 loss: 0.4101\n",
      "epoch 9 loss: 0.1544\n",
      "epoch 10 loss: 0.1861\n",
      "epoch 11 loss: 0.1661\n",
      "epoch 12 loss: 0.1051\n",
      "epoch 13 loss: 0.1133\n",
      "epoch 14 loss: 0.1179\n",
      "epoch 15 loss: 0.1259\n",
      "epoch 16 loss: 0.1286\n",
      "epoch 17 loss: 0.1101\n",
      "epoch 18 loss: 0.0895\n",
      "epoch 19 loss: 0.0655\n",
      "epoch 20 loss: 0.0789\n",
      "epoch 21 loss: 0.0875\n",
      "epoch 22 loss: 0.0818\n",
      "epoch 23 loss: 0.0760\n",
      "epoch 24 loss: 0.0833\n",
      "epoch 25 loss: 0.0994\n",
      "epoch 26 loss: 0.0675\n",
      "epoch 27 loss: 0.0948\n",
      "epoch 28 loss: 0.0742\n",
      "epoch 29 loss: 0.0506\n",
      "epoch 30 loss: 0.0639\n",
      "18\n",
      "epoch 1 loss: 0.8255\n",
      "epoch 2 loss: 1.0086\n",
      "epoch 3 loss: 0.6459\n",
      "epoch 4 loss: 0.9569\n",
      "epoch 5 loss: 0.3825\n",
      "epoch 6 loss: 0.3184\n",
      "epoch 7 loss: 0.2398\n",
      "epoch 8 loss: 0.1736\n",
      "epoch 9 loss: 0.1294\n",
      "epoch 10 loss: 0.1028\n",
      "epoch 11 loss: 0.1178\n",
      "epoch 12 loss: 0.1049\n",
      "epoch 13 loss: 0.0758\n",
      "epoch 14 loss: 0.0884\n",
      "epoch 15 loss: 0.1079\n",
      "epoch 16 loss: 0.0912\n",
      "epoch 17 loss: 0.1094\n",
      "epoch 18 loss: 0.0693\n",
      "epoch 19 loss: 0.0638\n",
      "epoch 20 loss: 0.0922\n",
      "epoch 21 loss: 0.0880\n",
      "epoch 22 loss: 0.0991\n",
      "epoch 23 loss: 0.0764\n",
      "epoch 24 loss: 0.0731\n",
      "epoch 25 loss: 0.0598\n",
      "epoch 26 loss: 0.0751\n",
      "epoch 27 loss: 0.0785\n",
      "epoch 28 loss: 0.0638\n",
      "epoch 29 loss: 0.0746\n",
      "epoch 30 loss: 0.0718\n",
      "19\n",
      "epoch 1 loss: 1.2262\n",
      "epoch 2 loss: 0.8658\n",
      "epoch 3 loss: 0.5421\n",
      "epoch 4 loss: 0.5206\n",
      "epoch 5 loss: 0.5102\n",
      "epoch 6 loss: 0.3221\n",
      "epoch 7 loss: 0.2615\n",
      "epoch 8 loss: 0.1921\n",
      "epoch 9 loss: 0.1404\n",
      "epoch 10 loss: 0.1157\n",
      "epoch 11 loss: 0.1280\n",
      "epoch 12 loss: 0.1193\n",
      "epoch 13 loss: 0.1186\n",
      "epoch 14 loss: 0.1112\n",
      "epoch 15 loss: 0.1302\n",
      "epoch 16 loss: 0.0987\n",
      "epoch 17 loss: 0.1895\n",
      "epoch 18 loss: 0.1594\n",
      "epoch 19 loss: 0.0894\n",
      "epoch 20 loss: 0.1615\n",
      "epoch 21 loss: 0.0777\n",
      "epoch 22 loss: 0.0812\n",
      "epoch 23 loss: 0.1031\n",
      "epoch 24 loss: 0.0718\n",
      "epoch 25 loss: 0.0923\n",
      "epoch 26 loss: 0.0763\n",
      "epoch 27 loss: 0.0783\n",
      "epoch 28 loss: 0.1024\n",
      "epoch 29 loss: 0.1163\n",
      "epoch 30 loss: 0.0532\n",
      "20\n",
      "epoch 1 loss: 1.0350\n",
      "epoch 2 loss: 0.5605\n",
      "epoch 3 loss: 0.3980\n",
      "epoch 4 loss: 0.3882\n",
      "epoch 5 loss: 0.2087\n",
      "epoch 6 loss: 0.1466\n",
      "epoch 7 loss: 0.1072\n",
      "epoch 8 loss: 0.1075\n",
      "epoch 9 loss: 0.1311\n",
      "epoch 10 loss: 0.0850\n",
      "epoch 11 loss: 0.0794\n",
      "epoch 12 loss: 0.1184\n",
      "epoch 13 loss: 0.0876\n",
      "epoch 14 loss: 0.0928\n",
      "epoch 15 loss: 0.1020\n",
      "epoch 16 loss: 0.1040\n",
      "epoch 17 loss: 0.0714\n",
      "epoch 18 loss: 0.0681\n",
      "epoch 19 loss: 0.0987\n",
      "epoch 20 loss: 0.0987\n",
      "epoch 21 loss: 0.0690\n",
      "epoch 22 loss: 0.0702\n",
      "epoch 23 loss: 0.0761\n",
      "epoch 24 loss: 0.0674\n",
      "epoch 25 loss: 0.0652\n",
      "epoch 26 loss: 0.0540\n",
      "epoch 27 loss: 0.0754\n",
      "epoch 28 loss: 0.0661\n",
      "epoch 29 loss: 0.0744\n",
      "epoch 30 loss: 0.0918\n",
      "21\n",
      "epoch 1 loss: 0.8962\n",
      "epoch 2 loss: 0.9568\n",
      "epoch 3 loss: 0.6920\n",
      "epoch 4 loss: 0.2769\n",
      "epoch 5 loss: 0.1738\n",
      "epoch 6 loss: 0.1493\n",
      "epoch 7 loss: 0.1241\n",
      "epoch 8 loss: 0.1090\n",
      "epoch 9 loss: 0.1000\n",
      "epoch 10 loss: 0.1149\n",
      "epoch 11 loss: 0.0882\n",
      "epoch 12 loss: 0.0926\n",
      "epoch 13 loss: 0.0660\n",
      "epoch 14 loss: 0.0817\n",
      "epoch 15 loss: 0.0713\n",
      "epoch 16 loss: 0.0736\n",
      "epoch 17 loss: 0.0654\n",
      "epoch 18 loss: 0.0577\n",
      "epoch 19 loss: 0.1177\n",
      "epoch 20 loss: 0.0745\n",
      "epoch 21 loss: 0.0620\n",
      "epoch 22 loss: 0.0554\n",
      "epoch 23 loss: 0.0527\n",
      "epoch 24 loss: 0.0688\n",
      "epoch 25 loss: 0.0589\n",
      "epoch 26 loss: 0.0611\n",
      "epoch 27 loss: 0.0644\n",
      "epoch 28 loss: 0.0397\n",
      "epoch 29 loss: 0.0589\n",
      "epoch 30 loss: 0.0646\n",
      "22\n",
      "epoch 1 loss: 0.6194\n",
      "epoch 2 loss: 0.7525\n",
      "epoch 3 loss: 0.6865\n",
      "epoch 4 loss: 0.6779\n",
      "epoch 5 loss: 0.4779\n",
      "epoch 6 loss: 0.2391\n",
      "epoch 7 loss: 0.1706\n",
      "epoch 8 loss: 0.1431\n",
      "epoch 9 loss: 0.1029\n",
      "epoch 10 loss: 0.1131\n",
      "epoch 11 loss: 0.1336\n",
      "epoch 12 loss: 0.0876\n",
      "epoch 13 loss: 0.0728\n",
      "epoch 14 loss: 0.0703\n",
      "epoch 15 loss: 0.0712\n",
      "epoch 16 loss: 0.0669\n",
      "epoch 17 loss: 0.0757\n",
      "epoch 18 loss: 0.0824\n",
      "epoch 19 loss: 0.0985\n",
      "epoch 20 loss: 0.0623\n",
      "epoch 21 loss: 0.0703\n",
      "epoch 22 loss: 0.0658\n",
      "epoch 23 loss: 0.0675\n",
      "epoch 24 loss: 0.0642\n",
      "epoch 25 loss: 0.0486\n",
      "epoch 26 loss: 0.0637\n",
      "epoch 27 loss: 0.0657\n",
      "epoch 28 loss: 0.0625\n",
      "epoch 29 loss: 0.0504\n",
      "epoch 30 loss: 0.0627\n",
      "23\n",
      "epoch 1 loss: 0.6996\n",
      "epoch 2 loss: 0.7152\n",
      "epoch 3 loss: 0.6083\n",
      "epoch 4 loss: 0.4766\n",
      "epoch 5 loss: 0.2320\n",
      "epoch 6 loss: 0.2042\n",
      "epoch 7 loss: 0.1808\n",
      "epoch 8 loss: 0.1204\n",
      "epoch 9 loss: 0.1274\n",
      "epoch 10 loss: 0.1054\n",
      "epoch 11 loss: 0.0942\n",
      "epoch 12 loss: 0.0867\n",
      "epoch 13 loss: 0.1081\n",
      "epoch 14 loss: 0.0821\n",
      "epoch 15 loss: 0.0901\n",
      "epoch 16 loss: 0.0633\n",
      "epoch 17 loss: 0.0797\n",
      "epoch 18 loss: 0.0666\n",
      "epoch 19 loss: 0.0899\n",
      "epoch 20 loss: 0.0831\n",
      "epoch 21 loss: 0.1341\n",
      "epoch 22 loss: 0.0772\n",
      "epoch 23 loss: 0.0583\n",
      "epoch 24 loss: 0.0673\n",
      "epoch 25 loss: 0.0723\n",
      "epoch 26 loss: 0.0851\n",
      "epoch 27 loss: 0.0891\n",
      "epoch 28 loss: 0.0733\n",
      "epoch 29 loss: 0.0651\n",
      "epoch 30 loss: 0.0506\n",
      "24\n",
      "epoch 1 loss: 1.1409\n",
      "epoch 2 loss: 0.5388\n",
      "epoch 3 loss: 0.6421\n",
      "epoch 4 loss: 0.7143\n",
      "epoch 5 loss: 0.6242\n",
      "epoch 6 loss: 0.2242\n",
      "epoch 7 loss: 0.1822\n",
      "epoch 8 loss: 0.1511\n",
      "epoch 9 loss: 0.1553\n",
      "epoch 10 loss: 0.1357\n",
      "epoch 11 loss: 0.1300\n",
      "epoch 12 loss: 0.0994\n",
      "epoch 13 loss: 0.1200\n",
      "epoch 14 loss: 0.1151\n",
      "epoch 15 loss: 0.1026\n",
      "epoch 16 loss: 0.0933\n",
      "epoch 17 loss: 0.0769\n",
      "epoch 18 loss: 0.0810\n",
      "epoch 19 loss: 0.0889\n",
      "epoch 20 loss: 0.0863\n",
      "epoch 21 loss: 0.0995\n",
      "epoch 22 loss: 0.0846\n",
      "epoch 23 loss: 0.0626\n",
      "epoch 24 loss: 0.0809\n",
      "epoch 25 loss: 0.0656\n",
      "epoch 26 loss: 0.0545\n",
      "epoch 27 loss: 0.0604\n",
      "epoch 28 loss: 0.0503\n",
      "epoch 29 loss: 0.0742\n",
      "epoch 30 loss: 0.0691\n",
      "25\n",
      "epoch 1 loss: 1.1030\n",
      "epoch 2 loss: 0.5104\n",
      "epoch 3 loss: 0.3746\n",
      "epoch 4 loss: 0.3058\n",
      "epoch 5 loss: 0.2802\n",
      "epoch 6 loss: 0.1905\n",
      "epoch 7 loss: 0.1585\n",
      "epoch 8 loss: 0.1356\n",
      "epoch 9 loss: 0.1401\n",
      "epoch 10 loss: 0.1250\n",
      "epoch 11 loss: 0.1349\n",
      "epoch 12 loss: 0.1117\n",
      "epoch 13 loss: 0.1051\n",
      "epoch 14 loss: 0.1025\n",
      "epoch 15 loss: 0.0972\n",
      "epoch 16 loss: 0.0900\n",
      "epoch 17 loss: 0.0815\n",
      "epoch 18 loss: 0.0761\n",
      "epoch 19 loss: 0.0793\n",
      "epoch 20 loss: 0.0752\n",
      "epoch 21 loss: 0.0877\n",
      "epoch 22 loss: 0.0824\n",
      "epoch 23 loss: 0.0801\n",
      "epoch 24 loss: 0.0644\n",
      "epoch 25 loss: 0.0830\n",
      "epoch 26 loss: 0.0803\n",
      "epoch 27 loss: 0.0752\n",
      "epoch 28 loss: 0.0716\n",
      "epoch 29 loss: 0.0756\n",
      "epoch 30 loss: 0.0763\n",
      "26\n",
      "epoch 1 loss: 1.0019\n",
      "epoch 2 loss: 0.6633\n",
      "epoch 3 loss: 0.4727\n",
      "epoch 4 loss: 0.4849\n",
      "epoch 5 loss: 0.2507\n",
      "epoch 6 loss: 0.1388\n",
      "epoch 7 loss: 0.1399\n",
      "epoch 8 loss: 0.1064\n",
      "epoch 9 loss: 0.1210\n",
      "epoch 10 loss: 0.1329\n",
      "epoch 11 loss: 0.1121\n",
      "epoch 12 loss: 0.0873\n",
      "epoch 13 loss: 0.1036\n",
      "epoch 14 loss: 0.1030\n",
      "epoch 15 loss: 0.1187\n",
      "epoch 16 loss: 0.0805\n",
      "epoch 17 loss: 0.1105\n",
      "epoch 18 loss: 0.0975\n",
      "epoch 19 loss: 0.0868\n",
      "epoch 20 loss: 0.0576\n",
      "epoch 21 loss: 0.0612\n",
      "epoch 22 loss: 0.0565\n",
      "epoch 23 loss: 0.0741\n",
      "epoch 24 loss: 0.0828\n",
      "epoch 25 loss: 0.0813\n",
      "epoch 26 loss: 0.0810\n",
      "epoch 27 loss: 0.0640\n",
      "epoch 28 loss: 0.0704\n",
      "epoch 29 loss: 0.0606\n",
      "epoch 30 loss: 0.0574\n",
      "27\n",
      "epoch 1 loss: 0.8369\n",
      "epoch 2 loss: 0.6268\n",
      "epoch 3 loss: 0.4054\n",
      "epoch 4 loss: 0.2141\n",
      "epoch 5 loss: 0.1553\n",
      "epoch 6 loss: 0.1546\n",
      "epoch 7 loss: 0.1339\n",
      "epoch 8 loss: 0.1027\n",
      "epoch 9 loss: 0.1107\n",
      "epoch 10 loss: 0.0732\n",
      "epoch 11 loss: 0.0769\n",
      "epoch 12 loss: 0.0810\n",
      "epoch 13 loss: 0.1115\n",
      "epoch 14 loss: 0.0851\n",
      "epoch 15 loss: 0.0653\n",
      "epoch 16 loss: 0.0756\n",
      "epoch 17 loss: 0.0864\n",
      "epoch 18 loss: 0.0894\n",
      "epoch 19 loss: 0.0563\n",
      "epoch 20 loss: 0.1025\n",
      "epoch 21 loss: 0.0628\n",
      "epoch 22 loss: 0.0755\n",
      "epoch 23 loss: 0.0699\n",
      "epoch 24 loss: 0.0604\n",
      "epoch 25 loss: 0.0797\n",
      "epoch 26 loss: 0.0553\n",
      "epoch 27 loss: 0.0622\n",
      "epoch 28 loss: 0.0764\n",
      "epoch 29 loss: 0.0593\n",
      "epoch 30 loss: 0.0669\n",
      "28\n",
      "epoch 1 loss: 0.8949\n",
      "epoch 2 loss: 0.4223\n",
      "epoch 3 loss: 0.3093\n",
      "epoch 4 loss: 0.2296\n",
      "epoch 5 loss: 0.1777\n",
      "epoch 6 loss: 0.1757\n",
      "epoch 7 loss: 0.1443\n",
      "epoch 8 loss: 0.1354\n",
      "epoch 9 loss: 0.1452\n",
      "epoch 10 loss: 0.1589\n",
      "epoch 11 loss: 0.1299\n",
      "epoch 12 loss: 0.0991\n",
      "epoch 13 loss: 0.0796\n",
      "epoch 14 loss: 0.0719\n",
      "epoch 15 loss: 0.1081\n",
      "epoch 16 loss: 0.0878\n",
      "epoch 17 loss: 0.0757\n",
      "epoch 18 loss: 0.1294\n",
      "epoch 19 loss: 0.0853\n",
      "epoch 20 loss: 0.0505\n",
      "epoch 21 loss: 0.0543\n",
      "epoch 22 loss: 0.1202\n",
      "epoch 23 loss: 0.0547\n",
      "epoch 24 loss: 0.0677\n",
      "epoch 25 loss: 0.0554\n",
      "epoch 26 loss: 0.0705\n",
      "epoch 27 loss: 0.0553\n",
      "epoch 28 loss: 0.0805\n",
      "epoch 29 loss: 0.0772\n",
      "epoch 30 loss: 0.0700\n",
      "29\n",
      "epoch 1 loss: 0.8800\n",
      "epoch 2 loss: 0.7812\n",
      "epoch 3 loss: 0.4947\n",
      "epoch 4 loss: 1.1914\n",
      "epoch 5 loss: 0.6530\n",
      "epoch 6 loss: 0.9077\n",
      "epoch 7 loss: 0.8176\n",
      "epoch 8 loss: 0.9846\n",
      "epoch 9 loss: 0.4969\n",
      "epoch 10 loss: 0.2340\n",
      "epoch 11 loss: 0.2015\n",
      "epoch 12 loss: 0.1116\n",
      "epoch 13 loss: 0.1199\n",
      "epoch 14 loss: 0.1388\n",
      "epoch 15 loss: 0.0885\n",
      "epoch 16 loss: 0.1263\n",
      "epoch 17 loss: 0.1420\n",
      "epoch 18 loss: 0.0956\n",
      "epoch 19 loss: 0.1496\n",
      "epoch 20 loss: 0.0872\n",
      "epoch 21 loss: 0.1083\n",
      "epoch 22 loss: 0.0836\n",
      "epoch 23 loss: 0.0798\n",
      "epoch 24 loss: 0.0715\n",
      "epoch 25 loss: 0.0846\n",
      "epoch 26 loss: 0.0857\n",
      "epoch 27 loss: 0.0638\n",
      "epoch 28 loss: 0.0927\n",
      "epoch 29 loss: 0.0766\n",
      "epoch 30 loss: 0.0760\n",
      "30\n",
      "epoch 1 loss: 0.9722\n",
      "epoch 2 loss: 0.6838\n",
      "epoch 3 loss: 0.7317\n",
      "epoch 4 loss: 0.6473\n",
      "epoch 5 loss: 0.4729\n",
      "epoch 6 loss: 0.3157\n",
      "epoch 7 loss: 0.2519\n",
      "epoch 8 loss: 0.1854\n",
      "epoch 9 loss: 0.1548\n",
      "epoch 10 loss: 0.1317\n",
      "epoch 11 loss: 0.1190\n",
      "epoch 12 loss: 0.1387\n",
      "epoch 13 loss: 0.1185\n",
      "epoch 14 loss: 0.1170\n",
      "epoch 15 loss: 0.0828\n",
      "epoch 16 loss: 0.0820\n",
      "epoch 17 loss: 0.0806\n",
      "epoch 18 loss: 0.0692\n",
      "epoch 19 loss: 0.1014\n",
      "epoch 20 loss: 0.0822\n",
      "epoch 21 loss: 0.0712\n",
      "epoch 22 loss: 0.0560\n",
      "epoch 23 loss: 0.0663\n",
      "epoch 24 loss: 0.0773\n",
      "epoch 25 loss: 0.0728\n",
      "epoch 26 loss: 0.0559\n",
      "epoch 27 loss: 0.0677\n",
      "epoch 28 loss: 0.0837\n",
      "epoch 29 loss: 0.0588\n",
      "epoch 30 loss: 0.0601\n",
      "31\n",
      "epoch 1 loss: 0.7062\n",
      "epoch 2 loss: 0.5554\n",
      "epoch 3 loss: 0.4403\n",
      "epoch 4 loss: 0.3597\n",
      "epoch 5 loss: 0.2111\n",
      "epoch 6 loss: 0.1376\n",
      "epoch 7 loss: 0.1198\n",
      "epoch 8 loss: 0.0987\n",
      "epoch 9 loss: 0.1066\n",
      "epoch 10 loss: 0.0799\n",
      "epoch 11 loss: 0.1061\n",
      "epoch 12 loss: 0.0816\n",
      "epoch 13 loss: 0.1513\n",
      "epoch 14 loss: 0.0538\n",
      "epoch 15 loss: 0.0663\n",
      "epoch 16 loss: 0.0812\n",
      "epoch 17 loss: 0.0937\n",
      "epoch 18 loss: 0.0614\n",
      "epoch 19 loss: 0.0770\n",
      "epoch 20 loss: 0.0587\n",
      "epoch 21 loss: 0.0901\n",
      "epoch 22 loss: 0.0938\n",
      "epoch 23 loss: 0.0628\n",
      "epoch 24 loss: 0.0570\n",
      "epoch 25 loss: 0.0698\n",
      "epoch 26 loss: 0.0770\n",
      "epoch 27 loss: 0.0757\n",
      "epoch 28 loss: 0.0612\n",
      "epoch 29 loss: 0.0738\n",
      "epoch 30 loss: 0.0502\n",
      "32\n",
      "epoch 1 loss: 0.8268\n",
      "epoch 2 loss: 0.7698\n",
      "epoch 3 loss: 0.4730\n",
      "epoch 4 loss: 0.2787\n",
      "epoch 5 loss: 0.2230\n",
      "epoch 6 loss: 0.1782\n",
      "epoch 7 loss: 0.1376\n",
      "epoch 8 loss: 0.1446\n",
      "epoch 9 loss: 0.1210\n",
      "epoch 10 loss: 0.1190\n",
      "epoch 11 loss: 0.0970\n",
      "epoch 12 loss: 0.0930\n",
      "epoch 13 loss: 0.0749\n",
      "epoch 14 loss: 0.1321\n",
      "epoch 15 loss: 0.1015\n",
      "epoch 16 loss: 0.0951\n",
      "epoch 17 loss: 0.1052\n",
      "epoch 18 loss: 0.0884\n",
      "epoch 19 loss: 0.0681\n",
      "epoch 20 loss: 0.0692\n",
      "epoch 21 loss: 0.0647\n",
      "epoch 22 loss: 0.0594\n",
      "epoch 23 loss: 0.0767\n",
      "epoch 24 loss: 0.0882\n",
      "epoch 25 loss: 0.0678\n",
      "epoch 26 loss: 0.0650\n",
      "epoch 27 loss: 0.0580\n",
      "epoch 28 loss: 0.0595\n",
      "epoch 29 loss: 0.0597\n",
      "epoch 30 loss: 0.0812\n",
      "33\n",
      "epoch 1 loss: 1.0768\n",
      "epoch 2 loss: 0.8951\n",
      "epoch 3 loss: 0.5784\n",
      "epoch 4 loss: 0.5006\n",
      "epoch 5 loss: 0.3513\n",
      "epoch 6 loss: 0.2272\n",
      "epoch 7 loss: 0.1771\n",
      "epoch 8 loss: 0.1561\n",
      "epoch 9 loss: 0.1391\n",
      "epoch 10 loss: 0.0999\n",
      "epoch 11 loss: 0.1263\n",
      "epoch 12 loss: 0.1394\n",
      "epoch 13 loss: 0.1005\n",
      "epoch 14 loss: 0.0768\n",
      "epoch 15 loss: 0.1151\n",
      "epoch 16 loss: 0.0927\n",
      "epoch 17 loss: 0.0807\n",
      "epoch 18 loss: 0.0862\n",
      "epoch 19 loss: 0.0723\n",
      "epoch 20 loss: 0.0844\n",
      "epoch 21 loss: 0.0757\n",
      "epoch 22 loss: 0.0839\n",
      "epoch 23 loss: 0.0768\n",
      "epoch 24 loss: 0.0852\n",
      "epoch 25 loss: 0.0908\n",
      "epoch 26 loss: 0.0592\n",
      "epoch 27 loss: 0.0891\n",
      "epoch 28 loss: 0.0680\n",
      "epoch 29 loss: 0.0605\n",
      "epoch 30 loss: 0.0641\n",
      "34\n",
      "epoch 1 loss: 1.0195\n",
      "epoch 2 loss: 0.6203\n",
      "epoch 3 loss: 0.8051\n",
      "epoch 4 loss: 0.5139\n",
      "epoch 5 loss: 0.4658\n",
      "epoch 6 loss: 0.5351\n",
      "epoch 7 loss: 0.2650\n",
      "epoch 8 loss: 0.2518\n",
      "epoch 9 loss: 0.1871\n",
      "epoch 10 loss: 0.1601\n",
      "epoch 11 loss: 0.1625\n",
      "epoch 12 loss: 0.1329\n",
      "epoch 13 loss: 0.1399\n",
      "epoch 14 loss: 0.1144\n",
      "epoch 15 loss: 0.1196\n",
      "epoch 16 loss: 0.1222\n",
      "epoch 17 loss: 0.1319\n",
      "epoch 18 loss: 0.1320\n",
      "epoch 19 loss: 0.1053\n",
      "epoch 20 loss: 0.1032\n",
      "epoch 21 loss: 0.1159\n",
      "epoch 22 loss: 0.1019\n",
      "epoch 23 loss: 0.0866\n",
      "epoch 24 loss: 0.1067\n",
      "epoch 25 loss: 0.1045\n",
      "epoch 26 loss: 0.0904\n",
      "epoch 27 loss: 0.0896\n",
      "epoch 28 loss: 0.1015\n",
      "epoch 29 loss: 0.1094\n",
      "epoch 30 loss: 0.0891\n",
      "35\n",
      "epoch 1 loss: 0.9529\n",
      "epoch 2 loss: 0.6805\n",
      "epoch 3 loss: 0.6481\n",
      "epoch 4 loss: 0.5870\n",
      "epoch 5 loss: 0.3770\n",
      "epoch 6 loss: 0.3030\n",
      "epoch 7 loss: 0.2284\n",
      "epoch 8 loss: 0.1288\n",
      "epoch 9 loss: 0.1275\n",
      "epoch 10 loss: 0.1396\n",
      "epoch 11 loss: 0.1076\n",
      "epoch 12 loss: 0.0915\n",
      "epoch 13 loss: 0.0844\n",
      "epoch 14 loss: 0.1169\n",
      "epoch 15 loss: 0.0956\n",
      "epoch 16 loss: 0.0736\n",
      "epoch 17 loss: 0.0959\n",
      "epoch 18 loss: 0.0688\n",
      "epoch 19 loss: 0.0841\n",
      "epoch 20 loss: 0.0736\n",
      "epoch 21 loss: 0.0627\n",
      "epoch 22 loss: 0.0900\n",
      "epoch 23 loss: 0.0652\n",
      "epoch 24 loss: 0.0752\n",
      "epoch 25 loss: 0.0657\n",
      "epoch 26 loss: 0.0742\n",
      "epoch 27 loss: 0.0557\n",
      "epoch 28 loss: 0.0529\n",
      "epoch 29 loss: 0.0545\n",
      "epoch 30 loss: 0.0597\n",
      "36\n",
      "epoch 1 loss: 0.9520\n",
      "epoch 2 loss: 0.5769\n",
      "epoch 3 loss: 0.4313\n",
      "epoch 4 loss: 0.4736\n",
      "epoch 5 loss: 0.2661\n",
      "epoch 6 loss: 0.1968\n",
      "epoch 7 loss: 0.1643\n",
      "epoch 8 loss: 0.1457\n",
      "epoch 9 loss: 0.1188\n",
      "epoch 10 loss: 0.0932\n",
      "epoch 11 loss: 0.1013\n",
      "epoch 12 loss: 0.0874\n",
      "epoch 13 loss: 0.1037\n",
      "epoch 14 loss: 0.0817\n",
      "epoch 15 loss: 0.0776\n",
      "epoch 16 loss: 0.0874\n",
      "epoch 17 loss: 0.0627\n",
      "epoch 18 loss: 0.1061\n",
      "epoch 19 loss: 0.0727\n",
      "epoch 20 loss: 0.0920\n",
      "epoch 21 loss: 0.0700\n",
      "epoch 22 loss: 0.0820\n",
      "epoch 23 loss: 0.0646\n",
      "epoch 24 loss: 0.0539\n",
      "epoch 25 loss: 0.0868\n",
      "epoch 26 loss: 0.0601\n",
      "epoch 27 loss: 0.0533\n",
      "epoch 28 loss: 0.0584\n",
      "epoch 29 loss: 0.0809\n",
      "epoch 30 loss: 0.0669\n",
      "37\n",
      "epoch 1 loss: 1.0409\n",
      "epoch 2 loss: 0.6936\n",
      "epoch 3 loss: 0.5950\n",
      "epoch 4 loss: 0.3481\n",
      "epoch 5 loss: 0.2895\n",
      "epoch 6 loss: 0.1770\n",
      "epoch 7 loss: 0.1084\n",
      "epoch 8 loss: 0.1134\n",
      "epoch 9 loss: 0.1220\n",
      "epoch 10 loss: 0.1160\n",
      "epoch 11 loss: 0.1083\n",
      "epoch 12 loss: 0.0855\n",
      "epoch 13 loss: 0.0701\n",
      "epoch 14 loss: 0.0988\n",
      "epoch 15 loss: 0.0665\n",
      "epoch 16 loss: 0.0995\n",
      "epoch 17 loss: 0.0788\n",
      "epoch 18 loss: 0.1064\n",
      "epoch 19 loss: 0.1033\n",
      "epoch 20 loss: 0.1328\n",
      "epoch 21 loss: 0.0643\n",
      "epoch 22 loss: 0.0713\n",
      "epoch 23 loss: 0.0803\n",
      "epoch 24 loss: 0.0722\n",
      "epoch 25 loss: 0.0777\n",
      "epoch 26 loss: 0.0653\n",
      "epoch 27 loss: 0.0787\n",
      "epoch 28 loss: 0.0773\n",
      "epoch 29 loss: 0.0582\n",
      "epoch 30 loss: 0.0603\n",
      "38\n",
      "epoch 1 loss: 0.8329\n",
      "epoch 2 loss: 0.6818\n",
      "epoch 3 loss: 0.5693\n",
      "epoch 4 loss: 0.2743\n",
      "epoch 5 loss: 0.2285\n",
      "epoch 6 loss: 0.1436\n",
      "epoch 7 loss: 0.1135\n",
      "epoch 8 loss: 0.1470\n",
      "epoch 9 loss: 0.1236\n",
      "epoch 10 loss: 0.1017\n",
      "epoch 11 loss: 0.1138\n",
      "epoch 12 loss: 0.1493\n",
      "epoch 13 loss: 0.1061\n",
      "epoch 14 loss: 0.0912\n",
      "epoch 15 loss: 0.0802\n",
      "epoch 16 loss: 0.1179\n",
      "epoch 17 loss: 0.0690\n",
      "epoch 18 loss: 0.0919\n",
      "epoch 19 loss: 0.1049\n",
      "epoch 20 loss: 0.0757\n",
      "epoch 21 loss: 0.1054\n",
      "epoch 22 loss: 0.0832\n",
      "epoch 23 loss: 0.0918\n",
      "epoch 24 loss: 0.0827\n",
      "epoch 25 loss: 0.0826\n",
      "epoch 26 loss: 0.0821\n",
      "epoch 27 loss: 0.0694\n",
      "epoch 28 loss: 0.0617\n",
      "epoch 29 loss: 0.0780\n",
      "epoch 30 loss: 0.0542\n",
      "39\n",
      "epoch 1 loss: 0.9963\n",
      "epoch 2 loss: 0.6400\n",
      "epoch 3 loss: 0.8296\n",
      "epoch 4 loss: 0.5663\n",
      "epoch 5 loss: 0.4264\n",
      "epoch 6 loss: 0.2472\n",
      "epoch 7 loss: 0.1633\n",
      "epoch 8 loss: 0.1612\n",
      "epoch 9 loss: 0.1299\n",
      "epoch 10 loss: 0.1251\n",
      "epoch 11 loss: 0.1307\n",
      "epoch 12 loss: 0.0872\n",
      "epoch 13 loss: 0.0850\n",
      "epoch 14 loss: 0.1337\n",
      "epoch 15 loss: 0.0967\n",
      "epoch 16 loss: 0.0843\n",
      "epoch 17 loss: 0.1060\n",
      "epoch 18 loss: 0.0847\n",
      "epoch 19 loss: 0.1519\n",
      "epoch 20 loss: 0.0723\n",
      "epoch 21 loss: 0.0805\n",
      "epoch 22 loss: 0.0738\n",
      "epoch 23 loss: 0.0728\n",
      "epoch 24 loss: 0.0707\n",
      "epoch 25 loss: 0.0773\n",
      "epoch 26 loss: 0.0717\n",
      "epoch 27 loss: 0.0870\n",
      "epoch 28 loss: 0.0649\n",
      "epoch 29 loss: 0.0659\n",
      "epoch 30 loss: 0.0721\n",
      "40\n",
      "epoch 1 loss: 0.8637\n",
      "epoch 2 loss: 0.7761\n",
      "epoch 3 loss: 0.7485\n",
      "epoch 4 loss: 0.4220\n",
      "epoch 5 loss: 0.2988\n",
      "epoch 6 loss: 0.1629\n",
      "epoch 7 loss: 0.1180\n",
      "epoch 8 loss: 0.1584\n",
      "epoch 9 loss: 0.1292\n",
      "epoch 10 loss: 0.1380\n",
      "epoch 11 loss: 0.1189\n",
      "epoch 12 loss: 0.0952\n",
      "epoch 13 loss: 0.0909\n",
      "epoch 14 loss: 0.0951\n",
      "epoch 15 loss: 0.1184\n",
      "epoch 16 loss: 0.1256\n",
      "epoch 17 loss: 0.0925\n",
      "epoch 18 loss: 0.0950\n",
      "epoch 19 loss: 0.1781\n",
      "epoch 20 loss: 0.0925\n",
      "epoch 21 loss: 0.0792\n",
      "epoch 22 loss: 0.0991\n",
      "epoch 23 loss: 0.0927\n",
      "epoch 24 loss: 0.0818\n",
      "epoch 25 loss: 0.0851\n",
      "epoch 26 loss: 0.0739\n",
      "epoch 27 loss: 0.0652\n",
      "epoch 28 loss: 0.0832\n",
      "epoch 29 loss: 0.0821\n",
      "epoch 30 loss: 0.0754\n",
      "41\n",
      "epoch 1 loss: 0.8438\n",
      "epoch 2 loss: 0.6189\n",
      "epoch 3 loss: 0.5884\n",
      "epoch 4 loss: 0.5588\n",
      "epoch 5 loss: 0.4127\n",
      "epoch 6 loss: 0.2418\n",
      "epoch 7 loss: 0.1347\n",
      "epoch 8 loss: 0.1542\n",
      "epoch 9 loss: 0.1350\n",
      "epoch 10 loss: 0.1299\n",
      "epoch 11 loss: 0.0770\n",
      "epoch 12 loss: 0.0903\n",
      "epoch 13 loss: 0.1022\n",
      "epoch 14 loss: 0.0871\n",
      "epoch 15 loss: 0.0754\n",
      "epoch 16 loss: 0.0808\n",
      "epoch 17 loss: 0.0908\n",
      "epoch 18 loss: 0.0888\n",
      "epoch 19 loss: 0.0844\n",
      "epoch 20 loss: 0.0824\n",
      "epoch 21 loss: 0.0703\n",
      "epoch 22 loss: 0.0889\n",
      "epoch 23 loss: 0.0642\n",
      "epoch 24 loss: 0.0926\n",
      "epoch 25 loss: 0.0822\n",
      "epoch 26 loss: 0.0600\n",
      "epoch 27 loss: 0.0614\n",
      "epoch 28 loss: 0.0579\n",
      "epoch 29 loss: 0.0690\n",
      "epoch 30 loss: 0.0524\n",
      "42\n",
      "epoch 1 loss: 0.8158\n",
      "epoch 2 loss: 0.4958\n",
      "epoch 3 loss: 0.6725\n",
      "epoch 4 loss: 0.4250\n",
      "epoch 5 loss: 0.3320\n",
      "epoch 6 loss: 0.2115\n",
      "epoch 7 loss: 0.1774\n",
      "epoch 8 loss: 0.1388\n",
      "epoch 9 loss: 0.1311\n",
      "epoch 10 loss: 0.1125\n",
      "epoch 11 loss: 0.0955\n",
      "epoch 12 loss: 0.0848\n",
      "epoch 13 loss: 0.0977\n",
      "epoch 14 loss: 0.0915\n",
      "epoch 15 loss: 0.0757\n",
      "epoch 16 loss: 0.0866\n",
      "epoch 17 loss: 0.0977\n",
      "epoch 18 loss: 0.1029\n",
      "epoch 19 loss: 0.0749\n",
      "epoch 20 loss: 0.0868\n",
      "epoch 21 loss: 0.0625\n",
      "epoch 22 loss: 0.0580\n",
      "epoch 23 loss: 0.0660\n",
      "epoch 24 loss: 0.0983\n",
      "epoch 25 loss: 0.0918\n",
      "epoch 26 loss: 0.0592\n",
      "epoch 27 loss: 0.0636\n",
      "epoch 28 loss: 0.0596\n",
      "epoch 29 loss: 0.0738\n",
      "epoch 30 loss: 0.0536\n",
      "43\n",
      "epoch 1 loss: 0.9844\n",
      "epoch 2 loss: 0.6101\n",
      "epoch 3 loss: 0.5067\n",
      "epoch 4 loss: 0.4142\n",
      "epoch 5 loss: 0.4185\n",
      "epoch 6 loss: 0.3059\n",
      "epoch 7 loss: 0.2426\n",
      "epoch 8 loss: 0.2127\n",
      "epoch 9 loss: 0.2058\n",
      "epoch 10 loss: 0.1758\n",
      "epoch 11 loss: 0.1592\n",
      "epoch 12 loss: 0.1109\n",
      "epoch 13 loss: 0.1041\n",
      "epoch 14 loss: 0.1322\n",
      "epoch 15 loss: 0.1571\n",
      "epoch 16 loss: 0.0973\n",
      "epoch 17 loss: 0.1082\n",
      "epoch 18 loss: 0.0960\n",
      "epoch 19 loss: 0.1210\n",
      "epoch 20 loss: 0.1158\n",
      "epoch 21 loss: 0.1008\n",
      "epoch 22 loss: 0.0824\n",
      "epoch 23 loss: 0.0899\n",
      "epoch 24 loss: 0.0714\n",
      "epoch 25 loss: 0.0495\n",
      "epoch 26 loss: 0.0859\n",
      "epoch 27 loss: 0.0886\n",
      "epoch 28 loss: 0.0756\n",
      "epoch 29 loss: 0.0590\n",
      "epoch 30 loss: 0.0784\n",
      "44\n",
      "epoch 1 loss: 0.8751\n",
      "epoch 2 loss: 0.6180\n",
      "epoch 3 loss: 0.5280\n",
      "epoch 4 loss: 0.2849\n",
      "epoch 5 loss: 0.2624\n",
      "epoch 6 loss: 0.1976\n",
      "epoch 7 loss: 0.1580\n",
      "epoch 8 loss: 0.1643\n",
      "epoch 9 loss: 0.1177\n",
      "epoch 10 loss: 0.1370\n",
      "epoch 11 loss: 0.1057\n",
      "epoch 12 loss: 0.1202\n",
      "epoch 13 loss: 0.1016\n",
      "epoch 14 loss: 0.0956\n",
      "epoch 15 loss: 0.1304\n",
      "epoch 16 loss: 0.1123\n",
      "epoch 17 loss: 0.0772\n",
      "epoch 18 loss: 0.0765\n",
      "epoch 19 loss: 0.0827\n",
      "epoch 20 loss: 0.0801\n",
      "epoch 21 loss: 0.0689\n",
      "epoch 22 loss: 0.0801\n",
      "epoch 23 loss: 0.0663\n",
      "epoch 24 loss: 0.0778\n",
      "epoch 25 loss: 0.0677\n",
      "epoch 26 loss: 0.0767\n",
      "epoch 27 loss: 0.0635\n",
      "epoch 28 loss: 0.0687\n",
      "epoch 29 loss: 0.0602\n",
      "epoch 30 loss: 0.0728\n",
      "45\n",
      "epoch 1 loss: 0.9057\n",
      "epoch 2 loss: 0.5730\n",
      "epoch 3 loss: 0.3690\n",
      "epoch 4 loss: 0.2467\n",
      "epoch 5 loss: 0.2734\n",
      "epoch 6 loss: 0.2178\n",
      "epoch 7 loss: 0.1205\n",
      "epoch 8 loss: 0.1336\n",
      "epoch 9 loss: 0.1170\n",
      "epoch 10 loss: 0.1158\n",
      "epoch 11 loss: 0.0951\n",
      "epoch 12 loss: 0.1051\n",
      "epoch 13 loss: 0.0633\n",
      "epoch 14 loss: 0.0986\n",
      "epoch 15 loss: 0.1418\n",
      "epoch 16 loss: 0.0816\n",
      "epoch 17 loss: 0.0763\n",
      "epoch 18 loss: 0.0682\n",
      "epoch 19 loss: 0.0891\n",
      "epoch 20 loss: 0.0973\n",
      "epoch 21 loss: 0.1450\n",
      "epoch 22 loss: 0.0737\n",
      "epoch 23 loss: 0.0776\n",
      "epoch 24 loss: 0.0743\n",
      "epoch 25 loss: 0.0799\n",
      "epoch 26 loss: 0.1011\n",
      "epoch 27 loss: 0.0628\n",
      "epoch 28 loss: 0.0635\n",
      "epoch 29 loss: 0.0602\n",
      "epoch 30 loss: 0.0716\n",
      "46\n",
      "epoch 1 loss: 0.7771\n",
      "epoch 2 loss: 0.5732\n",
      "epoch 3 loss: 0.6156\n",
      "epoch 4 loss: 0.3546\n",
      "epoch 5 loss: 0.2072\n",
      "epoch 6 loss: 0.1676\n",
      "epoch 7 loss: 0.1379\n",
      "epoch 8 loss: 0.1215\n",
      "epoch 9 loss: 0.1584\n",
      "epoch 10 loss: 0.1595\n",
      "epoch 11 loss: 0.1310\n",
      "epoch 12 loss: 0.0962\n",
      "epoch 13 loss: 0.0885\n",
      "epoch 14 loss: 0.0997\n",
      "epoch 15 loss: 0.0711\n",
      "epoch 16 loss: 0.0988\n",
      "epoch 17 loss: 0.0781\n",
      "epoch 18 loss: 0.0740\n",
      "epoch 19 loss: 0.0637\n",
      "epoch 20 loss: 0.0902\n",
      "epoch 21 loss: 0.0832\n",
      "epoch 22 loss: 0.0677\n",
      "epoch 23 loss: 0.0640\n",
      "epoch 24 loss: 0.0590\n",
      "epoch 25 loss: 0.0584\n",
      "epoch 26 loss: 0.0612\n",
      "epoch 27 loss: 0.0702\n",
      "epoch 28 loss: 0.1046\n",
      "epoch 29 loss: 0.0663\n",
      "epoch 30 loss: 0.0555\n",
      "47\n",
      "epoch 1 loss: 1.0261\n",
      "epoch 2 loss: 0.6012\n",
      "epoch 3 loss: 0.4029\n",
      "epoch 4 loss: 0.3403\n",
      "epoch 5 loss: 0.2413\n",
      "epoch 6 loss: 0.1455\n",
      "epoch 7 loss: 0.1370\n",
      "epoch 8 loss: 0.1302\n",
      "epoch 9 loss: 0.1325\n",
      "epoch 10 loss: 0.1333\n",
      "epoch 11 loss: 0.1426\n",
      "epoch 12 loss: 0.1079\n",
      "epoch 13 loss: 0.1155\n",
      "epoch 14 loss: 0.1119\n",
      "epoch 15 loss: 0.1215\n",
      "epoch 16 loss: 0.0762\n",
      "epoch 17 loss: 0.0810\n",
      "epoch 18 loss: 0.0696\n",
      "epoch 19 loss: 0.0625\n",
      "epoch 20 loss: 0.0843\n",
      "epoch 21 loss: 0.0828\n",
      "epoch 22 loss: 0.0648\n",
      "epoch 23 loss: 0.0847\n",
      "epoch 24 loss: 0.0632\n",
      "epoch 25 loss: 0.0806\n",
      "epoch 26 loss: 0.0656\n",
      "epoch 27 loss: 0.0697\n",
      "epoch 28 loss: 0.0580\n",
      "epoch 29 loss: 0.0577\n",
      "epoch 30 loss: 0.0750\n",
      "48\n",
      "epoch 1 loss: 1.1564\n",
      "epoch 2 loss: 0.7347\n",
      "epoch 3 loss: 0.4600\n",
      "epoch 4 loss: 0.4195\n",
      "epoch 5 loss: 1.1544\n",
      "epoch 6 loss: 0.3715\n",
      "epoch 7 loss: 0.2775\n",
      "epoch 8 loss: 0.2160\n",
      "epoch 9 loss: 0.1817\n",
      "epoch 10 loss: 0.1371\n",
      "epoch 11 loss: 0.1207\n",
      "epoch 12 loss: 0.1190\n",
      "epoch 13 loss: 0.1377\n",
      "epoch 14 loss: 0.0930\n",
      "epoch 15 loss: 0.1103\n",
      "epoch 16 loss: 0.0964\n",
      "epoch 17 loss: 0.0861\n",
      "epoch 18 loss: 0.0779\n",
      "epoch 19 loss: 0.0761\n",
      "epoch 20 loss: 0.0727\n",
      "epoch 21 loss: 0.0692\n",
      "epoch 22 loss: 0.0894\n",
      "epoch 23 loss: 0.0633\n",
      "epoch 24 loss: 0.0877\n",
      "epoch 25 loss: 0.0908\n",
      "epoch 26 loss: 0.0879\n",
      "epoch 27 loss: 0.0933\n",
      "epoch 28 loss: 0.0887\n",
      "epoch 29 loss: 0.0724\n",
      "epoch 30 loss: 0.0878\n",
      "49\n",
      "epoch 1 loss: 0.7002\n",
      "epoch 2 loss: 0.5776\n",
      "epoch 3 loss: 0.4718\n",
      "epoch 4 loss: 0.6695\n",
      "epoch 5 loss: 0.3623\n",
      "epoch 6 loss: 0.2009\n",
      "epoch 7 loss: 0.1436\n",
      "epoch 8 loss: 0.1380\n",
      "epoch 9 loss: 0.1388\n",
      "epoch 10 loss: 0.1150\n",
      "epoch 11 loss: 0.1131\n",
      "epoch 12 loss: 0.0678\n",
      "epoch 13 loss: 0.1063\n",
      "epoch 14 loss: 0.0937\n",
      "epoch 15 loss: 0.0762\n",
      "epoch 16 loss: 0.1012\n",
      "epoch 17 loss: 0.0889\n",
      "epoch 18 loss: 0.0635\n",
      "epoch 19 loss: 0.0673\n",
      "epoch 20 loss: 0.0759\n",
      "epoch 21 loss: 0.0850\n",
      "epoch 22 loss: 0.0761\n",
      "epoch 23 loss: 0.0754\n",
      "epoch 24 loss: 0.0729\n",
      "epoch 25 loss: 0.0721\n",
      "epoch 26 loss: 0.0629\n",
      "epoch 27 loss: 0.0919\n",
      "epoch 28 loss: 0.0705\n",
      "epoch 29 loss: 0.0621\n",
      "epoch 30 loss: 0.0634\n",
      "50\n",
      "epoch 1 loss: 0.7289\n",
      "epoch 2 loss: 0.3913\n",
      "epoch 3 loss: 0.4307\n",
      "epoch 4 loss: 0.3650\n",
      "epoch 5 loss: 0.2448\n",
      "epoch 6 loss: 0.1517\n",
      "epoch 7 loss: 0.1484\n",
      "epoch 8 loss: 0.1117\n",
      "epoch 9 loss: 0.0883\n",
      "epoch 10 loss: 0.1022\n",
      "epoch 11 loss: 0.1094\n",
      "epoch 12 loss: 0.0929\n",
      "epoch 13 loss: 0.0738\n",
      "epoch 14 loss: 0.1117\n",
      "epoch 15 loss: 0.0862\n",
      "epoch 16 loss: 0.0994\n",
      "epoch 17 loss: 0.0486\n",
      "epoch 18 loss: 0.0764\n",
      "epoch 19 loss: 0.0706\n",
      "epoch 20 loss: 0.0659\n",
      "epoch 21 loss: 0.0798\n",
      "epoch 22 loss: 0.1245\n",
      "epoch 23 loss: 0.0896\n",
      "epoch 24 loss: 0.0676\n",
      "epoch 25 loss: 0.0709\n",
      "epoch 26 loss: 0.0823\n",
      "epoch 27 loss: 0.0580\n",
      "epoch 28 loss: 0.0785\n",
      "epoch 29 loss: 0.0499\n",
      "epoch 30 loss: 0.0985\n",
      "51\n",
      "epoch 1 loss: 1.2386\n",
      "epoch 2 loss: 0.6960\n",
      "epoch 3 loss: 0.4651\n",
      "epoch 4 loss: 0.4196\n",
      "epoch 5 loss: 0.3974\n",
      "epoch 6 loss: 0.3057\n",
      "epoch 7 loss: 0.2115\n",
      "epoch 8 loss: 0.1466\n",
      "epoch 9 loss: 0.1663\n",
      "epoch 10 loss: 0.1133\n",
      "epoch 11 loss: 0.1181\n",
      "epoch 12 loss: 0.1420\n",
      "epoch 13 loss: 0.1267\n",
      "epoch 14 loss: 0.1206\n",
      "epoch 15 loss: 0.1138\n",
      "epoch 16 loss: 0.0881\n",
      "epoch 17 loss: 0.0726\n",
      "epoch 18 loss: 0.0726\n",
      "epoch 19 loss: 0.0792\n",
      "epoch 20 loss: 0.0674\n",
      "epoch 21 loss: 0.0755\n",
      "epoch 22 loss: 0.0734\n",
      "epoch 23 loss: 0.0792\n",
      "epoch 24 loss: 0.0810\n",
      "epoch 25 loss: 0.0678\n",
      "epoch 26 loss: 0.0741\n",
      "epoch 27 loss: 0.0775\n",
      "epoch 28 loss: 0.0921\n",
      "epoch 29 loss: 0.0629\n",
      "epoch 30 loss: 0.0810\n",
      "52\n",
      "epoch 1 loss: 0.6373\n",
      "epoch 2 loss: 0.4877\n",
      "epoch 3 loss: 0.3554\n",
      "epoch 4 loss: 0.3924\n",
      "epoch 5 loss: 0.2703\n",
      "epoch 6 loss: 0.1573\n",
      "epoch 7 loss: 0.1370\n",
      "epoch 8 loss: 0.1249\n",
      "epoch 9 loss: 0.1172\n",
      "epoch 10 loss: 0.0938\n",
      "epoch 11 loss: 0.1022\n",
      "epoch 12 loss: 0.1048\n",
      "epoch 13 loss: 0.0907\n",
      "epoch 14 loss: 0.0987\n",
      "epoch 15 loss: 0.0651\n",
      "epoch 16 loss: 0.0710\n",
      "epoch 17 loss: 0.0796\n",
      "epoch 18 loss: 0.0675\n",
      "epoch 19 loss: 0.0835\n",
      "epoch 20 loss: 0.0721\n",
      "epoch 21 loss: 0.0758\n",
      "epoch 22 loss: 0.0747\n",
      "epoch 23 loss: 0.0624\n",
      "epoch 24 loss: 0.0691\n",
      "epoch 25 loss: 0.0668\n",
      "epoch 26 loss: 0.0731\n",
      "epoch 27 loss: 0.0701\n",
      "epoch 28 loss: 0.0751\n",
      "epoch 29 loss: 0.0644\n",
      "epoch 30 loss: 0.0567\n",
      "53\n",
      "epoch 1 loss: 0.8467\n",
      "epoch 2 loss: 0.5936\n",
      "epoch 3 loss: 0.3185\n",
      "epoch 4 loss: 0.1906\n",
      "epoch 5 loss: 0.1419\n",
      "epoch 6 loss: 0.1758\n",
      "epoch 7 loss: 0.1510\n",
      "epoch 8 loss: 0.1390\n",
      "epoch 9 loss: 0.1154\n",
      "epoch 10 loss: 0.1234\n",
      "epoch 11 loss: 0.1071\n",
      "epoch 12 loss: 0.1682\n",
      "epoch 13 loss: 0.0882\n",
      "epoch 14 loss: 0.1068\n",
      "epoch 15 loss: 0.0861\n",
      "epoch 16 loss: 0.0907\n",
      "epoch 17 loss: 0.1033\n",
      "epoch 18 loss: 0.0881\n",
      "epoch 19 loss: 0.0972\n",
      "epoch 20 loss: 0.1042\n",
      "epoch 21 loss: 0.0694\n",
      "epoch 22 loss: 0.0829\n",
      "epoch 23 loss: 0.0670\n",
      "epoch 24 loss: 0.0780\n",
      "epoch 25 loss: 0.0814\n",
      "epoch 26 loss: 0.0577\n",
      "epoch 27 loss: 0.0721\n",
      "epoch 28 loss: 0.0719\n",
      "epoch 29 loss: 0.0661\n",
      "epoch 30 loss: 0.0926\n",
      "54\n",
      "epoch 1 loss: 0.8427\n",
      "epoch 2 loss: 0.6498\n",
      "epoch 3 loss: 0.7289\n",
      "epoch 4 loss: 0.4914\n",
      "epoch 5 loss: 0.3391\n",
      "epoch 6 loss: 0.3369\n",
      "epoch 7 loss: 0.2086\n",
      "epoch 8 loss: 0.1926\n",
      "epoch 9 loss: 0.2172\n",
      "epoch 10 loss: 0.1422\n",
      "epoch 11 loss: 0.1273\n",
      "epoch 12 loss: 0.1121\n",
      "epoch 13 loss: 0.1266\n",
      "epoch 14 loss: 0.1291\n",
      "epoch 15 loss: 0.1076\n",
      "epoch 16 loss: 0.1317\n",
      "epoch 17 loss: 0.1141\n",
      "epoch 18 loss: 0.1282\n",
      "epoch 19 loss: 0.0835\n",
      "epoch 20 loss: 0.0788\n",
      "epoch 21 loss: 0.0830\n",
      "epoch 22 loss: 0.0595\n",
      "epoch 23 loss: 0.1047\n",
      "epoch 24 loss: 0.0916\n",
      "epoch 25 loss: 0.0774\n",
      "epoch 26 loss: 0.0580\n",
      "epoch 27 loss: 0.0663\n",
      "epoch 28 loss: 0.0831\n",
      "epoch 29 loss: 0.0687\n",
      "epoch 30 loss: 0.0666\n",
      "55\n",
      "epoch 1 loss: 1.0455\n",
      "epoch 2 loss: 0.7110\n",
      "epoch 3 loss: 0.4150\n",
      "epoch 4 loss: 0.2764\n",
      "epoch 5 loss: 0.2060\n",
      "epoch 6 loss: 0.1668\n",
      "epoch 7 loss: 0.1658\n",
      "epoch 8 loss: 0.1536\n",
      "epoch 9 loss: 0.1339\n",
      "epoch 10 loss: 0.1577\n",
      "epoch 11 loss: 0.0905\n",
      "epoch 12 loss: 0.1089\n",
      "epoch 13 loss: 0.1383\n",
      "epoch 14 loss: 0.0792\n",
      "epoch 15 loss: 0.1016\n",
      "epoch 16 loss: 0.0847\n",
      "epoch 17 loss: 0.0959\n",
      "epoch 18 loss: 0.0862\n",
      "epoch 19 loss: 0.1000\n",
      "epoch 20 loss: 0.0726\n",
      "epoch 21 loss: 0.0677\n",
      "epoch 22 loss: 0.0732\n",
      "epoch 23 loss: 0.0762\n",
      "epoch 24 loss: 0.0818\n",
      "epoch 25 loss: 0.0727\n",
      "epoch 26 loss: 0.0533\n",
      "epoch 27 loss: 0.0565\n",
      "epoch 28 loss: 0.0559\n",
      "epoch 29 loss: 0.0639\n",
      "epoch 30 loss: 0.0618\n",
      "56\n",
      "epoch 1 loss: 1.0160\n",
      "epoch 2 loss: 0.6403\n",
      "epoch 3 loss: 0.8166\n",
      "epoch 4 loss: 0.4797\n",
      "epoch 5 loss: 0.4296\n",
      "epoch 6 loss: 0.2464\n",
      "epoch 7 loss: 0.1624\n",
      "epoch 8 loss: 0.1395\n",
      "epoch 9 loss: 0.1128\n",
      "epoch 10 loss: 0.1299\n",
      "epoch 11 loss: 0.1263\n",
      "epoch 12 loss: 0.1299\n",
      "epoch 13 loss: 0.1189\n",
      "epoch 14 loss: 0.1013\n",
      "epoch 15 loss: 0.1468\n",
      "epoch 16 loss: 0.1234\n",
      "epoch 17 loss: 0.0904\n",
      "epoch 18 loss: 0.1126\n",
      "epoch 19 loss: 0.1287\n",
      "epoch 20 loss: 0.1289\n",
      "epoch 21 loss: 0.0639\n",
      "epoch 22 loss: 0.0800\n",
      "epoch 23 loss: 0.0788\n",
      "epoch 24 loss: 0.0819\n",
      "epoch 25 loss: 0.0895\n",
      "epoch 26 loss: 0.0784\n",
      "epoch 27 loss: 0.0961\n",
      "epoch 28 loss: 0.1367\n",
      "epoch 29 loss: 0.1324\n",
      "epoch 30 loss: 0.0670\n",
      "57\n",
      "epoch 1 loss: 1.1106\n",
      "epoch 2 loss: 0.6386\n",
      "epoch 3 loss: 0.5875\n",
      "epoch 4 loss: 0.2395\n",
      "epoch 5 loss: 0.1813\n",
      "epoch 6 loss: 0.1834\n",
      "epoch 7 loss: 0.1515\n",
      "epoch 8 loss: 0.1533\n",
      "epoch 9 loss: 0.1255\n",
      "epoch 10 loss: 0.1138\n",
      "epoch 11 loss: 0.1055\n",
      "epoch 12 loss: 0.1043\n",
      "epoch 13 loss: 0.1047\n",
      "epoch 14 loss: 0.0761\n",
      "epoch 15 loss: 0.0820\n",
      "epoch 16 loss: 0.0929\n",
      "epoch 17 loss: 0.1517\n",
      "epoch 18 loss: 0.0994\n",
      "epoch 19 loss: 0.0785\n",
      "epoch 20 loss: 0.0699\n",
      "epoch 21 loss: 0.0967\n",
      "epoch 22 loss: 0.0645\n",
      "epoch 23 loss: 0.0757\n",
      "epoch 24 loss: 0.0656\n",
      "epoch 25 loss: 0.1007\n",
      "epoch 26 loss: 0.0905\n",
      "epoch 27 loss: 0.0787\n",
      "epoch 28 loss: 0.0779\n",
      "epoch 29 loss: 0.0702\n",
      "epoch 30 loss: 0.0693\n",
      "58\n",
      "epoch 1 loss: 0.9019\n",
      "epoch 2 loss: 0.5817\n",
      "epoch 3 loss: 0.7569\n",
      "epoch 4 loss: 0.3507\n",
      "epoch 5 loss: 0.1956\n",
      "epoch 6 loss: 0.1433\n",
      "epoch 7 loss: 0.1221\n",
      "epoch 8 loss: 0.1287\n",
      "epoch 9 loss: 0.1014\n",
      "epoch 10 loss: 0.0922\n",
      "epoch 11 loss: 0.0820\n",
      "epoch 12 loss: 0.0611\n",
      "epoch 13 loss: 0.0691\n",
      "epoch 14 loss: 0.0591\n",
      "epoch 15 loss: 0.0724\n",
      "epoch 16 loss: 0.0662\n",
      "epoch 17 loss: 0.0770\n",
      "epoch 18 loss: 0.0699\n",
      "epoch 19 loss: 0.0733\n",
      "epoch 20 loss: 0.0689\n",
      "epoch 21 loss: 0.0761\n",
      "epoch 22 loss: 0.0629\n",
      "epoch 23 loss: 0.0528\n",
      "epoch 24 loss: 0.0642\n",
      "epoch 25 loss: 0.0943\n",
      "epoch 26 loss: 0.0716\n",
      "epoch 27 loss: 0.0685\n",
      "epoch 28 loss: 0.0649\n",
      "epoch 29 loss: 0.0429\n",
      "epoch 30 loss: 0.0656\n",
      "59\n",
      "epoch 1 loss: 0.7011\n",
      "epoch 2 loss: 0.6775\n",
      "epoch 3 loss: 0.5027\n",
      "epoch 4 loss: 0.3407\n",
      "epoch 5 loss: 0.2123\n",
      "epoch 6 loss: 0.1379\n",
      "epoch 7 loss: 0.1649\n",
      "epoch 8 loss: 0.1402\n",
      "epoch 9 loss: 0.1421\n",
      "epoch 10 loss: 0.1285\n",
      "epoch 11 loss: 0.1075\n",
      "epoch 12 loss: 0.1035\n",
      "epoch 13 loss: 0.0985\n",
      "epoch 14 loss: 0.0847\n",
      "epoch 15 loss: 0.1077\n",
      "epoch 16 loss: 0.0680\n",
      "epoch 17 loss: 0.0955\n",
      "epoch 18 loss: 0.0760\n",
      "epoch 19 loss: 0.0837\n",
      "epoch 20 loss: 0.1193\n",
      "epoch 21 loss: 0.0711\n",
      "epoch 22 loss: 0.1096\n",
      "epoch 23 loss: 0.0980\n",
      "epoch 24 loss: 0.0844\n",
      "epoch 25 loss: 0.0919\n",
      "epoch 26 loss: 0.0647\n",
      "epoch 27 loss: 0.0587\n",
      "epoch 28 loss: 0.0504\n",
      "epoch 29 loss: 0.0650\n",
      "epoch 30 loss: 0.0610\n",
      "60\n",
      "epoch 1 loss: 0.9604\n",
      "epoch 2 loss: 0.6651\n",
      "epoch 3 loss: 0.5254\n",
      "epoch 4 loss: 0.3864\n",
      "epoch 5 loss: 0.2757\n",
      "epoch 6 loss: 0.1960\n",
      "epoch 7 loss: 0.1931\n",
      "epoch 8 loss: 0.1075\n",
      "epoch 9 loss: 0.1097\n",
      "epoch 10 loss: 0.1175\n",
      "epoch 11 loss: 0.1223\n",
      "epoch 12 loss: 0.0858\n",
      "epoch 13 loss: 0.1065\n",
      "epoch 14 loss: 0.0805\n",
      "epoch 15 loss: 0.0689\n",
      "epoch 16 loss: 0.0890\n",
      "epoch 17 loss: 0.0826\n",
      "epoch 18 loss: 0.0957\n",
      "epoch 19 loss: 0.0774\n",
      "epoch 20 loss: 0.0757\n",
      "epoch 21 loss: 0.0745\n",
      "epoch 22 loss: 0.1082\n",
      "epoch 23 loss: 0.0677\n",
      "epoch 24 loss: 0.0689\n",
      "epoch 25 loss: 0.0827\n",
      "epoch 26 loss: 0.0498\n",
      "epoch 27 loss: 0.0804\n",
      "epoch 28 loss: 0.0815\n",
      "epoch 29 loss: 0.0710\n",
      "epoch 30 loss: 0.0712\n",
      "61\n",
      "epoch 1 loss: 0.6617\n",
      "epoch 2 loss: 0.6289\n",
      "epoch 3 loss: 0.5023\n",
      "epoch 4 loss: 0.2657\n",
      "epoch 5 loss: 0.1939\n",
      "epoch 6 loss: 0.1781\n",
      "epoch 7 loss: 0.1304\n",
      "epoch 8 loss: 0.1544\n",
      "epoch 9 loss: 0.1198\n",
      "epoch 10 loss: 0.1150\n",
      "epoch 11 loss: 0.1112\n",
      "epoch 12 loss: 0.1023\n",
      "epoch 13 loss: 0.1022\n",
      "epoch 14 loss: 0.1140\n",
      "epoch 15 loss: 0.0886\n",
      "epoch 16 loss: 0.0886\n",
      "epoch 17 loss: 0.0725\n",
      "epoch 18 loss: 0.0993\n",
      "epoch 19 loss: 0.0560\n",
      "epoch 20 loss: 0.0707\n",
      "epoch 21 loss: 0.0784\n",
      "epoch 22 loss: 0.0763\n",
      "epoch 23 loss: 0.0576\n",
      "epoch 24 loss: 0.0600\n",
      "epoch 25 loss: 0.0747\n",
      "epoch 26 loss: 0.0574\n",
      "epoch 27 loss: 0.0766\n",
      "epoch 28 loss: 0.0614\n",
      "epoch 29 loss: 0.0630\n",
      "epoch 30 loss: 0.0527\n",
      "62\n",
      "epoch 1 loss: 0.8496\n",
      "epoch 2 loss: 0.5905\n",
      "epoch 3 loss: 0.4324\n",
      "epoch 4 loss: 0.2574\n",
      "epoch 5 loss: 0.1685\n",
      "epoch 6 loss: 0.1215\n",
      "epoch 7 loss: 0.1385\n",
      "epoch 8 loss: 0.1083\n",
      "epoch 9 loss: 0.0894\n",
      "epoch 10 loss: 0.1544\n",
      "epoch 11 loss: 0.0904\n",
      "epoch 12 loss: 0.1026\n",
      "epoch 13 loss: 0.0869\n",
      "epoch 14 loss: 0.0771\n",
      "epoch 15 loss: 0.0859\n",
      "epoch 16 loss: 0.0933\n",
      "epoch 17 loss: 0.0571\n",
      "epoch 18 loss: 0.0806\n",
      "epoch 19 loss: 0.0610\n",
      "epoch 20 loss: 0.0543\n",
      "epoch 21 loss: 0.0649\n",
      "epoch 22 loss: 0.0498\n",
      "epoch 23 loss: 0.0695\n",
      "epoch 24 loss: 0.0563\n",
      "epoch 25 loss: 0.0696\n",
      "epoch 26 loss: 0.0570\n",
      "epoch 27 loss: 0.0639\n",
      "epoch 28 loss: 0.0523\n",
      "epoch 29 loss: 0.0556\n",
      "epoch 30 loss: 0.0594\n",
      "63\n",
      "epoch 1 loss: 1.0121\n",
      "epoch 2 loss: 0.7450\n",
      "epoch 3 loss: 0.6237\n",
      "epoch 4 loss: 0.6698\n",
      "epoch 5 loss: 0.3784\n",
      "epoch 6 loss: 0.2621\n",
      "epoch 7 loss: 0.1495\n",
      "epoch 8 loss: 0.1322\n",
      "epoch 9 loss: 0.1185\n",
      "epoch 10 loss: 0.1153\n",
      "epoch 11 loss: 0.1159\n",
      "epoch 12 loss: 0.1304\n",
      "epoch 13 loss: 0.0870\n",
      "epoch 14 loss: 0.1689\n",
      "epoch 15 loss: 0.0913\n",
      "epoch 16 loss: 0.0816\n",
      "epoch 17 loss: 0.0922\n",
      "epoch 18 loss: 0.0910\n",
      "epoch 19 loss: 0.0670\n",
      "epoch 20 loss: 0.0623\n",
      "epoch 21 loss: 0.0773\n",
      "epoch 22 loss: 0.0780\n",
      "epoch 23 loss: 0.0861\n",
      "epoch 24 loss: 0.0869\n",
      "epoch 25 loss: 0.1132\n",
      "epoch 26 loss: 0.0567\n",
      "epoch 27 loss: 0.0858\n",
      "epoch 28 loss: 0.0653\n",
      "epoch 29 loss: 0.0648\n",
      "epoch 30 loss: 0.0676\n",
      "64\n",
      "epoch 1 loss: 0.7934\n",
      "epoch 2 loss: 0.8957\n",
      "epoch 3 loss: 0.3252\n",
      "epoch 4 loss: 0.2626\n",
      "epoch 5 loss: 0.2402\n",
      "epoch 6 loss: 0.1670\n",
      "epoch 7 loss: 0.1453\n",
      "epoch 8 loss: 0.1548\n",
      "epoch 9 loss: 0.1266\n",
      "epoch 10 loss: 0.1826\n",
      "epoch 11 loss: 0.1519\n",
      "epoch 12 loss: 0.1214\n",
      "epoch 13 loss: 0.1365\n",
      "epoch 14 loss: 0.0965\n",
      "epoch 15 loss: 0.0863\n",
      "epoch 16 loss: 0.0948\n",
      "epoch 17 loss: 0.0941\n",
      "epoch 18 loss: 0.0663\n",
      "epoch 19 loss: 0.0958\n",
      "epoch 20 loss: 0.0710\n",
      "epoch 21 loss: 0.0725\n",
      "epoch 22 loss: 0.0825\n",
      "epoch 23 loss: 0.0645\n",
      "epoch 24 loss: 0.0667\n",
      "epoch 25 loss: 0.0653\n",
      "epoch 26 loss: 0.0629\n",
      "epoch 27 loss: 0.0943\n",
      "epoch 28 loss: 0.0764\n",
      "epoch 29 loss: 0.0558\n",
      "epoch 30 loss: 0.0616\n",
      "65\n",
      "epoch 1 loss: 0.9923\n",
      "epoch 2 loss: 0.6946\n",
      "epoch 3 loss: 0.5862\n",
      "epoch 4 loss: 0.3484\n",
      "epoch 5 loss: 0.4138\n",
      "epoch 6 loss: 0.4207\n",
      "epoch 7 loss: 0.1840\n",
      "epoch 8 loss: 0.1699\n",
      "epoch 9 loss: 0.1283\n",
      "epoch 10 loss: 0.1244\n",
      "epoch 11 loss: 0.1237\n",
      "epoch 12 loss: 0.0859\n",
      "epoch 13 loss: 0.1174\n",
      "epoch 14 loss: 0.1062\n",
      "epoch 15 loss: 0.1552\n",
      "epoch 16 loss: 0.0765\n",
      "epoch 17 loss: 0.0814\n",
      "epoch 18 loss: 0.0794\n",
      "epoch 19 loss: 0.0721\n",
      "epoch 20 loss: 0.0880\n",
      "epoch 21 loss: 0.0897\n",
      "epoch 22 loss: 0.0699\n",
      "epoch 23 loss: 0.0750\n",
      "epoch 24 loss: 0.0902\n",
      "epoch 25 loss: 0.0696\n",
      "epoch 26 loss: 0.0614\n",
      "epoch 27 loss: 0.0935\n",
      "epoch 28 loss: 0.0805\n",
      "epoch 29 loss: 0.0588\n",
      "epoch 30 loss: 0.0887\n",
      "66\n",
      "epoch 1 loss: 1.0417\n",
      "epoch 2 loss: 0.4443\n",
      "epoch 3 loss: 0.5549\n",
      "epoch 4 loss: 0.4377\n",
      "epoch 5 loss: 0.2749\n",
      "epoch 6 loss: 0.1757\n",
      "epoch 7 loss: 0.1666\n",
      "epoch 8 loss: 0.1281\n",
      "epoch 9 loss: 0.0960\n",
      "epoch 10 loss: 0.0914\n",
      "epoch 11 loss: 0.1210\n",
      "epoch 12 loss: 0.1107\n",
      "epoch 13 loss: 0.1115\n",
      "epoch 14 loss: 0.0678\n",
      "epoch 15 loss: 0.1052\n",
      "epoch 16 loss: 0.0851\n",
      "epoch 17 loss: 0.0954\n",
      "epoch 18 loss: 0.0814\n",
      "epoch 19 loss: 0.0598\n",
      "epoch 20 loss: 0.0624\n",
      "epoch 21 loss: 0.0733\n",
      "epoch 22 loss: 0.0601\n",
      "epoch 23 loss: 0.0888\n",
      "epoch 24 loss: 0.0706\n",
      "epoch 25 loss: 0.0696\n",
      "epoch 26 loss: 0.0647\n",
      "epoch 27 loss: 0.0524\n",
      "epoch 28 loss: 0.0584\n",
      "epoch 29 loss: 0.0616\n",
      "epoch 30 loss: 0.0606\n",
      "67\n",
      "epoch 1 loss: 0.9346\n",
      "epoch 2 loss: 0.6475\n",
      "epoch 3 loss: 0.6075\n",
      "epoch 4 loss: 0.3268\n",
      "epoch 5 loss: 0.3350\n",
      "epoch 6 loss: 0.2425\n",
      "epoch 7 loss: 0.1805\n",
      "epoch 8 loss: 0.1872\n",
      "epoch 9 loss: 0.1859\n",
      "epoch 10 loss: 0.1303\n",
      "epoch 11 loss: 0.1506\n",
      "epoch 12 loss: 0.1159\n",
      "epoch 13 loss: 0.1082\n",
      "epoch 14 loss: 0.1141\n",
      "epoch 15 loss: 0.1404\n",
      "epoch 16 loss: 0.1079\n",
      "epoch 17 loss: 0.1402\n",
      "epoch 18 loss: 0.1148\n",
      "epoch 19 loss: 0.0938\n",
      "epoch 20 loss: 0.0898\n",
      "epoch 21 loss: 0.1074\n",
      "epoch 22 loss: 0.1399\n",
      "epoch 23 loss: 0.0951\n",
      "epoch 24 loss: 0.1457\n",
      "epoch 25 loss: 0.1338\n",
      "epoch 26 loss: 0.1511\n",
      "epoch 27 loss: 0.1272\n",
      "epoch 28 loss: 0.0841\n",
      "epoch 29 loss: 0.0664\n",
      "epoch 30 loss: 0.1148\n",
      "68\n",
      "epoch 1 loss: 1.0229\n",
      "epoch 2 loss: 0.7263\n",
      "epoch 3 loss: 0.6366\n",
      "epoch 4 loss: 0.3536\n",
      "epoch 5 loss: 0.3661\n",
      "epoch 6 loss: 0.1852\n",
      "epoch 7 loss: 0.1339\n",
      "epoch 8 loss: 0.1603\n",
      "epoch 9 loss: 0.1249\n",
      "epoch 10 loss: 0.0930\n",
      "epoch 11 loss: 0.1184\n",
      "epoch 12 loss: 0.0951\n",
      "epoch 13 loss: 0.0971\n",
      "epoch 14 loss: 0.1134\n",
      "epoch 15 loss: 0.0683\n",
      "epoch 16 loss: 0.0684\n",
      "epoch 17 loss: 0.0784\n",
      "epoch 18 loss: 0.0968\n",
      "epoch 19 loss: 0.0706\n",
      "epoch 20 loss: 0.0851\n",
      "epoch 21 loss: 0.0677\n",
      "epoch 22 loss: 0.0676\n",
      "epoch 23 loss: 0.0553\n",
      "epoch 24 loss: 0.0740\n",
      "epoch 25 loss: 0.0719\n",
      "epoch 26 loss: 0.0559\n",
      "epoch 27 loss: 0.0611\n",
      "epoch 28 loss: 0.0551\n",
      "epoch 29 loss: 0.0734\n",
      "epoch 30 loss: 0.0589\n",
      "69\n",
      "epoch 1 loss: 0.9636\n",
      "epoch 2 loss: 0.7852\n",
      "epoch 3 loss: 0.3493\n",
      "epoch 4 loss: 0.3026\n",
      "epoch 5 loss: 0.2768\n",
      "epoch 6 loss: 0.1873\n",
      "epoch 7 loss: 0.1892\n",
      "epoch 8 loss: 0.1288\n",
      "epoch 9 loss: 0.1287\n",
      "epoch 10 loss: 0.1991\n",
      "epoch 11 loss: 0.1526\n",
      "epoch 12 loss: 0.1299\n",
      "epoch 13 loss: 0.1343\n",
      "epoch 14 loss: 0.1165\n",
      "epoch 15 loss: 0.1284\n",
      "epoch 16 loss: 0.0846\n",
      "epoch 17 loss: 0.0930\n",
      "epoch 18 loss: 0.0978\n",
      "epoch 19 loss: 0.0755\n",
      "epoch 20 loss: 0.1107\n",
      "epoch 21 loss: 0.1139\n",
      "epoch 22 loss: 0.1033\n",
      "epoch 23 loss: 0.1019\n",
      "epoch 24 loss: 0.0822\n",
      "epoch 25 loss: 0.0754\n",
      "epoch 26 loss: 0.1350\n",
      "epoch 27 loss: 0.0966\n",
      "epoch 28 loss: 0.0784\n",
      "epoch 29 loss: 0.0988\n",
      "epoch 30 loss: 0.0675\n",
      "70\n",
      "epoch 1 loss: 1.1363\n",
      "epoch 2 loss: 0.4581\n",
      "epoch 3 loss: 0.6046\n",
      "epoch 4 loss: 0.4346\n",
      "epoch 5 loss: 0.2110\n",
      "epoch 6 loss: 0.1680\n",
      "epoch 7 loss: 0.1790\n",
      "epoch 8 loss: 0.1253\n",
      "epoch 9 loss: 0.1318\n",
      "epoch 10 loss: 0.1180\n",
      "epoch 11 loss: 0.1141\n",
      "epoch 12 loss: 0.1059\n",
      "epoch 13 loss: 0.1301\n",
      "epoch 14 loss: 0.0925\n",
      "epoch 15 loss: 0.1079\n",
      "epoch 16 loss: 0.1066\n",
      "epoch 17 loss: 0.1230\n",
      "epoch 18 loss: 0.0937\n",
      "epoch 19 loss: 0.1247\n",
      "epoch 20 loss: 0.1414\n",
      "epoch 21 loss: 0.0902\n",
      "epoch 22 loss: 0.0731\n",
      "epoch 23 loss: 0.1153\n",
      "epoch 24 loss: 0.0765\n",
      "epoch 25 loss: 0.0916\n",
      "epoch 26 loss: 0.0571\n",
      "epoch 27 loss: 0.0597\n",
      "epoch 28 loss: 0.0635\n",
      "epoch 29 loss: 0.0725\n",
      "epoch 30 loss: 0.0653\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T19:29:18.073411Z",
     "start_time": "2025-10-10T18:20:52.729021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "\n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4,\n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_kw3_km6_ky10_matrix.csv', index=False)"
   ],
   "id": "946c3d2aa7d3f8be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:1149: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {ep+1} loss: {float(loss):.4f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7318\n",
      "epoch 2 loss: 0.7618\n",
      "epoch 3 loss: 0.2973\n",
      "epoch 4 loss: 0.2207\n",
      "epoch 5 loss: 0.1220\n",
      "epoch 6 loss: 0.0872\n",
      "epoch 7 loss: 0.0832\n",
      "epoch 8 loss: 0.0541\n",
      "epoch 9 loss: 0.0669\n",
      "epoch 10 loss: 0.0568\n",
      "epoch 11 loss: 0.0574\n",
      "epoch 12 loss: 0.0434\n",
      "epoch 13 loss: 0.0529\n",
      "epoch 14 loss: 0.0541\n",
      "epoch 15 loss: 0.0407\n",
      "epoch 16 loss: 0.0426\n",
      "epoch 17 loss: 0.0381\n",
      "epoch 18 loss: 0.0454\n",
      "epoch 19 loss: 0.0297\n",
      "epoch 20 loss: 0.0332\n",
      "epoch 21 loss: 0.0386\n",
      "epoch 22 loss: 0.0353\n",
      "epoch 23 loss: 0.0444\n",
      "epoch 24 loss: 0.0390\n",
      "epoch 25 loss: 0.0257\n",
      "epoch 26 loss: 0.0337\n",
      "epoch 27 loss: 0.0288\n",
      "epoch 28 loss: 0.0365\n",
      "epoch 29 loss: 0.0308\n",
      "epoch 30 loss: 0.0258\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_35858/291482010.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7625\n",
      "epoch 2 loss: 0.5450\n",
      "epoch 3 loss: 0.5818\n",
      "epoch 4 loss: 0.3141\n",
      "epoch 5 loss: 0.2066\n",
      "epoch 6 loss: 0.1066\n",
      "epoch 7 loss: 0.0603\n",
      "epoch 8 loss: 0.0490\n",
      "epoch 9 loss: 0.0436\n",
      "epoch 10 loss: 0.0433\n",
      "epoch 11 loss: 0.0423\n",
      "epoch 12 loss: 0.0420\n",
      "epoch 13 loss: 0.0461\n",
      "epoch 14 loss: 0.0327\n",
      "epoch 15 loss: 0.0310\n",
      "epoch 16 loss: 0.0308\n",
      "epoch 17 loss: 0.0367\n",
      "epoch 18 loss: 0.0355\n",
      "epoch 19 loss: 0.0362\n",
      "epoch 20 loss: 0.0308\n",
      "epoch 21 loss: 0.0322\n",
      "epoch 22 loss: 0.0333\n",
      "epoch 23 loss: 0.0275\n",
      "epoch 24 loss: 0.0342\n",
      "epoch 25 loss: 0.0283\n",
      "epoch 26 loss: 0.0288\n",
      "epoch 27 loss: 0.0267\n",
      "epoch 28 loss: 0.0260\n",
      "epoch 29 loss: 0.0379\n",
      "epoch 30 loss: 0.0303\n",
      "3\n",
      "epoch 1 loss: 0.8113\n",
      "epoch 2 loss: 0.6777\n",
      "epoch 3 loss: 0.4506\n",
      "epoch 4 loss: 0.3018\n",
      "epoch 5 loss: 0.2304\n",
      "epoch 6 loss: 0.1295\n",
      "epoch 7 loss: 0.0943\n",
      "epoch 8 loss: 0.0800\n",
      "epoch 9 loss: 0.0697\n",
      "epoch 10 loss: 0.0551\n",
      "epoch 11 loss: 0.0683\n",
      "epoch 12 loss: 0.0383\n",
      "epoch 13 loss: 0.0548\n",
      "epoch 14 loss: 0.0506\n",
      "epoch 15 loss: 0.0444\n",
      "epoch 16 loss: 0.0470\n",
      "epoch 17 loss: 0.0392\n",
      "epoch 18 loss: 0.0458\n",
      "epoch 19 loss: 0.0500\n",
      "epoch 20 loss: 0.0414\n",
      "epoch 21 loss: 0.0476\n",
      "epoch 22 loss: 0.0337\n",
      "epoch 23 loss: 0.0491\n",
      "epoch 24 loss: 0.0355\n",
      "epoch 25 loss: 0.0322\n",
      "epoch 26 loss: 0.0351\n",
      "epoch 27 loss: 0.0371\n",
      "epoch 28 loss: 0.0370\n",
      "epoch 29 loss: 0.0313\n",
      "epoch 30 loss: 0.0344\n",
      "4\n",
      "epoch 1 loss: 0.8877\n",
      "epoch 2 loss: 0.5732\n",
      "epoch 3 loss: 0.5404\n",
      "epoch 4 loss: 0.3982\n",
      "epoch 5 loss: 0.2522\n",
      "epoch 6 loss: 0.1100\n",
      "epoch 7 loss: 0.0906\n",
      "epoch 8 loss: 0.0656\n",
      "epoch 9 loss: 0.0473\n",
      "epoch 10 loss: 0.0554\n",
      "epoch 11 loss: 0.0407\n",
      "epoch 12 loss: 0.0473\n",
      "epoch 13 loss: 0.0518\n",
      "epoch 14 loss: 0.0455\n",
      "epoch 15 loss: 0.0411\n",
      "epoch 16 loss: 0.0369\n",
      "epoch 17 loss: 0.0373\n",
      "epoch 18 loss: 0.0425\n",
      "epoch 19 loss: 0.0420\n",
      "epoch 20 loss: 0.0489\n",
      "epoch 21 loss: 0.0455\n",
      "epoch 22 loss: 0.0399\n",
      "epoch 23 loss: 0.0428\n",
      "epoch 24 loss: 0.0323\n",
      "epoch 25 loss: 0.0378\n",
      "epoch 26 loss: 0.0332\n",
      "epoch 27 loss: 0.0335\n",
      "epoch 28 loss: 0.0341\n",
      "epoch 29 loss: 0.0327\n",
      "epoch 30 loss: 0.0313\n",
      "5\n",
      "epoch 1 loss: 0.9929\n",
      "epoch 2 loss: 0.6220\n",
      "epoch 3 loss: 0.3387\n",
      "epoch 4 loss: 0.3166\n",
      "epoch 5 loss: 0.2049\n",
      "epoch 6 loss: 0.1199\n",
      "epoch 7 loss: 0.0846\n",
      "epoch 8 loss: 0.0682\n",
      "epoch 9 loss: 0.0531\n",
      "epoch 10 loss: 0.0480\n",
      "epoch 11 loss: 0.0469\n",
      "epoch 12 loss: 0.0555\n",
      "epoch 13 loss: 0.0414\n",
      "epoch 14 loss: 0.0433\n",
      "epoch 15 loss: 0.0449\n",
      "epoch 16 loss: 0.0425\n",
      "epoch 17 loss: 0.0452\n",
      "epoch 18 loss: 0.0420\n",
      "epoch 19 loss: 0.0342\n",
      "epoch 20 loss: 0.0348\n",
      "epoch 21 loss: 0.0310\n",
      "epoch 22 loss: 0.0435\n",
      "epoch 23 loss: 0.0389\n",
      "epoch 24 loss: 0.0284\n",
      "epoch 25 loss: 0.0384\n",
      "epoch 26 loss: 0.0299\n",
      "epoch 27 loss: 0.0354\n",
      "epoch 28 loss: 0.0293\n",
      "epoch 29 loss: 0.0393\n",
      "epoch 30 loss: 0.0308\n",
      "6\n",
      "epoch 1 loss: 0.7296\n",
      "epoch 2 loss: 0.5129\n",
      "epoch 3 loss: 0.3029\n",
      "epoch 4 loss: 0.2211\n",
      "epoch 5 loss: 0.1967\n",
      "epoch 6 loss: 0.1336\n",
      "epoch 7 loss: 0.1393\n",
      "epoch 8 loss: 0.1078\n",
      "epoch 9 loss: 0.0872\n",
      "epoch 10 loss: 0.0856\n",
      "epoch 11 loss: 0.0561\n",
      "epoch 12 loss: 0.0493\n",
      "epoch 13 loss: 0.0584\n",
      "epoch 14 loss: 0.0535\n",
      "epoch 15 loss: 0.0439\n",
      "epoch 16 loss: 0.0504\n",
      "epoch 17 loss: 0.0426\n",
      "epoch 18 loss: 0.0355\n",
      "epoch 19 loss: 0.0367\n",
      "epoch 20 loss: 0.0372\n",
      "epoch 21 loss: 0.0322\n",
      "epoch 22 loss: 0.0372\n",
      "epoch 23 loss: 0.0388\n",
      "epoch 24 loss: 0.0324\n",
      "epoch 25 loss: 0.0341\n",
      "epoch 26 loss: 0.0374\n",
      "epoch 27 loss: 0.0328\n",
      "epoch 28 loss: 0.0305\n",
      "epoch 29 loss: 0.0302\n",
      "epoch 30 loss: 0.0304\n",
      "7\n",
      "epoch 1 loss: 0.8588\n",
      "epoch 2 loss: 0.7409\n",
      "epoch 3 loss: 0.5072\n",
      "epoch 4 loss: 0.2654\n",
      "epoch 5 loss: 0.2186\n",
      "epoch 6 loss: 0.1493\n",
      "epoch 7 loss: 0.1155\n",
      "epoch 8 loss: 0.0921\n",
      "epoch 9 loss: 0.0587\n",
      "epoch 10 loss: 0.0543\n",
      "epoch 11 loss: 0.0523\n",
      "epoch 12 loss: 0.0659\n",
      "epoch 13 loss: 0.0595\n",
      "epoch 14 loss: 0.0465\n",
      "epoch 15 loss: 0.0691\n",
      "epoch 16 loss: 0.0414\n",
      "epoch 17 loss: 0.0420\n",
      "epoch 18 loss: 0.0587\n",
      "epoch 19 loss: 0.0599\n",
      "epoch 20 loss: 0.0501\n",
      "epoch 21 loss: 0.0497\n",
      "epoch 22 loss: 0.0420\n",
      "epoch 23 loss: 0.0411\n",
      "epoch 24 loss: 0.0443\n",
      "epoch 25 loss: 0.0480\n",
      "epoch 26 loss: 0.0392\n",
      "epoch 27 loss: 0.0400\n",
      "epoch 28 loss: 0.0434\n",
      "epoch 29 loss: 0.0322\n",
      "epoch 30 loss: 0.0469\n",
      "8\n",
      "epoch 1 loss: 0.7377\n",
      "epoch 2 loss: 0.4358\n",
      "epoch 3 loss: 0.3014\n",
      "epoch 4 loss: 0.2395\n",
      "epoch 5 loss: 0.1724\n",
      "epoch 6 loss: 0.0957\n",
      "epoch 7 loss: 0.0679\n",
      "epoch 8 loss: 0.0514\n",
      "epoch 9 loss: 0.0508\n",
      "epoch 10 loss: 0.0452\n",
      "epoch 11 loss: 0.0555\n",
      "epoch 12 loss: 0.0386\n",
      "epoch 13 loss: 0.0389\n",
      "epoch 14 loss: 0.0422\n",
      "epoch 15 loss: 0.0373\n",
      "epoch 16 loss: 0.0422\n",
      "epoch 17 loss: 0.0306\n",
      "epoch 18 loss: 0.0332\n",
      "epoch 19 loss: 0.0380\n",
      "epoch 20 loss: 0.0346\n",
      "epoch 21 loss: 0.0365\n",
      "epoch 22 loss: 0.0280\n",
      "epoch 23 loss: 0.0420\n",
      "epoch 24 loss: 0.0339\n",
      "epoch 25 loss: 0.0325\n",
      "epoch 26 loss: 0.0199\n",
      "epoch 27 loss: 0.0286\n",
      "epoch 28 loss: 0.0304\n",
      "epoch 29 loss: 0.0317\n",
      "epoch 30 loss: 0.0295\n",
      "9\n",
      "epoch 1 loss: 0.9754\n",
      "epoch 2 loss: 0.6706\n",
      "epoch 3 loss: 0.4450\n",
      "epoch 4 loss: 0.4582\n",
      "epoch 5 loss: 0.2396\n",
      "epoch 6 loss: 0.1668\n",
      "epoch 7 loss: 0.1283\n",
      "epoch 8 loss: 0.0834\n",
      "epoch 9 loss: 0.0836\n",
      "epoch 10 loss: 0.0781\n",
      "epoch 11 loss: 0.0568\n",
      "epoch 12 loss: 0.0581\n",
      "epoch 13 loss: 0.0471\n",
      "epoch 14 loss: 0.0510\n",
      "epoch 15 loss: 0.0472\n",
      "epoch 16 loss: 0.0362\n",
      "epoch 17 loss: 0.0502\n",
      "epoch 18 loss: 0.0443\n",
      "epoch 19 loss: 0.0379\n",
      "epoch 20 loss: 0.0482\n",
      "epoch 21 loss: 0.0462\n",
      "epoch 22 loss: 0.0412\n",
      "epoch 23 loss: 0.0530\n",
      "epoch 24 loss: 0.0498\n",
      "epoch 25 loss: 0.0523\n",
      "epoch 26 loss: 0.0459\n",
      "epoch 27 loss: 0.0362\n",
      "epoch 28 loss: 0.0461\n",
      "epoch 29 loss: 0.0337\n",
      "epoch 30 loss: 0.0352\n",
      "10\n",
      "epoch 1 loss: 0.9659\n",
      "epoch 2 loss: 0.6499\n",
      "epoch 3 loss: 0.5002\n",
      "epoch 4 loss: 0.5934\n",
      "epoch 5 loss: 0.6386\n",
      "epoch 6 loss: 0.3625\n",
      "epoch 7 loss: 0.5314\n",
      "epoch 8 loss: 0.2825\n",
      "epoch 9 loss: 0.2297\n",
      "epoch 10 loss: 0.1920\n",
      "epoch 11 loss: 0.0740\n",
      "epoch 12 loss: 0.0649\n",
      "epoch 13 loss: 0.0775\n",
      "epoch 14 loss: 0.0563\n",
      "epoch 15 loss: 0.0635\n",
      "epoch 16 loss: 0.0519\n",
      "epoch 17 loss: 0.0539\n",
      "epoch 18 loss: 0.0646\n",
      "epoch 19 loss: 0.0539\n",
      "epoch 20 loss: 0.0489\n",
      "epoch 21 loss: 0.0529\n",
      "epoch 22 loss: 0.0378\n",
      "epoch 23 loss: 0.0450\n",
      "epoch 24 loss: 0.0410\n",
      "epoch 25 loss: 0.0398\n",
      "epoch 26 loss: 0.0411\n",
      "epoch 27 loss: 0.0351\n",
      "epoch 28 loss: 0.0370\n",
      "epoch 29 loss: 0.0385\n",
      "epoch 30 loss: 0.0445\n",
      "11\n",
      "epoch 1 loss: 0.7033\n",
      "epoch 2 loss: 0.4780\n",
      "epoch 3 loss: 0.3984\n",
      "epoch 4 loss: 0.3364\n",
      "epoch 5 loss: 0.3059\n",
      "epoch 6 loss: 0.1928\n",
      "epoch 7 loss: 0.0693\n",
      "epoch 8 loss: 0.0685\n",
      "epoch 9 loss: 0.0591\n",
      "epoch 10 loss: 0.0522\n",
      "epoch 11 loss: 0.0445\n",
      "epoch 12 loss: 0.0459\n",
      "epoch 13 loss: 0.0405\n",
      "epoch 14 loss: 0.0358\n",
      "epoch 15 loss: 0.0323\n",
      "epoch 16 loss: 0.0339\n",
      "epoch 17 loss: 0.0437\n",
      "epoch 18 loss: 0.0329\n",
      "epoch 19 loss: 0.0314\n",
      "epoch 20 loss: 0.0327\n",
      "epoch 21 loss: 0.0390\n",
      "epoch 22 loss: 0.0309\n",
      "epoch 23 loss: 0.0285\n",
      "epoch 24 loss: 0.0301\n",
      "epoch 25 loss: 0.0314\n",
      "epoch 26 loss: 0.0286\n",
      "epoch 27 loss: 0.0364\n",
      "epoch 28 loss: 0.0289\n",
      "epoch 29 loss: 0.0250\n",
      "epoch 30 loss: 0.0290\n",
      "12\n",
      "epoch 1 loss: 0.9142\n",
      "epoch 2 loss: 0.7305\n",
      "epoch 3 loss: 0.4952\n",
      "epoch 4 loss: 0.3469\n",
      "epoch 5 loss: 0.3027\n",
      "epoch 6 loss: 0.3037\n",
      "epoch 7 loss: 0.1619\n",
      "epoch 8 loss: 0.0704\n",
      "epoch 9 loss: 0.0940\n",
      "epoch 10 loss: 0.0505\n",
      "epoch 11 loss: 0.0549\n",
      "epoch 12 loss: 0.0593\n",
      "epoch 13 loss: 0.0411\n",
      "epoch 14 loss: 0.0430\n",
      "epoch 15 loss: 0.0433\n",
      "epoch 16 loss: 0.0348\n",
      "epoch 17 loss: 0.0474\n",
      "epoch 18 loss: 0.0413\n",
      "epoch 19 loss: 0.0465\n",
      "epoch 20 loss: 0.0414\n",
      "epoch 21 loss: 0.0466\n",
      "epoch 22 loss: 0.0379\n",
      "epoch 23 loss: 0.0407\n",
      "epoch 24 loss: 0.0412\n",
      "epoch 25 loss: 0.0381\n",
      "epoch 26 loss: 0.0348\n",
      "epoch 27 loss: 0.0311\n",
      "epoch 28 loss: 0.0293\n",
      "epoch 29 loss: 0.0389\n",
      "epoch 30 loss: 0.0346\n",
      "13\n",
      "epoch 1 loss: 0.8967\n",
      "epoch 2 loss: 0.7772\n",
      "epoch 3 loss: 0.7404\n",
      "epoch 4 loss: 0.4907\n",
      "epoch 5 loss: 0.6206\n",
      "epoch 6 loss: 0.2452\n",
      "epoch 7 loss: 0.1574\n",
      "epoch 8 loss: 0.1062\n",
      "epoch 9 loss: 0.0493\n",
      "epoch 10 loss: 0.0573\n",
      "epoch 11 loss: 0.0521\n",
      "epoch 12 loss: 0.0377\n",
      "epoch 13 loss: 0.0468\n",
      "epoch 14 loss: 0.0373\n",
      "epoch 15 loss: 0.0349\n",
      "epoch 16 loss: 0.0430\n",
      "epoch 17 loss: 0.0453\n",
      "epoch 18 loss: 0.0371\n",
      "epoch 19 loss: 0.0389\n",
      "epoch 20 loss: 0.0433\n",
      "epoch 21 loss: 0.0330\n",
      "epoch 22 loss: 0.0333\n",
      "epoch 23 loss: 0.0306\n",
      "epoch 24 loss: 0.0342\n",
      "epoch 25 loss: 0.0324\n",
      "epoch 26 loss: 0.0396\n",
      "epoch 27 loss: 0.0271\n",
      "epoch 28 loss: 0.0423\n",
      "epoch 29 loss: 0.0367\n",
      "epoch 30 loss: 0.0273\n",
      "14\n",
      "epoch 1 loss: 0.9251\n",
      "epoch 2 loss: 0.6856\n",
      "epoch 3 loss: 0.5028\n",
      "epoch 4 loss: 0.6929\n",
      "epoch 5 loss: 0.4291\n",
      "epoch 6 loss: 0.1652\n",
      "epoch 7 loss: 0.1684\n",
      "epoch 8 loss: 0.1391\n",
      "epoch 9 loss: 0.0635\n",
      "epoch 10 loss: 0.0658\n",
      "epoch 11 loss: 0.0520\n",
      "epoch 12 loss: 0.0446\n",
      "epoch 13 loss: 0.0504\n",
      "epoch 14 loss: 0.0543\n",
      "epoch 15 loss: 0.0440\n",
      "epoch 16 loss: 0.0363\n",
      "epoch 17 loss: 0.0413\n",
      "epoch 18 loss: 0.0408\n",
      "epoch 19 loss: 0.0334\n",
      "epoch 20 loss: 0.0338\n",
      "epoch 21 loss: 0.0403\n",
      "epoch 22 loss: 0.0383\n",
      "epoch 23 loss: 0.0368\n",
      "epoch 24 loss: 0.0366\n",
      "epoch 25 loss: 0.0369\n",
      "epoch 26 loss: 0.0367\n",
      "epoch 27 loss: 0.0389\n",
      "epoch 28 loss: 0.0300\n",
      "epoch 29 loss: 0.0408\n",
      "epoch 30 loss: 0.0402\n",
      "15\n",
      "epoch 1 loss: 0.8168\n",
      "epoch 2 loss: 0.7199\n",
      "epoch 3 loss: 0.5859\n",
      "epoch 4 loss: 0.6296\n",
      "epoch 5 loss: 0.6044\n",
      "epoch 6 loss: 0.4624\n",
      "epoch 7 loss: 0.2396\n",
      "epoch 8 loss: 0.0989\n",
      "epoch 9 loss: 0.0738\n",
      "epoch 10 loss: 0.0536\n",
      "epoch 11 loss: 0.0552\n",
      "epoch 12 loss: 0.0422\n",
      "epoch 13 loss: 0.0587\n",
      "epoch 14 loss: 0.0556\n",
      "epoch 15 loss: 0.0438\n",
      "epoch 16 loss: 0.0498\n",
      "epoch 17 loss: 0.0476\n",
      "epoch 18 loss: 0.0312\n",
      "epoch 19 loss: 0.0362\n",
      "epoch 20 loss: 0.0357\n",
      "epoch 21 loss: 0.0427\n",
      "epoch 22 loss: 0.0492\n",
      "epoch 23 loss: 0.0388\n",
      "epoch 24 loss: 0.0477\n",
      "epoch 25 loss: 0.0397\n",
      "epoch 26 loss: 0.0291\n",
      "epoch 27 loss: 0.0362\n",
      "epoch 28 loss: 0.0354\n",
      "epoch 29 loss: 0.0414\n",
      "epoch 30 loss: 0.0360\n",
      "16\n",
      "epoch 1 loss: 0.9618\n",
      "epoch 2 loss: 0.5131\n",
      "epoch 3 loss: 0.5198\n",
      "epoch 4 loss: 0.2792\n",
      "epoch 5 loss: 0.1155\n",
      "epoch 6 loss: 0.0838\n",
      "epoch 7 loss: 0.0651\n",
      "epoch 8 loss: 0.0558\n",
      "epoch 9 loss: 0.0466\n",
      "epoch 10 loss: 0.0481\n",
      "epoch 11 loss: 0.0355\n",
      "epoch 12 loss: 0.0424\n",
      "epoch 13 loss: 0.0539\n",
      "epoch 14 loss: 0.0488\n",
      "epoch 15 loss: 0.0452\n",
      "epoch 16 loss: 0.0412\n",
      "epoch 17 loss: 0.0370\n",
      "epoch 18 loss: 0.0363\n",
      "epoch 19 loss: 0.0294\n",
      "epoch 20 loss: 0.0332\n",
      "epoch 21 loss: 0.0313\n",
      "epoch 22 loss: 0.0290\n",
      "epoch 23 loss: 0.0310\n",
      "epoch 24 loss: 0.0355\n",
      "epoch 25 loss: 0.0352\n",
      "epoch 26 loss: 0.0300\n",
      "epoch 27 loss: 0.0274\n",
      "epoch 28 loss: 0.0348\n",
      "epoch 29 loss: 0.0297\n",
      "epoch 30 loss: 0.0272\n",
      "17\n",
      "epoch 1 loss: 0.6742\n",
      "epoch 2 loss: 0.5135\n",
      "epoch 3 loss: 0.4649\n",
      "epoch 4 loss: 0.4507\n",
      "epoch 5 loss: 0.2710\n",
      "epoch 6 loss: 0.1354\n",
      "epoch 7 loss: 0.0782\n",
      "epoch 8 loss: 0.0762\n",
      "epoch 9 loss: 0.0604\n",
      "epoch 10 loss: 0.0560\n",
      "epoch 11 loss: 0.0464\n",
      "epoch 12 loss: 0.0481\n",
      "epoch 13 loss: 0.0684\n",
      "epoch 14 loss: 0.0406\n",
      "epoch 15 loss: 0.0429\n",
      "epoch 16 loss: 0.0448\n",
      "epoch 17 loss: 0.0403\n",
      "epoch 18 loss: 0.0409\n",
      "epoch 19 loss: 0.0425\n",
      "epoch 20 loss: 0.0472\n",
      "epoch 21 loss: 0.0314\n",
      "epoch 22 loss: 0.0419\n",
      "epoch 23 loss: 0.0379\n",
      "epoch 24 loss: 0.0355\n",
      "epoch 25 loss: 0.0405\n",
      "epoch 26 loss: 0.0261\n",
      "epoch 27 loss: 0.0379\n",
      "epoch 28 loss: 0.0367\n",
      "epoch 29 loss: 0.0303\n",
      "epoch 30 loss: 0.0331\n",
      "18\n",
      "epoch 1 loss: 0.9838\n",
      "epoch 2 loss: 0.5478\n",
      "epoch 3 loss: 0.4976\n",
      "epoch 4 loss: 0.2472\n",
      "epoch 5 loss: 0.1765\n",
      "epoch 6 loss: 0.1037\n",
      "epoch 7 loss: 0.0524\n",
      "epoch 8 loss: 0.0678\n",
      "epoch 9 loss: 0.0484\n",
      "epoch 10 loss: 0.0407\n",
      "epoch 11 loss: 0.0468\n",
      "epoch 12 loss: 0.0433\n",
      "epoch 13 loss: 0.0362\n",
      "epoch 14 loss: 0.0291\n",
      "epoch 15 loss: 0.0385\n",
      "epoch 16 loss: 0.0367\n",
      "epoch 17 loss: 0.0386\n",
      "epoch 18 loss: 0.0304\n",
      "epoch 19 loss: 0.0270\n",
      "epoch 20 loss: 0.0317\n",
      "epoch 21 loss: 0.0309\n",
      "epoch 22 loss: 0.0414\n",
      "epoch 23 loss: 0.0301\n",
      "epoch 24 loss: 0.0289\n",
      "epoch 25 loss: 0.0266\n",
      "epoch 26 loss: 0.0325\n",
      "epoch 27 loss: 0.0369\n",
      "epoch 28 loss: 0.0259\n",
      "epoch 29 loss: 0.0263\n",
      "epoch 30 loss: 0.0280\n",
      "19\n",
      "epoch 1 loss: 0.7012\n",
      "epoch 2 loss: 0.6312\n",
      "epoch 3 loss: 0.4658\n",
      "epoch 4 loss: 0.3521\n",
      "epoch 5 loss: 0.2350\n",
      "epoch 6 loss: 0.1531\n",
      "epoch 7 loss: 0.0998\n",
      "epoch 8 loss: 0.0679\n",
      "epoch 9 loss: 0.0658\n",
      "epoch 10 loss: 0.0657\n",
      "epoch 11 loss: 0.0724\n",
      "epoch 12 loss: 0.0591\n",
      "epoch 13 loss: 0.0559\n",
      "epoch 14 loss: 0.0522\n",
      "epoch 15 loss: 0.0453\n",
      "epoch 16 loss: 0.0457\n",
      "epoch 17 loss: 0.0385\n",
      "epoch 18 loss: 0.0485\n",
      "epoch 19 loss: 0.0418\n",
      "epoch 20 loss: 0.0454\n",
      "epoch 21 loss: 0.0365\n",
      "epoch 22 loss: 0.0400\n",
      "epoch 23 loss: 0.0461\n",
      "epoch 24 loss: 0.0429\n",
      "epoch 25 loss: 0.0482\n",
      "epoch 26 loss: 0.0431\n",
      "epoch 27 loss: 0.0466\n",
      "epoch 28 loss: 0.0354\n",
      "epoch 29 loss: 0.0339\n",
      "epoch 30 loss: 0.0368\n",
      "20\n",
      "epoch 1 loss: 1.0741\n",
      "epoch 2 loss: 0.6784\n",
      "epoch 3 loss: 0.5685\n",
      "epoch 4 loss: 0.3555\n",
      "epoch 5 loss: 0.2863\n",
      "epoch 6 loss: 0.1268\n",
      "epoch 7 loss: 0.0680\n",
      "epoch 8 loss: 0.0536\n",
      "epoch 9 loss: 0.0432\n",
      "epoch 10 loss: 0.0415\n",
      "epoch 11 loss: 0.0408\n",
      "epoch 12 loss: 0.0521\n",
      "epoch 13 loss: 0.0494\n",
      "epoch 14 loss: 0.0269\n",
      "epoch 15 loss: 0.0433\n",
      "epoch 16 loss: 0.0435\n",
      "epoch 17 loss: 0.0293\n",
      "epoch 18 loss: 0.0393\n",
      "epoch 19 loss: 0.0370\n",
      "epoch 20 loss: 0.0394\n",
      "epoch 21 loss: 0.0354\n",
      "epoch 22 loss: 0.0316\n",
      "epoch 23 loss: 0.0336\n",
      "epoch 24 loss: 0.0294\n",
      "epoch 25 loss: 0.0386\n",
      "epoch 26 loss: 0.0281\n",
      "epoch 27 loss: 0.0320\n",
      "epoch 28 loss: 0.0242\n",
      "epoch 29 loss: 0.0317\n",
      "epoch 30 loss: 0.0244\n",
      "21\n",
      "epoch 1 loss: 0.6692\n",
      "epoch 2 loss: 0.4381\n",
      "epoch 3 loss: 0.4048\n",
      "epoch 4 loss: 0.2536\n",
      "epoch 5 loss: 0.1306\n",
      "epoch 6 loss: 0.0856\n",
      "epoch 7 loss: 0.0590\n",
      "epoch 8 loss: 0.0563\n",
      "epoch 9 loss: 0.0430\n",
      "epoch 10 loss: 0.0451\n",
      "epoch 11 loss: 0.0476\n",
      "epoch 12 loss: 0.0409\n",
      "epoch 13 loss: 0.0404\n",
      "epoch 14 loss: 0.0351\n",
      "epoch 15 loss: 0.0349\n",
      "epoch 16 loss: 0.0339\n",
      "epoch 17 loss: 0.0395\n",
      "epoch 18 loss: 0.0286\n",
      "epoch 19 loss: 0.0310\n",
      "epoch 20 loss: 0.0316\n",
      "epoch 21 loss: 0.0241\n",
      "epoch 22 loss: 0.0267\n",
      "epoch 23 loss: 0.0253\n",
      "epoch 24 loss: 0.0345\n",
      "epoch 25 loss: 0.0250\n",
      "epoch 26 loss: 0.0280\n",
      "epoch 27 loss: 0.0330\n",
      "epoch 28 loss: 0.0276\n",
      "epoch 29 loss: 0.0334\n",
      "epoch 30 loss: 0.0257\n",
      "22\n",
      "epoch 1 loss: 0.8527\n",
      "epoch 2 loss: 0.5354\n",
      "epoch 3 loss: 0.3329\n",
      "epoch 4 loss: 0.2447\n",
      "epoch 5 loss: 0.1916\n",
      "epoch 6 loss: 0.0895\n",
      "epoch 7 loss: 0.0609\n",
      "epoch 8 loss: 0.0702\n",
      "epoch 9 loss: 0.0448\n",
      "epoch 10 loss: 0.0511\n",
      "epoch 11 loss: 0.0379\n",
      "epoch 12 loss: 0.0391\n",
      "epoch 13 loss: 0.0499\n",
      "epoch 14 loss: 0.0371\n",
      "epoch 15 loss: 0.0465\n",
      "epoch 16 loss: 0.0438\n",
      "epoch 17 loss: 0.0433\n",
      "epoch 18 loss: 0.0451\n",
      "epoch 19 loss: 0.0393\n",
      "epoch 20 loss: 0.0362\n",
      "epoch 21 loss: 0.0380\n",
      "epoch 22 loss: 0.0381\n",
      "epoch 23 loss: 0.0299\n",
      "epoch 24 loss: 0.0327\n",
      "epoch 25 loss: 0.0295\n",
      "epoch 26 loss: 0.0264\n",
      "epoch 27 loss: 0.0331\n",
      "epoch 28 loss: 0.0364\n",
      "epoch 29 loss: 0.0298\n",
      "epoch 30 loss: 0.0358\n",
      "23\n",
      "epoch 1 loss: 0.8529\n",
      "epoch 2 loss: 0.5465\n",
      "epoch 3 loss: 0.4200\n",
      "epoch 4 loss: 0.4304\n",
      "epoch 5 loss: 0.5097\n",
      "epoch 6 loss: 0.3043\n",
      "epoch 7 loss: 0.1720\n",
      "epoch 8 loss: 0.0869\n",
      "epoch 9 loss: 0.0613\n",
      "epoch 10 loss: 0.0675\n",
      "epoch 11 loss: 0.0455\n",
      "epoch 12 loss: 0.0505\n",
      "epoch 13 loss: 0.0480\n",
      "epoch 14 loss: 0.0516\n",
      "epoch 15 loss: 0.0555\n",
      "epoch 16 loss: 0.0378\n",
      "epoch 17 loss: 0.0523\n",
      "epoch 18 loss: 0.0328\n",
      "epoch 19 loss: 0.0541\n",
      "epoch 20 loss: 0.0398\n",
      "epoch 21 loss: 0.0329\n",
      "epoch 22 loss: 0.0359\n",
      "epoch 23 loss: 0.0365\n",
      "epoch 24 loss: 0.0403\n",
      "epoch 25 loss: 0.0342\n",
      "epoch 26 loss: 0.0408\n",
      "epoch 27 loss: 0.0304\n",
      "epoch 28 loss: 0.0314\n",
      "epoch 29 loss: 0.0324\n",
      "epoch 30 loss: 0.0345\n",
      "24\n",
      "epoch 1 loss: 0.9833\n",
      "epoch 2 loss: 0.5262\n",
      "epoch 3 loss: 0.3159\n",
      "epoch 4 loss: 0.2233\n",
      "epoch 5 loss: 0.1809\n",
      "epoch 6 loss: 0.1295\n",
      "epoch 7 loss: 0.0685\n",
      "epoch 8 loss: 0.0952\n",
      "epoch 9 loss: 0.0650\n",
      "epoch 10 loss: 0.0687\n",
      "epoch 11 loss: 0.0785\n",
      "epoch 12 loss: 0.0680\n",
      "epoch 13 loss: 0.0471\n",
      "epoch 14 loss: 0.0646\n",
      "epoch 15 loss: 0.0554\n",
      "epoch 16 loss: 0.0476\n",
      "epoch 17 loss: 0.0457\n",
      "epoch 18 loss: 0.0504\n",
      "epoch 19 loss: 0.0428\n",
      "epoch 20 loss: 0.0317\n",
      "epoch 21 loss: 0.0435\n",
      "epoch 22 loss: 0.0306\n",
      "epoch 23 loss: 0.0499\n",
      "epoch 24 loss: 0.0441\n",
      "epoch 25 loss: 0.0500\n",
      "epoch 26 loss: 0.0392\n",
      "epoch 27 loss: 0.0370\n",
      "epoch 28 loss: 0.0424\n",
      "epoch 29 loss: 0.0363\n",
      "epoch 30 loss: 0.0305\n",
      "25\n",
      "epoch 1 loss: 1.3953\n",
      "epoch 2 loss: 0.6419\n",
      "epoch 3 loss: 0.5256\n",
      "epoch 4 loss: 0.4952\n",
      "epoch 5 loss: 0.2554\n",
      "epoch 6 loss: 0.1685\n",
      "epoch 7 loss: 0.0963\n",
      "epoch 8 loss: 0.0617\n",
      "epoch 9 loss: 0.0583\n",
      "epoch 10 loss: 0.0569\n",
      "epoch 11 loss: 0.0495\n",
      "epoch 12 loss: 0.0425\n",
      "epoch 13 loss: 0.0451\n",
      "epoch 14 loss: 0.0504\n",
      "epoch 15 loss: 0.0382\n",
      "epoch 16 loss: 0.0390\n",
      "epoch 17 loss: 0.0397\n",
      "epoch 18 loss: 0.0402\n",
      "epoch 19 loss: 0.0381\n",
      "epoch 20 loss: 0.0386\n",
      "epoch 21 loss: 0.0306\n",
      "epoch 22 loss: 0.0392\n",
      "epoch 23 loss: 0.0327\n",
      "epoch 24 loss: 0.0296\n",
      "epoch 25 loss: 0.0286\n",
      "epoch 26 loss: 0.0262\n",
      "epoch 27 loss: 0.0239\n",
      "epoch 28 loss: 0.0303\n",
      "epoch 29 loss: 0.0254\n",
      "epoch 30 loss: 0.0302\n",
      "26\n",
      "epoch 1 loss: 0.9354\n",
      "epoch 2 loss: 0.4201\n",
      "epoch 3 loss: 0.4882\n",
      "epoch 4 loss: 0.3993\n",
      "epoch 5 loss: 0.2929\n",
      "epoch 6 loss: 0.1300\n",
      "epoch 7 loss: 0.0824\n",
      "epoch 8 loss: 0.0642\n",
      "epoch 9 loss: 0.0642\n",
      "epoch 10 loss: 0.0611\n",
      "epoch 11 loss: 0.0555\n",
      "epoch 12 loss: 0.0564\n",
      "epoch 13 loss: 0.0593\n",
      "epoch 14 loss: 0.0523\n",
      "epoch 15 loss: 0.0447\n",
      "epoch 16 loss: 0.0485\n",
      "epoch 17 loss: 0.0434\n",
      "epoch 18 loss: 0.0404\n",
      "epoch 19 loss: 0.0385\n",
      "epoch 20 loss: 0.0466\n",
      "epoch 21 loss: 0.0446\n",
      "epoch 22 loss: 0.0351\n",
      "epoch 23 loss: 0.0363\n",
      "epoch 24 loss: 0.0400\n",
      "epoch 25 loss: 0.0407\n",
      "epoch 26 loss: 0.0399\n",
      "epoch 27 loss: 0.0294\n",
      "epoch 28 loss: 0.0340\n",
      "epoch 29 loss: 0.0296\n",
      "epoch 30 loss: 0.0281\n",
      "27\n",
      "epoch 1 loss: 0.8878\n",
      "epoch 2 loss: 0.8240\n",
      "epoch 3 loss: 0.5371\n",
      "epoch 4 loss: 0.3130\n",
      "epoch 5 loss: 0.2444\n",
      "epoch 6 loss: 0.1557\n",
      "epoch 7 loss: 0.1270\n",
      "epoch 8 loss: 0.0961\n",
      "epoch 9 loss: 0.0664\n",
      "epoch 10 loss: 0.0607\n",
      "epoch 11 loss: 0.0457\n",
      "epoch 12 loss: 0.0545\n",
      "epoch 13 loss: 0.0515\n",
      "epoch 14 loss: 0.0511\n",
      "epoch 15 loss: 0.0353\n",
      "epoch 16 loss: 0.0442\n",
      "epoch 17 loss: 0.0419\n",
      "epoch 18 loss: 0.0347\n",
      "epoch 19 loss: 0.0462\n",
      "epoch 20 loss: 0.0362\n",
      "epoch 21 loss: 0.0353\n",
      "epoch 22 loss: 0.0336\n",
      "epoch 23 loss: 0.0267\n",
      "epoch 24 loss: 0.0406\n",
      "epoch 25 loss: 0.0321\n",
      "epoch 26 loss: 0.0248\n",
      "epoch 27 loss: 0.0355\n",
      "epoch 28 loss: 0.0312\n",
      "epoch 29 loss: 0.0280\n",
      "epoch 30 loss: 0.0329\n",
      "28\n",
      "epoch 1 loss: 0.6016\n",
      "epoch 2 loss: 0.5616\n",
      "epoch 3 loss: 0.5500\n",
      "epoch 4 loss: 0.4442\n",
      "epoch 5 loss: 0.4650\n",
      "epoch 6 loss: 0.2650\n",
      "epoch 7 loss: 0.1738\n",
      "epoch 8 loss: 0.1083\n",
      "epoch 9 loss: 0.0669\n",
      "epoch 10 loss: 0.0519\n",
      "epoch 11 loss: 0.0569\n",
      "epoch 12 loss: 0.0491\n",
      "epoch 13 loss: 0.0420\n",
      "epoch 14 loss: 0.0449\n",
      "epoch 15 loss: 0.0393\n",
      "epoch 16 loss: 0.0368\n",
      "epoch 17 loss: 0.0414\n",
      "epoch 18 loss: 0.0337\n",
      "epoch 19 loss: 0.0311\n",
      "epoch 20 loss: 0.0372\n",
      "epoch 21 loss: 0.0379\n",
      "epoch 22 loss: 0.0433\n",
      "epoch 23 loss: 0.0297\n",
      "epoch 24 loss: 0.0312\n",
      "epoch 25 loss: 0.0317\n",
      "epoch 26 loss: 0.0382\n",
      "epoch 27 loss: 0.0296\n",
      "epoch 28 loss: 0.0336\n",
      "epoch 29 loss: 0.0257\n",
      "epoch 30 loss: 0.0289\n",
      "29\n",
      "epoch 1 loss: 0.7398\n",
      "epoch 2 loss: 0.9248\n",
      "epoch 3 loss: 0.9751\n",
      "epoch 4 loss: 0.6684\n",
      "epoch 5 loss: 0.3230\n",
      "epoch 6 loss: 0.2437\n",
      "epoch 7 loss: 0.2443\n",
      "epoch 8 loss: 0.1511\n",
      "epoch 9 loss: 0.1166\n",
      "epoch 10 loss: 0.1031\n",
      "epoch 11 loss: 0.0740\n",
      "epoch 12 loss: 0.0610\n",
      "epoch 13 loss: 0.0509\n",
      "epoch 14 loss: 0.0558\n",
      "epoch 15 loss: 0.0436\n",
      "epoch 16 loss: 0.0488\n",
      "epoch 17 loss: 0.0420\n",
      "epoch 18 loss: 0.0446\n",
      "epoch 19 loss: 0.0382\n",
      "epoch 20 loss: 0.0401\n",
      "epoch 21 loss: 0.0375\n",
      "epoch 22 loss: 0.0411\n",
      "epoch 23 loss: 0.0423\n",
      "epoch 24 loss: 0.0395\n",
      "epoch 25 loss: 0.0349\n",
      "epoch 26 loss: 0.0392\n",
      "epoch 27 loss: 0.0359\n",
      "epoch 28 loss: 0.0463\n",
      "epoch 29 loss: 0.0330\n",
      "epoch 30 loss: 0.0325\n",
      "30\n",
      "epoch 1 loss: 0.6143\n",
      "epoch 2 loss: 0.5673\n",
      "epoch 3 loss: 0.4690\n",
      "epoch 4 loss: 0.8778\n",
      "epoch 5 loss: 0.6241\n",
      "epoch 6 loss: 0.4716\n",
      "epoch 7 loss: 0.4307\n",
      "epoch 8 loss: 0.1437\n",
      "epoch 9 loss: 0.1067\n",
      "epoch 10 loss: 0.0658\n",
      "epoch 11 loss: 0.0704\n",
      "epoch 12 loss: 0.0475\n",
      "epoch 13 loss: 0.0474\n",
      "epoch 14 loss: 0.0395\n",
      "epoch 15 loss: 0.0457\n",
      "epoch 16 loss: 0.0428\n",
      "epoch 17 loss: 0.0411\n",
      "epoch 18 loss: 0.0502\n",
      "epoch 19 loss: 0.0314\n",
      "epoch 20 loss: 0.0321\n",
      "epoch 21 loss: 0.0374\n",
      "epoch 22 loss: 0.0408\n",
      "epoch 23 loss: 0.0330\n",
      "epoch 24 loss: 0.0294\n",
      "epoch 25 loss: 0.0327\n",
      "epoch 26 loss: 0.0261\n",
      "epoch 27 loss: 0.0282\n",
      "epoch 28 loss: 0.0238\n",
      "epoch 29 loss: 0.0222\n",
      "epoch 30 loss: 0.0295\n",
      "31\n",
      "epoch 1 loss: 0.7575\n",
      "epoch 2 loss: 0.4940\n",
      "epoch 3 loss: 0.4270\n",
      "epoch 4 loss: 0.2808\n",
      "epoch 5 loss: 0.1735\n",
      "epoch 6 loss: 0.0878\n",
      "epoch 7 loss: 0.0709\n",
      "epoch 8 loss: 0.0542\n",
      "epoch 9 loss: 0.0391\n",
      "epoch 10 loss: 0.0549\n",
      "epoch 11 loss: 0.0406\n",
      "epoch 12 loss: 0.0453\n",
      "epoch 13 loss: 0.0483\n",
      "epoch 14 loss: 0.0367\n",
      "epoch 15 loss: 0.0427\n",
      "epoch 16 loss: 0.0368\n",
      "epoch 17 loss: 0.0388\n",
      "epoch 18 loss: 0.0371\n",
      "epoch 19 loss: 0.0399\n",
      "epoch 20 loss: 0.0362\n",
      "epoch 21 loss: 0.0396\n",
      "epoch 22 loss: 0.0327\n",
      "epoch 23 loss: 0.0456\n",
      "epoch 24 loss: 0.0436\n",
      "epoch 25 loss: 0.0460\n",
      "epoch 26 loss: 0.0351\n",
      "epoch 27 loss: 0.0342\n",
      "epoch 28 loss: 0.0303\n",
      "epoch 29 loss: 0.0253\n",
      "epoch 30 loss: 0.0281\n",
      "32\n",
      "epoch 1 loss: 0.9458\n",
      "epoch 2 loss: 0.6472\n",
      "epoch 3 loss: 0.5685\n",
      "epoch 4 loss: 0.4124\n",
      "epoch 5 loss: 0.3807\n",
      "epoch 6 loss: 0.2488\n",
      "epoch 7 loss: 0.1705\n",
      "epoch 8 loss: 0.1102\n",
      "epoch 9 loss: 0.0641\n",
      "epoch 10 loss: 0.0632\n",
      "epoch 11 loss: 0.0518\n",
      "epoch 12 loss: 0.0566\n",
      "epoch 13 loss: 0.0364\n",
      "epoch 14 loss: 0.0409\n",
      "epoch 15 loss: 0.0452\n",
      "epoch 16 loss: 0.0537\n",
      "epoch 17 loss: 0.0420\n",
      "epoch 18 loss: 0.0436\n",
      "epoch 19 loss: 0.0424\n",
      "epoch 20 loss: 0.0304\n",
      "epoch 21 loss: 0.0316\n",
      "epoch 22 loss: 0.0366\n",
      "epoch 23 loss: 0.0389\n",
      "epoch 24 loss: 0.0414\n",
      "epoch 25 loss: 0.0395\n",
      "epoch 26 loss: 0.0302\n",
      "epoch 27 loss: 0.0314\n",
      "epoch 28 loss: 0.0325\n",
      "epoch 29 loss: 0.0277\n",
      "epoch 30 loss: 0.0334\n",
      "33\n",
      "epoch 1 loss: 0.8257\n",
      "epoch 2 loss: 0.6708\n",
      "epoch 3 loss: 0.5165\n",
      "epoch 4 loss: 0.4247\n",
      "epoch 5 loss: 0.4285\n",
      "epoch 6 loss: 0.5172\n",
      "epoch 7 loss: 0.4876\n",
      "epoch 8 loss: 0.2571\n",
      "epoch 9 loss: 0.2017\n",
      "epoch 10 loss: 0.0789\n",
      "epoch 11 loss: 0.0691\n",
      "epoch 12 loss: 0.0415\n",
      "epoch 13 loss: 0.0415\n",
      "epoch 14 loss: 0.0417\n",
      "epoch 15 loss: 0.0403\n",
      "epoch 16 loss: 0.0298\n",
      "epoch 17 loss: 0.0465\n",
      "epoch 18 loss: 0.0340\n",
      "epoch 19 loss: 0.0318\n",
      "epoch 20 loss: 0.0373\n",
      "epoch 21 loss: 0.0406\n",
      "epoch 22 loss: 0.0374\n",
      "epoch 23 loss: 0.0340\n",
      "epoch 24 loss: 0.0391\n",
      "epoch 25 loss: 0.0321\n",
      "epoch 26 loss: 0.0317\n",
      "epoch 27 loss: 0.0300\n",
      "epoch 28 loss: 0.0284\n",
      "epoch 29 loss: 0.0303\n",
      "epoch 30 loss: 0.0272\n",
      "34\n",
      "epoch 1 loss: 0.7835\n",
      "epoch 2 loss: 0.4948\n",
      "epoch 3 loss: 0.3740\n",
      "epoch 4 loss: 0.2405\n",
      "epoch 5 loss: 0.1745\n",
      "epoch 6 loss: 0.0934\n",
      "epoch 7 loss: 0.0729\n",
      "epoch 8 loss: 0.0659\n",
      "epoch 9 loss: 0.0483\n",
      "epoch 10 loss: 0.0579\n",
      "epoch 11 loss: 0.0452\n",
      "epoch 12 loss: 0.0529\n",
      "epoch 13 loss: 0.0439\n",
      "epoch 14 loss: 0.0338\n",
      "epoch 15 loss: 0.0482\n",
      "epoch 16 loss: 0.0378\n",
      "epoch 17 loss: 0.0328\n",
      "epoch 18 loss: 0.0397\n",
      "epoch 19 loss: 0.0395\n",
      "epoch 20 loss: 0.0469\n",
      "epoch 21 loss: 0.0468\n",
      "epoch 22 loss: 0.0254\n",
      "epoch 23 loss: 0.0403\n",
      "epoch 24 loss: 0.0386\n",
      "epoch 25 loss: 0.0342\n",
      "epoch 26 loss: 0.0330\n",
      "epoch 27 loss: 0.0320\n",
      "epoch 28 loss: 0.0296\n",
      "epoch 29 loss: 0.0396\n",
      "epoch 30 loss: 0.0283\n",
      "35\n",
      "epoch 1 loss: 0.9494\n",
      "epoch 2 loss: 0.4006\n",
      "epoch 3 loss: 0.4904\n",
      "epoch 4 loss: 0.2816\n",
      "epoch 5 loss: 0.2056\n",
      "epoch 6 loss: 0.1364\n",
      "epoch 7 loss: 0.0803\n",
      "epoch 8 loss: 0.0637\n",
      "epoch 9 loss: 0.0612\n",
      "epoch 10 loss: 0.0450\n",
      "epoch 11 loss: 0.0514\n",
      "epoch 12 loss: 0.0472\n",
      "epoch 13 loss: 0.0488\n",
      "epoch 14 loss: 0.0416\n",
      "epoch 15 loss: 0.0386\n",
      "epoch 16 loss: 0.0286\n",
      "epoch 17 loss: 0.0439\n",
      "epoch 18 loss: 0.0471\n",
      "epoch 19 loss: 0.0355\n",
      "epoch 20 loss: 0.0293\n",
      "epoch 21 loss: 0.0356\n",
      "epoch 22 loss: 0.0369\n",
      "epoch 23 loss: 0.0455\n",
      "epoch 24 loss: 0.0322\n",
      "epoch 25 loss: 0.0359\n",
      "epoch 26 loss: 0.0349\n",
      "epoch 27 loss: 0.0361\n",
      "epoch 28 loss: 0.0343\n",
      "epoch 29 loss: 0.0352\n",
      "epoch 30 loss: 0.0322\n",
      "36\n",
      "epoch 1 loss: 0.6616\n",
      "epoch 2 loss: 0.4526\n",
      "epoch 3 loss: 0.3063\n",
      "epoch 4 loss: 0.1549\n",
      "epoch 5 loss: 0.1830\n",
      "epoch 6 loss: 0.1642\n",
      "epoch 7 loss: 0.1339\n",
      "epoch 8 loss: 0.1115\n",
      "epoch 9 loss: 0.0969\n",
      "epoch 10 loss: 0.0677\n",
      "epoch 11 loss: 0.0530\n",
      "epoch 12 loss: 0.0501\n",
      "epoch 13 loss: 0.0530\n",
      "epoch 14 loss: 0.0632\n",
      "epoch 15 loss: 0.0574\n",
      "epoch 16 loss: 0.0502\n",
      "epoch 17 loss: 0.0499\n",
      "epoch 18 loss: 0.0461\n",
      "epoch 19 loss: 0.0374\n",
      "epoch 20 loss: 0.0416\n",
      "epoch 21 loss: 0.0497\n",
      "epoch 22 loss: 0.0326\n",
      "epoch 23 loss: 0.0377\n",
      "epoch 24 loss: 0.0506\n",
      "epoch 25 loss: 0.0301\n",
      "epoch 26 loss: 0.0424\n",
      "epoch 27 loss: 0.0474\n",
      "epoch 28 loss: 0.0352\n",
      "epoch 29 loss: 0.0498\n",
      "epoch 30 loss: 0.0335\n",
      "37\n",
      "epoch 1 loss: 1.3589\n",
      "epoch 2 loss: 0.7851\n",
      "epoch 3 loss: 0.5002\n",
      "epoch 4 loss: 0.4554\n",
      "epoch 5 loss: 0.2920\n",
      "epoch 6 loss: 0.2300\n",
      "epoch 7 loss: 0.1217\n",
      "epoch 8 loss: 0.0806\n",
      "epoch 9 loss: 0.0519\n",
      "epoch 10 loss: 0.0580\n",
      "epoch 11 loss: 0.0621\n",
      "epoch 12 loss: 0.0482\n",
      "epoch 13 loss: 0.0561\n",
      "epoch 14 loss: 0.0642\n",
      "epoch 15 loss: 0.0462\n",
      "epoch 16 loss: 0.0455\n",
      "epoch 17 loss: 0.0332\n",
      "epoch 18 loss: 0.0464\n",
      "epoch 19 loss: 0.0509\n",
      "epoch 20 loss: 0.0407\n",
      "epoch 21 loss: 0.0352\n",
      "epoch 22 loss: 0.0439\n",
      "epoch 23 loss: 0.0385\n",
      "epoch 24 loss: 0.0407\n",
      "epoch 25 loss: 0.0451\n",
      "epoch 26 loss: 0.0328\n",
      "epoch 27 loss: 0.0346\n",
      "epoch 28 loss: 0.0332\n",
      "epoch 29 loss: 0.0376\n",
      "epoch 30 loss: 0.0417\n",
      "38\n",
      "epoch 1 loss: 0.8626\n",
      "epoch 2 loss: 0.6302\n",
      "epoch 3 loss: 0.4135\n",
      "epoch 4 loss: 0.4941\n",
      "epoch 5 loss: 0.4119\n",
      "epoch 6 loss: 0.2926\n",
      "epoch 7 loss: 0.1565\n",
      "epoch 8 loss: 0.0690\n",
      "epoch 9 loss: 0.0592\n",
      "epoch 10 loss: 0.0764\n",
      "epoch 11 loss: 0.0460\n",
      "epoch 12 loss: 0.0591\n",
      "epoch 13 loss: 0.0539\n",
      "epoch 14 loss: 0.0435\n",
      "epoch 15 loss: 0.0489\n",
      "epoch 16 loss: 0.0455\n",
      "epoch 17 loss: 0.0519\n",
      "epoch 18 loss: 0.0390\n",
      "epoch 19 loss: 0.0527\n",
      "epoch 20 loss: 0.0483\n",
      "epoch 21 loss: 0.0407\n",
      "epoch 22 loss: 0.0393\n",
      "epoch 23 loss: 0.0512\n",
      "epoch 24 loss: 0.0497\n",
      "epoch 25 loss: 0.0420\n",
      "epoch 26 loss: 0.0414\n",
      "epoch 27 loss: 0.0380\n",
      "epoch 28 loss: 0.0400\n",
      "epoch 29 loss: 0.0234\n",
      "epoch 30 loss: 0.0397\n",
      "39\n",
      "epoch 1 loss: 0.7829\n",
      "epoch 2 loss: 0.6240\n",
      "epoch 3 loss: 0.4752\n",
      "epoch 4 loss: 0.3167\n",
      "epoch 5 loss: 0.2141\n",
      "epoch 6 loss: 0.1314\n",
      "epoch 7 loss: 0.0715\n",
      "epoch 8 loss: 0.0631\n",
      "epoch 9 loss: 0.0556\n",
      "epoch 10 loss: 0.0519\n",
      "epoch 11 loss: 0.0430\n",
      "epoch 12 loss: 0.0468\n",
      "epoch 13 loss: 0.0463\n",
      "epoch 14 loss: 0.0389\n",
      "epoch 15 loss: 0.0423\n",
      "epoch 16 loss: 0.0364\n",
      "epoch 17 loss: 0.0458\n",
      "epoch 18 loss: 0.0371\n",
      "epoch 19 loss: 0.0385\n",
      "epoch 20 loss: 0.0360\n",
      "epoch 21 loss: 0.0343\n",
      "epoch 22 loss: 0.0285\n",
      "epoch 23 loss: 0.0311\n",
      "epoch 24 loss: 0.0312\n",
      "epoch 25 loss: 0.0346\n",
      "epoch 26 loss: 0.0315\n",
      "epoch 27 loss: 0.0336\n",
      "epoch 28 loss: 0.0356\n",
      "epoch 29 loss: 0.0292\n",
      "epoch 30 loss: 0.0373\n",
      "40\n",
      "epoch 1 loss: 1.1488\n",
      "epoch 2 loss: 0.8453\n",
      "epoch 3 loss: 0.5357\n",
      "epoch 4 loss: 0.4004\n",
      "epoch 5 loss: 0.3919\n",
      "epoch 6 loss: 0.3061\n",
      "epoch 7 loss: 0.1907\n",
      "epoch 8 loss: 0.1002\n",
      "epoch 9 loss: 0.0846\n",
      "epoch 10 loss: 0.0525\n",
      "epoch 11 loss: 0.0604\n",
      "epoch 12 loss: 0.0666\n",
      "epoch 13 loss: 0.0557\n",
      "epoch 14 loss: 0.0519\n",
      "epoch 15 loss: 0.0408\n",
      "epoch 16 loss: 0.0550\n",
      "epoch 17 loss: 0.0465\n",
      "epoch 18 loss: 0.0402\n",
      "epoch 19 loss: 0.0576\n",
      "epoch 20 loss: 0.0354\n",
      "epoch 21 loss: 0.0405\n",
      "epoch 22 loss: 0.0412\n",
      "epoch 23 loss: 0.0443\n",
      "epoch 24 loss: 0.0457\n",
      "epoch 25 loss: 0.0389\n",
      "epoch 26 loss: 0.0385\n",
      "epoch 27 loss: 0.0392\n",
      "epoch 28 loss: 0.0456\n",
      "epoch 29 loss: 0.0297\n",
      "epoch 30 loss: 0.0261\n",
      "41\n",
      "epoch 1 loss: 0.7904\n",
      "epoch 2 loss: 0.4911\n",
      "epoch 3 loss: 0.3804\n",
      "epoch 4 loss: 0.1824\n",
      "epoch 5 loss: 0.1187\n",
      "epoch 6 loss: 0.0596\n",
      "epoch 7 loss: 0.0498\n",
      "epoch 8 loss: 0.0565\n",
      "epoch 9 loss: 0.0433\n",
      "epoch 10 loss: 0.0462\n",
      "epoch 11 loss: 0.0504\n",
      "epoch 12 loss: 0.0409\n",
      "epoch 13 loss: 0.0357\n",
      "epoch 14 loss: 0.0416\n",
      "epoch 15 loss: 0.0355\n",
      "epoch 16 loss: 0.0356\n",
      "epoch 17 loss: 0.0304\n",
      "epoch 18 loss: 0.0275\n",
      "epoch 19 loss: 0.0368\n",
      "epoch 20 loss: 0.0353\n",
      "epoch 21 loss: 0.0338\n",
      "epoch 22 loss: 0.0403\n",
      "epoch 23 loss: 0.0406\n",
      "epoch 24 loss: 0.0306\n",
      "epoch 25 loss: 0.0319\n",
      "epoch 26 loss: 0.0295\n",
      "epoch 27 loss: 0.0339\n",
      "epoch 28 loss: 0.0297\n",
      "epoch 29 loss: 0.0324\n",
      "epoch 30 loss: 0.0230\n",
      "42\n",
      "epoch 1 loss: 0.7156\n",
      "epoch 2 loss: 0.4910\n",
      "epoch 3 loss: 0.5199\n",
      "epoch 4 loss: 0.2588\n",
      "epoch 5 loss: 0.1831\n",
      "epoch 6 loss: 0.0947\n",
      "epoch 7 loss: 0.0825\n",
      "epoch 8 loss: 0.0611\n",
      "epoch 9 loss: 0.0572\n",
      "epoch 10 loss: 0.0601\n",
      "epoch 11 loss: 0.0456\n",
      "epoch 12 loss: 0.0483\n",
      "epoch 13 loss: 0.0498\n",
      "epoch 14 loss: 0.0426\n",
      "epoch 15 loss: 0.0429\n",
      "epoch 16 loss: 0.0368\n",
      "epoch 17 loss: 0.0370\n",
      "epoch 18 loss: 0.0327\n",
      "epoch 19 loss: 0.0360\n",
      "epoch 20 loss: 0.0368\n",
      "epoch 21 loss: 0.0373\n",
      "epoch 22 loss: 0.0317\n",
      "epoch 23 loss: 0.0225\n",
      "epoch 24 loss: 0.0341\n",
      "epoch 25 loss: 0.0280\n",
      "epoch 26 loss: 0.0359\n",
      "epoch 27 loss: 0.0264\n",
      "epoch 28 loss: 0.0295\n",
      "epoch 29 loss: 0.0300\n",
      "epoch 30 loss: 0.0302\n",
      "43\n",
      "epoch 1 loss: 0.8380\n",
      "epoch 2 loss: 0.5963\n",
      "epoch 3 loss: 0.5670\n",
      "epoch 4 loss: 0.2411\n",
      "epoch 5 loss: 0.1269\n",
      "epoch 6 loss: 0.0934\n",
      "epoch 7 loss: 0.0707\n",
      "epoch 8 loss: 0.0446\n",
      "epoch 9 loss: 0.0529\n",
      "epoch 10 loss: 0.0474\n",
      "epoch 11 loss: 0.0477\n",
      "epoch 12 loss: 0.0508\n",
      "epoch 13 loss: 0.0334\n",
      "epoch 14 loss: 0.0427\n",
      "epoch 15 loss: 0.0424\n",
      "epoch 16 loss: 0.0348\n",
      "epoch 17 loss: 0.0432\n",
      "epoch 18 loss: 0.0380\n",
      "epoch 19 loss: 0.0370\n",
      "epoch 20 loss: 0.0379\n",
      "epoch 21 loss: 0.0305\n",
      "epoch 22 loss: 0.0321\n",
      "epoch 23 loss: 0.0386\n",
      "epoch 24 loss: 0.0387\n",
      "epoch 25 loss: 0.0261\n",
      "epoch 26 loss: 0.0272\n",
      "epoch 27 loss: 0.0380\n",
      "epoch 28 loss: 0.0323\n",
      "epoch 29 loss: 0.0330\n",
      "epoch 30 loss: 0.0259\n",
      "44\n",
      "epoch 1 loss: 0.7532\n",
      "epoch 2 loss: 0.6045\n",
      "epoch 3 loss: 0.5839\n",
      "epoch 4 loss: 0.4061\n",
      "epoch 5 loss: 0.3174\n",
      "epoch 6 loss: 0.2043\n",
      "epoch 7 loss: 0.1718\n",
      "epoch 8 loss: 0.1029\n",
      "epoch 9 loss: 0.0742\n",
      "epoch 10 loss: 0.0498\n",
      "epoch 11 loss: 0.0455\n",
      "epoch 12 loss: 0.0457\n",
      "epoch 13 loss: 0.0512\n",
      "epoch 14 loss: 0.0450\n",
      "epoch 15 loss: 0.0410\n",
      "epoch 16 loss: 0.0490\n",
      "epoch 17 loss: 0.0371\n",
      "epoch 18 loss: 0.0365\n",
      "epoch 19 loss: 0.0326\n",
      "epoch 20 loss: 0.0397\n",
      "epoch 21 loss: 0.0384\n",
      "epoch 22 loss: 0.0333\n",
      "epoch 23 loss: 0.0334\n",
      "epoch 24 loss: 0.0280\n",
      "epoch 25 loss: 0.0335\n",
      "epoch 26 loss: 0.0328\n",
      "epoch 27 loss: 0.0354\n",
      "epoch 28 loss: 0.0279\n",
      "epoch 29 loss: 0.0368\n",
      "epoch 30 loss: 0.0370\n",
      "45\n",
      "epoch 1 loss: 0.8044\n",
      "epoch 2 loss: 0.4648\n",
      "epoch 3 loss: 0.3710\n",
      "epoch 4 loss: 0.2740\n",
      "epoch 5 loss: 0.3521\n",
      "epoch 6 loss: 0.1522\n",
      "epoch 7 loss: 0.0813\n",
      "epoch 8 loss: 0.0544\n",
      "epoch 9 loss: 0.0520\n",
      "epoch 10 loss: 0.0436\n",
      "epoch 11 loss: 0.0439\n",
      "epoch 12 loss: 0.0428\n",
      "epoch 13 loss: 0.0407\n",
      "epoch 14 loss: 0.0347\n",
      "epoch 15 loss: 0.0489\n",
      "epoch 16 loss: 0.0390\n",
      "epoch 17 loss: 0.0366\n",
      "epoch 18 loss: 0.0322\n",
      "epoch 19 loss: 0.0405\n",
      "epoch 20 loss: 0.0266\n",
      "epoch 21 loss: 0.0314\n",
      "epoch 22 loss: 0.0292\n",
      "epoch 23 loss: 0.0286\n",
      "epoch 24 loss: 0.0313\n",
      "epoch 25 loss: 0.0327\n",
      "epoch 26 loss: 0.0262\n",
      "epoch 27 loss: 0.0260\n",
      "epoch 28 loss: 0.0287\n",
      "epoch 29 loss: 0.0247\n",
      "epoch 30 loss: 0.0317\n",
      "46\n",
      "epoch 1 loss: 0.6730\n",
      "epoch 2 loss: 0.8438\n",
      "epoch 3 loss: 0.5526\n",
      "epoch 4 loss: 1.3093\n",
      "epoch 5 loss: 0.3554\n",
      "epoch 6 loss: 0.2567\n",
      "epoch 7 loss: 0.1494\n",
      "epoch 8 loss: 0.0956\n",
      "epoch 9 loss: 0.0608\n",
      "epoch 10 loss: 0.0549\n",
      "epoch 11 loss: 0.0661\n",
      "epoch 12 loss: 0.0430\n",
      "epoch 13 loss: 0.0476\n",
      "epoch 14 loss: 0.0625\n",
      "epoch 15 loss: 0.0601\n",
      "epoch 16 loss: 0.0537\n",
      "epoch 17 loss: 0.0496\n",
      "epoch 18 loss: 0.0391\n",
      "epoch 19 loss: 0.0545\n",
      "epoch 20 loss: 0.0433\n",
      "epoch 21 loss: 0.0443\n",
      "epoch 22 loss: 0.0455\n",
      "epoch 23 loss: 0.0424\n",
      "epoch 24 loss: 0.0370\n",
      "epoch 25 loss: 0.0351\n",
      "epoch 26 loss: 0.0394\n",
      "epoch 27 loss: 0.0337\n",
      "epoch 28 loss: 0.0400\n",
      "epoch 29 loss: 0.0370\n",
      "epoch 30 loss: 0.0283\n",
      "47\n",
      "epoch 1 loss: 1.0284\n",
      "epoch 2 loss: 0.5835\n",
      "epoch 3 loss: 0.6137\n",
      "epoch 4 loss: 0.4511\n",
      "epoch 5 loss: 0.3388\n",
      "epoch 6 loss: 0.1848\n",
      "epoch 7 loss: 0.1722\n",
      "epoch 8 loss: 0.1175\n",
      "epoch 9 loss: 0.0778\n",
      "epoch 10 loss: 0.0762\n",
      "epoch 11 loss: 0.0524\n",
      "epoch 12 loss: 0.0602\n",
      "epoch 13 loss: 0.0500\n",
      "epoch 14 loss: 0.0582\n",
      "epoch 15 loss: 0.0540\n",
      "epoch 16 loss: 0.0408\n",
      "epoch 17 loss: 0.0619\n",
      "epoch 18 loss: 0.0540\n",
      "epoch 19 loss: 0.0380\n",
      "epoch 20 loss: 0.0418\n",
      "epoch 21 loss: 0.0499\n",
      "epoch 22 loss: 0.0333\n",
      "epoch 23 loss: 0.0451\n",
      "epoch 24 loss: 0.0602\n",
      "epoch 25 loss: 0.0297\n",
      "epoch 26 loss: 0.0426\n",
      "epoch 27 loss: 0.0416\n",
      "epoch 28 loss: 0.0417\n",
      "epoch 29 loss: 0.0572\n",
      "epoch 30 loss: 0.0440\n",
      "48\n",
      "epoch 1 loss: 0.6759\n",
      "epoch 2 loss: 0.6527\n",
      "epoch 3 loss: 0.4665\n",
      "epoch 4 loss: 0.3856\n",
      "epoch 5 loss: 0.2319\n",
      "epoch 6 loss: 0.1232\n",
      "epoch 7 loss: 0.0790\n",
      "epoch 8 loss: 0.0675\n",
      "epoch 9 loss: 0.0600\n",
      "epoch 10 loss: 0.0505\n",
      "epoch 11 loss: 0.0492\n",
      "epoch 12 loss: 0.0468\n",
      "epoch 13 loss: 0.0423\n",
      "epoch 14 loss: 0.0370\n",
      "epoch 15 loss: 0.0434\n",
      "epoch 16 loss: 0.0457\n",
      "epoch 17 loss: 0.0312\n",
      "epoch 18 loss: 0.0310\n",
      "epoch 19 loss: 0.0369\n",
      "epoch 20 loss: 0.0293\n",
      "epoch 21 loss: 0.0315\n",
      "epoch 22 loss: 0.0380\n",
      "epoch 23 loss: 0.0318\n",
      "epoch 24 loss: 0.0403\n",
      "epoch 25 loss: 0.0376\n",
      "epoch 26 loss: 0.0367\n",
      "epoch 27 loss: 0.0334\n",
      "epoch 28 loss: 0.0309\n",
      "epoch 29 loss: 0.0258\n",
      "epoch 30 loss: 0.0325\n",
      "49\n",
      "epoch 1 loss: 1.0988\n",
      "epoch 2 loss: 0.7251\n",
      "epoch 3 loss: 0.4809\n",
      "epoch 4 loss: 0.2126\n",
      "epoch 5 loss: 0.1818\n",
      "epoch 6 loss: 0.1052\n",
      "epoch 7 loss: 0.0634\n",
      "epoch 8 loss: 0.0736\n",
      "epoch 9 loss: 0.0493\n",
      "epoch 10 loss: 0.0595\n",
      "epoch 11 loss: 0.0433\n",
      "epoch 12 loss: 0.0511\n",
      "epoch 13 loss: 0.0429\n",
      "epoch 14 loss: 0.0411\n",
      "epoch 15 loss: 0.0608\n",
      "epoch 16 loss: 0.0398\n",
      "epoch 17 loss: 0.0437\n",
      "epoch 18 loss: 0.0385\n",
      "epoch 19 loss: 0.0309\n",
      "epoch 20 loss: 0.0439\n",
      "epoch 21 loss: 0.0312\n",
      "epoch 22 loss: 0.0517\n",
      "epoch 23 loss: 0.0451\n",
      "epoch 24 loss: 0.0507\n",
      "epoch 25 loss: 0.0458\n",
      "epoch 26 loss: 0.0525\n",
      "epoch 27 loss: 0.0426\n",
      "epoch 28 loss: 0.0436\n",
      "epoch 29 loss: 0.0386\n",
      "epoch 30 loss: 0.0464\n",
      "50\n",
      "epoch 1 loss: 0.6741\n",
      "epoch 2 loss: 0.4988\n",
      "epoch 3 loss: 0.3858\n",
      "epoch 4 loss: 0.2608\n",
      "epoch 5 loss: 0.1676\n",
      "epoch 6 loss: 0.0906\n",
      "epoch 7 loss: 0.0863\n",
      "epoch 8 loss: 0.0516\n",
      "epoch 9 loss: 0.0546\n",
      "epoch 10 loss: 0.0421\n",
      "epoch 11 loss: 0.0515\n",
      "epoch 12 loss: 0.0535\n",
      "epoch 13 loss: 0.0441\n",
      "epoch 14 loss: 0.0423\n",
      "epoch 15 loss: 0.0449\n",
      "epoch 16 loss: 0.0433\n",
      "epoch 17 loss: 0.0394\n",
      "epoch 18 loss: 0.0433\n",
      "epoch 19 loss: 0.0401\n",
      "epoch 20 loss: 0.0393\n",
      "epoch 21 loss: 0.0307\n",
      "epoch 22 loss: 0.0374\n",
      "epoch 23 loss: 0.0397\n",
      "epoch 24 loss: 0.0361\n",
      "epoch 25 loss: 0.0320\n",
      "epoch 26 loss: 0.0318\n",
      "epoch 27 loss: 0.0279\n",
      "epoch 28 loss: 0.0420\n",
      "epoch 29 loss: 0.0299\n",
      "epoch 30 loss: 0.0385\n",
      "51\n",
      "epoch 1 loss: 0.7732\n",
      "epoch 2 loss: 0.6416\n",
      "epoch 3 loss: 0.6382\n",
      "epoch 4 loss: 0.4864\n",
      "epoch 5 loss: 0.4919\n",
      "epoch 6 loss: 0.3156\n",
      "epoch 7 loss: 0.1608\n",
      "epoch 8 loss: 0.1016\n",
      "epoch 9 loss: 0.0759\n",
      "epoch 10 loss: 0.0615\n",
      "epoch 11 loss: 0.0545\n",
      "epoch 12 loss: 0.0467\n",
      "epoch 13 loss: 0.0401\n",
      "epoch 14 loss: 0.0396\n",
      "epoch 15 loss: 0.0426\n",
      "epoch 16 loss: 0.0367\n",
      "epoch 17 loss: 0.0361\n",
      "epoch 18 loss: 0.0349\n",
      "epoch 19 loss: 0.0339\n",
      "epoch 20 loss: 0.0386\n",
      "epoch 21 loss: 0.0380\n",
      "epoch 22 loss: 0.0346\n",
      "epoch 23 loss: 0.0264\n",
      "epoch 24 loss: 0.0264\n",
      "epoch 25 loss: 0.0268\n",
      "epoch 26 loss: 0.0345\n",
      "epoch 27 loss: 0.0326\n",
      "epoch 28 loss: 0.0328\n",
      "epoch 29 loss: 0.0288\n",
      "epoch 30 loss: 0.0285\n",
      "52\n",
      "epoch 1 loss: 0.8444\n",
      "epoch 2 loss: 0.5606\n",
      "epoch 3 loss: 0.2976\n",
      "epoch 4 loss: 0.1981\n",
      "epoch 5 loss: 0.1638\n",
      "epoch 6 loss: 0.0891\n",
      "epoch 7 loss: 0.0637\n",
      "epoch 8 loss: 0.0519\n",
      "epoch 9 loss: 0.0562\n",
      "epoch 10 loss: 0.0668\n",
      "epoch 11 loss: 0.0523\n",
      "epoch 12 loss: 0.0528\n",
      "epoch 13 loss: 0.0413\n",
      "epoch 14 loss: 0.0430\n",
      "epoch 15 loss: 0.0477\n",
      "epoch 16 loss: 0.0403\n",
      "epoch 17 loss: 0.0498\n",
      "epoch 18 loss: 0.0425\n",
      "epoch 19 loss: 0.0343\n",
      "epoch 20 loss: 0.0302\n",
      "epoch 21 loss: 0.0412\n",
      "epoch 22 loss: 0.0366\n",
      "epoch 23 loss: 0.0368\n",
      "epoch 24 loss: 0.0422\n",
      "epoch 25 loss: 0.0371\n",
      "epoch 26 loss: 0.0430\n",
      "epoch 27 loss: 0.0412\n",
      "epoch 28 loss: 0.0357\n",
      "epoch 29 loss: 0.0263\n",
      "epoch 30 loss: 0.0420\n",
      "53\n",
      "epoch 1 loss: 0.7658\n",
      "epoch 2 loss: 0.5064\n",
      "epoch 3 loss: 0.5404\n",
      "epoch 4 loss: 0.5785\n",
      "epoch 5 loss: 0.5616\n",
      "epoch 6 loss: 0.3592\n",
      "epoch 7 loss: 0.2919\n",
      "epoch 8 loss: 0.1438\n",
      "epoch 9 loss: 0.0808\n",
      "epoch 10 loss: 0.0593\n",
      "epoch 11 loss: 0.0495\n",
      "epoch 12 loss: 0.0569\n",
      "epoch 13 loss: 0.0493\n",
      "epoch 14 loss: 0.0477\n",
      "epoch 15 loss: 0.0499\n",
      "epoch 16 loss: 0.0437\n",
      "epoch 17 loss: 0.0342\n",
      "epoch 18 loss: 0.0427\n",
      "epoch 19 loss: 0.0411\n",
      "epoch 20 loss: 0.0483\n",
      "epoch 21 loss: 0.0456\n",
      "epoch 22 loss: 0.0376\n",
      "epoch 23 loss: 0.0403\n",
      "epoch 24 loss: 0.0450\n",
      "epoch 25 loss: 0.0288\n",
      "epoch 26 loss: 0.0456\n",
      "epoch 27 loss: 0.0283\n",
      "epoch 28 loss: 0.0437\n",
      "epoch 29 loss: 0.0349\n",
      "epoch 30 loss: 0.0386\n",
      "54\n",
      "epoch 1 loss: 1.3229\n",
      "epoch 2 loss: 0.6475\n",
      "epoch 3 loss: 0.6705\n",
      "epoch 4 loss: 0.6884\n",
      "epoch 5 loss: 0.5123\n",
      "epoch 6 loss: 0.2692\n",
      "epoch 7 loss: 0.2225\n",
      "epoch 8 loss: 0.0974\n",
      "epoch 9 loss: 0.0754\n",
      "epoch 10 loss: 0.0559\n",
      "epoch 11 loss: 0.0516\n",
      "epoch 12 loss: 0.0447\n",
      "epoch 13 loss: 0.0532\n",
      "epoch 14 loss: 0.0487\n",
      "epoch 15 loss: 0.0427\n",
      "epoch 16 loss: 0.0477\n",
      "epoch 17 loss: 0.0373\n",
      "epoch 18 loss: 0.0427\n",
      "epoch 19 loss: 0.0454\n",
      "epoch 20 loss: 0.0388\n",
      "epoch 21 loss: 0.0350\n",
      "epoch 22 loss: 0.0445\n",
      "epoch 23 loss: 0.0383\n",
      "epoch 24 loss: 0.0312\n",
      "epoch 25 loss: 0.0486\n",
      "epoch 26 loss: 0.0389\n",
      "epoch 27 loss: 0.0272\n",
      "epoch 28 loss: 0.0287\n",
      "epoch 29 loss: 0.0354\n",
      "epoch 30 loss: 0.0338\n",
      "55\n",
      "epoch 1 loss: 1.1325\n",
      "epoch 2 loss: 0.5518\n",
      "epoch 3 loss: 0.3783\n",
      "epoch 4 loss: 0.2789\n",
      "epoch 5 loss: 0.2279\n",
      "epoch 6 loss: 0.0953\n",
      "epoch 7 loss: 0.0650\n",
      "epoch 8 loss: 0.0463\n",
      "epoch 9 loss: 0.0486\n",
      "epoch 10 loss: 0.0326\n",
      "epoch 11 loss: 0.0378\n",
      "epoch 12 loss: 0.0362\n",
      "epoch 13 loss: 0.0438\n",
      "epoch 14 loss: 0.0470\n",
      "epoch 15 loss: 0.0355\n",
      "epoch 16 loss: 0.0324\n",
      "epoch 17 loss: 0.0274\n",
      "epoch 18 loss: 0.0306\n",
      "epoch 19 loss: 0.0321\n",
      "epoch 20 loss: 0.0391\n",
      "epoch 21 loss: 0.0348\n",
      "epoch 22 loss: 0.0336\n",
      "epoch 23 loss: 0.0290\n",
      "epoch 24 loss: 0.0302\n",
      "epoch 25 loss: 0.0251\n",
      "epoch 26 loss: 0.0296\n",
      "epoch 27 loss: 0.0279\n",
      "epoch 28 loss: 0.0268\n",
      "epoch 29 loss: 0.0387\n",
      "epoch 30 loss: 0.0286\n",
      "56\n",
      "epoch 1 loss: 0.9743\n",
      "epoch 2 loss: 0.6260\n",
      "epoch 3 loss: 0.5472\n",
      "epoch 4 loss: 0.2840\n",
      "epoch 5 loss: 0.2022\n",
      "epoch 6 loss: 0.1018\n",
      "epoch 7 loss: 0.0696\n",
      "epoch 8 loss: 0.0634\n",
      "epoch 9 loss: 0.0479\n",
      "epoch 10 loss: 0.0508\n",
      "epoch 11 loss: 0.0567\n",
      "epoch 12 loss: 0.0508\n",
      "epoch 13 loss: 0.0354\n",
      "epoch 14 loss: 0.0367\n",
      "epoch 15 loss: 0.0375\n",
      "epoch 16 loss: 0.0437\n",
      "epoch 17 loss: 0.0439\n",
      "epoch 18 loss: 0.0354\n",
      "epoch 19 loss: 0.0298\n",
      "epoch 20 loss: 0.0286\n",
      "epoch 21 loss: 0.0362\n",
      "epoch 22 loss: 0.0319\n",
      "epoch 23 loss: 0.0287\n",
      "epoch 24 loss: 0.0258\n",
      "epoch 25 loss: 0.0307\n",
      "epoch 26 loss: 0.0300\n",
      "epoch 27 loss: 0.0251\n",
      "epoch 28 loss: 0.0324\n",
      "epoch 29 loss: 0.0272\n",
      "epoch 30 loss: 0.0322\n",
      "57\n",
      "epoch 1 loss: 0.8687\n",
      "epoch 2 loss: 0.4179\n",
      "epoch 3 loss: 0.4779\n",
      "epoch 4 loss: 0.5925\n",
      "epoch 5 loss: 0.5863\n",
      "epoch 6 loss: 0.3763\n",
      "epoch 7 loss: 0.4663\n",
      "epoch 8 loss: 0.5579\n",
      "epoch 9 loss: 0.5199\n",
      "epoch 10 loss: 0.3541\n",
      "epoch 11 loss: 0.1558\n",
      "epoch 12 loss: 0.1087\n",
      "epoch 13 loss: 0.0805\n",
      "epoch 14 loss: 0.0579\n",
      "epoch 15 loss: 0.0567\n",
      "epoch 16 loss: 0.0597\n",
      "epoch 17 loss: 0.0465\n",
      "epoch 18 loss: 0.0392\n",
      "epoch 19 loss: 0.0330\n",
      "epoch 20 loss: 0.0311\n",
      "epoch 21 loss: 0.0355\n",
      "epoch 22 loss: 0.0356\n",
      "epoch 23 loss: 0.0398\n",
      "epoch 24 loss: 0.0364\n",
      "epoch 25 loss: 0.0370\n",
      "epoch 26 loss: 0.0334\n",
      "epoch 27 loss: 0.0352\n",
      "epoch 28 loss: 0.0320\n",
      "epoch 29 loss: 0.0358\n",
      "epoch 30 loss: 0.0397\n",
      "58\n",
      "epoch 1 loss: 0.6621\n",
      "epoch 2 loss: 0.5942\n",
      "epoch 3 loss: 0.3330\n",
      "epoch 4 loss: 0.2193\n",
      "epoch 5 loss: 0.1082\n",
      "epoch 6 loss: 0.0803\n",
      "epoch 7 loss: 0.0723\n",
      "epoch 8 loss: 0.0586\n",
      "epoch 9 loss: 0.0461\n",
      "epoch 10 loss: 0.0455\n",
      "epoch 11 loss: 0.0370\n",
      "epoch 12 loss: 0.0316\n",
      "epoch 13 loss: 0.0465\n",
      "epoch 14 loss: 0.0492\n",
      "epoch 15 loss: 0.0467\n",
      "epoch 16 loss: 0.0337\n",
      "epoch 17 loss: 0.0357\n",
      "epoch 18 loss: 0.0253\n",
      "epoch 19 loss: 0.0328\n",
      "epoch 20 loss: 0.0288\n",
      "epoch 21 loss: 0.0386\n",
      "epoch 22 loss: 0.0366\n",
      "epoch 23 loss: 0.0371\n",
      "epoch 24 loss: 0.0334\n",
      "epoch 25 loss: 0.0297\n",
      "epoch 26 loss: 0.0355\n",
      "epoch 27 loss: 0.0399\n",
      "epoch 28 loss: 0.0306\n",
      "epoch 29 loss: 0.0336\n",
      "epoch 30 loss: 0.0248\n",
      "59\n",
      "epoch 1 loss: 0.8333\n",
      "epoch 2 loss: 0.4377\n",
      "epoch 3 loss: 0.4065\n",
      "epoch 4 loss: 0.3021\n",
      "epoch 5 loss: 0.1208\n",
      "epoch 6 loss: 0.0846\n",
      "epoch 7 loss: 0.0815\n",
      "epoch 8 loss: 0.0512\n",
      "epoch 9 loss: 0.0419\n",
      "epoch 10 loss: 0.0483\n",
      "epoch 11 loss: 0.0473\n",
      "epoch 12 loss: 0.0355\n",
      "epoch 13 loss: 0.0435\n",
      "epoch 14 loss: 0.0410\n",
      "epoch 15 loss: 0.0373\n",
      "epoch 16 loss: 0.0444\n",
      "epoch 17 loss: 0.0329\n",
      "epoch 18 loss: 0.0437\n",
      "epoch 19 loss: 0.0332\n",
      "epoch 20 loss: 0.0354\n",
      "epoch 21 loss: 0.0375\n",
      "epoch 22 loss: 0.0318\n",
      "epoch 23 loss: 0.0330\n",
      "epoch 24 loss: 0.0367\n",
      "epoch 25 loss: 0.0321\n",
      "epoch 26 loss: 0.0294\n",
      "epoch 27 loss: 0.0248\n",
      "epoch 28 loss: 0.0271\n",
      "epoch 29 loss: 0.0350\n",
      "epoch 30 loss: 0.0375\n",
      "60\n",
      "epoch 1 loss: 0.7366\n",
      "epoch 2 loss: 0.6306\n",
      "epoch 3 loss: 0.5906\n",
      "epoch 4 loss: 0.4820\n",
      "epoch 5 loss: 0.1656\n",
      "epoch 6 loss: 0.2039\n",
      "epoch 7 loss: 0.1146\n",
      "epoch 8 loss: 0.0646\n",
      "epoch 9 loss: 0.0620\n",
      "epoch 10 loss: 0.0636\n",
      "epoch 11 loss: 0.0517\n",
      "epoch 12 loss: 0.0368\n",
      "epoch 13 loss: 0.0361\n",
      "epoch 14 loss: 0.0455\n",
      "epoch 15 loss: 0.0340\n",
      "epoch 16 loss: 0.0366\n",
      "epoch 17 loss: 0.0383\n",
      "epoch 18 loss: 0.0363\n",
      "epoch 19 loss: 0.0342\n",
      "epoch 20 loss: 0.0394\n",
      "epoch 21 loss: 0.0360\n",
      "epoch 22 loss: 0.0320\n",
      "epoch 23 loss: 0.0330\n",
      "epoch 24 loss: 0.0308\n",
      "epoch 25 loss: 0.0359\n",
      "epoch 26 loss: 0.0336\n",
      "epoch 27 loss: 0.0392\n",
      "epoch 28 loss: 0.0295\n",
      "epoch 29 loss: 0.0293\n",
      "epoch 30 loss: 0.0275\n",
      "61\n",
      "epoch 1 loss: 0.6940\n",
      "epoch 2 loss: 0.5060\n",
      "epoch 3 loss: 0.6137\n",
      "epoch 4 loss: 0.4116\n",
      "epoch 5 loss: 0.3365\n",
      "epoch 6 loss: 0.1615\n",
      "epoch 7 loss: 0.1040\n",
      "epoch 8 loss: 0.0673\n",
      "epoch 9 loss: 0.0624\n",
      "epoch 10 loss: 0.0450\n",
      "epoch 11 loss: 0.0396\n",
      "epoch 12 loss: 0.0496\n",
      "epoch 13 loss: 0.0443\n",
      "epoch 14 loss: 0.0432\n",
      "epoch 15 loss: 0.0361\n",
      "epoch 16 loss: 0.0455\n",
      "epoch 17 loss: 0.0432\n",
      "epoch 18 loss: 0.0427\n",
      "epoch 19 loss: 0.0313\n",
      "epoch 20 loss: 0.0429\n",
      "epoch 21 loss: 0.0349\n",
      "epoch 22 loss: 0.0343\n",
      "epoch 23 loss: 0.0321\n",
      "epoch 24 loss: 0.0348\n",
      "epoch 25 loss: 0.0346\n",
      "epoch 26 loss: 0.0240\n",
      "epoch 27 loss: 0.0323\n",
      "epoch 28 loss: 0.0287\n",
      "epoch 29 loss: 0.0323\n",
      "epoch 30 loss: 0.0326\n",
      "62\n",
      "epoch 1 loss: 0.6600\n",
      "epoch 2 loss: 0.6993\n",
      "epoch 3 loss: 0.3470\n",
      "epoch 4 loss: 0.1685\n",
      "epoch 5 loss: 0.0951\n",
      "epoch 6 loss: 0.0839\n",
      "epoch 7 loss: 0.0728\n",
      "epoch 8 loss: 0.0591\n",
      "epoch 9 loss: 0.0447\n",
      "epoch 10 loss: 0.0370\n",
      "epoch 11 loss: 0.0465\n",
      "epoch 12 loss: 0.0328\n",
      "epoch 13 loss: 0.0328\n",
      "epoch 14 loss: 0.0318\n",
      "epoch 15 loss: 0.0330\n",
      "epoch 16 loss: 0.0326\n",
      "epoch 17 loss: 0.0272\n",
      "epoch 18 loss: 0.0241\n",
      "epoch 19 loss: 0.0290\n",
      "epoch 20 loss: 0.0325\n",
      "epoch 21 loss: 0.0285\n",
      "epoch 22 loss: 0.0306\n",
      "epoch 23 loss: 0.0282\n",
      "epoch 24 loss: 0.0379\n",
      "epoch 25 loss: 0.0293\n",
      "epoch 26 loss: 0.0262\n",
      "epoch 27 loss: 0.0233\n",
      "epoch 28 loss: 0.0312\n",
      "epoch 29 loss: 0.0272\n",
      "epoch 30 loss: 0.0225\n",
      "63\n",
      "epoch 1 loss: 1.0104\n",
      "epoch 2 loss: 0.7151\n",
      "epoch 3 loss: 0.3388\n",
      "epoch 4 loss: 0.1733\n",
      "epoch 5 loss: 0.1610\n",
      "epoch 6 loss: 0.1129\n",
      "epoch 7 loss: 0.0743\n",
      "epoch 8 loss: 0.0532\n",
      "epoch 9 loss: 0.0592\n",
      "epoch 10 loss: 0.0436\n",
      "epoch 11 loss: 0.0455\n",
      "epoch 12 loss: 0.0368\n",
      "epoch 13 loss: 0.0434\n",
      "epoch 14 loss: 0.0420\n",
      "epoch 15 loss: 0.0354\n",
      "epoch 16 loss: 0.0500\n",
      "epoch 17 loss: 0.0370\n",
      "epoch 18 loss: 0.0393\n",
      "epoch 19 loss: 0.0334\n",
      "epoch 20 loss: 0.0388\n",
      "epoch 21 loss: 0.0355\n",
      "epoch 22 loss: 0.0324\n",
      "epoch 23 loss: 0.0305\n",
      "epoch 24 loss: 0.0381\n",
      "epoch 25 loss: 0.0330\n",
      "epoch 26 loss: 0.0331\n",
      "epoch 27 loss: 0.0356\n",
      "epoch 28 loss: 0.0365\n",
      "epoch 29 loss: 0.0258\n",
      "epoch 30 loss: 0.0292\n",
      "64\n",
      "epoch 1 loss: 0.7707\n",
      "epoch 2 loss: 0.6243\n",
      "epoch 3 loss: 0.4282\n",
      "epoch 4 loss: 0.2656\n",
      "epoch 5 loss: 0.1648\n",
      "epoch 6 loss: 0.0961\n",
      "epoch 7 loss: 0.0585\n",
      "epoch 8 loss: 0.0575\n",
      "epoch 9 loss: 0.0471\n",
      "epoch 10 loss: 0.0520\n",
      "epoch 11 loss: 0.0500\n",
      "epoch 12 loss: 0.0372\n",
      "epoch 13 loss: 0.0410\n",
      "epoch 14 loss: 0.0435\n",
      "epoch 15 loss: 0.0349\n",
      "epoch 16 loss: 0.0343\n",
      "epoch 17 loss: 0.0329\n",
      "epoch 18 loss: 0.0325\n",
      "epoch 19 loss: 0.0362\n",
      "epoch 20 loss: 0.0385\n",
      "epoch 21 loss: 0.0341\n",
      "epoch 22 loss: 0.0319\n",
      "epoch 23 loss: 0.0395\n",
      "epoch 24 loss: 0.0338\n",
      "epoch 25 loss: 0.0367\n",
      "epoch 26 loss: 0.0321\n",
      "epoch 27 loss: 0.0386\n",
      "epoch 28 loss: 0.0297\n",
      "epoch 29 loss: 0.0369\n",
      "epoch 30 loss: 0.0349\n",
      "65\n",
      "epoch 1 loss: 1.0234\n",
      "epoch 2 loss: 0.4869\n",
      "epoch 3 loss: 0.3734\n",
      "epoch 4 loss: 0.4342\n",
      "epoch 5 loss: 0.4069\n",
      "epoch 6 loss: 0.3648\n",
      "epoch 7 loss: 0.3675\n",
      "epoch 8 loss: 0.2811\n",
      "epoch 9 loss: 0.2716\n",
      "epoch 10 loss: 0.1186\n",
      "epoch 11 loss: 0.0754\n",
      "epoch 12 loss: 0.0646\n",
      "epoch 13 loss: 0.0556\n",
      "epoch 14 loss: 0.0433\n",
      "epoch 15 loss: 0.0419\n",
      "epoch 16 loss: 0.0472\n",
      "epoch 17 loss: 0.0389\n",
      "epoch 18 loss: 0.0415\n",
      "epoch 19 loss: 0.0376\n",
      "epoch 20 loss: 0.0390\n",
      "epoch 21 loss: 0.0347\n",
      "epoch 22 loss: 0.0345\n",
      "epoch 23 loss: 0.0329\n",
      "epoch 24 loss: 0.0379\n",
      "epoch 25 loss: 0.0360\n",
      "epoch 26 loss: 0.0333\n",
      "epoch 27 loss: 0.0253\n",
      "epoch 28 loss: 0.0271\n",
      "epoch 29 loss: 0.0366\n",
      "epoch 30 loss: 0.0374\n",
      "66\n",
      "epoch 1 loss: 0.7737\n",
      "epoch 2 loss: 0.4841\n",
      "epoch 3 loss: 0.3715\n",
      "epoch 4 loss: 0.2935\n",
      "epoch 5 loss: 0.1841\n",
      "epoch 6 loss: 0.0973\n",
      "epoch 7 loss: 0.0705\n",
      "epoch 8 loss: 0.0561\n",
      "epoch 9 loss: 0.0463\n",
      "epoch 10 loss: 0.0325\n",
      "epoch 11 loss: 0.0431\n",
      "epoch 12 loss: 0.0359\n",
      "epoch 13 loss: 0.0419\n",
      "epoch 14 loss: 0.0316\n",
      "epoch 15 loss: 0.0399\n",
      "epoch 16 loss: 0.0477\n",
      "epoch 17 loss: 0.0357\n",
      "epoch 18 loss: 0.0402\n",
      "epoch 19 loss: 0.0393\n",
      "epoch 20 loss: 0.0370\n",
      "epoch 21 loss: 0.0334\n",
      "epoch 22 loss: 0.0341\n",
      "epoch 23 loss: 0.0245\n",
      "epoch 24 loss: 0.0260\n",
      "epoch 25 loss: 0.0333\n",
      "epoch 26 loss: 0.0339\n",
      "epoch 27 loss: 0.0259\n",
      "epoch 28 loss: 0.0271\n",
      "epoch 29 loss: 0.0363\n",
      "epoch 30 loss: 0.0290\n",
      "67\n",
      "epoch 1 loss: 0.6491\n",
      "epoch 2 loss: 0.5850\n",
      "epoch 3 loss: 0.4630\n",
      "epoch 4 loss: 0.3566\n",
      "epoch 5 loss: 0.2503\n",
      "epoch 6 loss: 0.1454\n",
      "epoch 7 loss: 0.0839\n",
      "epoch 8 loss: 0.0960\n",
      "epoch 9 loss: 0.0750\n",
      "epoch 10 loss: 0.0483\n",
      "epoch 11 loss: 0.0509\n",
      "epoch 12 loss: 0.0391\n",
      "epoch 13 loss: 0.0398\n",
      "epoch 14 loss: 0.0318\n",
      "epoch 15 loss: 0.0432\n",
      "epoch 16 loss: 0.0331\n",
      "epoch 17 loss: 0.0400\n",
      "epoch 18 loss: 0.0398\n",
      "epoch 19 loss: 0.0386\n",
      "epoch 20 loss: 0.0377\n",
      "epoch 21 loss: 0.0339\n",
      "epoch 22 loss: 0.0316\n",
      "epoch 23 loss: 0.0304\n",
      "epoch 24 loss: 0.0289\n",
      "epoch 25 loss: 0.0310\n",
      "epoch 26 loss: 0.0248\n",
      "epoch 27 loss: 0.0292\n",
      "epoch 28 loss: 0.0313\n",
      "epoch 29 loss: 0.0320\n",
      "epoch 30 loss: 0.0278\n",
      "68\n",
      "epoch 1 loss: 0.9689\n",
      "epoch 2 loss: 0.5105\n",
      "epoch 3 loss: 0.5660\n",
      "epoch 4 loss: 0.3928\n",
      "epoch 5 loss: 0.2058\n",
      "epoch 6 loss: 0.1086\n",
      "epoch 7 loss: 0.0875\n",
      "epoch 8 loss: 0.0560\n",
      "epoch 9 loss: 0.0520\n",
      "epoch 10 loss: 0.0457\n",
      "epoch 11 loss: 0.0536\n",
      "epoch 12 loss: 0.0396\n",
      "epoch 13 loss: 0.0429\n",
      "epoch 14 loss: 0.0383\n",
      "epoch 15 loss: 0.0350\n",
      "epoch 16 loss: 0.0406\n",
      "epoch 17 loss: 0.0358\n",
      "epoch 18 loss: 0.0462\n",
      "epoch 19 loss: 0.0457\n",
      "epoch 20 loss: 0.0438\n",
      "epoch 21 loss: 0.0384\n",
      "epoch 22 loss: 0.0270\n",
      "epoch 23 loss: 0.0390\n",
      "epoch 24 loss: 0.0398\n",
      "epoch 25 loss: 0.0379\n",
      "epoch 26 loss: 0.0266\n",
      "epoch 27 loss: 0.0378\n",
      "epoch 28 loss: 0.0363\n",
      "epoch 29 loss: 0.0382\n",
      "epoch 30 loss: 0.0302\n",
      "69\n",
      "epoch 1 loss: 0.9678\n",
      "epoch 2 loss: 0.4593\n",
      "epoch 3 loss: 0.2114\n",
      "epoch 4 loss: 0.1527\n",
      "epoch 5 loss: 0.1460\n",
      "epoch 6 loss: 0.1049\n",
      "epoch 7 loss: 0.0963\n",
      "epoch 8 loss: 0.0670\n",
      "epoch 9 loss: 0.0641\n",
      "epoch 10 loss: 0.0618\n",
      "epoch 11 loss: 0.0591\n",
      "epoch 12 loss: 0.0582\n",
      "epoch 13 loss: 0.0551\n",
      "epoch 14 loss: 0.0419\n",
      "epoch 15 loss: 0.0449\n",
      "epoch 16 loss: 0.0417\n",
      "epoch 17 loss: 0.0319\n",
      "epoch 18 loss: 0.0313\n",
      "epoch 19 loss: 0.0374\n",
      "epoch 20 loss: 0.0288\n",
      "epoch 21 loss: 0.0439\n",
      "epoch 22 loss: 0.0368\n",
      "epoch 23 loss: 0.0411\n",
      "epoch 24 loss: 0.0375\n",
      "epoch 25 loss: 0.0361\n",
      "epoch 26 loss: 0.0373\n",
      "epoch 27 loss: 0.0327\n",
      "epoch 28 loss: 0.0342\n",
      "epoch 29 loss: 0.0401\n",
      "epoch 30 loss: 0.0229\n",
      "70\n",
      "epoch 1 loss: 1.0577\n",
      "epoch 2 loss: 0.8171\n",
      "epoch 3 loss: 0.3469\n",
      "epoch 4 loss: 0.2860\n",
      "epoch 5 loss: 0.1871\n",
      "epoch 6 loss: 0.1319\n",
      "epoch 7 loss: 0.1322\n",
      "epoch 8 loss: 0.0955\n",
      "epoch 9 loss: 0.0828\n",
      "epoch 10 loss: 0.0718\n",
      "epoch 11 loss: 0.0820\n",
      "epoch 12 loss: 0.0674\n",
      "epoch 13 loss: 0.0955\n",
      "epoch 14 loss: 0.0661\n",
      "epoch 15 loss: 0.0685\n",
      "epoch 16 loss: 0.0476\n",
      "epoch 17 loss: 0.0461\n",
      "epoch 18 loss: 0.0434\n",
      "epoch 19 loss: 0.0427\n",
      "epoch 20 loss: 0.0464\n",
      "epoch 21 loss: 0.0371\n",
      "epoch 22 loss: 0.0494\n",
      "epoch 23 loss: 0.0424\n",
      "epoch 24 loss: 0.0530\n",
      "epoch 25 loss: 0.0430\n",
      "epoch 26 loss: 0.0427\n",
      "epoch 27 loss: 0.0451\n",
      "epoch 28 loss: 0.0397\n",
      "epoch 29 loss: 0.0246\n",
      "epoch 30 loss: 0.0435\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN_based Asym",
   "id": "b23fd78f03c3bfc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T01:42:16.734142Z",
     "start_time": "2025-10-05T23:12:16.624566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_asym_feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_asy_con = pd.concat([results_aep_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_asy_con.to_csv(out_dir + '/results_aep_asy_con.csv', index=False)"
   ],
   "id": "44d660bd30d194a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:1098: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {epoch+1} loss:\", float(loss))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.8716088533401489\n",
      "epoch 2 loss: 0.5656700134277344\n",
      "epoch 3 loss: 0.2816126048564911\n",
      "epoch 4 loss: 0.18627262115478516\n",
      "epoch 5 loss: 0.1277090609073639\n",
      "epoch 6 loss: 0.17016418278217316\n",
      "epoch 7 loss: 0.19621028006076813\n",
      "epoch 8 loss: 0.15606823563575745\n",
      "epoch 9 loss: 0.12370668351650238\n",
      "epoch 10 loss: 0.13687169551849365\n",
      "epoch 11 loss: 0.11630795896053314\n",
      "epoch 12 loss: 0.13793213665485382\n",
      "epoch 13 loss: 0.1174502968788147\n",
      "epoch 14 loss: 0.09193851053714752\n",
      "epoch 15 loss: 0.10576235502958298\n",
      "epoch 16 loss: 0.0884748324751854\n",
      "epoch 17 loss: 0.07523579150438309\n",
      "epoch 18 loss: 0.09537186473608017\n",
      "epoch 19 loss: 0.07470802962779999\n",
      "epoch 20 loss: 0.07857320457696915\n",
      "epoch 21 loss: 0.07284165918827057\n",
      "epoch 22 loss: 0.09372812509536743\n",
      "epoch 23 loss: 0.07426580041646957\n",
      "epoch 24 loss: 0.0773773044347763\n",
      "epoch 25 loss: 0.07014121115207672\n",
      "epoch 26 loss: 0.06971672922372818\n",
      "epoch 27 loss: 0.08010360598564148\n",
      "epoch 28 loss: 0.07375162094831467\n",
      "epoch 29 loss: 0.09400392323732376\n",
      "epoch 30 loss: 0.08329245448112488\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_94343/1543808945.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_asy_con = pd.concat([results_aep_asy_con, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.9588718414306641\n",
      "epoch 2 loss: 0.43228188157081604\n",
      "epoch 3 loss: 0.3142145574092865\n",
      "epoch 4 loss: 0.21514825522899628\n",
      "epoch 5 loss: 0.159245103597641\n",
      "epoch 6 loss: 0.15616479516029358\n",
      "epoch 7 loss: 0.15222501754760742\n",
      "epoch 8 loss: 0.1274441033601761\n",
      "epoch 9 loss: 0.10940007120370865\n",
      "epoch 10 loss: 0.14267919957637787\n",
      "epoch 11 loss: 0.09964807331562042\n",
      "epoch 12 loss: 0.12889045476913452\n",
      "epoch 13 loss: 0.08514443039894104\n",
      "epoch 14 loss: 0.11737193912267685\n",
      "epoch 15 loss: 0.0958469808101654\n",
      "epoch 16 loss: 0.08066171407699585\n",
      "epoch 17 loss: 0.08790330588817596\n",
      "epoch 18 loss: 0.11226285248994827\n",
      "epoch 19 loss: 0.10864437371492386\n",
      "epoch 20 loss: 0.070216104388237\n",
      "epoch 21 loss: 0.09542708843946457\n",
      "epoch 22 loss: 0.10567907989025116\n",
      "epoch 23 loss: 0.08188700675964355\n",
      "epoch 24 loss: 0.09222248941659927\n",
      "epoch 25 loss: 0.07744976133108139\n",
      "epoch 26 loss: 0.07560469210147858\n",
      "epoch 27 loss: 0.09272344410419464\n",
      "epoch 28 loss: 0.07512500137090683\n",
      "epoch 29 loss: 0.07745170593261719\n",
      "epoch 30 loss: 0.07833646982908249\n",
      "3\n",
      "epoch 1 loss: 0.7368077039718628\n",
      "epoch 2 loss: 0.655387818813324\n",
      "epoch 3 loss: 0.4653405249118805\n",
      "epoch 4 loss: 0.2742307782173157\n",
      "epoch 5 loss: 0.13393534719944\n",
      "epoch 6 loss: 0.12731046974658966\n",
      "epoch 7 loss: 0.15478162467479706\n",
      "epoch 8 loss: 0.1175769567489624\n",
      "epoch 9 loss: 0.10955037921667099\n",
      "epoch 10 loss: 0.08410991728305817\n",
      "epoch 11 loss: 0.16311992704868317\n",
      "epoch 12 loss: 0.08597380667924881\n",
      "epoch 13 loss: 0.09481383860111237\n",
      "epoch 14 loss: 0.07637076824903488\n",
      "epoch 15 loss: 0.07287874817848206\n",
      "epoch 16 loss: 0.09411049634218216\n",
      "epoch 17 loss: 0.08734500408172607\n",
      "epoch 18 loss: 0.0975128784775734\n",
      "epoch 19 loss: 0.060853369534015656\n",
      "epoch 20 loss: 0.07362379133701324\n",
      "epoch 21 loss: 0.07029501348733902\n",
      "epoch 22 loss: 0.1058720126748085\n",
      "epoch 23 loss: 0.0738244354724884\n",
      "epoch 24 loss: 0.10060394555330276\n",
      "epoch 25 loss: 0.0786111131310463\n",
      "epoch 26 loss: 0.07647422701120377\n",
      "epoch 27 loss: 0.07284863293170929\n",
      "epoch 28 loss: 0.08448226749897003\n",
      "epoch 29 loss: 0.07380276918411255\n",
      "epoch 30 loss: 0.07059083878993988\n",
      "4\n",
      "epoch 1 loss: 0.8875972628593445\n",
      "epoch 2 loss: 0.4860243797302246\n",
      "epoch 3 loss: 0.21473483741283417\n",
      "epoch 4 loss: 0.18793700635433197\n",
      "epoch 5 loss: 0.15434005856513977\n",
      "epoch 6 loss: 0.13617858290672302\n",
      "epoch 7 loss: 0.15698708593845367\n",
      "epoch 8 loss: 0.1388251632452011\n",
      "epoch 9 loss: 0.09911540895700455\n",
      "epoch 10 loss: 0.10028932243585587\n",
      "epoch 11 loss: 0.08326344192028046\n",
      "epoch 12 loss: 0.08573220670223236\n",
      "epoch 13 loss: 0.12908834218978882\n",
      "epoch 14 loss: 0.09000271558761597\n",
      "epoch 15 loss: 0.10370869934558868\n",
      "epoch 16 loss: 0.10133392363786697\n",
      "epoch 17 loss: 0.08441241085529327\n",
      "epoch 18 loss: 0.07333177328109741\n",
      "epoch 19 loss: 0.08462931960821152\n",
      "epoch 20 loss: 0.07685238122940063\n",
      "epoch 21 loss: 0.05395802482962608\n",
      "epoch 22 loss: 0.06624282151460648\n",
      "epoch 23 loss: 0.07453136891126633\n",
      "epoch 24 loss: 0.07267177104949951\n",
      "epoch 25 loss: 0.07355958968400955\n",
      "epoch 26 loss: 0.0962555930018425\n",
      "epoch 27 loss: 0.05943397060036659\n",
      "epoch 28 loss: 0.09512005746364594\n",
      "epoch 29 loss: 0.07611992955207825\n",
      "epoch 30 loss: 0.07225983589887619\n",
      "5\n",
      "epoch 1 loss: 0.6217957735061646\n",
      "epoch 2 loss: 1.4299174547195435\n",
      "epoch 3 loss: 0.36240139603614807\n",
      "epoch 4 loss: 0.21379323303699493\n",
      "epoch 5 loss: 0.14911453425884247\n",
      "epoch 6 loss: 0.14109161496162415\n",
      "epoch 7 loss: 0.1355905681848526\n",
      "epoch 8 loss: 0.12195179611444473\n",
      "epoch 9 loss: 0.13200102746486664\n",
      "epoch 10 loss: 0.10050838440656662\n",
      "epoch 11 loss: 0.10160164535045624\n",
      "epoch 12 loss: 0.07804695516824722\n",
      "epoch 13 loss: 0.08742330968379974\n",
      "epoch 14 loss: 0.0990571677684784\n",
      "epoch 15 loss: 0.09226518869400024\n",
      "epoch 16 loss: 0.09792729467153549\n",
      "epoch 17 loss: 0.0710495114326477\n",
      "epoch 18 loss: 0.09223999828100204\n",
      "epoch 19 loss: 0.08073589205741882\n",
      "epoch 20 loss: 0.066358782351017\n",
      "epoch 21 loss: 0.06993000954389572\n",
      "epoch 22 loss: 0.10267942398786545\n",
      "epoch 23 loss: 0.07593773305416107\n",
      "epoch 24 loss: 0.07759648561477661\n",
      "epoch 25 loss: 0.06345127522945404\n",
      "epoch 26 loss: 0.09084741026163101\n",
      "epoch 27 loss: 0.055241238325834274\n",
      "epoch 28 loss: 0.08497535437345505\n",
      "epoch 29 loss: 0.07669439166784286\n",
      "epoch 30 loss: 0.06700226664543152\n",
      "6\n",
      "epoch 1 loss: 0.7393061518669128\n",
      "epoch 2 loss: 0.7736510634422302\n",
      "epoch 3 loss: 0.32337871193885803\n",
      "epoch 4 loss: 0.1625184416770935\n",
      "epoch 5 loss: 0.1613587737083435\n",
      "epoch 6 loss: 0.12994706630706787\n",
      "epoch 7 loss: 0.11709944903850555\n",
      "epoch 8 loss: 0.10341981798410416\n",
      "epoch 9 loss: 0.1054568737745285\n",
      "epoch 10 loss: 0.0827656015753746\n",
      "epoch 11 loss: 0.0955611914396286\n",
      "epoch 12 loss: 0.12329014390707016\n",
      "epoch 13 loss: 0.07092371582984924\n",
      "epoch 14 loss: 0.1007651686668396\n",
      "epoch 15 loss: 0.11117637902498245\n",
      "epoch 16 loss: 0.0938815325498581\n",
      "epoch 17 loss: 0.0768890380859375\n",
      "epoch 18 loss: 0.0849628746509552\n",
      "epoch 19 loss: 0.08504994958639145\n",
      "epoch 20 loss: 0.0646856427192688\n",
      "epoch 21 loss: 0.07155938446521759\n",
      "epoch 22 loss: 0.07851845026016235\n",
      "epoch 23 loss: 0.08116243779659271\n",
      "epoch 24 loss: 0.08884511888027191\n",
      "epoch 25 loss: 0.07572286576032639\n",
      "epoch 26 loss: 0.0496981106698513\n",
      "epoch 27 loss: 0.08764313161373138\n",
      "epoch 28 loss: 0.07745373994112015\n",
      "epoch 29 loss: 0.07076389342546463\n",
      "epoch 30 loss: 0.07681368291378021\n",
      "7\n",
      "epoch 1 loss: 1.0032479763031006\n",
      "epoch 2 loss: 0.6031175851821899\n",
      "epoch 3 loss: 0.33693644404411316\n",
      "epoch 4 loss: 0.1485327184200287\n",
      "epoch 5 loss: 0.15305601060390472\n",
      "epoch 6 loss: 0.139302060008049\n",
      "epoch 7 loss: 0.1593458652496338\n",
      "epoch 8 loss: 0.16775846481323242\n",
      "epoch 9 loss: 0.12837885320186615\n",
      "epoch 10 loss: 0.11320434510707855\n",
      "epoch 11 loss: 0.12057683616876602\n",
      "epoch 12 loss: 0.1183425560593605\n",
      "epoch 13 loss: 0.09692902863025665\n",
      "epoch 14 loss: 0.09600388258695602\n",
      "epoch 15 loss: 0.07947850227355957\n",
      "epoch 16 loss: 0.10492091625928879\n",
      "epoch 17 loss: 0.08556114882230759\n",
      "epoch 18 loss: 0.09139389544725418\n",
      "epoch 19 loss: 0.09860628098249435\n",
      "epoch 20 loss: 0.07425708323717117\n",
      "epoch 21 loss: 0.07869133353233337\n",
      "epoch 22 loss: 0.09187422692775726\n",
      "epoch 23 loss: 0.09292368590831757\n",
      "epoch 24 loss: 0.060266684740781784\n",
      "epoch 25 loss: 0.09239397943019867\n",
      "epoch 26 loss: 0.08754783868789673\n",
      "epoch 27 loss: 0.07817680388689041\n",
      "epoch 28 loss: 0.08869870007038116\n",
      "epoch 29 loss: 0.08424680680036545\n",
      "epoch 30 loss: 0.09242318570613861\n",
      "8\n",
      "epoch 1 loss: 0.6388516426086426\n",
      "epoch 2 loss: 0.6936413645744324\n",
      "epoch 3 loss: 0.821069598197937\n",
      "epoch 4 loss: 0.517568051815033\n",
      "epoch 5 loss: 0.4159610867500305\n",
      "epoch 6 loss: 0.2146231085062027\n",
      "epoch 7 loss: 0.12288498133420944\n",
      "epoch 8 loss: 0.08421202003955841\n",
      "epoch 9 loss: 0.09663895517587662\n",
      "epoch 10 loss: 0.1406632512807846\n",
      "epoch 11 loss: 0.09915018081665039\n",
      "epoch 12 loss: 0.09614131599664688\n",
      "epoch 13 loss: 0.1169094443321228\n",
      "epoch 14 loss: 0.11406651139259338\n",
      "epoch 15 loss: 0.11960417032241821\n",
      "epoch 16 loss: 0.09984730184078217\n",
      "epoch 17 loss: 0.09855165332555771\n",
      "epoch 18 loss: 0.10110288113355637\n",
      "epoch 19 loss: 0.08848454803228378\n",
      "epoch 20 loss: 0.09301120787858963\n",
      "epoch 21 loss: 0.09436595439910889\n",
      "epoch 22 loss: 0.09319331496953964\n",
      "epoch 23 loss: 0.088371641933918\n",
      "epoch 24 loss: 0.08093693852424622\n",
      "epoch 25 loss: 0.06828311085700989\n",
      "epoch 26 loss: 0.07287445664405823\n",
      "epoch 27 loss: 0.06970568001270294\n",
      "epoch 28 loss: 0.08027178049087524\n",
      "epoch 29 loss: 0.08123532682657242\n",
      "epoch 30 loss: 0.07537834346294403\n",
      "9\n",
      "epoch 1 loss: 0.8340923190116882\n",
      "epoch 2 loss: 0.44625046849250793\n",
      "epoch 3 loss: 0.27850669622421265\n",
      "epoch 4 loss: 0.15401029586791992\n",
      "epoch 5 loss: 0.15134470164775848\n",
      "epoch 6 loss: 0.12894295156002045\n",
      "epoch 7 loss: 0.11289656162261963\n",
      "epoch 8 loss: 0.10817073285579681\n",
      "epoch 9 loss: 0.0942026749253273\n",
      "epoch 10 loss: 0.13212326169013977\n",
      "epoch 11 loss: 0.0813693031668663\n",
      "epoch 12 loss: 0.07856415957212448\n",
      "epoch 13 loss: 0.12925441563129425\n",
      "epoch 14 loss: 0.09419247508049011\n",
      "epoch 15 loss: 0.0991557314991951\n",
      "epoch 16 loss: 0.09336918592453003\n",
      "epoch 17 loss: 0.10171092301607132\n",
      "epoch 18 loss: 0.0933065265417099\n",
      "epoch 19 loss: 0.08210178464651108\n",
      "epoch 20 loss: 0.06976967304944992\n",
      "epoch 21 loss: 0.08141563832759857\n",
      "epoch 22 loss: 0.07414032518863678\n",
      "epoch 23 loss: 0.07730752974748611\n",
      "epoch 24 loss: 0.06070292368531227\n",
      "epoch 25 loss: 0.08539821207523346\n",
      "epoch 26 loss: 0.08013022691011429\n",
      "epoch 27 loss: 0.08960311114788055\n",
      "epoch 28 loss: 0.07199638336896896\n",
      "epoch 29 loss: 0.07035130262374878\n",
      "epoch 30 loss: 0.08267728239297867\n",
      "10\n",
      "epoch 1 loss: 0.8849680423736572\n",
      "epoch 2 loss: 0.5331291556358337\n",
      "epoch 3 loss: 0.32958465814590454\n",
      "epoch 4 loss: 0.21411307156085968\n",
      "epoch 5 loss: 0.1768944412469864\n",
      "epoch 6 loss: 0.10568375885486603\n",
      "epoch 7 loss: 0.13906219601631165\n",
      "epoch 8 loss: 0.1062825471162796\n",
      "epoch 9 loss: 0.14827898144721985\n",
      "epoch 10 loss: 0.07838843017816544\n",
      "epoch 11 loss: 0.10961253941059113\n",
      "epoch 12 loss: 0.09453103691339493\n",
      "epoch 13 loss: 0.127688467502594\n",
      "epoch 14 loss: 0.08180125057697296\n",
      "epoch 15 loss: 0.12045814096927643\n",
      "epoch 16 loss: 0.10471402108669281\n",
      "epoch 17 loss: 0.13314363360404968\n",
      "epoch 18 loss: 0.07981747388839722\n",
      "epoch 19 loss: 0.073493592441082\n",
      "epoch 20 loss: 0.07722547650337219\n",
      "epoch 21 loss: 0.11005257070064545\n",
      "epoch 22 loss: 0.0873497873544693\n",
      "epoch 23 loss: 0.07241714745759964\n",
      "epoch 24 loss: 0.07987608015537262\n",
      "epoch 25 loss: 0.07307892292737961\n",
      "epoch 26 loss: 0.07876252382993698\n",
      "epoch 27 loss: 0.08014877885580063\n",
      "epoch 28 loss: 0.08224504441022873\n",
      "epoch 29 loss: 0.07956072688102722\n",
      "epoch 30 loss: 0.08898957818746567\n",
      "11\n",
      "epoch 1 loss: 0.8174329996109009\n",
      "epoch 2 loss: 0.6659828424453735\n",
      "epoch 3 loss: 0.4510967433452606\n",
      "epoch 4 loss: 0.225095734000206\n",
      "epoch 5 loss: 0.15575622022151947\n",
      "epoch 6 loss: 0.1094186082482338\n",
      "epoch 7 loss: 0.1618153154850006\n",
      "epoch 8 loss: 0.1357826292514801\n",
      "epoch 9 loss: 0.11531921476125717\n",
      "epoch 10 loss: 0.10617853701114655\n",
      "epoch 11 loss: 0.0827355682849884\n",
      "epoch 12 loss: 0.10748299211263657\n",
      "epoch 13 loss: 0.08345084637403488\n",
      "epoch 14 loss: 0.1261427402496338\n",
      "epoch 15 loss: 0.0996628925204277\n",
      "epoch 16 loss: 0.12823225557804108\n",
      "epoch 17 loss: 0.12119778245687485\n",
      "epoch 18 loss: 0.09722068160772324\n",
      "epoch 19 loss: 0.07769042998552322\n",
      "epoch 20 loss: 0.08337567746639252\n",
      "epoch 21 loss: 0.10909442603588104\n",
      "epoch 22 loss: 0.07867825776338577\n",
      "epoch 23 loss: 0.09752941131591797\n",
      "epoch 24 loss: 0.09358277916908264\n",
      "epoch 25 loss: 0.06816477328538895\n",
      "epoch 26 loss: 0.07081294804811478\n",
      "epoch 27 loss: 0.07344050705432892\n",
      "epoch 28 loss: 0.0846383199095726\n",
      "epoch 29 loss: 0.10803775489330292\n",
      "epoch 30 loss: 0.07924722135066986\n",
      "12\n",
      "epoch 1 loss: 0.9125531911849976\n",
      "epoch 2 loss: 0.7833144068717957\n",
      "epoch 3 loss: 0.5335820913314819\n",
      "epoch 4 loss: 0.3430231809616089\n",
      "epoch 5 loss: 0.16758175194263458\n",
      "epoch 6 loss: 0.18467576801776886\n",
      "epoch 7 loss: 0.11264064162969589\n",
      "epoch 8 loss: 0.14260369539260864\n",
      "epoch 9 loss: 0.10468731820583344\n",
      "epoch 10 loss: 0.14487656950950623\n",
      "epoch 11 loss: 0.11589670181274414\n",
      "epoch 12 loss: 0.12128540128469467\n",
      "epoch 13 loss: 0.09826193004846573\n",
      "epoch 14 loss: 0.09723684191703796\n",
      "epoch 15 loss: 0.10125359892845154\n",
      "epoch 16 loss: 0.08229607343673706\n",
      "epoch 17 loss: 0.08458361774682999\n",
      "epoch 18 loss: 0.0796852633357048\n",
      "epoch 19 loss: 0.09001835435628891\n",
      "epoch 20 loss: 0.07101040333509445\n",
      "epoch 21 loss: 0.06669308245182037\n",
      "epoch 22 loss: 0.10718086361885071\n",
      "epoch 23 loss: 0.07323909550905228\n",
      "epoch 24 loss: 0.09099190682172775\n",
      "epoch 25 loss: 0.0753685012459755\n",
      "epoch 26 loss: 0.08044339716434479\n",
      "epoch 27 loss: 0.06276972591876984\n",
      "epoch 28 loss: 0.08016474545001984\n",
      "epoch 29 loss: 0.08682817965745926\n",
      "epoch 30 loss: 0.06932470947504044\n",
      "13\n",
      "epoch 1 loss: 0.8656520247459412\n",
      "epoch 2 loss: 0.6634069085121155\n",
      "epoch 3 loss: 0.558343231678009\n",
      "epoch 4 loss: 0.280775785446167\n",
      "epoch 5 loss: 0.13444232940673828\n",
      "epoch 6 loss: 0.13892945647239685\n",
      "epoch 7 loss: 0.1305786669254303\n",
      "epoch 8 loss: 0.12270734459161758\n",
      "epoch 9 loss: 0.10425707697868347\n",
      "epoch 10 loss: 0.135301873087883\n",
      "epoch 11 loss: 0.10116864740848541\n",
      "epoch 12 loss: 0.08465665578842163\n",
      "epoch 13 loss: 0.0903979167342186\n",
      "epoch 14 loss: 0.10024237632751465\n",
      "epoch 15 loss: 0.12034311145544052\n",
      "epoch 16 loss: 0.08040022850036621\n",
      "epoch 17 loss: 0.06391593813896179\n",
      "epoch 18 loss: 0.09096366912126541\n",
      "epoch 19 loss: 0.10321974009275436\n",
      "epoch 20 loss: 0.10977856069803238\n",
      "epoch 21 loss: 0.0937841385602951\n",
      "epoch 22 loss: 0.07389948517084122\n",
      "epoch 23 loss: 0.0692153349518776\n",
      "epoch 24 loss: 0.06698407232761383\n",
      "epoch 25 loss: 0.07784666121006012\n",
      "epoch 26 loss: 0.08752904087305069\n",
      "epoch 27 loss: 0.08491351455450058\n",
      "epoch 28 loss: 0.07640489935874939\n",
      "epoch 29 loss: 0.06741836667060852\n",
      "epoch 30 loss: 0.07432370632886887\n",
      "14\n",
      "epoch 1 loss: 0.7340921759605408\n",
      "epoch 2 loss: 0.4736175537109375\n",
      "epoch 3 loss: 0.345066100358963\n",
      "epoch 4 loss: 0.2524932324886322\n",
      "epoch 5 loss: 0.17865309119224548\n",
      "epoch 6 loss: 0.1386900097131729\n",
      "epoch 7 loss: 0.1469242125749588\n",
      "epoch 8 loss: 0.09782439470291138\n",
      "epoch 9 loss: 0.10470038652420044\n",
      "epoch 10 loss: 0.11306154727935791\n",
      "epoch 11 loss: 0.08526229113340378\n",
      "epoch 12 loss: 0.1342860609292984\n",
      "epoch 13 loss: 0.11605434119701385\n",
      "epoch 14 loss: 0.10576365143060684\n",
      "epoch 15 loss: 0.10709748417139053\n",
      "epoch 16 loss: 0.11901459842920303\n",
      "epoch 17 loss: 0.1006292849779129\n",
      "epoch 18 loss: 0.10988078266382217\n",
      "epoch 19 loss: 0.10044670850038528\n",
      "epoch 20 loss: 0.08756041526794434\n",
      "epoch 21 loss: 0.0696941465139389\n",
      "epoch 22 loss: 0.07966210693120956\n",
      "epoch 23 loss: 0.09386956691741943\n",
      "epoch 24 loss: 0.08924984186887741\n",
      "epoch 25 loss: 0.05750884488224983\n",
      "epoch 26 loss: 0.07046111673116684\n",
      "epoch 27 loss: 0.07504885643720627\n",
      "epoch 28 loss: 0.08958162367343903\n",
      "epoch 29 loss: 0.06806037575006485\n",
      "epoch 30 loss: 0.07770431041717529\n",
      "15\n",
      "epoch 1 loss: 0.7398570775985718\n",
      "epoch 2 loss: 0.5822935700416565\n",
      "epoch 3 loss: 0.37179476022720337\n",
      "epoch 4 loss: 0.30378755927085876\n",
      "epoch 5 loss: 0.15779533982276917\n",
      "epoch 6 loss: 0.13058911263942719\n",
      "epoch 7 loss: 0.14235924184322357\n",
      "epoch 8 loss: 0.08918642997741699\n",
      "epoch 9 loss: 0.11440474539995193\n",
      "epoch 10 loss: 0.10707646608352661\n",
      "epoch 11 loss: 0.08557379245758057\n",
      "epoch 12 loss: 0.10732836276292801\n",
      "epoch 13 loss: 0.09257972240447998\n",
      "epoch 14 loss: 0.08093220740556717\n",
      "epoch 15 loss: 0.08566740900278091\n",
      "epoch 16 loss: 0.08485732227563858\n",
      "epoch 17 loss: 0.0719393640756607\n",
      "epoch 18 loss: 0.1037171259522438\n",
      "epoch 19 loss: 0.11040230840444565\n",
      "epoch 20 loss: 0.07156813144683838\n",
      "epoch 21 loss: 0.10899291187524796\n",
      "epoch 22 loss: 0.07843337208032608\n",
      "epoch 23 loss: 0.08548706769943237\n",
      "epoch 24 loss: 0.0927010327577591\n",
      "epoch 25 loss: 0.09598499536514282\n",
      "epoch 26 loss: 0.067926786839962\n",
      "epoch 27 loss: 0.09433439373970032\n",
      "epoch 28 loss: 0.08640524744987488\n",
      "epoch 29 loss: 0.09999728947877884\n",
      "epoch 30 loss: 0.07277955114841461\n",
      "16\n",
      "epoch 1 loss: 0.6842432618141174\n",
      "epoch 2 loss: 0.5754931569099426\n",
      "epoch 3 loss: 0.3706209361553192\n",
      "epoch 4 loss: 0.2700834274291992\n",
      "epoch 5 loss: 0.13377390801906586\n",
      "epoch 6 loss: 0.1615888625383377\n",
      "epoch 7 loss: 0.0994664654135704\n",
      "epoch 8 loss: 0.14244534075260162\n",
      "epoch 9 loss: 0.07590124756097794\n",
      "epoch 10 loss: 0.09304840117692947\n",
      "epoch 11 loss: 0.09323780983686447\n",
      "epoch 12 loss: 0.08604138344526291\n",
      "epoch 13 loss: 0.08113978058099747\n",
      "epoch 14 loss: 0.11755014210939407\n",
      "epoch 15 loss: 0.10521510243415833\n",
      "epoch 16 loss: 0.08529527485370636\n",
      "epoch 17 loss: 0.07629182934761047\n",
      "epoch 18 loss: 0.09740416705608368\n",
      "epoch 19 loss: 0.06886971741914749\n",
      "epoch 20 loss: 0.08144517242908478\n",
      "epoch 21 loss: 0.07435812056064606\n",
      "epoch 22 loss: 0.06901566684246063\n",
      "epoch 23 loss: 0.06358737498521805\n",
      "epoch 24 loss: 0.057872217148542404\n",
      "epoch 25 loss: 0.06552016735076904\n",
      "epoch 26 loss: 0.08123249560594559\n",
      "epoch 27 loss: 0.06953984498977661\n",
      "epoch 28 loss: 0.071708083152771\n",
      "epoch 29 loss: 0.07709448784589767\n",
      "epoch 30 loss: 0.07437289506196976\n",
      "17\n",
      "epoch 1 loss: 0.8012486100196838\n",
      "epoch 2 loss: 0.5903500914573669\n",
      "epoch 3 loss: 0.2827107012271881\n",
      "epoch 4 loss: 0.22321632504463196\n",
      "epoch 5 loss: 0.20751477777957916\n",
      "epoch 6 loss: 0.11901270598173141\n",
      "epoch 7 loss: 0.14220425486564636\n",
      "epoch 8 loss: 0.1391858011484146\n",
      "epoch 9 loss: 0.09988263994455338\n",
      "epoch 10 loss: 0.10107311606407166\n",
      "epoch 11 loss: 0.09213090687990189\n",
      "epoch 12 loss: 0.11427037417888641\n",
      "epoch 13 loss: 0.10500413179397583\n",
      "epoch 14 loss: 0.09505723416805267\n",
      "epoch 15 loss: 0.0841238796710968\n",
      "epoch 16 loss: 0.09412108361721039\n",
      "epoch 17 loss: 0.07825317233800888\n",
      "epoch 18 loss: 0.10480000078678131\n",
      "epoch 19 loss: 0.08944940567016602\n",
      "epoch 20 loss: 0.0883670374751091\n",
      "epoch 21 loss: 0.079838827252388\n",
      "epoch 22 loss: 0.08076651394367218\n",
      "epoch 23 loss: 0.10027127712965012\n",
      "epoch 24 loss: 0.08676153421401978\n",
      "epoch 25 loss: 0.08759383112192154\n",
      "epoch 26 loss: 0.07780813425779343\n",
      "epoch 27 loss: 0.08503367751836777\n",
      "epoch 28 loss: 0.08267785608768463\n",
      "epoch 29 loss: 0.09514875710010529\n",
      "epoch 30 loss: 0.0913710668683052\n",
      "18\n",
      "epoch 1 loss: 0.8377372622489929\n",
      "epoch 2 loss: 0.572893500328064\n",
      "epoch 3 loss: 0.33724284172058105\n",
      "epoch 4 loss: 0.24099281430244446\n",
      "epoch 5 loss: 0.17043536901474\n",
      "epoch 6 loss: 0.14565984904766083\n",
      "epoch 7 loss: 0.1452101171016693\n",
      "epoch 8 loss: 0.12865671515464783\n",
      "epoch 9 loss: 0.11262400448322296\n",
      "epoch 10 loss: 0.1451927125453949\n",
      "epoch 11 loss: 0.11288981884717941\n",
      "epoch 12 loss: 0.0895843505859375\n",
      "epoch 13 loss: 0.09664912521839142\n",
      "epoch 14 loss: 0.08362855017185211\n",
      "epoch 15 loss: 0.09066914767026901\n",
      "epoch 16 loss: 0.0897032618522644\n",
      "epoch 17 loss: 0.08510270714759827\n",
      "epoch 18 loss: 0.06490366160869598\n",
      "epoch 19 loss: 0.09493090957403183\n",
      "epoch 20 loss: 0.0899745374917984\n",
      "epoch 21 loss: 0.10008687525987625\n",
      "epoch 22 loss: 0.11556113511323929\n",
      "epoch 23 loss: 0.10938296467065811\n",
      "epoch 24 loss: 0.07271748036146164\n",
      "epoch 25 loss: 0.06494548916816711\n",
      "epoch 26 loss: 0.06935003399848938\n",
      "epoch 27 loss: 0.08080222457647324\n",
      "epoch 28 loss: 0.07417506724596024\n",
      "epoch 29 loss: 0.08579578995704651\n",
      "epoch 30 loss: 0.07436762750148773\n",
      "19\n",
      "epoch 1 loss: 0.8676823973655701\n",
      "epoch 2 loss: 0.6581346392631531\n",
      "epoch 3 loss: 0.2822677493095398\n",
      "epoch 4 loss: 0.20115740597248077\n",
      "epoch 5 loss: 0.17504969239234924\n",
      "epoch 6 loss: 0.16765029728412628\n",
      "epoch 7 loss: 0.12810097634792328\n",
      "epoch 8 loss: 0.10876303166151047\n",
      "epoch 9 loss: 0.17984141409397125\n",
      "epoch 10 loss: 0.13300779461860657\n",
      "epoch 11 loss: 0.08338044583797455\n",
      "epoch 12 loss: 0.10220729559659958\n",
      "epoch 13 loss: 0.10674552619457245\n",
      "epoch 14 loss: 0.07469478994607925\n",
      "epoch 15 loss: 0.07799103856086731\n",
      "epoch 16 loss: 0.0903545469045639\n",
      "epoch 17 loss: 0.09350405633449554\n",
      "epoch 18 loss: 0.07917778939008713\n",
      "epoch 19 loss: 0.1023624837398529\n",
      "epoch 20 loss: 0.07114323228597641\n",
      "epoch 21 loss: 0.06892434507608414\n",
      "epoch 22 loss: 0.09334878623485565\n",
      "epoch 23 loss: 0.08117034286260605\n",
      "epoch 24 loss: 0.09642861783504486\n",
      "epoch 25 loss: 0.09762582927942276\n",
      "epoch 26 loss: 0.1067691370844841\n",
      "epoch 27 loss: 0.09707869589328766\n",
      "epoch 28 loss: 0.058931734412908554\n",
      "epoch 29 loss: 0.08221462368965149\n",
      "epoch 30 loss: 0.05986976996064186\n",
      "20\n",
      "epoch 1 loss: 0.8422934412956238\n",
      "epoch 2 loss: 0.5494933724403381\n",
      "epoch 3 loss: 0.2311503291130066\n",
      "epoch 4 loss: 0.16807261109352112\n",
      "epoch 5 loss: 0.18554869294166565\n",
      "epoch 6 loss: 0.15560436248779297\n",
      "epoch 7 loss: 0.1303345263004303\n",
      "epoch 8 loss: 0.1429741382598877\n",
      "epoch 9 loss: 0.13101696968078613\n",
      "epoch 10 loss: 0.13440659642219543\n",
      "epoch 11 loss: 0.08757277578115463\n",
      "epoch 12 loss: 0.11112421751022339\n",
      "epoch 13 loss: 0.10241241008043289\n",
      "epoch 14 loss: 0.08835823833942413\n",
      "epoch 15 loss: 0.07657197117805481\n",
      "epoch 16 loss: 0.10302980989217758\n",
      "epoch 17 loss: 0.1003984659910202\n",
      "epoch 18 loss: 0.1146998256444931\n",
      "epoch 19 loss: 0.10298998653888702\n",
      "epoch 20 loss: 0.11256714910268784\n",
      "epoch 21 loss: 0.08290351927280426\n",
      "epoch 22 loss: 0.09319926798343658\n",
      "epoch 23 loss: 0.09975090622901917\n",
      "epoch 24 loss: 0.06454147398471832\n",
      "epoch 25 loss: 0.09612414240837097\n",
      "epoch 26 loss: 0.0848240852355957\n",
      "epoch 27 loss: 0.08788707107305527\n",
      "epoch 28 loss: 0.07386645674705505\n",
      "epoch 29 loss: 0.06644894182682037\n",
      "epoch 30 loss: 0.07991847395896912\n",
      "21\n",
      "epoch 1 loss: 0.7606312036514282\n",
      "epoch 2 loss: 0.7303466200828552\n",
      "epoch 3 loss: 0.4663614332675934\n",
      "epoch 4 loss: 0.4764602482318878\n",
      "epoch 5 loss: 0.23596234619617462\n",
      "epoch 6 loss: 0.14766621589660645\n",
      "epoch 7 loss: 0.13449792563915253\n",
      "epoch 8 loss: 0.08731599152088165\n",
      "epoch 9 loss: 0.14318276941776276\n",
      "epoch 10 loss: 0.11220791935920715\n",
      "epoch 11 loss: 0.12340769171714783\n",
      "epoch 12 loss: 0.09021399170160294\n",
      "epoch 13 loss: 0.16687072813510895\n",
      "epoch 14 loss: 0.08796214312314987\n",
      "epoch 15 loss: 0.08212938904762268\n",
      "epoch 16 loss: 0.0711478739976883\n",
      "epoch 17 loss: 0.08062954992055893\n",
      "epoch 18 loss: 0.07852134108543396\n",
      "epoch 19 loss: 0.08868677914142609\n",
      "epoch 20 loss: 0.0827372819185257\n",
      "epoch 21 loss: 0.08936410397291183\n",
      "epoch 22 loss: 0.08080794662237167\n",
      "epoch 23 loss: 0.07889460772275925\n",
      "epoch 24 loss: 0.08391550183296204\n",
      "epoch 25 loss: 0.09423874318599701\n",
      "epoch 26 loss: 0.0904630497097969\n",
      "epoch 27 loss: 0.07033374905586243\n",
      "epoch 28 loss: 0.0778498649597168\n",
      "epoch 29 loss: 0.05974392220377922\n",
      "epoch 30 loss: 0.07024455070495605\n",
      "22\n",
      "epoch 1 loss: 0.677191972732544\n",
      "epoch 2 loss: 0.4661003351211548\n",
      "epoch 3 loss: 0.2850121259689331\n",
      "epoch 4 loss: 0.16693437099456787\n",
      "epoch 5 loss: 0.134186789393425\n",
      "epoch 6 loss: 0.141909658908844\n",
      "epoch 7 loss: 0.12632393836975098\n",
      "epoch 8 loss: 0.11670006811618805\n",
      "epoch 9 loss: 0.1236439123749733\n",
      "epoch 10 loss: 0.12035071104764938\n",
      "epoch 11 loss: 0.11342082917690277\n",
      "epoch 12 loss: 0.09077193588018417\n",
      "epoch 13 loss: 0.10505595058202744\n",
      "epoch 14 loss: 0.11709894984960556\n",
      "epoch 15 loss: 0.12107767909765244\n",
      "epoch 16 loss: 0.0862465649843216\n",
      "epoch 17 loss: 0.09464819729328156\n",
      "epoch 18 loss: 0.1296934187412262\n",
      "epoch 19 loss: 0.08640921860933304\n",
      "epoch 20 loss: 0.11391449719667435\n",
      "epoch 21 loss: 0.10090294480323792\n",
      "epoch 22 loss: 0.07797877490520477\n",
      "epoch 23 loss: 0.1110333725810051\n",
      "epoch 24 loss: 0.07907576858997345\n",
      "epoch 25 loss: 0.09358806163072586\n",
      "epoch 26 loss: 0.08298603445291519\n",
      "epoch 27 loss: 0.09450716525316238\n",
      "epoch 28 loss: 0.06396763771772385\n",
      "epoch 29 loss: 0.06226889044046402\n",
      "epoch 30 loss: 0.07319459319114685\n",
      "23\n",
      "epoch 1 loss: 0.8510515093803406\n",
      "epoch 2 loss: 0.7817408442497253\n",
      "epoch 3 loss: 0.62319415807724\n",
      "epoch 4 loss: 0.33351245522499084\n",
      "epoch 5 loss: 0.187360018491745\n",
      "epoch 6 loss: 0.18290852010250092\n",
      "epoch 7 loss: 0.15311084687709808\n",
      "epoch 8 loss: 0.11832144111394882\n",
      "epoch 9 loss: 0.10819022357463837\n",
      "epoch 10 loss: 0.1348053365945816\n",
      "epoch 11 loss: 0.09217692911624908\n",
      "epoch 12 loss: 0.21274858713150024\n",
      "epoch 13 loss: 0.13986098766326904\n",
      "epoch 14 loss: 0.12056224048137665\n",
      "epoch 15 loss: 0.07023876905441284\n",
      "epoch 16 loss: 0.1281963735818863\n",
      "epoch 17 loss: 0.0774594321846962\n",
      "epoch 18 loss: 0.09243910014629364\n",
      "epoch 19 loss: 0.07952135056257248\n",
      "epoch 20 loss: 0.09453419595956802\n",
      "epoch 21 loss: 0.07950808107852936\n",
      "epoch 22 loss: 0.07782133668661118\n",
      "epoch 23 loss: 0.07550966739654541\n",
      "epoch 24 loss: 0.057785432785749435\n",
      "epoch 25 loss: 0.07917772233486176\n",
      "epoch 26 loss: 0.07959555834531784\n",
      "epoch 27 loss: 0.09035257250070572\n",
      "epoch 28 loss: 0.08202815055847168\n",
      "epoch 29 loss: 0.06812139600515366\n",
      "epoch 30 loss: 0.08477673679590225\n",
      "24\n",
      "epoch 1 loss: 0.807929515838623\n",
      "epoch 2 loss: 0.6882057189941406\n",
      "epoch 3 loss: 0.3345438838005066\n",
      "epoch 4 loss: 0.24302877485752106\n",
      "epoch 5 loss: 0.1391996443271637\n",
      "epoch 6 loss: 0.14659209549427032\n",
      "epoch 7 loss: 0.17651595175266266\n",
      "epoch 8 loss: 0.1266874521970749\n",
      "epoch 9 loss: 0.09370333701372147\n",
      "epoch 10 loss: 0.10760381817817688\n",
      "epoch 11 loss: 0.09844043105840683\n",
      "epoch 12 loss: 0.133686825633049\n",
      "epoch 13 loss: 0.09022613614797592\n",
      "epoch 14 loss: 0.08629968762397766\n",
      "epoch 15 loss: 0.10948488861322403\n",
      "epoch 16 loss: 0.08575800806283951\n",
      "epoch 17 loss: 0.09577665477991104\n",
      "epoch 18 loss: 0.11036836355924606\n",
      "epoch 19 loss: 0.10556569695472717\n",
      "epoch 20 loss: 0.11373626440763474\n",
      "epoch 21 loss: 0.09825592488050461\n",
      "epoch 22 loss: 0.06488749384880066\n",
      "epoch 23 loss: 0.08283685147762299\n",
      "epoch 24 loss: 0.0659848004579544\n",
      "epoch 25 loss: 0.08841788023710251\n",
      "epoch 26 loss: 0.08892595022916794\n",
      "epoch 27 loss: 0.08376707881689072\n",
      "epoch 28 loss: 0.079065702855587\n",
      "epoch 29 loss: 0.07333122938871384\n",
      "epoch 30 loss: 0.08129357546567917\n",
      "25\n",
      "epoch 1 loss: 0.7795920372009277\n",
      "epoch 2 loss: 0.5440563559532166\n",
      "epoch 3 loss: 0.24119041860103607\n",
      "epoch 4 loss: 0.17541128396987915\n",
      "epoch 5 loss: 0.1466081291437149\n",
      "epoch 6 loss: 0.12823966145515442\n",
      "epoch 7 loss: 0.1372816562652588\n",
      "epoch 8 loss: 0.14599120616912842\n",
      "epoch 9 loss: 0.13844113051891327\n",
      "epoch 10 loss: 0.08774413913488388\n",
      "epoch 11 loss: 0.08825299888849258\n",
      "epoch 12 loss: 0.09764309227466583\n",
      "epoch 13 loss: 0.0728193074464798\n",
      "epoch 14 loss: 0.11757416278123856\n",
      "epoch 15 loss: 0.11121232807636261\n",
      "epoch 16 loss: 0.08712507784366608\n",
      "epoch 17 loss: 0.0732935220003128\n",
      "epoch 18 loss: 0.08100519329309464\n",
      "epoch 19 loss: 0.07806386053562164\n",
      "epoch 20 loss: 0.08431661874055862\n",
      "epoch 21 loss: 0.07042387127876282\n",
      "epoch 22 loss: 0.08701853454113007\n",
      "epoch 23 loss: 0.07748789340257645\n",
      "epoch 24 loss: 0.08537692576646805\n",
      "epoch 25 loss: 0.09097815304994583\n",
      "epoch 26 loss: 0.10242249816656113\n",
      "epoch 27 loss: 0.07969480752944946\n",
      "epoch 28 loss: 0.08909261971712112\n",
      "epoch 29 loss: 0.07779727131128311\n",
      "epoch 30 loss: 0.08228873461484909\n",
      "26\n",
      "epoch 1 loss: 0.8509328365325928\n",
      "epoch 2 loss: 0.7380304336547852\n",
      "epoch 3 loss: 0.35850587487220764\n",
      "epoch 4 loss: 0.2161295861005783\n",
      "epoch 5 loss: 0.18815065920352936\n",
      "epoch 6 loss: 0.12326137721538544\n",
      "epoch 7 loss: 0.15787896513938904\n",
      "epoch 8 loss: 0.1375284492969513\n",
      "epoch 9 loss: 0.12926535308361053\n",
      "epoch 10 loss: 0.12915362417697906\n",
      "epoch 11 loss: 0.10961825400590897\n",
      "epoch 12 loss: 0.11495596915483475\n",
      "epoch 13 loss: 0.1004381999373436\n",
      "epoch 14 loss: 0.09556981921195984\n",
      "epoch 15 loss: 0.07717034965753555\n",
      "epoch 16 loss: 0.06662528216838837\n",
      "epoch 17 loss: 0.07734768092632294\n",
      "epoch 18 loss: 0.07371047139167786\n",
      "epoch 19 loss: 0.07889016717672348\n",
      "epoch 20 loss: 0.0637117326259613\n",
      "epoch 21 loss: 0.11365383863449097\n",
      "epoch 22 loss: 0.11849784851074219\n",
      "epoch 23 loss: 0.08514972031116486\n",
      "epoch 24 loss: 0.09701909124851227\n",
      "epoch 25 loss: 0.08866215497255325\n",
      "epoch 26 loss: 0.07151774317026138\n",
      "epoch 27 loss: 0.08187119662761688\n",
      "epoch 28 loss: 0.06724187731742859\n",
      "epoch 29 loss: 0.0738903284072876\n",
      "epoch 30 loss: 0.07983928173780441\n",
      "27\n",
      "epoch 1 loss: 0.7907887101173401\n",
      "epoch 2 loss: 0.6602478623390198\n",
      "epoch 3 loss: 0.4542115330696106\n",
      "epoch 4 loss: 0.3721891939640045\n",
      "epoch 5 loss: 0.15963362157344818\n",
      "epoch 6 loss: 0.1590195745229721\n",
      "epoch 7 loss: 0.1607334017753601\n",
      "epoch 8 loss: 0.13929083943367004\n",
      "epoch 9 loss: 0.16359147429466248\n",
      "epoch 10 loss: 0.13144245743751526\n",
      "epoch 11 loss: 0.08632645010948181\n",
      "epoch 12 loss: 0.11634718626737595\n",
      "epoch 13 loss: 0.11732105165719986\n",
      "epoch 14 loss: 0.09609709680080414\n",
      "epoch 15 loss: 0.0913609191775322\n",
      "epoch 16 loss: 0.12447579205036163\n",
      "epoch 17 loss: 0.10175890475511551\n",
      "epoch 18 loss: 0.1271776705980301\n",
      "epoch 19 loss: 0.09140370786190033\n",
      "epoch 20 loss: 0.09210829436779022\n",
      "epoch 21 loss: 0.08956976234912872\n",
      "epoch 22 loss: 0.0877799466252327\n",
      "epoch 23 loss: 0.0763813778758049\n",
      "epoch 24 loss: 0.09872077405452728\n",
      "epoch 25 loss: 0.06503884494304657\n",
      "epoch 26 loss: 0.09596831351518631\n",
      "epoch 27 loss: 0.07220256328582764\n",
      "epoch 28 loss: 0.09642907977104187\n",
      "epoch 29 loss: 0.06730081886053085\n",
      "epoch 30 loss: 0.07305837422609329\n",
      "28\n",
      "epoch 1 loss: 0.7625412344932556\n",
      "epoch 2 loss: 0.3718460202217102\n",
      "epoch 3 loss: 0.30927592515945435\n",
      "epoch 4 loss: 0.18636904656887054\n",
      "epoch 5 loss: 0.16561266779899597\n",
      "epoch 6 loss: 0.12987160682678223\n",
      "epoch 7 loss: 0.13987769186496735\n",
      "epoch 8 loss: 0.11456157267093658\n",
      "epoch 9 loss: 0.08744172006845474\n",
      "epoch 10 loss: 0.10468685626983643\n",
      "epoch 11 loss: 0.08299575001001358\n",
      "epoch 12 loss: 0.10215822607278824\n",
      "epoch 13 loss: 0.15831997990608215\n",
      "epoch 14 loss: 0.1048959344625473\n",
      "epoch 15 loss: 0.11638219654560089\n",
      "epoch 16 loss: 0.09227338433265686\n",
      "epoch 17 loss: 0.08555620163679123\n",
      "epoch 18 loss: 0.09353145956993103\n",
      "epoch 19 loss: 0.09245108813047409\n",
      "epoch 20 loss: 0.10124915838241577\n",
      "epoch 21 loss: 0.09928090870380402\n",
      "epoch 22 loss: 0.07221300899982452\n",
      "epoch 23 loss: 0.08914802968502045\n",
      "epoch 24 loss: 0.0701577216386795\n",
      "epoch 25 loss: 0.07621993869543076\n",
      "epoch 26 loss: 0.07979071140289307\n",
      "epoch 27 loss: 0.0746019184589386\n",
      "epoch 28 loss: 0.08275674283504486\n",
      "epoch 29 loss: 0.07607623189687729\n",
      "epoch 30 loss: 0.056574929505586624\n",
      "29\n",
      "epoch 1 loss: 0.9157862663269043\n",
      "epoch 2 loss: 0.4101431369781494\n",
      "epoch 3 loss: 0.28617557883262634\n",
      "epoch 4 loss: 0.17535726726055145\n",
      "epoch 5 loss: 0.15702354907989502\n",
      "epoch 6 loss: 0.13086098432540894\n",
      "epoch 7 loss: 0.14475883543491364\n",
      "epoch 8 loss: 0.1375538855791092\n",
      "epoch 9 loss: 0.10154823213815689\n",
      "epoch 10 loss: 0.14412687718868256\n",
      "epoch 11 loss: 0.12387984246015549\n",
      "epoch 12 loss: 0.1021081730723381\n",
      "epoch 13 loss: 0.08455962687730789\n",
      "epoch 14 loss: 0.0763646736741066\n",
      "epoch 15 loss: 0.07722502201795578\n",
      "epoch 16 loss: 0.08890364319086075\n",
      "epoch 17 loss: 0.12172818928956985\n",
      "epoch 18 loss: 0.07326287031173706\n",
      "epoch 19 loss: 0.08520880341529846\n",
      "epoch 20 loss: 0.10826682299375534\n",
      "epoch 21 loss: 0.09423327445983887\n",
      "epoch 22 loss: 0.09580719470977783\n",
      "epoch 23 loss: 0.08336703479290009\n",
      "epoch 24 loss: 0.09538853913545609\n",
      "epoch 25 loss: 0.09885559976100922\n",
      "epoch 26 loss: 0.08999539166688919\n",
      "epoch 27 loss: 0.09191176295280457\n",
      "epoch 28 loss: 0.13134272396564484\n",
      "epoch 29 loss: 0.08076363801956177\n",
      "epoch 30 loss: 0.08970803022384644\n",
      "30\n",
      "epoch 1 loss: 0.6524428725242615\n",
      "epoch 2 loss: 0.2926885783672333\n",
      "epoch 3 loss: 0.15975020825862885\n",
      "epoch 4 loss: 0.15173183381557465\n",
      "epoch 5 loss: 0.11326564103364944\n",
      "epoch 6 loss: 0.12488765269517899\n",
      "epoch 7 loss: 0.1295141875743866\n",
      "epoch 8 loss: 0.125332772731781\n",
      "epoch 9 loss: 0.12797245383262634\n",
      "epoch 10 loss: 0.1641976237297058\n",
      "epoch 11 loss: 0.1598202884197235\n",
      "epoch 12 loss: 0.10622716695070267\n",
      "epoch 13 loss: 0.09914962947368622\n",
      "epoch 14 loss: 0.1475074589252472\n",
      "epoch 15 loss: 0.08399683982133865\n",
      "epoch 16 loss: 0.09624131768941879\n",
      "epoch 17 loss: 0.07389615476131439\n",
      "epoch 18 loss: 0.12970609962940216\n",
      "epoch 19 loss: 0.10069771111011505\n",
      "epoch 20 loss: 0.11984294652938843\n",
      "epoch 21 loss: 0.07108618319034576\n",
      "epoch 22 loss: 0.0948353260755539\n",
      "epoch 23 loss: 0.066018246114254\n",
      "epoch 24 loss: 0.0677935779094696\n",
      "epoch 25 loss: 0.08474783599376678\n",
      "epoch 26 loss: 0.07798124104738235\n",
      "epoch 27 loss: 0.08639609813690186\n",
      "epoch 28 loss: 0.08719120174646378\n",
      "epoch 29 loss: 0.08583550900220871\n",
      "epoch 30 loss: 0.08511733263731003\n",
      "31\n",
      "epoch 1 loss: 0.714779794216156\n",
      "epoch 2 loss: 0.49596333503723145\n",
      "epoch 3 loss: 0.4028523564338684\n",
      "epoch 4 loss: 0.16011859476566315\n",
      "epoch 5 loss: 0.14056061208248138\n",
      "epoch 6 loss: 0.14566010236740112\n",
      "epoch 7 loss: 0.14530467987060547\n",
      "epoch 8 loss: 0.09267653524875641\n",
      "epoch 9 loss: 0.1322939395904541\n",
      "epoch 10 loss: 0.11947440356016159\n",
      "epoch 11 loss: 0.1746378242969513\n",
      "epoch 12 loss: 0.12409146130084991\n",
      "epoch 13 loss: 0.11257153749465942\n",
      "epoch 14 loss: 0.11404038965702057\n",
      "epoch 15 loss: 0.09504379332065582\n",
      "epoch 16 loss: 0.091657355427742\n",
      "epoch 17 loss: 0.11178404837846756\n",
      "epoch 18 loss: 0.07652344554662704\n",
      "epoch 19 loss: 0.07974876463413239\n",
      "epoch 20 loss: 0.10177300125360489\n",
      "epoch 21 loss: 0.08972997963428497\n",
      "epoch 22 loss: 0.07655112445354462\n",
      "epoch 23 loss: 0.07109483331441879\n",
      "epoch 24 loss: 0.08926529437303543\n",
      "epoch 25 loss: 0.08014410734176636\n",
      "epoch 26 loss: 0.06403304636478424\n",
      "epoch 27 loss: 0.0807279497385025\n",
      "epoch 28 loss: 0.08397699147462845\n",
      "epoch 29 loss: 0.08861517906188965\n",
      "epoch 30 loss: 0.06654536724090576\n",
      "32\n",
      "epoch 1 loss: 0.759934663772583\n",
      "epoch 2 loss: 0.563352108001709\n",
      "epoch 3 loss: 0.20592644810676575\n",
      "epoch 4 loss: 0.16970953345298767\n",
      "epoch 5 loss: 0.10770283639431\n",
      "epoch 6 loss: 0.13596510887145996\n",
      "epoch 7 loss: 0.17173916101455688\n",
      "epoch 8 loss: 0.11956889182329178\n",
      "epoch 9 loss: 0.10231588780879974\n",
      "epoch 10 loss: 0.08353171497583389\n",
      "epoch 11 loss: 0.10078568756580353\n",
      "epoch 12 loss: 0.11149497330188751\n",
      "epoch 13 loss: 0.11205843836069107\n",
      "epoch 14 loss: 0.09342341125011444\n",
      "epoch 15 loss: 0.09933417290449142\n",
      "epoch 16 loss: 0.08385524153709412\n",
      "epoch 17 loss: 0.10927257686853409\n",
      "epoch 18 loss: 0.07468678802251816\n",
      "epoch 19 loss: 0.0831238329410553\n",
      "epoch 20 loss: 0.07690073549747467\n",
      "epoch 21 loss: 0.09316064417362213\n",
      "epoch 22 loss: 0.08656687289476395\n",
      "epoch 23 loss: 0.13285234570503235\n",
      "epoch 24 loss: 0.09862121939659119\n",
      "epoch 25 loss: 0.08884565532207489\n",
      "epoch 26 loss: 0.09422097355127335\n",
      "epoch 27 loss: 0.07749931514263153\n",
      "epoch 28 loss: 0.060285668820142746\n",
      "epoch 29 loss: 0.12382233887910843\n",
      "epoch 30 loss: 0.05383845418691635\n",
      "33\n",
      "epoch 1 loss: 0.7820892930030823\n",
      "epoch 2 loss: 0.7651998400688171\n",
      "epoch 3 loss: 0.27034634351730347\n",
      "epoch 4 loss: 0.18154017627239227\n",
      "epoch 5 loss: 0.12689104676246643\n",
      "epoch 6 loss: 0.12286297231912613\n",
      "epoch 7 loss: 0.15203426778316498\n",
      "epoch 8 loss: 0.13506972789764404\n",
      "epoch 9 loss: 0.13428883254528046\n",
      "epoch 10 loss: 0.0970587357878685\n",
      "epoch 11 loss: 0.08956367522478104\n",
      "epoch 12 loss: 0.12468697130680084\n",
      "epoch 13 loss: 0.08610939979553223\n",
      "epoch 14 loss: 0.1063343808054924\n",
      "epoch 15 loss: 0.09253133833408356\n",
      "epoch 16 loss: 0.07777738571166992\n",
      "epoch 17 loss: 0.09979750961065292\n",
      "epoch 18 loss: 0.09094268083572388\n",
      "epoch 19 loss: 0.07323474436998367\n",
      "epoch 20 loss: 0.06370675563812256\n",
      "epoch 21 loss: 0.08139350265264511\n",
      "epoch 22 loss: 0.1182376891374588\n",
      "epoch 23 loss: 0.08708907663822174\n",
      "epoch 24 loss: 0.10069884359836578\n",
      "epoch 25 loss: 0.07620043307542801\n",
      "epoch 26 loss: 0.06482312083244324\n",
      "epoch 27 loss: 0.0836973562836647\n",
      "epoch 28 loss: 0.06284306198358536\n",
      "epoch 29 loss: 0.0789908766746521\n",
      "epoch 30 loss: 0.06153467297554016\n",
      "34\n",
      "epoch 1 loss: 0.8426075577735901\n",
      "epoch 2 loss: 0.44249191880226135\n",
      "epoch 3 loss: 0.32941320538520813\n",
      "epoch 4 loss: 0.1948610246181488\n",
      "epoch 5 loss: 0.15592248737812042\n",
      "epoch 6 loss: 0.1280260682106018\n",
      "epoch 7 loss: 0.11214885115623474\n",
      "epoch 8 loss: 0.12519586086273193\n",
      "epoch 9 loss: 0.08803748339414597\n",
      "epoch 10 loss: 0.10878409445285797\n",
      "epoch 11 loss: 0.09918241947889328\n",
      "epoch 12 loss: 0.1280362755060196\n",
      "epoch 13 loss: 0.11354091018438339\n",
      "epoch 14 loss: 0.11181970685720444\n",
      "epoch 15 loss: 0.11759328842163086\n",
      "epoch 16 loss: 0.09727243334054947\n",
      "epoch 17 loss: 0.09919754415750504\n",
      "epoch 18 loss: 0.10758742690086365\n",
      "epoch 19 loss: 0.07685123383998871\n",
      "epoch 20 loss: 0.09388145059347153\n",
      "epoch 21 loss: 0.15760637819766998\n",
      "epoch 22 loss: 0.09272049367427826\n",
      "epoch 23 loss: 0.08157452195882797\n",
      "epoch 24 loss: 0.07741431891918182\n",
      "epoch 25 loss: 0.08746387809515\n",
      "epoch 26 loss: 0.08961436152458191\n",
      "epoch 27 loss: 0.06167193129658699\n",
      "epoch 28 loss: 0.08965365588665009\n",
      "epoch 29 loss: 0.0559827983379364\n",
      "epoch 30 loss: 0.07975242286920547\n",
      "35\n",
      "epoch 1 loss: 0.9223031401634216\n",
      "epoch 2 loss: 0.574905276298523\n",
      "epoch 3 loss: 0.23629988729953766\n",
      "epoch 4 loss: 0.13862353563308716\n",
      "epoch 5 loss: 0.16319723427295685\n",
      "epoch 6 loss: 0.16432276368141174\n",
      "epoch 7 loss: 0.15471704304218292\n",
      "epoch 8 loss: 0.12091711163520813\n",
      "epoch 9 loss: 0.10049502551555634\n",
      "epoch 10 loss: 0.13106000423431396\n",
      "epoch 11 loss: 0.10590969771146774\n",
      "epoch 12 loss: 0.13896362483501434\n",
      "epoch 13 loss: 0.08546005189418793\n",
      "epoch 14 loss: 0.09929236024618149\n",
      "epoch 15 loss: 0.07433603703975677\n",
      "epoch 16 loss: 0.09909680485725403\n",
      "epoch 17 loss: 0.0949721485376358\n",
      "epoch 18 loss: 0.10900301486253738\n",
      "epoch 19 loss: 0.08390485495328903\n",
      "epoch 20 loss: 0.08593221008777618\n",
      "epoch 21 loss: 0.0836055800318718\n",
      "epoch 22 loss: 0.0855768620967865\n",
      "epoch 23 loss: 0.09810543060302734\n",
      "epoch 24 loss: 0.1076260432600975\n",
      "epoch 25 loss: 0.09607188403606415\n",
      "epoch 26 loss: 0.06380078196525574\n",
      "epoch 27 loss: 0.08702321350574493\n",
      "epoch 28 loss: 0.07605577260255814\n",
      "epoch 29 loss: 0.09636542946100235\n",
      "epoch 30 loss: 0.08428793400526047\n",
      "36\n",
      "epoch 1 loss: 0.7440489530563354\n",
      "epoch 2 loss: 1.006884217262268\n",
      "epoch 3 loss: 0.398497611284256\n",
      "epoch 4 loss: 0.3037309944629669\n",
      "epoch 5 loss: 0.17774252593517303\n",
      "epoch 6 loss: 0.14425921440124512\n",
      "epoch 7 loss: 0.14954853057861328\n",
      "epoch 8 loss: 0.1694890409708023\n",
      "epoch 9 loss: 0.14941388368606567\n",
      "epoch 10 loss: 0.14646366238594055\n",
      "epoch 11 loss: 0.11725248396396637\n",
      "epoch 12 loss: 0.09422850608825684\n",
      "epoch 13 loss: 0.10605333000421524\n",
      "epoch 14 loss: 0.07984703779220581\n",
      "epoch 15 loss: 0.11726905405521393\n",
      "epoch 16 loss: 0.10800133645534515\n",
      "epoch 17 loss: 0.09685227274894714\n",
      "epoch 18 loss: 0.09773805737495422\n",
      "epoch 19 loss: 0.10953722149133682\n",
      "epoch 20 loss: 0.07590091973543167\n",
      "epoch 21 loss: 0.08975622802972794\n",
      "epoch 22 loss: 0.08261995762586594\n",
      "epoch 23 loss: 0.10736525058746338\n",
      "epoch 24 loss: 0.08731386810541153\n",
      "epoch 25 loss: 0.07936311513185501\n",
      "epoch 26 loss: 0.06565364450216293\n",
      "epoch 27 loss: 0.10047977417707443\n",
      "epoch 28 loss: 0.09034937620162964\n",
      "epoch 29 loss: 0.06668327003717422\n",
      "epoch 30 loss: 0.08694817870855331\n",
      "37\n",
      "epoch 1 loss: 0.7476205229759216\n",
      "epoch 2 loss: 0.45471036434173584\n",
      "epoch 3 loss: 0.3180089294910431\n",
      "epoch 4 loss: 0.20666611194610596\n",
      "epoch 5 loss: 0.1708204299211502\n",
      "epoch 6 loss: 0.12169259041547775\n",
      "epoch 7 loss: 0.13025057315826416\n",
      "epoch 8 loss: 0.10911809653043747\n",
      "epoch 9 loss: 0.09844794124364853\n",
      "epoch 10 loss: 0.10550063103437424\n",
      "epoch 11 loss: 0.11216621100902557\n",
      "epoch 12 loss: 0.12520642578601837\n",
      "epoch 13 loss: 0.08988949656486511\n",
      "epoch 14 loss: 0.07004321366548538\n",
      "epoch 15 loss: 0.0949668362736702\n",
      "epoch 16 loss: 0.0771927610039711\n",
      "epoch 17 loss: 0.09004808962345123\n",
      "epoch 18 loss: 0.11638922244310379\n",
      "epoch 19 loss: 0.08224427700042725\n",
      "epoch 20 loss: 0.08670477569103241\n",
      "epoch 21 loss: 0.06705529242753983\n",
      "epoch 22 loss: 0.07968483865261078\n",
      "epoch 23 loss: 0.08169367164373398\n",
      "epoch 24 loss: 0.07339468598365784\n",
      "epoch 25 loss: 0.07197540998458862\n",
      "epoch 26 loss: 0.09334563463926315\n",
      "epoch 27 loss: 0.057789355516433716\n",
      "epoch 28 loss: 0.07486051321029663\n",
      "epoch 29 loss: 0.0883263349533081\n",
      "epoch 30 loss: 0.07087667286396027\n",
      "38\n",
      "epoch 1 loss: 0.9417439103126526\n",
      "epoch 2 loss: 0.5719857215881348\n",
      "epoch 3 loss: 0.3123604953289032\n",
      "epoch 4 loss: 0.20737212896347046\n",
      "epoch 5 loss: 0.14949765801429749\n",
      "epoch 6 loss: 0.16280636191368103\n",
      "epoch 7 loss: 0.1323196440935135\n",
      "epoch 8 loss: 0.12814289331436157\n",
      "epoch 9 loss: 0.09526550024747849\n",
      "epoch 10 loss: 0.09610733389854431\n",
      "epoch 11 loss: 0.09287002682685852\n",
      "epoch 12 loss: 0.08612218499183655\n",
      "epoch 13 loss: 0.07382359355688095\n",
      "epoch 14 loss: 0.08449875563383102\n",
      "epoch 15 loss: 0.0867220014333725\n",
      "epoch 16 loss: 0.08950954675674438\n",
      "epoch 17 loss: 0.09374955296516418\n",
      "epoch 18 loss: 0.07720346748828888\n",
      "epoch 19 loss: 0.081543929874897\n",
      "epoch 20 loss: 0.09962239116430283\n",
      "epoch 21 loss: 0.0880032479763031\n",
      "epoch 22 loss: 0.07683424651622772\n",
      "epoch 23 loss: 0.06860814988613129\n",
      "epoch 24 loss: 0.06427879631519318\n",
      "epoch 25 loss: 0.07850807160139084\n",
      "epoch 26 loss: 0.07188504934310913\n",
      "epoch 27 loss: 0.05203432962298393\n",
      "epoch 28 loss: 0.07923630625009537\n",
      "epoch 29 loss: 0.06925325840711594\n",
      "epoch 30 loss: 0.09129711240530014\n",
      "39\n",
      "epoch 1 loss: 0.7493882775306702\n",
      "epoch 2 loss: 0.37499403953552246\n",
      "epoch 3 loss: 0.30087170004844666\n",
      "epoch 4 loss: 0.18724875152111053\n",
      "epoch 5 loss: 0.12766994535923004\n",
      "epoch 6 loss: 0.13420958817005157\n",
      "epoch 7 loss: 0.13952825963497162\n",
      "epoch 8 loss: 0.10413579642772675\n",
      "epoch 9 loss: 0.10627245157957077\n",
      "epoch 10 loss: 0.0960063710808754\n",
      "epoch 11 loss: 0.10609457641839981\n",
      "epoch 12 loss: 0.09176814556121826\n",
      "epoch 13 loss: 0.1031898483633995\n",
      "epoch 14 loss: 0.0900716483592987\n",
      "epoch 15 loss: 0.07220231741666794\n",
      "epoch 16 loss: 0.08518997579813004\n",
      "epoch 17 loss: 0.06936176121234894\n",
      "epoch 18 loss: 0.09376464784145355\n",
      "epoch 19 loss: 0.08304281532764435\n",
      "epoch 20 loss: 0.08825931698083878\n",
      "epoch 21 loss: 0.07026559114456177\n",
      "epoch 22 loss: 0.09965990483760834\n",
      "epoch 23 loss: 0.08094656467437744\n",
      "epoch 24 loss: 0.07102762907743454\n",
      "epoch 25 loss: 0.08074034005403519\n",
      "epoch 26 loss: 0.09022345393896103\n",
      "epoch 27 loss: 0.07848130166530609\n",
      "epoch 28 loss: 0.05491240322589874\n",
      "epoch 29 loss: 0.06956323981285095\n",
      "epoch 30 loss: 0.08112446218729019\n",
      "40\n",
      "epoch 1 loss: 0.5745798945426941\n",
      "epoch 2 loss: 0.505280613899231\n",
      "epoch 3 loss: 0.296191930770874\n",
      "epoch 4 loss: 0.1629268079996109\n",
      "epoch 5 loss: 0.147293820977211\n",
      "epoch 6 loss: 0.14698132872581482\n",
      "epoch 7 loss: 0.15261320769786835\n",
      "epoch 8 loss: 0.1311328262090683\n",
      "epoch 9 loss: 0.06860461831092834\n",
      "epoch 10 loss: 0.11219565570354462\n",
      "epoch 11 loss: 0.09608261287212372\n",
      "epoch 12 loss: 0.0997668132185936\n",
      "epoch 13 loss: 0.07971715927124023\n",
      "epoch 14 loss: 0.06186026334762573\n",
      "epoch 15 loss: 0.11906875669956207\n",
      "epoch 16 loss: 0.09354071319103241\n",
      "epoch 17 loss: 0.10336464643478394\n",
      "epoch 18 loss: 0.09570332616567612\n",
      "epoch 19 loss: 0.08492099493741989\n",
      "epoch 20 loss: 0.098516546189785\n",
      "epoch 21 loss: 0.09832336008548737\n",
      "epoch 22 loss: 0.07810530811548233\n",
      "epoch 23 loss: 0.07229635119438171\n",
      "epoch 24 loss: 0.06035550683736801\n",
      "epoch 25 loss: 0.09972818940877914\n",
      "epoch 26 loss: 0.06060583144426346\n",
      "epoch 27 loss: 0.0772639811038971\n",
      "epoch 28 loss: 0.07857710123062134\n",
      "epoch 29 loss: 0.09209035336971283\n",
      "epoch 30 loss: 0.08438000082969666\n",
      "41\n",
      "epoch 1 loss: 1.0808031558990479\n",
      "epoch 2 loss: 0.4612565040588379\n",
      "epoch 3 loss: 0.30887994170188904\n",
      "epoch 4 loss: 0.16547316312789917\n",
      "epoch 5 loss: 0.13567912578582764\n",
      "epoch 6 loss: 0.13450226187705994\n",
      "epoch 7 loss: 0.11605191230773926\n",
      "epoch 8 loss: 0.15053005516529083\n",
      "epoch 9 loss: 0.10189596563577652\n",
      "epoch 10 loss: 0.10660796612501144\n",
      "epoch 11 loss: 0.08877881616353989\n",
      "epoch 12 loss: 0.08711017668247223\n",
      "epoch 13 loss: 0.10791908204555511\n",
      "epoch 14 loss: 0.08991487324237823\n",
      "epoch 15 loss: 0.09813243895769119\n",
      "epoch 16 loss: 0.09318061172962189\n",
      "epoch 17 loss: 0.08214603364467621\n",
      "epoch 18 loss: 0.11244139075279236\n",
      "epoch 19 loss: 0.06821943074464798\n",
      "epoch 20 loss: 0.09522314369678497\n",
      "epoch 21 loss: 0.09225290268659592\n",
      "epoch 22 loss: 0.07678455114364624\n",
      "epoch 23 loss: 0.08540681004524231\n",
      "epoch 24 loss: 0.0900099128484726\n",
      "epoch 25 loss: 0.08869697898626328\n",
      "epoch 26 loss: 0.09881578385829926\n",
      "epoch 27 loss: 0.06981342285871506\n",
      "epoch 28 loss: 0.060721270740032196\n",
      "epoch 29 loss: 0.07264823466539383\n",
      "epoch 30 loss: 0.05881713330745697\n",
      "42\n",
      "epoch 1 loss: 0.7673906087875366\n",
      "epoch 2 loss: 0.4424690902233124\n",
      "epoch 3 loss: 0.2305726557970047\n",
      "epoch 4 loss: 0.1818428784608841\n",
      "epoch 5 loss: 0.1608741134405136\n",
      "epoch 6 loss: 0.14942042529582977\n",
      "epoch 7 loss: 0.15032212436199188\n",
      "epoch 8 loss: 0.1364906281232834\n",
      "epoch 9 loss: 0.10437219589948654\n",
      "epoch 10 loss: 0.12095136940479279\n",
      "epoch 11 loss: 0.1301266998052597\n",
      "epoch 12 loss: 0.1726050227880478\n",
      "epoch 13 loss: 0.08576428890228271\n",
      "epoch 14 loss: 0.1046605333685875\n",
      "epoch 15 loss: 0.07797478884458542\n",
      "epoch 16 loss: 0.10513897985219955\n",
      "epoch 17 loss: 0.07289466261863708\n",
      "epoch 18 loss: 0.09687785059213638\n",
      "epoch 19 loss: 0.07866346836090088\n",
      "epoch 20 loss: 0.08900178223848343\n",
      "epoch 21 loss: 0.07841355353593826\n",
      "epoch 22 loss: 0.0843612402677536\n",
      "epoch 23 loss: 0.08025442808866501\n",
      "epoch 24 loss: 0.09046804159879684\n",
      "epoch 25 loss: 0.07551537454128265\n",
      "epoch 26 loss: 0.08099202811717987\n",
      "epoch 27 loss: 0.07242106646299362\n",
      "epoch 28 loss: 0.084543377161026\n",
      "epoch 29 loss: 0.06957056373357773\n",
      "epoch 30 loss: 0.06498854607343674\n",
      "43\n",
      "epoch 1 loss: 0.7108256220817566\n",
      "epoch 2 loss: 0.6665396094322205\n",
      "epoch 3 loss: 0.42683443427085876\n",
      "epoch 4 loss: 0.22872556746006012\n",
      "epoch 5 loss: 0.14624257385730743\n",
      "epoch 6 loss: 0.14665238559246063\n",
      "epoch 7 loss: 0.12250563502311707\n",
      "epoch 8 loss: 0.1047341451048851\n",
      "epoch 9 loss: 0.11686421930789948\n",
      "epoch 10 loss: 0.148782879114151\n",
      "epoch 11 loss: 0.11203383654356003\n",
      "epoch 12 loss: 0.09888054430484772\n",
      "epoch 13 loss: 0.09584197402000427\n",
      "epoch 14 loss: 0.12363449484109879\n",
      "epoch 15 loss: 0.1734902560710907\n",
      "epoch 16 loss: 0.12178034335374832\n",
      "epoch 17 loss: 0.1126239150762558\n",
      "epoch 18 loss: 0.13501136004924774\n",
      "epoch 19 loss: 0.07039162516593933\n",
      "epoch 20 loss: 0.10457435995340347\n",
      "epoch 21 loss: 0.09801791608333588\n",
      "epoch 22 loss: 0.07733187824487686\n",
      "epoch 23 loss: 0.087541863322258\n",
      "epoch 24 loss: 0.09647645056247711\n",
      "epoch 25 loss: 0.09428823739290237\n",
      "epoch 26 loss: 0.1172737181186676\n",
      "epoch 27 loss: 0.1139201894402504\n",
      "epoch 28 loss: 0.07885439693927765\n",
      "epoch 29 loss: 0.07583357393741608\n",
      "epoch 30 loss: 0.08315353840589523\n",
      "44\n",
      "epoch 1 loss: 0.9001168608665466\n",
      "epoch 2 loss: 1.0430792570114136\n",
      "epoch 3 loss: 0.3695102334022522\n",
      "epoch 4 loss: 0.2443680614233017\n",
      "epoch 5 loss: 0.1442543864250183\n",
      "epoch 6 loss: 0.12856410443782806\n",
      "epoch 7 loss: 0.1149466261267662\n",
      "epoch 8 loss: 0.10867476463317871\n",
      "epoch 9 loss: 0.12694844603538513\n",
      "epoch 10 loss: 0.09322820603847504\n",
      "epoch 11 loss: 0.08964031934738159\n",
      "epoch 12 loss: 0.09579475224018097\n",
      "epoch 13 loss: 0.12656961381435394\n",
      "epoch 14 loss: 0.09011264890432358\n",
      "epoch 15 loss: 0.09837378561496735\n",
      "epoch 16 loss: 0.1270119845867157\n",
      "epoch 17 loss: 0.0916903018951416\n",
      "epoch 18 loss: 0.07093466818332672\n",
      "epoch 19 loss: 0.09988083690404892\n",
      "epoch 20 loss: 0.0823560506105423\n",
      "epoch 21 loss: 0.07485584169626236\n",
      "epoch 22 loss: 0.06772756576538086\n",
      "epoch 23 loss: 0.07390350848436356\n",
      "epoch 24 loss: 0.08423849940299988\n",
      "epoch 25 loss: 0.07823093980550766\n",
      "epoch 26 loss: 0.11475006490945816\n",
      "epoch 27 loss: 0.07225671410560608\n",
      "epoch 28 loss: 0.10432326048612595\n",
      "epoch 29 loss: 0.07823208719491959\n",
      "epoch 30 loss: 0.09323408454656601\n",
      "45\n",
      "epoch 1 loss: 0.7144736647605896\n",
      "epoch 2 loss: 0.4450472295284271\n",
      "epoch 3 loss: 0.5915613770484924\n",
      "epoch 4 loss: 0.27864256501197815\n",
      "epoch 5 loss: 0.1458849459886551\n",
      "epoch 6 loss: 0.14152786135673523\n",
      "epoch 7 loss: 0.15531153976917267\n",
      "epoch 8 loss: 0.11185616999864578\n",
      "epoch 9 loss: 0.0955791100859642\n",
      "epoch 10 loss: 0.09898187220096588\n",
      "epoch 11 loss: 0.11654926836490631\n",
      "epoch 12 loss: 0.10104437172412872\n",
      "epoch 13 loss: 0.10681448131799698\n",
      "epoch 14 loss: 0.08923204243183136\n",
      "epoch 15 loss: 0.10034283250570297\n",
      "epoch 16 loss: 0.07427617162466049\n",
      "epoch 17 loss: 0.09263060241937637\n",
      "epoch 18 loss: 0.09043514728546143\n",
      "epoch 19 loss: 0.0857698991894722\n",
      "epoch 20 loss: 0.07016794383525848\n",
      "epoch 21 loss: 0.06690829247236252\n",
      "epoch 22 loss: 0.07443179935216904\n",
      "epoch 23 loss: 0.08033253252506256\n",
      "epoch 24 loss: 0.07870150357484818\n",
      "epoch 25 loss: 0.08515550941228867\n",
      "epoch 26 loss: 0.09106682986021042\n",
      "epoch 27 loss: 0.07627354562282562\n",
      "epoch 28 loss: 0.07207545638084412\n",
      "epoch 29 loss: 0.06732812523841858\n",
      "epoch 30 loss: 0.09006617963314056\n",
      "46\n",
      "epoch 1 loss: 0.7735239267349243\n",
      "epoch 2 loss: 0.6972591280937195\n",
      "epoch 3 loss: 0.4560439884662628\n",
      "epoch 4 loss: 0.1483955830335617\n",
      "epoch 5 loss: 0.15520402789115906\n",
      "epoch 6 loss: 0.16986578702926636\n",
      "epoch 7 loss: 0.12195595353841782\n",
      "epoch 8 loss: 0.1224486231803894\n",
      "epoch 9 loss: 0.09049464762210846\n",
      "epoch 10 loss: 0.10504455119371414\n",
      "epoch 11 loss: 0.10374587029218674\n",
      "epoch 12 loss: 0.08434659242630005\n",
      "epoch 13 loss: 0.08171222358942032\n",
      "epoch 14 loss: 0.09339785575866699\n",
      "epoch 15 loss: 0.08480912446975708\n",
      "epoch 16 loss: 0.09518183022737503\n",
      "epoch 17 loss: 0.11074865609407425\n",
      "epoch 18 loss: 0.07790760695934296\n",
      "epoch 19 loss: 0.09536433219909668\n",
      "epoch 20 loss: 0.08836228400468826\n",
      "epoch 21 loss: 0.07659251242876053\n",
      "epoch 22 loss: 0.08452040702104568\n",
      "epoch 23 loss: 0.09230472892522812\n",
      "epoch 24 loss: 0.06450057029724121\n",
      "epoch 25 loss: 0.066165991127491\n",
      "epoch 26 loss: 0.09989095479249954\n",
      "epoch 27 loss: 0.06643646210432053\n",
      "epoch 28 loss: 0.07691848278045654\n",
      "epoch 29 loss: 0.08165983110666275\n",
      "epoch 30 loss: 0.09534267336130142\n",
      "47\n",
      "epoch 1 loss: 0.8548861742019653\n",
      "epoch 2 loss: 0.6069401502609253\n",
      "epoch 3 loss: 0.31104472279548645\n",
      "epoch 4 loss: 0.23291675746440887\n",
      "epoch 5 loss: 0.16792190074920654\n",
      "epoch 6 loss: 0.1476755142211914\n",
      "epoch 7 loss: 0.15987636148929596\n",
      "epoch 8 loss: 0.1001918762922287\n",
      "epoch 9 loss: 0.11865095049142838\n",
      "epoch 10 loss: 0.14533346891403198\n",
      "epoch 11 loss: 0.10494091361761093\n",
      "epoch 12 loss: 0.11955977231264114\n",
      "epoch 13 loss: 0.10895451158285141\n",
      "epoch 14 loss: 0.06597612798213959\n",
      "epoch 15 loss: 0.07769178599119186\n",
      "epoch 16 loss: 0.10949347168207169\n",
      "epoch 17 loss: 0.08562611043453217\n",
      "epoch 18 loss: 0.09825970232486725\n",
      "epoch 19 loss: 0.06658295542001724\n",
      "epoch 20 loss: 0.07198010385036469\n",
      "epoch 21 loss: 0.08507072925567627\n",
      "epoch 22 loss: 0.07034092396497726\n",
      "epoch 23 loss: 0.07679248601198196\n",
      "epoch 24 loss: 0.09454703330993652\n",
      "epoch 25 loss: 0.09437759965658188\n",
      "epoch 26 loss: 0.07788414508104324\n",
      "epoch 27 loss: 0.0829082727432251\n",
      "epoch 28 loss: 0.08435436338186264\n",
      "epoch 29 loss: 0.08073312789201736\n",
      "epoch 30 loss: 0.06683631241321564\n",
      "48\n",
      "epoch 1 loss: 0.7067262530326843\n",
      "epoch 2 loss: 0.5050990581512451\n",
      "epoch 3 loss: 0.2215006798505783\n",
      "epoch 4 loss: 0.18564492464065552\n",
      "epoch 5 loss: 0.16926147043704987\n",
      "epoch 6 loss: 0.1514754295349121\n",
      "epoch 7 loss: 0.14683885872364044\n",
      "epoch 8 loss: 0.1335047483444214\n",
      "epoch 9 loss: 0.12390065938234329\n",
      "epoch 10 loss: 0.08972696959972382\n",
      "epoch 11 loss: 0.07666164636611938\n",
      "epoch 12 loss: 0.09505005925893784\n",
      "epoch 13 loss: 0.09665032476186752\n",
      "epoch 14 loss: 0.08736178278923035\n",
      "epoch 15 loss: 0.08755944669246674\n",
      "epoch 16 loss: 0.08966746181249619\n",
      "epoch 17 loss: 0.10136667639017105\n",
      "epoch 18 loss: 0.08810848742723465\n",
      "epoch 19 loss: 0.07064277678728104\n",
      "epoch 20 loss: 0.10024406015872955\n",
      "epoch 21 loss: 0.09982000291347504\n",
      "epoch 22 loss: 0.08901342004537582\n",
      "epoch 23 loss: 0.09005829691886902\n",
      "epoch 24 loss: 0.09239180386066437\n",
      "epoch 25 loss: 0.07731176167726517\n",
      "epoch 26 loss: 0.08800391852855682\n",
      "epoch 27 loss: 0.06788966804742813\n",
      "epoch 28 loss: 0.0861678272485733\n",
      "epoch 29 loss: 0.07858983427286148\n",
      "epoch 30 loss: 0.07720737904310226\n",
      "49\n",
      "epoch 1 loss: 0.8480837345123291\n",
      "epoch 2 loss: 0.3609890043735504\n",
      "epoch 3 loss: 0.2772883474826813\n",
      "epoch 4 loss: 0.20347850024700165\n",
      "epoch 5 loss: 0.1678730547428131\n",
      "epoch 6 loss: 0.16214807331562042\n",
      "epoch 7 loss: 0.1350373923778534\n",
      "epoch 8 loss: 0.11589944362640381\n",
      "epoch 9 loss: 0.10921282321214676\n",
      "epoch 10 loss: 0.11694156378507614\n",
      "epoch 11 loss: 0.08685530722141266\n",
      "epoch 12 loss: 0.10218804329633713\n",
      "epoch 13 loss: 0.08137837052345276\n",
      "epoch 14 loss: 0.09456935524940491\n",
      "epoch 15 loss: 0.09662231802940369\n",
      "epoch 16 loss: 0.08134636282920837\n",
      "epoch 17 loss: 0.10301404446363449\n",
      "epoch 18 loss: 0.06624356657266617\n",
      "epoch 19 loss: 0.08013782650232315\n",
      "epoch 20 loss: 0.08716551959514618\n",
      "epoch 21 loss: 0.08452320843935013\n",
      "epoch 22 loss: 0.06953942030668259\n",
      "epoch 23 loss: 0.08672764897346497\n",
      "epoch 24 loss: 0.0829518660902977\n",
      "epoch 25 loss: 0.09047247469425201\n",
      "epoch 26 loss: 0.0784667506814003\n",
      "epoch 27 loss: 0.06091507151722908\n",
      "epoch 28 loss: 0.07092352211475372\n",
      "epoch 29 loss: 0.069209985435009\n",
      "epoch 30 loss: 0.05864492803812027\n",
      "50\n",
      "epoch 1 loss: 0.7433770298957825\n",
      "epoch 2 loss: 0.621881902217865\n",
      "epoch 3 loss: 0.27040916681289673\n",
      "epoch 4 loss: 0.1521037369966507\n",
      "epoch 5 loss: 0.1909298449754715\n",
      "epoch 6 loss: 0.16836263239383698\n",
      "epoch 7 loss: 0.11034221202135086\n",
      "epoch 8 loss: 0.112990602850914\n",
      "epoch 9 loss: 0.14087799191474915\n",
      "epoch 10 loss: 0.08908089250326157\n",
      "epoch 11 loss: 0.11024491488933563\n",
      "epoch 12 loss: 0.08095469325780869\n",
      "epoch 13 loss: 0.0963749811053276\n",
      "epoch 14 loss: 0.08182045817375183\n",
      "epoch 15 loss: 0.08766672760248184\n",
      "epoch 16 loss: 0.11568265408277512\n",
      "epoch 17 loss: 0.10061924904584885\n",
      "epoch 18 loss: 0.08966656774282455\n",
      "epoch 19 loss: 0.09534397721290588\n",
      "epoch 20 loss: 0.09320373088121414\n",
      "epoch 21 loss: 0.08367703855037689\n",
      "epoch 22 loss: 0.08354654908180237\n",
      "epoch 23 loss: 0.06549742072820663\n",
      "epoch 24 loss: 0.09873402118682861\n",
      "epoch 25 loss: 0.065269835293293\n",
      "epoch 26 loss: 0.07220349460840225\n",
      "epoch 27 loss: 0.07149746268987656\n",
      "epoch 28 loss: 0.08292564749717712\n",
      "epoch 29 loss: 0.08569759130477905\n",
      "epoch 30 loss: 0.06503956019878387\n",
      "51\n",
      "epoch 1 loss: 1.0056782960891724\n",
      "epoch 2 loss: 0.6718695759773254\n",
      "epoch 3 loss: 0.3730505704879761\n",
      "epoch 4 loss: 0.21305163204669952\n",
      "epoch 5 loss: 0.16472676396369934\n",
      "epoch 6 loss: 0.1562250256538391\n",
      "epoch 7 loss: 0.12076918035745621\n",
      "epoch 8 loss: 0.1417860984802246\n",
      "epoch 9 loss: 0.10823652893304825\n",
      "epoch 10 loss: 0.1003686934709549\n",
      "epoch 11 loss: 0.08533744513988495\n",
      "epoch 12 loss: 0.08048942685127258\n",
      "epoch 13 loss: 0.12135324627161026\n",
      "epoch 14 loss: 0.07462778687477112\n",
      "epoch 15 loss: 0.09098447114229202\n",
      "epoch 16 loss: 0.11494387686252594\n",
      "epoch 17 loss: 0.09356149286031723\n",
      "epoch 18 loss: 0.07399653643369675\n",
      "epoch 19 loss: 0.0723438486456871\n",
      "epoch 20 loss: 0.07427208125591278\n",
      "epoch 21 loss: 0.09595169872045517\n",
      "epoch 22 loss: 0.08730874955654144\n",
      "epoch 23 loss: 0.06518588215112686\n",
      "epoch 24 loss: 0.09246163070201874\n",
      "epoch 25 loss: 0.10622954368591309\n",
      "epoch 26 loss: 0.07704659551382065\n",
      "epoch 27 loss: 0.0557527132332325\n",
      "epoch 28 loss: 0.08031599968671799\n",
      "epoch 29 loss: 0.05630069226026535\n",
      "epoch 30 loss: 0.06893184036016464\n",
      "52\n",
      "epoch 1 loss: 1.030415415763855\n",
      "epoch 2 loss: 0.54545658826828\n",
      "epoch 3 loss: 0.42025473713874817\n",
      "epoch 4 loss: 0.15112115442752838\n",
      "epoch 5 loss: 0.13540495932102203\n",
      "epoch 6 loss: 0.1429131180047989\n",
      "epoch 7 loss: 0.13084179162979126\n",
      "epoch 8 loss: 0.07630207389593124\n",
      "epoch 9 loss: 0.12287526577711105\n",
      "epoch 10 loss: 0.12029363214969635\n",
      "epoch 11 loss: 0.12900108098983765\n",
      "epoch 12 loss: 0.10630451887845993\n",
      "epoch 13 loss: 0.09429354220628738\n",
      "epoch 14 loss: 0.10761262476444244\n",
      "epoch 15 loss: 0.10373088717460632\n",
      "epoch 16 loss: 0.08033476024866104\n",
      "epoch 17 loss: 0.08277877420186996\n",
      "epoch 18 loss: 0.07815972715616226\n",
      "epoch 19 loss: 0.08111496269702911\n",
      "epoch 20 loss: 0.0873434990644455\n",
      "epoch 21 loss: 0.08229614794254303\n",
      "epoch 22 loss: 0.08276700228452682\n",
      "epoch 23 loss: 0.08424840122461319\n",
      "epoch 24 loss: 0.10487856715917587\n",
      "epoch 25 loss: 0.07120941579341888\n",
      "epoch 26 loss: 0.06714580208063126\n",
      "epoch 27 loss: 0.09026277810335159\n",
      "epoch 28 loss: 0.07906260341405869\n",
      "epoch 29 loss: 0.06858247518539429\n",
      "epoch 30 loss: 0.07898502051830292\n",
      "53\n",
      "epoch 1 loss: 0.7054913640022278\n",
      "epoch 2 loss: 0.6697239875793457\n",
      "epoch 3 loss: 0.37738746404647827\n",
      "epoch 4 loss: 0.1962791085243225\n",
      "epoch 5 loss: 0.15181854367256165\n",
      "epoch 6 loss: 0.1192798987030983\n",
      "epoch 7 loss: 0.12466827034950256\n",
      "epoch 8 loss: 0.1263817846775055\n",
      "epoch 9 loss: 0.15504422783851624\n",
      "epoch 10 loss: 0.11608292162418365\n",
      "epoch 11 loss: 0.10393322259187698\n",
      "epoch 12 loss: 0.07818849384784698\n",
      "epoch 13 loss: 0.12184730917215347\n",
      "epoch 14 loss: 0.09109123051166534\n",
      "epoch 15 loss: 0.1216336265206337\n",
      "epoch 16 loss: 0.08075185120105743\n",
      "epoch 17 loss: 0.09482748806476593\n",
      "epoch 18 loss: 0.09930846095085144\n",
      "epoch 19 loss: 0.10519436001777649\n",
      "epoch 20 loss: 0.10230819135904312\n",
      "epoch 21 loss: 0.08005690574645996\n",
      "epoch 22 loss: 0.09104351699352264\n",
      "epoch 23 loss: 0.08777894079685211\n",
      "epoch 24 loss: 0.0845634862780571\n",
      "epoch 25 loss: 0.09691991657018661\n",
      "epoch 26 loss: 0.06774188578128815\n",
      "epoch 27 loss: 0.09089986979961395\n",
      "epoch 28 loss: 0.09523706883192062\n",
      "epoch 29 loss: 0.06763080507516861\n",
      "epoch 30 loss: 0.0882192999124527\n",
      "54\n",
      "epoch 1 loss: 0.9005604386329651\n",
      "epoch 2 loss: 0.6643286943435669\n",
      "epoch 3 loss: 0.3349614441394806\n",
      "epoch 4 loss: 0.2352864295244217\n",
      "epoch 5 loss: 0.16783703863620758\n",
      "epoch 6 loss: 0.13424408435821533\n",
      "epoch 7 loss: 0.1351054608821869\n",
      "epoch 8 loss: 0.12826068699359894\n",
      "epoch 9 loss: 0.09092516452074051\n",
      "epoch 10 loss: 0.11453554779291153\n",
      "epoch 11 loss: 0.12116585671901703\n",
      "epoch 12 loss: 0.0820237323641777\n",
      "epoch 13 loss: 0.11005444824695587\n",
      "epoch 14 loss: 0.08454225212335587\n",
      "epoch 15 loss: 0.09333645552396774\n",
      "epoch 16 loss: 0.14902222156524658\n",
      "epoch 17 loss: 0.07191012054681778\n",
      "epoch 18 loss: 0.08589913696050644\n",
      "epoch 19 loss: 0.11560247838497162\n",
      "epoch 20 loss: 0.07248596101999283\n",
      "epoch 21 loss: 0.06560228765010834\n",
      "epoch 22 loss: 0.08901003748178482\n",
      "epoch 23 loss: 0.06592673063278198\n",
      "epoch 24 loss: 0.0684368833899498\n",
      "epoch 25 loss: 0.05784236267209053\n",
      "epoch 26 loss: 0.09164828807115555\n",
      "epoch 27 loss: 0.07440045475959778\n",
      "epoch 28 loss: 0.0690712034702301\n",
      "epoch 29 loss: 0.0646870881319046\n",
      "epoch 30 loss: 0.06560272723436356\n",
      "55\n",
      "epoch 1 loss: 0.7877946496009827\n",
      "epoch 2 loss: 0.4224297106266022\n",
      "epoch 3 loss: 0.19829636812210083\n",
      "epoch 4 loss: 0.14425353705883026\n",
      "epoch 5 loss: 0.15196068584918976\n",
      "epoch 6 loss: 0.13976836204528809\n",
      "epoch 7 loss: 0.12344952672719955\n",
      "epoch 8 loss: 0.10777026414871216\n",
      "epoch 9 loss: 0.09738431870937347\n",
      "epoch 10 loss: 0.1212809830904007\n",
      "epoch 11 loss: 0.08450078964233398\n",
      "epoch 12 loss: 0.10524832457304001\n",
      "epoch 13 loss: 0.0920514166355133\n",
      "epoch 14 loss: 0.08334598690271378\n",
      "epoch 15 loss: 0.09184782952070236\n",
      "epoch 16 loss: 0.11543577164411545\n",
      "epoch 17 loss: 0.06685929745435715\n",
      "epoch 18 loss: 0.08835846185684204\n",
      "epoch 19 loss: 0.08887651562690735\n",
      "epoch 20 loss: 0.08202996850013733\n",
      "epoch 21 loss: 0.07448945939540863\n",
      "epoch 22 loss: 0.07375320792198181\n",
      "epoch 23 loss: 0.07612385600805283\n",
      "epoch 24 loss: 0.08138873428106308\n",
      "epoch 25 loss: 0.07686680555343628\n",
      "epoch 26 loss: 0.05852338299155235\n",
      "epoch 27 loss: 0.059578824788331985\n",
      "epoch 28 loss: 0.06417032331228256\n",
      "epoch 29 loss: 0.0608070008456707\n",
      "epoch 30 loss: 0.062318719923496246\n",
      "56\n",
      "epoch 1 loss: 0.9907808303833008\n",
      "epoch 2 loss: 0.7462966442108154\n",
      "epoch 3 loss: 0.3374718129634857\n",
      "epoch 4 loss: 0.1989300549030304\n",
      "epoch 5 loss: 0.1671960949897766\n",
      "epoch 6 loss: 0.16031624376773834\n",
      "epoch 7 loss: 0.15733477473258972\n",
      "epoch 8 loss: 0.13113649189472198\n",
      "epoch 9 loss: 0.16034843027591705\n",
      "epoch 10 loss: 0.11677857488393784\n",
      "epoch 11 loss: 0.1059606671333313\n",
      "epoch 12 loss: 0.13190701603889465\n",
      "epoch 13 loss: 0.08919274061918259\n",
      "epoch 14 loss: 0.08069039136171341\n",
      "epoch 15 loss: 0.07824097573757172\n",
      "epoch 16 loss: 0.07081183046102524\n",
      "epoch 17 loss: 0.1009342148900032\n",
      "epoch 18 loss: 0.0794423371553421\n",
      "epoch 19 loss: 0.10838006436824799\n",
      "epoch 20 loss: 0.09390918165445328\n",
      "epoch 21 loss: 0.07444240897893906\n",
      "epoch 22 loss: 0.08102384954690933\n",
      "epoch 23 loss: 0.09920327365398407\n",
      "epoch 24 loss: 0.08036063611507416\n",
      "epoch 25 loss: 0.1023806557059288\n",
      "epoch 26 loss: 0.08965983241796494\n",
      "epoch 27 loss: 0.07034452259540558\n",
      "epoch 28 loss: 0.08305978775024414\n",
      "epoch 29 loss: 0.07784467190504074\n",
      "epoch 30 loss: 0.08311836421489716\n",
      "57\n",
      "epoch 1 loss: 1.0174120664596558\n",
      "epoch 2 loss: 0.5552690625190735\n",
      "epoch 3 loss: 0.28759658336639404\n",
      "epoch 4 loss: 0.2048233151435852\n",
      "epoch 5 loss: 0.17584505677223206\n",
      "epoch 6 loss: 0.14486177265644073\n",
      "epoch 7 loss: 0.12965697050094604\n",
      "epoch 8 loss: 0.12064768373966217\n",
      "epoch 9 loss: 0.12955030798912048\n",
      "epoch 10 loss: 0.11444315314292908\n",
      "epoch 11 loss: 0.09568159282207489\n",
      "epoch 12 loss: 0.11519093811511993\n",
      "epoch 13 loss: 0.09810319542884827\n",
      "epoch 14 loss: 0.12728489935398102\n",
      "epoch 15 loss: 0.08048208057880402\n",
      "epoch 16 loss: 0.10747546702623367\n",
      "epoch 17 loss: 0.10944505035877228\n",
      "epoch 18 loss: 0.098690465092659\n",
      "epoch 19 loss: 0.10305389016866684\n",
      "epoch 20 loss: 0.08482322841882706\n",
      "epoch 21 loss: 0.07895872741937637\n",
      "epoch 22 loss: 0.08430415391921997\n",
      "epoch 23 loss: 0.06964695453643799\n",
      "epoch 24 loss: 0.07639699429273605\n",
      "epoch 25 loss: 0.09012353420257568\n",
      "epoch 26 loss: 0.07201515883207321\n",
      "epoch 27 loss: 0.06877734512090683\n",
      "epoch 28 loss: 0.08334280550479889\n",
      "epoch 29 loss: 0.07295383512973785\n",
      "epoch 30 loss: 0.09201490134000778\n",
      "58\n",
      "epoch 1 loss: 0.5333589911460876\n",
      "epoch 2 loss: 0.3826669454574585\n",
      "epoch 3 loss: 0.33115527033805847\n",
      "epoch 4 loss: 0.16885770857334137\n",
      "epoch 5 loss: 0.12660640478134155\n",
      "epoch 6 loss: 0.16934023797512054\n",
      "epoch 7 loss: 0.12206672877073288\n",
      "epoch 8 loss: 0.1065082922577858\n",
      "epoch 9 loss: 0.128932386636734\n",
      "epoch 10 loss: 0.1143726259469986\n",
      "epoch 11 loss: 0.09365692734718323\n",
      "epoch 12 loss: 0.08617011457681656\n",
      "epoch 13 loss: 0.07319680601358414\n",
      "epoch 14 loss: 0.09043029695749283\n",
      "epoch 15 loss: 0.09089003503322601\n",
      "epoch 16 loss: 0.06631118804216385\n",
      "epoch 17 loss: 0.09225479513406754\n",
      "epoch 18 loss: 0.07977738976478577\n",
      "epoch 19 loss: 0.08151719719171524\n",
      "epoch 20 loss: 0.08472470194101334\n",
      "epoch 21 loss: 0.08845311403274536\n",
      "epoch 22 loss: 0.11189600825309753\n",
      "epoch 23 loss: 0.07245811074972153\n",
      "epoch 24 loss: 0.08176625519990921\n",
      "epoch 25 loss: 0.13077479600906372\n",
      "epoch 26 loss: 0.09016020596027374\n",
      "epoch 27 loss: 0.09103283286094666\n",
      "epoch 28 loss: 0.08324040472507477\n",
      "epoch 29 loss: 0.08345276117324829\n",
      "epoch 30 loss: 0.06097118929028511\n",
      "59\n",
      "epoch 1 loss: 0.5741603970527649\n",
      "epoch 2 loss: 0.4609006643295288\n",
      "epoch 3 loss: 0.26996660232543945\n",
      "epoch 4 loss: 0.21057121455669403\n",
      "epoch 5 loss: 0.17044903337955475\n",
      "epoch 6 loss: 0.1161857321858406\n",
      "epoch 7 loss: 0.21236459910869598\n",
      "epoch 8 loss: 0.10879257321357727\n",
      "epoch 9 loss: 0.07883184403181076\n",
      "epoch 10 loss: 0.08478155732154846\n",
      "epoch 11 loss: 0.08638779073953629\n",
      "epoch 12 loss: 0.09555651992559433\n",
      "epoch 13 loss: 0.0573035292327404\n",
      "epoch 14 loss: 0.09720411151647568\n",
      "epoch 15 loss: 0.10852305591106415\n",
      "epoch 16 loss: 0.10288272053003311\n",
      "epoch 17 loss: 0.0981782078742981\n",
      "epoch 18 loss: 0.08495277166366577\n",
      "epoch 19 loss: 0.08006863296031952\n",
      "epoch 20 loss: 0.09561148285865784\n",
      "epoch 21 loss: 0.0822315365076065\n",
      "epoch 22 loss: 0.06623939424753189\n",
      "epoch 23 loss: 0.09265848994255066\n",
      "epoch 24 loss: 0.08352752774953842\n",
      "epoch 25 loss: 0.07799901813268661\n",
      "epoch 26 loss: 0.09712708741426468\n",
      "epoch 27 loss: 0.08057278394699097\n",
      "epoch 28 loss: 0.08463598042726517\n",
      "epoch 29 loss: 0.08038672804832458\n",
      "epoch 30 loss: 0.0688018947839737\n",
      "60\n",
      "epoch 1 loss: 0.8505595922470093\n",
      "epoch 2 loss: 0.5493314266204834\n",
      "epoch 3 loss: 0.2562713623046875\n",
      "epoch 4 loss: 0.16435210406780243\n",
      "epoch 5 loss: 0.1458558291196823\n",
      "epoch 6 loss: 0.14449720084667206\n",
      "epoch 7 loss: 0.10563699901103973\n",
      "epoch 8 loss: 0.08960895240306854\n",
      "epoch 9 loss: 0.0936674177646637\n",
      "epoch 10 loss: 0.10176680237054825\n",
      "epoch 11 loss: 0.08806464821100235\n",
      "epoch 12 loss: 0.07311905920505524\n",
      "epoch 13 loss: 0.08068067580461502\n",
      "epoch 14 loss: 0.08986079692840576\n",
      "epoch 15 loss: 0.09111515432596207\n",
      "epoch 16 loss: 0.08210527896881104\n",
      "epoch 17 loss: 0.0856005921959877\n",
      "epoch 18 loss: 0.09686928987503052\n",
      "epoch 19 loss: 0.07817386090755463\n",
      "epoch 20 loss: 0.11901595443487167\n",
      "epoch 21 loss: 0.09863713383674622\n",
      "epoch 22 loss: 0.12366177141666412\n",
      "epoch 23 loss: 0.07936976850032806\n",
      "epoch 24 loss: 0.0675530806183815\n",
      "epoch 25 loss: 0.08675584942102432\n",
      "epoch 26 loss: 0.08988189697265625\n",
      "epoch 27 loss: 0.06733912974596024\n",
      "epoch 28 loss: 0.06266893446445465\n",
      "epoch 29 loss: 0.07108005881309509\n",
      "epoch 30 loss: 0.0840596854686737\n",
      "61\n",
      "epoch 1 loss: 0.9335463047027588\n",
      "epoch 2 loss: 0.45786812901496887\n",
      "epoch 3 loss: 0.28847959637641907\n",
      "epoch 4 loss: 0.20222222805023193\n",
      "epoch 5 loss: 0.1272055059671402\n",
      "epoch 6 loss: 0.12153895944356918\n",
      "epoch 7 loss: 0.09431851655244827\n",
      "epoch 8 loss: 0.134281724691391\n",
      "epoch 9 loss: 0.12414804100990295\n",
      "epoch 10 loss: 0.13853172957897186\n",
      "epoch 11 loss: 0.08251562714576721\n",
      "epoch 12 loss: 0.09322204440832138\n",
      "epoch 13 loss: 0.08727887272834778\n",
      "epoch 14 loss: 0.08785958588123322\n",
      "epoch 15 loss: 0.10131216794252396\n",
      "epoch 16 loss: 0.09850646555423737\n",
      "epoch 17 loss: 0.08832621574401855\n",
      "epoch 18 loss: 0.10005290061235428\n",
      "epoch 19 loss: 0.07414086908102036\n",
      "epoch 20 loss: 0.07819586247205734\n",
      "epoch 21 loss: 0.11289644986391068\n",
      "epoch 22 loss: 0.07121729850769043\n",
      "epoch 23 loss: 0.08199132233858109\n",
      "epoch 24 loss: 0.05865307152271271\n",
      "epoch 25 loss: 0.1261870563030243\n",
      "epoch 26 loss: 0.08877333253622055\n",
      "epoch 27 loss: 0.07858104258775711\n",
      "epoch 28 loss: 0.07475567609071732\n",
      "epoch 29 loss: 0.09303981065750122\n",
      "epoch 30 loss: 0.07605958729982376\n",
      "62\n",
      "epoch 1 loss: 0.6913951635360718\n",
      "epoch 2 loss: 0.6872440576553345\n",
      "epoch 3 loss: 0.31423497200012207\n",
      "epoch 4 loss: 0.1783575564622879\n",
      "epoch 5 loss: 0.15036942064762115\n",
      "epoch 6 loss: 0.14754581451416016\n",
      "epoch 7 loss: 0.14967377483844757\n",
      "epoch 8 loss: 0.14791496098041534\n",
      "epoch 9 loss: 0.16389544308185577\n",
      "epoch 10 loss: 0.11621749401092529\n",
      "epoch 11 loss: 0.12162533402442932\n",
      "epoch 12 loss: 0.11441316455602646\n",
      "epoch 13 loss: 0.11297739297151566\n",
      "epoch 14 loss: 0.12342877686023712\n",
      "epoch 15 loss: 0.08364072442054749\n",
      "epoch 16 loss: 0.10491982102394104\n",
      "epoch 17 loss: 0.08882064372301102\n",
      "epoch 18 loss: 0.08360449224710464\n",
      "epoch 19 loss: 0.06484142690896988\n",
      "epoch 20 loss: 0.08648768067359924\n",
      "epoch 21 loss: 0.08594822138547897\n",
      "epoch 22 loss: 0.08722621947526932\n",
      "epoch 23 loss: 0.08104220032691956\n",
      "epoch 24 loss: 0.08821605890989304\n",
      "epoch 25 loss: 0.06906184554100037\n",
      "epoch 26 loss: 0.07078570872545242\n",
      "epoch 27 loss: 0.1010294184088707\n",
      "epoch 28 loss: 0.0713716596364975\n",
      "epoch 29 loss: 0.08172693848609924\n",
      "epoch 30 loss: 0.08638426661491394\n",
      "63\n",
      "epoch 1 loss: 0.7907230854034424\n",
      "epoch 2 loss: 0.46390122175216675\n",
      "epoch 3 loss: 0.22828789055347443\n",
      "epoch 4 loss: 0.1632198542356491\n",
      "epoch 5 loss: 0.13861171901226044\n",
      "epoch 6 loss: 0.1287480890750885\n",
      "epoch 7 loss: 0.09824703633785248\n",
      "epoch 8 loss: 0.08752420544624329\n",
      "epoch 9 loss: 0.13288432359695435\n",
      "epoch 10 loss: 0.08047270029783249\n",
      "epoch 11 loss: 0.08246396481990814\n",
      "epoch 12 loss: 0.1650480479001999\n",
      "epoch 13 loss: 0.1060190424323082\n",
      "epoch 14 loss: 0.09140884131193161\n",
      "epoch 15 loss: 0.09875591844320297\n",
      "epoch 16 loss: 0.09253184497356415\n",
      "epoch 17 loss: 0.07509110867977142\n",
      "epoch 18 loss: 0.10916467756032944\n",
      "epoch 19 loss: 0.08538862317800522\n",
      "epoch 20 loss: 0.06826845556497574\n",
      "epoch 21 loss: 0.09125203639268875\n",
      "epoch 22 loss: 0.09198275208473206\n",
      "epoch 23 loss: 0.09103143960237503\n",
      "epoch 24 loss: 0.11420052498579025\n",
      "epoch 25 loss: 0.08633860945701599\n",
      "epoch 26 loss: 0.0824153870344162\n",
      "epoch 27 loss: 0.08938264846801758\n",
      "epoch 28 loss: 0.0942864939570427\n",
      "epoch 29 loss: 0.06600089371204376\n",
      "epoch 30 loss: 0.07184166461229324\n",
      "64\n",
      "epoch 1 loss: 0.950564980506897\n",
      "epoch 2 loss: 0.7136293649673462\n",
      "epoch 3 loss: 0.38610145449638367\n",
      "epoch 4 loss: 0.2524269223213196\n",
      "epoch 5 loss: 0.1559295356273651\n",
      "epoch 6 loss: 0.14231173694133759\n",
      "epoch 7 loss: 0.12301918119192123\n",
      "epoch 8 loss: 0.1274259239435196\n",
      "epoch 9 loss: 0.11705532670021057\n",
      "epoch 10 loss: 0.1111965999007225\n",
      "epoch 11 loss: 0.09227588027715683\n",
      "epoch 12 loss: 0.12550099194049835\n",
      "epoch 13 loss: 0.09943616390228271\n",
      "epoch 14 loss: 0.08680156618356705\n",
      "epoch 15 loss: 0.07289900630712509\n",
      "epoch 16 loss: 0.07997475564479828\n",
      "epoch 17 loss: 0.07168819010257721\n",
      "epoch 18 loss: 0.06638101488351822\n",
      "epoch 19 loss: 0.07821422815322876\n",
      "epoch 20 loss: 0.07144348323345184\n",
      "epoch 21 loss: 0.09052293747663498\n",
      "epoch 22 loss: 0.09889930486679077\n",
      "epoch 23 loss: 0.11413487792015076\n",
      "epoch 24 loss: 0.07059778273105621\n",
      "epoch 25 loss: 0.0805889219045639\n",
      "epoch 26 loss: 0.0802171528339386\n",
      "epoch 27 loss: 0.08370034396648407\n",
      "epoch 28 loss: 0.07531760632991791\n",
      "epoch 29 loss: 0.07270029932260513\n",
      "epoch 30 loss: 0.07411990314722061\n",
      "65\n",
      "epoch 1 loss: 0.7479158639907837\n",
      "epoch 2 loss: 0.6142529845237732\n",
      "epoch 3 loss: 0.37859225273132324\n",
      "epoch 4 loss: 0.2188996821641922\n",
      "epoch 5 loss: 0.19966872036457062\n",
      "epoch 6 loss: 0.15587720274925232\n",
      "epoch 7 loss: 0.1192757859826088\n",
      "epoch 8 loss: 0.13348472118377686\n",
      "epoch 9 loss: 0.11906571686267853\n",
      "epoch 10 loss: 0.09264698624610901\n",
      "epoch 11 loss: 0.08140623569488525\n",
      "epoch 12 loss: 0.09218629449605942\n",
      "epoch 13 loss: 0.11067110300064087\n",
      "epoch 14 loss: 0.09954430162906647\n",
      "epoch 15 loss: 0.08162392675876617\n",
      "epoch 16 loss: 0.098460353910923\n",
      "epoch 17 loss: 0.09507372230291367\n",
      "epoch 18 loss: 0.08968769758939743\n",
      "epoch 19 loss: 0.08844567090272903\n",
      "epoch 20 loss: 0.08285518735647202\n",
      "epoch 21 loss: 0.07494887709617615\n",
      "epoch 22 loss: 0.07561050355434418\n",
      "epoch 23 loss: 0.08072464168071747\n",
      "epoch 24 loss: 0.09335894137620926\n",
      "epoch 25 loss: 0.08386825770139694\n",
      "epoch 26 loss: 0.08931385725736618\n",
      "epoch 27 loss: 0.08903664350509644\n",
      "epoch 28 loss: 0.06800161302089691\n",
      "epoch 29 loss: 0.058394186198711395\n",
      "epoch 30 loss: 0.07669997960329056\n",
      "66\n",
      "epoch 1 loss: 0.7823207974433899\n",
      "epoch 2 loss: 0.5482608675956726\n",
      "epoch 3 loss: 0.33031943440437317\n",
      "epoch 4 loss: 0.17957212030887604\n",
      "epoch 5 loss: 0.21836470067501068\n",
      "epoch 6 loss: 0.182870551943779\n",
      "epoch 7 loss: 0.14848101139068604\n",
      "epoch 8 loss: 0.12892185151576996\n",
      "epoch 9 loss: 0.1450532078742981\n",
      "epoch 10 loss: 0.09122534096240997\n",
      "epoch 11 loss: 0.12225471436977386\n",
      "epoch 12 loss: 0.08837168663740158\n",
      "epoch 13 loss: 0.07985811680555344\n",
      "epoch 14 loss: 0.1018911823630333\n",
      "epoch 15 loss: 0.07029352337121964\n",
      "epoch 16 loss: 0.08111841976642609\n",
      "epoch 17 loss: 0.09319523721933365\n",
      "epoch 18 loss: 0.07451242208480835\n",
      "epoch 19 loss: 0.07724898308515549\n",
      "epoch 20 loss: 0.09720288962125778\n",
      "epoch 21 loss: 0.06393487751483917\n",
      "epoch 22 loss: 0.07118267565965652\n",
      "epoch 23 loss: 0.09189926832914352\n",
      "epoch 24 loss: 0.07561346888542175\n",
      "epoch 25 loss: 0.09185489267110825\n",
      "epoch 26 loss: 0.09102807193994522\n",
      "epoch 27 loss: 0.07557183504104614\n",
      "epoch 28 loss: 0.07595198601484299\n",
      "epoch 29 loss: 0.0861559584736824\n",
      "epoch 30 loss: 0.08327731490135193\n",
      "67\n",
      "epoch 1 loss: 0.8431854248046875\n",
      "epoch 2 loss: 0.6977214813232422\n",
      "epoch 3 loss: 0.40613123774528503\n",
      "epoch 4 loss: 0.22866995632648468\n",
      "epoch 5 loss: 0.18803545832633972\n",
      "epoch 6 loss: 0.13465933501720428\n",
      "epoch 7 loss: 0.11273198574781418\n",
      "epoch 8 loss: 0.13829714059829712\n",
      "epoch 9 loss: 0.09603693336248398\n",
      "epoch 10 loss: 0.12033084034919739\n",
      "epoch 11 loss: 0.1154356375336647\n",
      "epoch 12 loss: 0.09301581233739853\n",
      "epoch 13 loss: 0.09378810971975327\n",
      "epoch 14 loss: 0.0843396857380867\n",
      "epoch 15 loss: 0.06567071378231049\n",
      "epoch 16 loss: 0.09423758834600449\n",
      "epoch 17 loss: 0.08569929003715515\n",
      "epoch 18 loss: 0.08426158875226974\n",
      "epoch 19 loss: 0.07363603264093399\n",
      "epoch 20 loss: 0.0917501449584961\n",
      "epoch 21 loss: 0.08477090299129486\n",
      "epoch 22 loss: 0.09540592133998871\n",
      "epoch 23 loss: 0.09731243550777435\n",
      "epoch 24 loss: 0.08316519111394882\n",
      "epoch 25 loss: 0.07046283781528473\n",
      "epoch 26 loss: 0.05986129119992256\n",
      "epoch 27 loss: 0.0810006782412529\n",
      "epoch 28 loss: 0.07465458661317825\n",
      "epoch 29 loss: 0.09188062697649002\n",
      "epoch 30 loss: 0.1008022278547287\n",
      "68\n",
      "epoch 1 loss: 0.8924838304519653\n",
      "epoch 2 loss: 0.47617825865745544\n",
      "epoch 3 loss: 0.28925392031669617\n",
      "epoch 4 loss: 0.18888966739177704\n",
      "epoch 5 loss: 0.13517449796199799\n",
      "epoch 6 loss: 0.15377821028232574\n",
      "epoch 7 loss: 0.12135281413793564\n",
      "epoch 8 loss: 0.08803810179233551\n",
      "epoch 9 loss: 0.10526715964078903\n",
      "epoch 10 loss: 0.09120045602321625\n",
      "epoch 11 loss: 0.08604612946510315\n",
      "epoch 12 loss: 0.1050606444478035\n",
      "epoch 13 loss: 0.08216099441051483\n",
      "epoch 14 loss: 0.0698738545179367\n",
      "epoch 15 loss: 0.08598032593727112\n",
      "epoch 16 loss: 0.11188167333602905\n",
      "epoch 17 loss: 0.09553580731153488\n",
      "epoch 18 loss: 0.0893833190202713\n",
      "epoch 19 loss: 0.08788970857858658\n",
      "epoch 20 loss: 0.061284083873033524\n",
      "epoch 21 loss: 0.11054608970880508\n",
      "epoch 22 loss: 0.09376205503940582\n",
      "epoch 23 loss: 0.08273614197969437\n",
      "epoch 24 loss: 0.06581583619117737\n",
      "epoch 25 loss: 0.0689455047249794\n",
      "epoch 26 loss: 0.07660908252000809\n",
      "epoch 27 loss: 0.09251189976930618\n",
      "epoch 28 loss: 0.07751848548650742\n",
      "epoch 29 loss: 0.0893603190779686\n",
      "epoch 30 loss: 0.08132077008485794\n",
      "69\n",
      "epoch 1 loss: 0.6750348806381226\n",
      "epoch 2 loss: 0.5897630453109741\n",
      "epoch 3 loss: 0.3527982532978058\n",
      "epoch 4 loss: 0.2064090073108673\n",
      "epoch 5 loss: 0.13608385622501373\n",
      "epoch 6 loss: 0.13716401159763336\n",
      "epoch 7 loss: 0.1310940384864807\n",
      "epoch 8 loss: 0.15583740174770355\n",
      "epoch 9 loss: 0.10153156518936157\n",
      "epoch 10 loss: 0.10036855190992355\n",
      "epoch 11 loss: 0.0919998437166214\n",
      "epoch 12 loss: 0.07696171849966049\n",
      "epoch 13 loss: 0.07994821667671204\n",
      "epoch 14 loss: 0.09046906232833862\n",
      "epoch 15 loss: 0.09047591686248779\n",
      "epoch 16 loss: 0.07164861261844635\n",
      "epoch 17 loss: 0.09810316562652588\n",
      "epoch 18 loss: 0.10492988675832748\n",
      "epoch 19 loss: 0.09265126287937164\n",
      "epoch 20 loss: 0.07061049342155457\n",
      "epoch 21 loss: 0.06152508780360222\n",
      "epoch 22 loss: 0.09886161983013153\n",
      "epoch 23 loss: 0.09893756359815598\n",
      "epoch 24 loss: 0.06514229625463486\n",
      "epoch 25 loss: 0.08429238200187683\n",
      "epoch 26 loss: 0.07085762917995453\n",
      "epoch 27 loss: 0.07676959037780762\n",
      "epoch 28 loss: 0.09662789851427078\n",
      "epoch 29 loss: 0.0658726617693901\n",
      "epoch 30 loss: 0.05915042757987976\n",
      "70\n",
      "epoch 1 loss: 0.9613192677497864\n",
      "epoch 2 loss: 0.552153468132019\n",
      "epoch 3 loss: 0.27310216426849365\n",
      "epoch 4 loss: 0.13048045337200165\n",
      "epoch 5 loss: 0.16791798174381256\n",
      "epoch 6 loss: 0.1376897245645523\n",
      "epoch 7 loss: 0.1289667785167694\n",
      "epoch 8 loss: 0.12094097584486008\n",
      "epoch 9 loss: 0.11251027882099152\n",
      "epoch 10 loss: 0.0999743863940239\n",
      "epoch 11 loss: 0.10270348191261292\n",
      "epoch 12 loss: 0.11548471450805664\n",
      "epoch 13 loss: 0.09801945090293884\n",
      "epoch 14 loss: 0.10660508275032043\n",
      "epoch 15 loss: 0.15045662224292755\n",
      "epoch 16 loss: 0.08617301285266876\n",
      "epoch 17 loss: 0.1176244392991066\n",
      "epoch 18 loss: 0.07206761091947556\n",
      "epoch 19 loss: 0.08876409381628036\n",
      "epoch 20 loss: 0.07831861078739166\n",
      "epoch 21 loss: 0.09054355323314667\n",
      "epoch 22 loss: 0.11648962646722794\n",
      "epoch 23 loss: 0.08420833200216293\n",
      "epoch 24 loss: 0.07424346357584\n",
      "epoch 25 loss: 0.11369141936302185\n",
      "epoch 26 loss: 0.07391545921564102\n",
      "epoch 27 loss: 0.10326985269784927\n",
      "epoch 28 loss: 0.10386382788419724\n",
      "epoch 29 loss: 0.11236446350812912\n",
      "epoch 30 loss: 0.09092575311660767\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T01:42:55.338552Z",
     "start_time": "2025-10-06T01:42:55.244144Z"
    }
   },
   "cell_type": "code",
   "source": "out_dir",
   "id": "264e1975114e7808",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comed_results'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test RNN_based ARMA",
   "id": "ad6bccf216b7bf43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T22:31:20.078739Z",
     "start_time": "2025-10-05T21:55:39.234796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"cpu\"))\n",
    "results_arma_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_ARMA_Feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_arma_asy_con.to_csv(out_dir + '/results_arma_asy_con.csv', index=False)"
   ],
   "id": "7ba75a50b7a82bbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:1098: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {epoch+1} loss:\", float(loss))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 1.096156358718872\n",
      "epoch 2 loss: 0.6445624232292175\n",
      "epoch 3 loss: 0.43184781074523926\n",
      "epoch 4 loss: 0.3598690330982208\n",
      "epoch 5 loss: 0.25350242853164673\n",
      "epoch 6 loss: 0.12622109055519104\n",
      "epoch 7 loss: 0.14301782846450806\n",
      "epoch 8 loss: 0.1533171832561493\n",
      "epoch 9 loss: 0.15587902069091797\n",
      "epoch 10 loss: 0.11551857739686966\n",
      "epoch 11 loss: 0.15973807871341705\n",
      "epoch 12 loss: 0.10921464115381241\n",
      "epoch 13 loss: 0.13086643815040588\n",
      "epoch 14 loss: 0.1311923712491989\n",
      "epoch 15 loss: 0.10647160559892654\n",
      "epoch 16 loss: 0.09958404302597046\n",
      "epoch 17 loss: 0.15009497106075287\n",
      "epoch 18 loss: 0.13686031103134155\n",
      "epoch 19 loss: 0.1073843315243721\n",
      "epoch 20 loss: 0.08351626992225647\n",
      "epoch 21 loss: 0.11221741884946823\n",
      "epoch 22 loss: 0.14926302433013916\n",
      "epoch 23 loss: 0.180104061961174\n",
      "epoch 24 loss: 0.08796479552984238\n",
      "epoch 25 loss: 0.11732230335474014\n",
      "epoch 26 loss: 0.1523258090019226\n",
      "epoch 27 loss: 0.14987215399742126\n",
      "epoch 28 loss: 0.11375413089990616\n",
      "epoch 29 loss: 0.10847536474466324\n",
      "epoch 30 loss: 0.08954482525587082\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_93068/420669042.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6989014148712158\n",
      "epoch 2 loss: 0.7636798620223999\n",
      "epoch 3 loss: 0.6333984136581421\n",
      "epoch 4 loss: 0.2736952304840088\n",
      "epoch 5 loss: 0.26033103466033936\n",
      "epoch 6 loss: 0.26153627038002014\n",
      "epoch 7 loss: 0.15889890491962433\n",
      "epoch 8 loss: 0.1982525736093521\n",
      "epoch 9 loss: 0.14516650140285492\n",
      "epoch 10 loss: 0.13712523877620697\n",
      "epoch 11 loss: 0.1461891531944275\n",
      "epoch 12 loss: 0.14406828582286835\n",
      "epoch 13 loss: 0.14261695742607117\n",
      "epoch 14 loss: 0.11779559403657913\n",
      "epoch 15 loss: 0.19249208271503448\n",
      "epoch 16 loss: 0.11482765525579453\n",
      "epoch 17 loss: 0.14036132395267487\n",
      "epoch 18 loss: 0.14708976447582245\n",
      "epoch 19 loss: 0.1392999291419983\n",
      "epoch 20 loss: 0.10045023262500763\n",
      "epoch 21 loss: 0.13224336504936218\n",
      "epoch 22 loss: 0.1298610121011734\n",
      "epoch 23 loss: 0.1333124339580536\n",
      "epoch 24 loss: 0.16133582592010498\n",
      "epoch 25 loss: 0.16351158916950226\n",
      "epoch 26 loss: 0.1421343833208084\n",
      "epoch 27 loss: 0.17865292727947235\n",
      "epoch 28 loss: 0.12352576851844788\n",
      "epoch 29 loss: 0.12006748467683792\n",
      "epoch 30 loss: 0.10758854448795319\n",
      "3\n",
      "epoch 1 loss: 0.7957356572151184\n",
      "epoch 2 loss: 0.5595837235450745\n",
      "epoch 3 loss: 0.5893303751945496\n",
      "epoch 4 loss: 0.35538458824157715\n",
      "epoch 5 loss: 0.19075807929039001\n",
      "epoch 6 loss: 0.21716444194316864\n",
      "epoch 7 loss: 0.17248886823654175\n",
      "epoch 8 loss: 0.186109721660614\n",
      "epoch 9 loss: 0.15370483696460724\n",
      "epoch 10 loss: 0.13527697324752808\n",
      "epoch 11 loss: 0.1369379311800003\n",
      "epoch 12 loss: 0.15177112817764282\n",
      "epoch 13 loss: 0.14298699796199799\n",
      "epoch 14 loss: 0.12644268572330475\n",
      "epoch 15 loss: 0.1317426562309265\n",
      "epoch 16 loss: 0.09296541661024094\n",
      "epoch 17 loss: 0.1289205551147461\n",
      "epoch 18 loss: 0.132148876786232\n",
      "epoch 19 loss: 0.13266807794570923\n",
      "epoch 20 loss: 0.12954765558242798\n",
      "epoch 21 loss: 0.12554891407489777\n",
      "epoch 22 loss: 0.0898161232471466\n",
      "epoch 23 loss: 0.10661717504262924\n",
      "epoch 24 loss: 0.11726591736078262\n",
      "epoch 25 loss: 0.10136683285236359\n",
      "epoch 26 loss: 0.09488661587238312\n",
      "epoch 27 loss: 0.10798849910497665\n",
      "epoch 28 loss: 0.14329716563224792\n",
      "epoch 29 loss: 0.10593918710947037\n",
      "epoch 30 loss: 0.10341795533895493\n",
      "4\n",
      "epoch 1 loss: 1.125255823135376\n",
      "epoch 2 loss: 0.736660361289978\n",
      "epoch 3 loss: 0.7591038942337036\n",
      "epoch 4 loss: 0.48081424832344055\n",
      "epoch 5 loss: 0.23071663081645966\n",
      "epoch 6 loss: 0.18361641466617584\n",
      "epoch 7 loss: 0.19102877378463745\n",
      "epoch 8 loss: 0.15053877234458923\n",
      "epoch 9 loss: 0.15230964124202728\n",
      "epoch 10 loss: 0.17368832230567932\n",
      "epoch 11 loss: 0.16750529408454895\n",
      "epoch 12 loss: 0.1417948305606842\n",
      "epoch 13 loss: 0.11832816153764725\n",
      "epoch 14 loss: 0.11224357783794403\n",
      "epoch 15 loss: 0.17292362451553345\n",
      "epoch 16 loss: 0.11681634187698364\n",
      "epoch 17 loss: 0.12781164050102234\n",
      "epoch 18 loss: 0.09262453019618988\n",
      "epoch 19 loss: 0.1575935333967209\n",
      "epoch 20 loss: 0.11377093195915222\n",
      "epoch 21 loss: 0.1432756930589676\n",
      "epoch 22 loss: 0.11664465814828873\n",
      "epoch 23 loss: 0.1304081529378891\n",
      "epoch 24 loss: 0.10822556167840958\n",
      "epoch 25 loss: 0.1591331958770752\n",
      "epoch 26 loss: 0.1283917874097824\n",
      "epoch 27 loss: 0.1185799241065979\n",
      "epoch 28 loss: 0.13356325030326843\n",
      "epoch 29 loss: 0.11053461581468582\n",
      "epoch 30 loss: 0.10476216673851013\n",
      "5\n",
      "epoch 1 loss: 0.9650088548660278\n",
      "epoch 2 loss: 0.9984626173973083\n",
      "epoch 3 loss: 0.5694655179977417\n",
      "epoch 4 loss: 0.3988276422023773\n",
      "epoch 5 loss: 0.24452856183052063\n",
      "epoch 6 loss: 0.20849086344242096\n",
      "epoch 7 loss: 0.175602987408638\n",
      "epoch 8 loss: 0.11602498590946198\n",
      "epoch 9 loss: 0.11163752526044846\n",
      "epoch 10 loss: 0.1608022153377533\n",
      "epoch 11 loss: 0.11939078569412231\n",
      "epoch 12 loss: 0.14718207716941833\n",
      "epoch 13 loss: 0.16026942431926727\n",
      "epoch 14 loss: 0.14612753689289093\n",
      "epoch 15 loss: 0.125920370221138\n",
      "epoch 16 loss: 0.14233249425888062\n",
      "epoch 17 loss: 0.13969631493091583\n",
      "epoch 18 loss: 0.12464138865470886\n",
      "epoch 19 loss: 0.11763413995504379\n",
      "epoch 20 loss: 0.13275228440761566\n",
      "epoch 21 loss: 0.13080033659934998\n",
      "epoch 22 loss: 0.12200865894556046\n",
      "epoch 23 loss: 0.10384685546159744\n",
      "epoch 24 loss: 0.12011566758155823\n",
      "epoch 25 loss: 0.09013304114341736\n",
      "epoch 26 loss: 0.11981455236673355\n",
      "epoch 27 loss: 0.13550356030464172\n",
      "epoch 28 loss: 0.16434788703918457\n",
      "epoch 29 loss: 0.12416833639144897\n",
      "epoch 30 loss: 0.08744831383228302\n",
      "6\n",
      "epoch 1 loss: 0.8772198557853699\n",
      "epoch 2 loss: 0.7130904197692871\n",
      "epoch 3 loss: 0.5500427484512329\n",
      "epoch 4 loss: 0.32860511541366577\n",
      "epoch 5 loss: 0.23123696446418762\n",
      "epoch 6 loss: 0.22314655780792236\n",
      "epoch 7 loss: 0.17687515914440155\n",
      "epoch 8 loss: 0.14219450950622559\n",
      "epoch 9 loss: 0.14859771728515625\n",
      "epoch 10 loss: 0.1699010729789734\n",
      "epoch 11 loss: 0.1792183220386505\n",
      "epoch 12 loss: 0.16252614557743073\n",
      "epoch 13 loss: 0.10407374054193497\n",
      "epoch 14 loss: 0.14541593194007874\n",
      "epoch 15 loss: 0.16055791079998016\n",
      "epoch 16 loss: 0.11708135157823563\n",
      "epoch 17 loss: 0.12373615056276321\n",
      "epoch 18 loss: 0.14078371226787567\n",
      "epoch 19 loss: 0.13115818798542023\n",
      "epoch 20 loss: 0.1227302998304367\n",
      "epoch 21 loss: 0.13297586143016815\n",
      "epoch 22 loss: 0.1342388093471527\n",
      "epoch 23 loss: 0.10611613094806671\n",
      "epoch 24 loss: 0.14503981173038483\n",
      "epoch 25 loss: 0.13378386199474335\n",
      "epoch 26 loss: 0.13950292766094208\n",
      "epoch 27 loss: 0.11746592819690704\n",
      "epoch 28 loss: 0.10349000990390778\n",
      "epoch 29 loss: 0.13800227642059326\n",
      "epoch 30 loss: 0.08814377337694168\n",
      "7\n",
      "epoch 1 loss: 1.0932782888412476\n",
      "epoch 2 loss: 0.86539626121521\n",
      "epoch 3 loss: 0.6022447347640991\n",
      "epoch 4 loss: 0.31504181027412415\n",
      "epoch 5 loss: 0.17217934131622314\n",
      "epoch 6 loss: 0.21131999790668488\n",
      "epoch 7 loss: 0.1536083072423935\n",
      "epoch 8 loss: 0.13059820234775543\n",
      "epoch 9 loss: 0.1547275185585022\n",
      "epoch 10 loss: 0.13983650505542755\n",
      "epoch 11 loss: 0.10038048028945923\n",
      "epoch 12 loss: 0.14439016580581665\n",
      "epoch 13 loss: 0.13385070860385895\n",
      "epoch 14 loss: 0.1455143839120865\n",
      "epoch 15 loss: 0.11926543712615967\n",
      "epoch 16 loss: 0.11918237060308456\n",
      "epoch 17 loss: 0.11497761309146881\n",
      "epoch 18 loss: 0.13063651323318481\n",
      "epoch 19 loss: 0.13281837105751038\n",
      "epoch 20 loss: 0.16205140948295593\n",
      "epoch 21 loss: 0.10551705211400986\n",
      "epoch 22 loss: 0.1135934442281723\n",
      "epoch 23 loss: 0.13947023451328278\n",
      "epoch 24 loss: 0.11601218581199646\n",
      "epoch 25 loss: 0.10550610721111298\n",
      "epoch 26 loss: 0.11998890340328217\n",
      "epoch 27 loss: 0.1149936094880104\n",
      "epoch 28 loss: 0.11031605303287506\n",
      "epoch 29 loss: 0.13774974644184113\n",
      "epoch 30 loss: 0.12188597023487091\n",
      "8\n",
      "epoch 1 loss: 0.8349622488021851\n",
      "epoch 2 loss: 0.911774754524231\n",
      "epoch 3 loss: 0.5379317402839661\n",
      "epoch 4 loss: 0.2907334566116333\n",
      "epoch 5 loss: 0.19248288869857788\n",
      "epoch 6 loss: 0.1846316158771515\n",
      "epoch 7 loss: 0.17870421707630157\n",
      "epoch 8 loss: 0.16920161247253418\n",
      "epoch 9 loss: 0.22325484454631805\n",
      "epoch 10 loss: 0.147792786359787\n",
      "epoch 11 loss: 0.14519649744033813\n",
      "epoch 12 loss: 0.17311248183250427\n",
      "epoch 13 loss: 0.13961036503314972\n",
      "epoch 14 loss: 0.12080219388008118\n",
      "epoch 15 loss: 0.1429053694009781\n",
      "epoch 16 loss: 0.14939212799072266\n",
      "epoch 17 loss: 0.16547054052352905\n",
      "epoch 18 loss: 0.14208577573299408\n",
      "epoch 19 loss: 0.11879131197929382\n",
      "epoch 20 loss: 0.13766656816005707\n",
      "epoch 21 loss: 0.15039564669132233\n",
      "epoch 22 loss: 0.13363245129585266\n",
      "epoch 23 loss: 0.12546135485172272\n",
      "epoch 24 loss: 0.11583565175533295\n",
      "epoch 25 loss: 0.18208374083042145\n",
      "epoch 26 loss: 0.11077655851840973\n",
      "epoch 27 loss: 0.10611946880817413\n",
      "epoch 28 loss: 0.15214937925338745\n",
      "epoch 29 loss: 0.12139169126749039\n",
      "epoch 30 loss: 0.09087908267974854\n",
      "9\n",
      "epoch 1 loss: 0.9716591238975525\n",
      "epoch 2 loss: 0.6124851703643799\n",
      "epoch 3 loss: 0.565818190574646\n",
      "epoch 4 loss: 0.242012158036232\n",
      "epoch 5 loss: 0.2736799120903015\n",
      "epoch 6 loss: 0.21062469482421875\n",
      "epoch 7 loss: 0.22220751643180847\n",
      "epoch 8 loss: 0.16289570927619934\n",
      "epoch 9 loss: 0.18945978581905365\n",
      "epoch 10 loss: 0.1674957424402237\n",
      "epoch 11 loss: 0.15405340492725372\n",
      "epoch 12 loss: 0.14881233870983124\n",
      "epoch 13 loss: 0.1540907770395279\n",
      "epoch 14 loss: 0.1305607706308365\n",
      "epoch 15 loss: 0.13296200335025787\n",
      "epoch 16 loss: 0.15226228535175323\n",
      "epoch 17 loss: 0.11383119970560074\n",
      "epoch 18 loss: 0.13530728220939636\n",
      "epoch 19 loss: 0.10267066955566406\n",
      "epoch 20 loss: 0.16437307000160217\n",
      "epoch 21 loss: 0.11026488244533539\n",
      "epoch 22 loss: 0.13621611893177032\n",
      "epoch 23 loss: 0.12616489827632904\n",
      "epoch 24 loss: 0.1255481094121933\n",
      "epoch 25 loss: 0.12345325946807861\n",
      "epoch 26 loss: 0.07695026695728302\n",
      "epoch 27 loss: 0.09851178526878357\n",
      "epoch 28 loss: 0.1366383582353592\n",
      "epoch 29 loss: 0.09925790876150131\n",
      "epoch 30 loss: 0.1195424422621727\n",
      "10\n",
      "epoch 1 loss: 0.9258819818496704\n",
      "epoch 2 loss: 0.776047945022583\n",
      "epoch 3 loss: 0.41757938265800476\n",
      "epoch 4 loss: 0.2694949209690094\n",
      "epoch 5 loss: 0.2293933480978012\n",
      "epoch 6 loss: 0.20908676087856293\n",
      "epoch 7 loss: 0.1965407282114029\n",
      "epoch 8 loss: 0.15670162439346313\n",
      "epoch 9 loss: 0.14122523367404938\n",
      "epoch 10 loss: 0.135176420211792\n",
      "epoch 11 loss: 0.19239220023155212\n",
      "epoch 12 loss: 0.14871615171432495\n",
      "epoch 13 loss: 0.12167459726333618\n",
      "epoch 14 loss: 0.12013648450374603\n",
      "epoch 15 loss: 0.1528252363204956\n",
      "epoch 16 loss: 0.13304802775382996\n",
      "epoch 17 loss: 0.14263999462127686\n",
      "epoch 18 loss: 0.14128056168556213\n",
      "epoch 19 loss: 0.10866083204746246\n",
      "epoch 20 loss: 0.10040540248155594\n",
      "epoch 21 loss: 0.15221905708312988\n",
      "epoch 22 loss: 0.10654211044311523\n",
      "epoch 23 loss: 0.11833298206329346\n",
      "epoch 24 loss: 0.13336129486560822\n",
      "epoch 25 loss: 0.1175423413515091\n",
      "epoch 26 loss: 0.12412473559379578\n",
      "epoch 27 loss: 0.12707102298736572\n",
      "epoch 28 loss: 0.17481377720832825\n",
      "epoch 29 loss: 0.17485098540782928\n",
      "epoch 30 loss: 0.1248493492603302\n",
      "11\n",
      "epoch 1 loss: 0.7137024402618408\n",
      "epoch 2 loss: 0.9784584641456604\n",
      "epoch 3 loss: 0.6299551129341125\n",
      "epoch 4 loss: 0.3123130798339844\n",
      "epoch 5 loss: 0.21035215258598328\n",
      "epoch 6 loss: 0.15999136865139008\n",
      "epoch 7 loss: 0.1249476820230484\n",
      "epoch 8 loss: 0.21285133063793182\n",
      "epoch 9 loss: 0.14158669114112854\n",
      "epoch 10 loss: 0.13350419700145721\n",
      "epoch 11 loss: 0.15868547558784485\n",
      "epoch 12 loss: 0.1395854949951172\n",
      "epoch 13 loss: 0.10815932601690292\n",
      "epoch 14 loss: 0.11261351406574249\n",
      "epoch 15 loss: 0.16730651259422302\n",
      "epoch 16 loss: 0.14135736227035522\n",
      "epoch 17 loss: 0.10974204540252686\n",
      "epoch 18 loss: 0.11428872495889664\n",
      "epoch 19 loss: 0.13399599492549896\n",
      "epoch 20 loss: 0.11450867354869843\n",
      "epoch 21 loss: 0.176970437169075\n",
      "epoch 22 loss: 0.12625300884246826\n",
      "epoch 23 loss: 0.14418737590312958\n",
      "epoch 24 loss: 0.14975586533546448\n",
      "epoch 25 loss: 0.14175575971603394\n",
      "epoch 26 loss: 0.10110758990049362\n",
      "epoch 27 loss: 0.1427249312400818\n",
      "epoch 28 loss: 0.1400945484638214\n",
      "epoch 29 loss: 0.11471374332904816\n",
      "epoch 30 loss: 0.12576298415660858\n",
      "12\n",
      "epoch 1 loss: 0.574529230594635\n",
      "epoch 2 loss: 0.7336550354957581\n",
      "epoch 3 loss: 0.4602208733558655\n",
      "epoch 4 loss: 0.19914233684539795\n",
      "epoch 5 loss: 0.16017578542232513\n",
      "epoch 6 loss: 0.18806155025959015\n",
      "epoch 7 loss: 0.16093002259731293\n",
      "epoch 8 loss: 0.1573491245508194\n",
      "epoch 9 loss: 0.1598985344171524\n",
      "epoch 10 loss: 0.12028444558382034\n",
      "epoch 11 loss: 0.13630591332912445\n",
      "epoch 12 loss: 0.09420670568943024\n",
      "epoch 13 loss: 0.13042277097702026\n",
      "epoch 14 loss: 0.12030727416276932\n",
      "epoch 15 loss: 0.11728409677743912\n",
      "epoch 16 loss: 0.12566739320755005\n",
      "epoch 17 loss: 0.13643912971019745\n",
      "epoch 18 loss: 0.13455075025558472\n",
      "epoch 19 loss: 0.116336390376091\n",
      "epoch 20 loss: 0.11417625099420547\n",
      "epoch 21 loss: 0.10768068581819534\n",
      "epoch 22 loss: 0.15452951192855835\n",
      "epoch 23 loss: 0.13071124255657196\n",
      "epoch 24 loss: 0.11155726760625839\n",
      "epoch 25 loss: 0.10750678181648254\n",
      "epoch 26 loss: 0.14933331310749054\n",
      "epoch 27 loss: 0.1400507539510727\n",
      "epoch 28 loss: 0.14403152465820312\n",
      "epoch 29 loss: 0.1294524073600769\n",
      "epoch 30 loss: 0.124534472823143\n",
      "13\n",
      "epoch 1 loss: 0.6458024978637695\n",
      "epoch 2 loss: 0.6708801984786987\n",
      "epoch 3 loss: 0.5394954085350037\n",
      "epoch 4 loss: 0.2931528389453888\n",
      "epoch 5 loss: 0.21841666102409363\n",
      "epoch 6 loss: 0.17439639568328857\n",
      "epoch 7 loss: 0.1883171796798706\n",
      "epoch 8 loss: 0.1704988181591034\n",
      "epoch 9 loss: 0.14999155700206757\n",
      "epoch 10 loss: 0.14115415513515472\n",
      "epoch 11 loss: 0.1365274041891098\n",
      "epoch 12 loss: 0.1376389116048813\n",
      "epoch 13 loss: 0.13963472843170166\n",
      "epoch 14 loss: 0.13359439373016357\n",
      "epoch 15 loss: 0.13006490468978882\n",
      "epoch 16 loss: 0.1468447744846344\n",
      "epoch 17 loss: 0.12552611529827118\n",
      "epoch 18 loss: 0.1267838180065155\n",
      "epoch 19 loss: 0.11337905377149582\n",
      "epoch 20 loss: 0.10822205990552902\n",
      "epoch 21 loss: 0.09500191360712051\n",
      "epoch 22 loss: 0.1390198916196823\n",
      "epoch 23 loss: 0.10752805322408676\n",
      "epoch 24 loss: 0.11290456354618073\n",
      "epoch 25 loss: 0.11690636724233627\n",
      "epoch 26 loss: 0.12497017532587051\n",
      "epoch 27 loss: 0.125504732131958\n",
      "epoch 28 loss: 0.1201629638671875\n",
      "epoch 29 loss: 0.12918466329574585\n",
      "epoch 30 loss: 0.11984541267156601\n",
      "14\n",
      "epoch 1 loss: 1.242990255355835\n",
      "epoch 2 loss: 0.7363969087600708\n",
      "epoch 3 loss: 0.41285619139671326\n",
      "epoch 4 loss: 0.4831433594226837\n",
      "epoch 5 loss: 0.4297649562358856\n",
      "epoch 6 loss: 0.19262243807315826\n",
      "epoch 7 loss: 0.15597569942474365\n",
      "epoch 8 loss: 0.16422471404075623\n",
      "epoch 9 loss: 0.1361081600189209\n",
      "epoch 10 loss: 0.15662139654159546\n",
      "epoch 11 loss: 0.14415477216243744\n",
      "epoch 12 loss: 0.14290647208690643\n",
      "epoch 13 loss: 0.18488243222236633\n",
      "epoch 14 loss: 0.1494981050491333\n",
      "epoch 15 loss: 0.15070685744285583\n",
      "epoch 16 loss: 0.148057222366333\n",
      "epoch 17 loss: 0.16319811344146729\n",
      "epoch 18 loss: 0.12175409495830536\n",
      "epoch 19 loss: 0.1738988310098648\n",
      "epoch 20 loss: 0.14445219933986664\n",
      "epoch 21 loss: 0.12105422466993332\n",
      "epoch 22 loss: 0.10555458813905716\n",
      "epoch 23 loss: 0.12455251812934875\n",
      "epoch 24 loss: 0.14589573442935944\n",
      "epoch 25 loss: 0.08284298330545425\n",
      "epoch 26 loss: 0.09402568638324738\n",
      "epoch 27 loss: 0.14061523973941803\n",
      "epoch 28 loss: 0.1284857988357544\n",
      "epoch 29 loss: 0.11280349642038345\n",
      "epoch 30 loss: 0.1670624017715454\n",
      "15\n",
      "epoch 1 loss: 0.7958449125289917\n",
      "epoch 2 loss: 0.582312822341919\n",
      "epoch 3 loss: 0.46709465980529785\n",
      "epoch 4 loss: 0.33899959921836853\n",
      "epoch 5 loss: 0.16555634140968323\n",
      "epoch 6 loss: 0.18252913653850555\n",
      "epoch 7 loss: 0.20616641640663147\n",
      "epoch 8 loss: 0.16280129551887512\n",
      "epoch 9 loss: 0.12992659211158752\n",
      "epoch 10 loss: 0.17767369747161865\n",
      "epoch 11 loss: 0.1673527956008911\n",
      "epoch 12 loss: 0.16244858503341675\n",
      "epoch 13 loss: 0.11210806667804718\n",
      "epoch 14 loss: 0.1302030086517334\n",
      "epoch 15 loss: 0.14235836267471313\n",
      "epoch 16 loss: 0.15993179380893707\n",
      "epoch 17 loss: 0.13508707284927368\n",
      "epoch 18 loss: 0.12136206775903702\n",
      "epoch 19 loss: 0.14054495096206665\n",
      "epoch 20 loss: 0.13247492909431458\n",
      "epoch 21 loss: 0.1175568625330925\n",
      "epoch 22 loss: 0.1433005928993225\n",
      "epoch 23 loss: 0.11116553097963333\n",
      "epoch 24 loss: 0.10594814270734787\n",
      "epoch 25 loss: 0.12445155531167984\n",
      "epoch 26 loss: 0.11269961297512054\n",
      "epoch 27 loss: 0.13359633088111877\n",
      "epoch 28 loss: 0.11951548606157303\n",
      "epoch 29 loss: 0.11573618650436401\n",
      "epoch 30 loss: 0.10528730601072311\n",
      "16\n",
      "epoch 1 loss: 0.7365200519561768\n",
      "epoch 2 loss: 0.7366093397140503\n",
      "epoch 3 loss: 0.43332207202911377\n",
      "epoch 4 loss: 0.42874056100845337\n",
      "epoch 5 loss: 0.2198859602212906\n",
      "epoch 6 loss: 0.19115205109119415\n",
      "epoch 7 loss: 0.1576010137796402\n",
      "epoch 8 loss: 0.16729548573493958\n",
      "epoch 9 loss: 0.16663804650306702\n",
      "epoch 10 loss: 0.18791070580482483\n",
      "epoch 11 loss: 0.11483164876699448\n",
      "epoch 12 loss: 0.17567498981952667\n",
      "epoch 13 loss: 0.1279040277004242\n",
      "epoch 14 loss: 0.1469365656375885\n",
      "epoch 15 loss: 0.16512134671211243\n",
      "epoch 16 loss: 0.1425168663263321\n",
      "epoch 17 loss: 0.11797705292701721\n",
      "epoch 18 loss: 0.129895880818367\n",
      "epoch 19 loss: 0.1235390454530716\n",
      "epoch 20 loss: 0.12428747862577438\n",
      "epoch 21 loss: 0.11681649833917618\n",
      "epoch 22 loss: 0.12411531805992126\n",
      "epoch 23 loss: 0.1406622678041458\n",
      "epoch 24 loss: 0.15461216866970062\n",
      "epoch 25 loss: 0.10150271654129028\n",
      "epoch 26 loss: 0.13167481124401093\n",
      "epoch 27 loss: 0.10315833985805511\n",
      "epoch 28 loss: 0.12336155772209167\n",
      "epoch 29 loss: 0.09761352837085724\n",
      "epoch 30 loss: 0.12668947875499725\n",
      "17\n",
      "epoch 1 loss: 0.9312434196472168\n",
      "epoch 2 loss: 0.8239710330963135\n",
      "epoch 3 loss: 0.5135606527328491\n",
      "epoch 4 loss: 0.28210511803627014\n",
      "epoch 5 loss: 0.20869965851306915\n",
      "epoch 6 loss: 0.1650705486536026\n",
      "epoch 7 loss: 0.18763315677642822\n",
      "epoch 8 loss: 0.15390795469284058\n",
      "epoch 9 loss: 0.15543130040168762\n",
      "epoch 10 loss: 0.12167174369096756\n",
      "epoch 11 loss: 0.11707685142755508\n",
      "epoch 12 loss: 0.1421506255865097\n",
      "epoch 13 loss: 0.17133095860481262\n",
      "epoch 14 loss: 0.1559339463710785\n",
      "epoch 15 loss: 0.11751493811607361\n",
      "epoch 16 loss: 0.11332576721906662\n",
      "epoch 17 loss: 0.11626122891902924\n",
      "epoch 18 loss: 0.10389066487550735\n",
      "epoch 19 loss: 0.14267727732658386\n",
      "epoch 20 loss: 0.12367050349712372\n",
      "epoch 21 loss: 0.1247939020395279\n",
      "epoch 22 loss: 0.11774343252182007\n",
      "epoch 23 loss: 0.13522890210151672\n",
      "epoch 24 loss: 0.1109166368842125\n",
      "epoch 25 loss: 0.1359405815601349\n",
      "epoch 26 loss: 0.122821144759655\n",
      "epoch 27 loss: 0.1317322850227356\n",
      "epoch 28 loss: 0.10741250216960907\n",
      "epoch 29 loss: 0.10672242194414139\n",
      "epoch 30 loss: 0.10361909866333008\n",
      "18\n",
      "epoch 1 loss: 0.810782790184021\n",
      "epoch 2 loss: 0.8185784816741943\n",
      "epoch 3 loss: 0.5365220308303833\n",
      "epoch 4 loss: 0.4375537633895874\n",
      "epoch 5 loss: 0.2990615963935852\n",
      "epoch 6 loss: 0.16739408671855927\n",
      "epoch 7 loss: 0.16733518242835999\n",
      "epoch 8 loss: 0.20567448437213898\n",
      "epoch 9 loss: 0.15291574597358704\n",
      "epoch 10 loss: 0.15075168013572693\n",
      "epoch 11 loss: 0.12116978317499161\n",
      "epoch 12 loss: 0.16489769518375397\n",
      "epoch 13 loss: 0.11663312464952469\n",
      "epoch 14 loss: 0.16455045342445374\n",
      "epoch 15 loss: 0.15157487988471985\n",
      "epoch 16 loss: 0.15354326367378235\n",
      "epoch 17 loss: 0.1018674224615097\n",
      "epoch 18 loss: 0.14774630963802338\n",
      "epoch 19 loss: 0.11425130814313889\n",
      "epoch 20 loss: 0.11236104369163513\n",
      "epoch 21 loss: 0.1160341277718544\n",
      "epoch 22 loss: 0.11923191696405411\n",
      "epoch 23 loss: 0.10304982215166092\n",
      "epoch 24 loss: 0.10974519699811935\n",
      "epoch 25 loss: 0.1221509501338005\n",
      "epoch 26 loss: 0.11326728016138077\n",
      "epoch 27 loss: 0.13932935893535614\n",
      "epoch 28 loss: 0.11203532665967941\n",
      "epoch 29 loss: 0.07841014117002487\n",
      "epoch 30 loss: 0.13729824125766754\n",
      "19\n",
      "epoch 1 loss: 1.0812574625015259\n",
      "epoch 2 loss: 0.9587807059288025\n",
      "epoch 3 loss: 0.6402446031570435\n",
      "epoch 4 loss: 0.30341196060180664\n",
      "epoch 5 loss: 0.18369853496551514\n",
      "epoch 6 loss: 0.22014406323432922\n",
      "epoch 7 loss: 0.17881572246551514\n",
      "epoch 8 loss: 0.1634938269853592\n",
      "epoch 9 loss: 0.11606939136981964\n",
      "epoch 10 loss: 0.1517113298177719\n",
      "epoch 11 loss: 0.1929890364408493\n",
      "epoch 12 loss: 0.13469958305358887\n",
      "epoch 13 loss: 0.13241182267665863\n",
      "epoch 14 loss: 0.1250072419643402\n",
      "epoch 15 loss: 0.1293819397687912\n",
      "epoch 16 loss: 0.12162523716688156\n",
      "epoch 17 loss: 0.13030430674552917\n",
      "epoch 18 loss: 0.12313622981309891\n",
      "epoch 19 loss: 0.13516779243946075\n",
      "epoch 20 loss: 0.1149110347032547\n",
      "epoch 21 loss: 0.09194692224264145\n",
      "epoch 22 loss: 0.10585689544677734\n",
      "epoch 23 loss: 0.11770963668823242\n",
      "epoch 24 loss: 0.1120089739561081\n",
      "epoch 25 loss: 0.10376188158988953\n",
      "epoch 26 loss: 0.12710663676261902\n",
      "epoch 27 loss: 0.12226973474025726\n",
      "epoch 28 loss: 0.11072777211666107\n",
      "epoch 29 loss: 0.08477388322353363\n",
      "epoch 30 loss: 0.1101265400648117\n",
      "20\n",
      "epoch 1 loss: 1.0054643154144287\n",
      "epoch 2 loss: 0.7154451012611389\n",
      "epoch 3 loss: 0.5789241194725037\n",
      "epoch 4 loss: 0.3300221264362335\n",
      "epoch 5 loss: 0.25046470761299133\n",
      "epoch 6 loss: 0.20647408068180084\n",
      "epoch 7 loss: 0.15933935344219208\n",
      "epoch 8 loss: 0.17818106710910797\n",
      "epoch 9 loss: 0.11091413348913193\n",
      "epoch 10 loss: 0.18388774991035461\n",
      "epoch 11 loss: 0.15035074949264526\n",
      "epoch 12 loss: 0.14492267370224\n",
      "epoch 13 loss: 0.13285736739635468\n",
      "epoch 14 loss: 0.1226162388920784\n",
      "epoch 15 loss: 0.1718933880329132\n",
      "epoch 16 loss: 0.11551465839147568\n",
      "epoch 17 loss: 0.1310623288154602\n",
      "epoch 18 loss: 0.17194990813732147\n",
      "epoch 19 loss: 0.15491627156734467\n",
      "epoch 20 loss: 0.11640096455812454\n",
      "epoch 21 loss: 0.11788978427648544\n",
      "epoch 22 loss: 0.14286690950393677\n",
      "epoch 23 loss: 0.1230187863111496\n",
      "epoch 24 loss: 0.12930412590503693\n",
      "epoch 25 loss: 0.1529340296983719\n",
      "epoch 26 loss: 0.14358390867710114\n",
      "epoch 27 loss: 0.13603325188159943\n",
      "epoch 28 loss: 0.11408993601799011\n",
      "epoch 29 loss: 0.09943319112062454\n",
      "epoch 30 loss: 0.11765890568494797\n",
      "21\n",
      "epoch 1 loss: 0.750850260257721\n",
      "epoch 2 loss: 0.6835381388664246\n",
      "epoch 3 loss: 0.5183421969413757\n",
      "epoch 4 loss: 0.34680554270744324\n",
      "epoch 5 loss: 0.1813632994890213\n",
      "epoch 6 loss: 0.19921527802944183\n",
      "epoch 7 loss: 0.14230689406394958\n",
      "epoch 8 loss: 0.16040852665901184\n",
      "epoch 9 loss: 0.1466146558523178\n",
      "epoch 10 loss: 0.11426357924938202\n",
      "epoch 11 loss: 0.16068406403064728\n",
      "epoch 12 loss: 0.14907628297805786\n",
      "epoch 13 loss: 0.14068388938903809\n",
      "epoch 14 loss: 0.13101790845394135\n",
      "epoch 15 loss: 0.10559116303920746\n",
      "epoch 16 loss: 0.1454598754644394\n",
      "epoch 17 loss: 0.11223046481609344\n",
      "epoch 18 loss: 0.1497432440519333\n",
      "epoch 19 loss: 0.13492535054683685\n",
      "epoch 20 loss: 0.10433877259492874\n",
      "epoch 21 loss: 0.10666082799434662\n",
      "epoch 22 loss: 0.12241971492767334\n",
      "epoch 23 loss: 0.1387438029050827\n",
      "epoch 24 loss: 0.13081377744674683\n",
      "epoch 25 loss: 0.10237852483987808\n",
      "epoch 26 loss: 0.12659530341625214\n",
      "epoch 27 loss: 0.09469180554151535\n",
      "epoch 28 loss: 0.10475236922502518\n",
      "epoch 29 loss: 0.09183705598115921\n",
      "epoch 30 loss: 0.11043255031108856\n",
      "22\n",
      "epoch 1 loss: 1.212213397026062\n",
      "epoch 2 loss: 0.9081786870956421\n",
      "epoch 3 loss: 0.4644849896430969\n",
      "epoch 4 loss: 0.37928342819213867\n",
      "epoch 5 loss: 0.27673423290252686\n",
      "epoch 6 loss: 0.2102963626384735\n",
      "epoch 7 loss: 0.17221590876579285\n",
      "epoch 8 loss: 0.1767701953649521\n",
      "epoch 9 loss: 0.21389621496200562\n",
      "epoch 10 loss: 0.12006166577339172\n",
      "epoch 11 loss: 0.1302586793899536\n",
      "epoch 12 loss: 0.14980168640613556\n",
      "epoch 13 loss: 0.1708061546087265\n",
      "epoch 14 loss: 0.13969112932682037\n",
      "epoch 15 loss: 0.15946124494075775\n",
      "epoch 16 loss: 0.20311620831489563\n",
      "epoch 17 loss: 0.11947593837976456\n",
      "epoch 18 loss: 0.13350558280944824\n",
      "epoch 19 loss: 0.15141822397708893\n",
      "epoch 20 loss: 0.14684022963047028\n",
      "epoch 21 loss: 0.1335531771183014\n",
      "epoch 22 loss: 0.11497633904218674\n",
      "epoch 23 loss: 0.08419898897409439\n",
      "epoch 24 loss: 0.13006511330604553\n",
      "epoch 25 loss: 0.12818142771720886\n",
      "epoch 26 loss: 0.11332035809755325\n",
      "epoch 27 loss: 0.09759009629487991\n",
      "epoch 28 loss: 0.10990675538778305\n",
      "epoch 29 loss: 0.10975205153226852\n",
      "epoch 30 loss: 0.16745781898498535\n",
      "23\n",
      "epoch 1 loss: 0.7713648080825806\n",
      "epoch 2 loss: 0.6561852097511292\n",
      "epoch 3 loss: 0.5632997155189514\n",
      "epoch 4 loss: 0.296379029750824\n",
      "epoch 5 loss: 0.2728659212589264\n",
      "epoch 6 loss: 0.20000790059566498\n",
      "epoch 7 loss: 0.1763187050819397\n",
      "epoch 8 loss: 0.1459224671125412\n",
      "epoch 9 loss: 0.137908935546875\n",
      "epoch 10 loss: 0.1554340124130249\n",
      "epoch 11 loss: 0.13593803346157074\n",
      "epoch 12 loss: 0.1617594212293625\n",
      "epoch 13 loss: 0.11965382844209671\n",
      "epoch 14 loss: 0.12611964344978333\n",
      "epoch 15 loss: 0.16130442917346954\n",
      "epoch 16 loss: 0.1281498223543167\n",
      "epoch 17 loss: 0.1324809193611145\n",
      "epoch 18 loss: 0.13331477344036102\n",
      "epoch 19 loss: 0.11348310858011246\n",
      "epoch 20 loss: 0.17551589012145996\n",
      "epoch 21 loss: 0.15297947824001312\n",
      "epoch 22 loss: 0.136007159948349\n",
      "epoch 23 loss: 0.1500082015991211\n",
      "epoch 24 loss: 0.13075727224349976\n",
      "epoch 25 loss: 0.110203817486763\n",
      "epoch 26 loss: 0.11892443150281906\n",
      "epoch 27 loss: 0.13604889810085297\n",
      "epoch 28 loss: 0.11463074386119843\n",
      "epoch 29 loss: 0.12542565166950226\n",
      "epoch 30 loss: 0.1194310337305069\n",
      "24\n",
      "epoch 1 loss: 1.0231128931045532\n",
      "epoch 2 loss: 0.9572916030883789\n",
      "epoch 3 loss: 0.3946710526943207\n",
      "epoch 4 loss: 0.3612167537212372\n",
      "epoch 5 loss: 0.23675061762332916\n",
      "epoch 6 loss: 0.16366982460021973\n",
      "epoch 7 loss: 0.15613238513469696\n",
      "epoch 8 loss: 0.15707500278949738\n",
      "epoch 9 loss: 0.14103029668331146\n",
      "epoch 10 loss: 0.15376199781894684\n",
      "epoch 11 loss: 0.10631361603736877\n",
      "epoch 12 loss: 0.13772012293338776\n",
      "epoch 13 loss: 0.1322500854730606\n",
      "epoch 14 loss: 0.11689194291830063\n",
      "epoch 15 loss: 0.12034323811531067\n",
      "epoch 16 loss: 0.15181885659694672\n",
      "epoch 17 loss: 0.16649800539016724\n",
      "epoch 18 loss: 0.1405092030763626\n",
      "epoch 19 loss: 0.11933340132236481\n",
      "epoch 20 loss: 0.12513858079910278\n",
      "epoch 21 loss: 0.1674707680940628\n",
      "epoch 22 loss: 0.1564408838748932\n",
      "epoch 23 loss: 0.1716247946023941\n",
      "epoch 24 loss: 0.11138912290334702\n",
      "epoch 25 loss: 0.12448287755250931\n",
      "epoch 26 loss: 0.12803210318088531\n",
      "epoch 27 loss: 0.11787652224302292\n",
      "epoch 28 loss: 0.10209812968969345\n",
      "epoch 29 loss: 0.12148869782686234\n",
      "epoch 30 loss: 0.1141040250658989\n",
      "25\n",
      "epoch 1 loss: 0.7614442110061646\n",
      "epoch 2 loss: 0.7813439965248108\n",
      "epoch 3 loss: 0.47887009382247925\n",
      "epoch 4 loss: 0.6075292229652405\n",
      "epoch 5 loss: 0.23084530234336853\n",
      "epoch 6 loss: 0.1926700472831726\n",
      "epoch 7 loss: 0.13908948004245758\n",
      "epoch 8 loss: 0.1301705241203308\n",
      "epoch 9 loss: 0.17136085033416748\n",
      "epoch 10 loss: 0.14804531633853912\n",
      "epoch 11 loss: 0.14723962545394897\n",
      "epoch 12 loss: 0.15733125805854797\n",
      "epoch 13 loss: 0.1430807262659073\n",
      "epoch 14 loss: 0.12179148942232132\n",
      "epoch 15 loss: 0.1258966624736786\n",
      "epoch 16 loss: 0.1506250649690628\n",
      "epoch 17 loss: 0.1296459287405014\n",
      "epoch 18 loss: 0.15248891711235046\n",
      "epoch 19 loss: 0.12550167739391327\n",
      "epoch 20 loss: 0.13461709022521973\n",
      "epoch 21 loss: 0.11740899831056595\n",
      "epoch 22 loss: 0.13225746154785156\n",
      "epoch 23 loss: 0.1421200931072235\n",
      "epoch 24 loss: 0.12129688262939453\n",
      "epoch 25 loss: 0.11030282080173492\n",
      "epoch 26 loss: 0.12589293718338013\n",
      "epoch 27 loss: 0.11486156284809113\n",
      "epoch 28 loss: 0.19866511225700378\n",
      "epoch 29 loss: 0.13705958425998688\n",
      "epoch 30 loss: 0.1333380490541458\n",
      "26\n",
      "epoch 1 loss: 0.7954155802726746\n",
      "epoch 2 loss: 1.0536233186721802\n",
      "epoch 3 loss: 0.47156718373298645\n",
      "epoch 4 loss: 0.3106086552143097\n",
      "epoch 5 loss: 0.23720674216747284\n",
      "epoch 6 loss: 0.16562776267528534\n",
      "epoch 7 loss: 0.2012803852558136\n",
      "epoch 8 loss: 0.18019406497478485\n",
      "epoch 9 loss: 0.14335480332374573\n",
      "epoch 10 loss: 0.19353115558624268\n",
      "epoch 11 loss: 0.17994444072246552\n",
      "epoch 12 loss: 0.15277916193008423\n",
      "epoch 13 loss: 0.1552417129278183\n",
      "epoch 14 loss: 0.16553866863250732\n",
      "epoch 15 loss: 0.16063350439071655\n",
      "epoch 16 loss: 0.13388782739639282\n",
      "epoch 17 loss: 0.1353641003370285\n",
      "epoch 18 loss: 0.14805209636688232\n",
      "epoch 19 loss: 0.13558664917945862\n",
      "epoch 20 loss: 0.11359108984470367\n",
      "epoch 21 loss: 0.15696901082992554\n",
      "epoch 22 loss: 0.13565820455551147\n",
      "epoch 23 loss: 0.1607935130596161\n",
      "epoch 24 loss: 0.15191029012203217\n",
      "epoch 25 loss: 0.13648368418216705\n",
      "epoch 26 loss: 0.14159458875656128\n",
      "epoch 27 loss: 0.11850137263536453\n",
      "epoch 28 loss: 0.09312273561954498\n",
      "epoch 29 loss: 0.1255294382572174\n",
      "epoch 30 loss: 0.11120184510946274\n",
      "27\n",
      "epoch 1 loss: 0.9146270751953125\n",
      "epoch 2 loss: 0.7691165804862976\n",
      "epoch 3 loss: 0.6201061010360718\n",
      "epoch 4 loss: 0.5701908469200134\n",
      "epoch 5 loss: 0.2908173203468323\n",
      "epoch 6 loss: 0.1724783033132553\n",
      "epoch 7 loss: 0.18268676102161407\n",
      "epoch 8 loss: 0.17124277353286743\n",
      "epoch 9 loss: 0.1567596197128296\n",
      "epoch 10 loss: 0.14109128713607788\n",
      "epoch 11 loss: 0.16333679854869843\n",
      "epoch 12 loss: 0.14317603409290314\n",
      "epoch 13 loss: 0.15650221705436707\n",
      "epoch 14 loss: 0.12212622165679932\n",
      "epoch 15 loss: 0.14103791117668152\n",
      "epoch 16 loss: 0.15828417241573334\n",
      "epoch 17 loss: 0.11983282119035721\n",
      "epoch 18 loss: 0.13210895657539368\n",
      "epoch 19 loss: 0.10707812011241913\n",
      "epoch 20 loss: 0.13913661241531372\n",
      "epoch 21 loss: 0.11144694685935974\n",
      "epoch 22 loss: 0.11075015366077423\n",
      "epoch 23 loss: 0.11737250536680222\n",
      "epoch 24 loss: 0.12322932481765747\n",
      "epoch 25 loss: 0.11485472321510315\n",
      "epoch 26 loss: 0.11711694300174713\n",
      "epoch 27 loss: 0.10358536243438721\n",
      "epoch 28 loss: 0.13433483242988586\n",
      "epoch 29 loss: 0.11020927131175995\n",
      "epoch 30 loss: 0.10651081800460815\n",
      "28\n",
      "epoch 1 loss: 0.8036307096481323\n",
      "epoch 2 loss: 0.7517317533493042\n",
      "epoch 3 loss: 0.5399082899093628\n",
      "epoch 4 loss: 0.3862210214138031\n",
      "epoch 5 loss: 0.18134623765945435\n",
      "epoch 6 loss: 0.17282888293266296\n",
      "epoch 7 loss: 0.20152291655540466\n",
      "epoch 8 loss: 0.15375542640686035\n",
      "epoch 9 loss: 0.165914386510849\n",
      "epoch 10 loss: 0.11654236912727356\n",
      "epoch 11 loss: 0.14915302395820618\n",
      "epoch 12 loss: 0.1602928638458252\n",
      "epoch 13 loss: 0.1951618492603302\n",
      "epoch 14 loss: 0.15923604369163513\n",
      "epoch 15 loss: 0.12060587853193283\n",
      "epoch 16 loss: 0.110623799264431\n",
      "epoch 17 loss: 0.14434891939163208\n",
      "epoch 18 loss: 0.140313521027565\n",
      "epoch 19 loss: 0.1356191337108612\n",
      "epoch 20 loss: 0.15133599936962128\n",
      "epoch 21 loss: 0.09635386615991592\n",
      "epoch 22 loss: 0.10798119753599167\n",
      "epoch 23 loss: 0.1178210973739624\n",
      "epoch 24 loss: 0.0891437828540802\n",
      "epoch 25 loss: 0.10994664579629898\n",
      "epoch 26 loss: 0.12535220384597778\n",
      "epoch 27 loss: 0.10567786544561386\n",
      "epoch 28 loss: 0.10399269312620163\n",
      "epoch 29 loss: 0.14350245893001556\n",
      "epoch 30 loss: 0.1031070128083229\n",
      "29\n",
      "epoch 1 loss: 0.7726913094520569\n",
      "epoch 2 loss: 0.8721697330474854\n",
      "epoch 3 loss: 0.5766780376434326\n",
      "epoch 4 loss: 0.28781163692474365\n",
      "epoch 5 loss: 0.21624740958213806\n",
      "epoch 6 loss: 0.16369815170764923\n",
      "epoch 7 loss: 0.16297151148319244\n",
      "epoch 8 loss: 0.167129248380661\n",
      "epoch 9 loss: 0.1837424337863922\n",
      "epoch 10 loss: 0.1729845404624939\n",
      "epoch 11 loss: 0.1281726360321045\n",
      "epoch 12 loss: 0.11089350283145905\n",
      "epoch 13 loss: 0.1141747310757637\n",
      "epoch 14 loss: 0.10605466365814209\n",
      "epoch 15 loss: 0.10935903340578079\n",
      "epoch 16 loss: 0.11705128103494644\n",
      "epoch 17 loss: 0.15846578776836395\n",
      "epoch 18 loss: 0.1326635479927063\n",
      "epoch 19 loss: 0.12530165910720825\n",
      "epoch 20 loss: 0.11432783305644989\n",
      "epoch 21 loss: 0.1546262800693512\n",
      "epoch 22 loss: 0.1668003350496292\n",
      "epoch 23 loss: 0.12681129574775696\n",
      "epoch 24 loss: 0.1348849982023239\n",
      "epoch 25 loss: 0.08844645321369171\n",
      "epoch 26 loss: 0.11207735538482666\n",
      "epoch 27 loss: 0.12514227628707886\n",
      "epoch 28 loss: 0.11543262004852295\n",
      "epoch 29 loss: 0.11097017675638199\n",
      "epoch 30 loss: 0.11537481844425201\n",
      "30\n",
      "epoch 1 loss: 0.8814441561698914\n",
      "epoch 2 loss: 0.6688675284385681\n",
      "epoch 3 loss: 0.5879008173942566\n",
      "epoch 4 loss: 0.3423905670642853\n",
      "epoch 5 loss: 0.2063770294189453\n",
      "epoch 6 loss: 0.14392685890197754\n",
      "epoch 7 loss: 0.18644021451473236\n",
      "epoch 8 loss: 0.14764797687530518\n",
      "epoch 9 loss: 0.14723290503025055\n",
      "epoch 10 loss: 0.1358775496482849\n",
      "epoch 11 loss: 0.11196251213550568\n",
      "epoch 12 loss: 0.14509211480617523\n",
      "epoch 13 loss: 0.1342715322971344\n",
      "epoch 14 loss: 0.1324099898338318\n",
      "epoch 15 loss: 0.150531604886055\n",
      "epoch 16 loss: 0.14300593733787537\n",
      "epoch 17 loss: 0.16796456277370453\n",
      "epoch 18 loss: 0.10667125880718231\n",
      "epoch 19 loss: 0.16527621448040009\n",
      "epoch 20 loss: 0.13166700303554535\n",
      "epoch 21 loss: 0.1192220076918602\n",
      "epoch 22 loss: 0.09739403426647186\n",
      "epoch 23 loss: 0.11070428043603897\n",
      "epoch 24 loss: 0.13601547479629517\n",
      "epoch 25 loss: 0.11195258796215057\n",
      "epoch 26 loss: 0.10660486668348312\n",
      "epoch 27 loss: 0.13215422630310059\n",
      "epoch 28 loss: 0.09715455770492554\n",
      "epoch 29 loss: 0.10098737478256226\n",
      "epoch 30 loss: 0.10073268413543701\n",
      "31\n",
      "epoch 1 loss: 0.7670026421546936\n",
      "epoch 2 loss: 0.8422286510467529\n",
      "epoch 3 loss: 0.7167028784751892\n",
      "epoch 4 loss: 0.5203237533569336\n",
      "epoch 5 loss: 0.3748222887516022\n",
      "epoch 6 loss: 0.15864983201026917\n",
      "epoch 7 loss: 0.2214442938566208\n",
      "epoch 8 loss: 0.17445100843906403\n",
      "epoch 9 loss: 0.21298977732658386\n",
      "epoch 10 loss: 0.13720235228538513\n",
      "epoch 11 loss: 0.13709740340709686\n",
      "epoch 12 loss: 0.16172944009304047\n",
      "epoch 13 loss: 0.1543121486902237\n",
      "epoch 14 loss: 0.16202913224697113\n",
      "epoch 15 loss: 0.11209826916456223\n",
      "epoch 16 loss: 0.1723364293575287\n",
      "epoch 17 loss: 0.13607163727283478\n",
      "epoch 18 loss: 0.1160026267170906\n",
      "epoch 19 loss: 0.15087813138961792\n",
      "epoch 20 loss: 0.14780589938163757\n",
      "epoch 21 loss: 0.10583379864692688\n",
      "epoch 22 loss: 0.1593163162469864\n",
      "epoch 23 loss: 0.17421846091747284\n",
      "epoch 24 loss: 0.11711364984512329\n",
      "epoch 25 loss: 0.15528693795204163\n",
      "epoch 26 loss: 0.16753961145877838\n",
      "epoch 27 loss: 0.12749886512756348\n",
      "epoch 28 loss: 0.139413520693779\n",
      "epoch 29 loss: 0.11458856612443924\n",
      "epoch 30 loss: 0.11114659905433655\n",
      "32\n",
      "epoch 1 loss: 0.8562186360359192\n",
      "epoch 2 loss: 0.9629704356193542\n",
      "epoch 3 loss: 0.6909399032592773\n",
      "epoch 4 loss: 0.38781240582466125\n",
      "epoch 5 loss: 0.24853336811065674\n",
      "epoch 6 loss: 0.257634699344635\n",
      "epoch 7 loss: 0.16120940446853638\n",
      "epoch 8 loss: 0.17089924216270447\n",
      "epoch 9 loss: 0.12203823775053024\n",
      "epoch 10 loss: 0.13450945913791656\n",
      "epoch 11 loss: 0.14146645367145538\n",
      "epoch 12 loss: 0.15321673452854156\n",
      "epoch 13 loss: 0.11539114266633987\n",
      "epoch 14 loss: 0.11615512520074844\n",
      "epoch 15 loss: 0.1112164705991745\n",
      "epoch 16 loss: 0.11777553707361221\n",
      "epoch 17 loss: 0.13792499899864197\n",
      "epoch 18 loss: 0.09917929768562317\n",
      "epoch 19 loss: 0.09138220548629761\n",
      "epoch 20 loss: 0.14387190341949463\n",
      "epoch 21 loss: 0.08772890269756317\n",
      "epoch 22 loss: 0.09900103509426117\n",
      "epoch 23 loss: 0.1241886168718338\n",
      "epoch 24 loss: 0.10377106815576553\n",
      "epoch 25 loss: 0.11194868385791779\n",
      "epoch 26 loss: 0.10908246785402298\n",
      "epoch 27 loss: 0.1247434988617897\n",
      "epoch 28 loss: 0.1287362277507782\n",
      "epoch 29 loss: 0.11161267012357712\n",
      "epoch 30 loss: 0.06557714194059372\n",
      "33\n",
      "epoch 1 loss: 0.85271155834198\n",
      "epoch 2 loss: 0.703387975692749\n",
      "epoch 3 loss: 0.3693830370903015\n",
      "epoch 4 loss: 0.2829238772392273\n",
      "epoch 5 loss: 0.2419804185628891\n",
      "epoch 6 loss: 0.1819385588169098\n",
      "epoch 7 loss: 0.16448085010051727\n",
      "epoch 8 loss: 0.13308492302894592\n",
      "epoch 9 loss: 0.1590687483549118\n",
      "epoch 10 loss: 0.15123194456100464\n",
      "epoch 11 loss: 0.14290635287761688\n",
      "epoch 12 loss: 0.12207677960395813\n",
      "epoch 13 loss: 0.1311231553554535\n",
      "epoch 14 loss: 0.14852793514728546\n",
      "epoch 15 loss: 0.12341814488172531\n",
      "epoch 16 loss: 0.14467157423496246\n",
      "epoch 17 loss: 0.13823430240154266\n",
      "epoch 18 loss: 0.12872126698493958\n",
      "epoch 19 loss: 0.1334225833415985\n",
      "epoch 20 loss: 0.14863504469394684\n",
      "epoch 21 loss: 0.10568703711032867\n",
      "epoch 22 loss: 0.11472465842962265\n",
      "epoch 23 loss: 0.12849709391593933\n",
      "epoch 24 loss: 0.10919352620840073\n",
      "epoch 25 loss: 0.1051623746752739\n",
      "epoch 26 loss: 0.1103837862610817\n",
      "epoch 27 loss: 0.11793749034404755\n",
      "epoch 28 loss: 0.0986056998372078\n",
      "epoch 29 loss: 0.11910778284072876\n",
      "epoch 30 loss: 0.10073097050189972\n",
      "34\n",
      "epoch 1 loss: 1.0088056325912476\n",
      "epoch 2 loss: 0.7785851359367371\n",
      "epoch 3 loss: 0.6925005316734314\n",
      "epoch 4 loss: 0.6465602517127991\n",
      "epoch 5 loss: 0.2788723111152649\n",
      "epoch 6 loss: 0.1864285171031952\n",
      "epoch 7 loss: 0.16028551757335663\n",
      "epoch 8 loss: 0.1774686872959137\n",
      "epoch 9 loss: 0.12774795293807983\n",
      "epoch 10 loss: 0.1648872047662735\n",
      "epoch 11 loss: 0.1613290011882782\n",
      "epoch 12 loss: 0.15293344855308533\n",
      "epoch 13 loss: 0.13319960236549377\n",
      "epoch 14 loss: 0.1277725249528885\n",
      "epoch 15 loss: 0.1246584951877594\n",
      "epoch 16 loss: 0.16202902793884277\n",
      "epoch 17 loss: 0.14455778896808624\n",
      "epoch 18 loss: 0.1305549293756485\n",
      "epoch 19 loss: 0.11709361523389816\n",
      "epoch 20 loss: 0.1632114052772522\n",
      "epoch 21 loss: 0.11078092455863953\n",
      "epoch 22 loss: 0.10287538170814514\n",
      "epoch 23 loss: 0.0961867943406105\n",
      "epoch 24 loss: 0.1479521542787552\n",
      "epoch 25 loss: 0.10348089039325714\n",
      "epoch 26 loss: 0.11927489191293716\n",
      "epoch 27 loss: 0.12560845911502838\n",
      "epoch 28 loss: 0.10907945781946182\n",
      "epoch 29 loss: 0.12353108078241348\n",
      "epoch 30 loss: 0.11691734194755554\n",
      "35\n",
      "epoch 1 loss: 1.0438114404678345\n",
      "epoch 2 loss: 0.7331690788269043\n",
      "epoch 3 loss: 0.4456256628036499\n",
      "epoch 4 loss: 0.22469724714756012\n",
      "epoch 5 loss: 0.14508262276649475\n",
      "epoch 6 loss: 0.16950371861457825\n",
      "epoch 7 loss: 0.14158329367637634\n",
      "epoch 8 loss: 0.17510320246219635\n",
      "epoch 9 loss: 0.16142164170742035\n",
      "epoch 10 loss: 0.1858711838722229\n",
      "epoch 11 loss: 0.15009234845638275\n",
      "epoch 12 loss: 0.1313144862651825\n",
      "epoch 13 loss: 0.1690254807472229\n",
      "epoch 14 loss: 0.1632401943206787\n",
      "epoch 15 loss: 0.13295024633407593\n",
      "epoch 16 loss: 0.12188505381345749\n",
      "epoch 17 loss: 0.13787530362606049\n",
      "epoch 18 loss: 0.12118986248970032\n",
      "epoch 19 loss: 0.1433490514755249\n",
      "epoch 20 loss: 0.12771612405776978\n",
      "epoch 21 loss: 0.12431354820728302\n",
      "epoch 22 loss: 0.12356396019458771\n",
      "epoch 23 loss: 0.1107996329665184\n",
      "epoch 24 loss: 0.07761537283658981\n",
      "epoch 25 loss: 0.19900932908058167\n",
      "epoch 26 loss: 0.14147813618183136\n",
      "epoch 27 loss: 0.13038001954555511\n",
      "epoch 28 loss: 0.1201707124710083\n",
      "epoch 29 loss: 0.09890102595090866\n",
      "epoch 30 loss: 0.13035713136196136\n",
      "36\n",
      "epoch 1 loss: 0.6954435110092163\n",
      "epoch 2 loss: 0.7825992703437805\n",
      "epoch 3 loss: 0.46027863025665283\n",
      "epoch 4 loss: 0.3844556510448456\n",
      "epoch 5 loss: 0.28868401050567627\n",
      "epoch 6 loss: 0.1256021112203598\n",
      "epoch 7 loss: 0.14844004809856415\n",
      "epoch 8 loss: 0.1394580602645874\n",
      "epoch 9 loss: 0.13793222606182098\n",
      "epoch 10 loss: 0.17264339327812195\n",
      "epoch 11 loss: 0.18656237423419952\n",
      "epoch 12 loss: 0.1458081752061844\n",
      "epoch 13 loss: 0.1534411907196045\n",
      "epoch 14 loss: 0.22536101937294006\n",
      "epoch 15 loss: 0.15987704694271088\n",
      "epoch 16 loss: 0.11501292139291763\n",
      "epoch 17 loss: 0.19802846014499664\n",
      "epoch 18 loss: 0.11996877938508987\n",
      "epoch 19 loss: 0.1064271628856659\n",
      "epoch 20 loss: 0.11243103444576263\n",
      "epoch 21 loss: 0.13684654235839844\n",
      "epoch 22 loss: 0.1524425894021988\n",
      "epoch 23 loss: 0.10730107873678207\n",
      "epoch 24 loss: 0.14034485816955566\n",
      "epoch 25 loss: 0.13870061933994293\n",
      "epoch 26 loss: 0.11948098242282867\n",
      "epoch 27 loss: 0.11365501582622528\n",
      "epoch 28 loss: 0.10597250610589981\n",
      "epoch 29 loss: 0.1367214322090149\n",
      "epoch 30 loss: 0.1436128169298172\n",
      "37\n",
      "epoch 1 loss: 0.908607006072998\n",
      "epoch 2 loss: 0.9786378145217896\n",
      "epoch 3 loss: 0.6728527545928955\n",
      "epoch 4 loss: 0.5449332594871521\n",
      "epoch 5 loss: 0.2914719581604004\n",
      "epoch 6 loss: 0.15307393670082092\n",
      "epoch 7 loss: 0.16777843236923218\n",
      "epoch 8 loss: 0.16305403411388397\n",
      "epoch 9 loss: 0.20111973583698273\n",
      "epoch 10 loss: 0.16101138293743134\n",
      "epoch 11 loss: 0.12999598681926727\n",
      "epoch 12 loss: 0.1299159824848175\n",
      "epoch 13 loss: 0.12894417345523834\n",
      "epoch 14 loss: 0.1325553059577942\n",
      "epoch 15 loss: 0.18152906000614166\n",
      "epoch 16 loss: 0.16827650368213654\n",
      "epoch 17 loss: 0.15545213222503662\n",
      "epoch 18 loss: 0.11261213570833206\n",
      "epoch 19 loss: 0.1330585777759552\n",
      "epoch 20 loss: 0.1272929608821869\n",
      "epoch 21 loss: 0.12592537701129913\n",
      "epoch 22 loss: 0.16129983961582184\n",
      "epoch 23 loss: 0.12185791879892349\n",
      "epoch 24 loss: 0.18557985126972198\n",
      "epoch 25 loss: 0.15343433618545532\n",
      "epoch 26 loss: 0.11596984416246414\n",
      "epoch 27 loss: 0.1218881607055664\n",
      "epoch 28 loss: 0.10561297833919525\n",
      "epoch 29 loss: 0.11906734853982925\n",
      "epoch 30 loss: 0.12740643322467804\n",
      "38\n",
      "epoch 1 loss: 0.992241621017456\n",
      "epoch 2 loss: 0.7532444596290588\n",
      "epoch 3 loss: 0.3851933479309082\n",
      "epoch 4 loss: 0.2692877948284149\n",
      "epoch 5 loss: 0.23450279235839844\n",
      "epoch 6 loss: 0.13762421905994415\n",
      "epoch 7 loss: 0.1287539154291153\n",
      "epoch 8 loss: 0.12954238057136536\n",
      "epoch 9 loss: 0.15728400647640228\n",
      "epoch 10 loss: 0.13263139128684998\n",
      "epoch 11 loss: 0.13801242411136627\n",
      "epoch 12 loss: 0.16819415986537933\n",
      "epoch 13 loss: 0.14970679581165314\n",
      "epoch 14 loss: 0.12181774526834488\n",
      "epoch 15 loss: 0.10736650228500366\n",
      "epoch 16 loss: 0.12909922003746033\n",
      "epoch 17 loss: 0.09144911915063858\n",
      "epoch 18 loss: 0.11924543976783752\n",
      "epoch 19 loss: 0.13373586535453796\n",
      "epoch 20 loss: 0.09157560765743256\n",
      "epoch 21 loss: 0.12743887305259705\n",
      "epoch 22 loss: 0.13871560990810394\n",
      "epoch 23 loss: 0.12820056080818176\n",
      "epoch 24 loss: 0.09408579021692276\n",
      "epoch 25 loss: 0.11748326569795609\n",
      "epoch 26 loss: 0.11380027234554291\n",
      "epoch 27 loss: 0.09091399610042572\n",
      "epoch 28 loss: 0.0925631895661354\n",
      "epoch 29 loss: 0.09520872682332993\n",
      "epoch 30 loss: 0.12895965576171875\n",
      "39\n",
      "epoch 1 loss: 1.1158146858215332\n",
      "epoch 2 loss: 0.7418251633644104\n",
      "epoch 3 loss: 0.6581348180770874\n",
      "epoch 4 loss: 0.3360070586204529\n",
      "epoch 5 loss: 0.20884984731674194\n",
      "epoch 6 loss: 0.151309072971344\n",
      "epoch 7 loss: 0.16452573239803314\n",
      "epoch 8 loss: 0.1533428579568863\n",
      "epoch 9 loss: 0.15250593423843384\n",
      "epoch 10 loss: 0.13283348083496094\n",
      "epoch 11 loss: 0.12489750236272812\n",
      "epoch 12 loss: 0.1549554318189621\n",
      "epoch 13 loss: 0.11321767419576645\n",
      "epoch 14 loss: 0.1439773291349411\n",
      "epoch 15 loss: 0.12117717415094376\n",
      "epoch 16 loss: 0.14205552637577057\n",
      "epoch 17 loss: 0.12270206958055496\n",
      "epoch 18 loss: 0.13797812163829803\n",
      "epoch 19 loss: 0.10305678099393845\n",
      "epoch 20 loss: 0.13018232583999634\n",
      "epoch 21 loss: 0.13300301134586334\n",
      "epoch 22 loss: 0.15224069356918335\n",
      "epoch 23 loss: 0.11144138872623444\n",
      "epoch 24 loss: 0.1337418258190155\n",
      "epoch 25 loss: 0.10468851029872894\n",
      "epoch 26 loss: 0.12969516217708588\n",
      "epoch 27 loss: 0.13058795034885406\n",
      "epoch 28 loss: 0.12021978944540024\n",
      "epoch 29 loss: 0.12542523443698883\n",
      "epoch 30 loss: 0.10801039636135101\n",
      "40\n",
      "epoch 1 loss: 0.8376765847206116\n",
      "epoch 2 loss: 0.6277579665184021\n",
      "epoch 3 loss: 0.5242181420326233\n",
      "epoch 4 loss: 0.26372912526130676\n",
      "epoch 5 loss: 0.21825115382671356\n",
      "epoch 6 loss: 0.18143193423748016\n",
      "epoch 7 loss: 0.16441941261291504\n",
      "epoch 8 loss: 0.14748209714889526\n",
      "epoch 9 loss: 0.15978668630123138\n",
      "epoch 10 loss: 0.15855680406093597\n",
      "epoch 11 loss: 0.12331221997737885\n",
      "epoch 12 loss: 0.1376861035823822\n",
      "epoch 13 loss: 0.15444380044937134\n",
      "epoch 14 loss: 0.1715211421251297\n",
      "epoch 15 loss: 0.1711089313030243\n",
      "epoch 16 loss: 0.1505756676197052\n",
      "epoch 17 loss: 0.1412743628025055\n",
      "epoch 18 loss: 0.15589077770709991\n",
      "epoch 19 loss: 0.1308603733778\n",
      "epoch 20 loss: 0.12762854993343353\n",
      "epoch 21 loss: 0.1292167454957962\n",
      "epoch 22 loss: 0.14405685663223267\n",
      "epoch 23 loss: 0.11150404810905457\n",
      "epoch 24 loss: 0.10967212170362473\n",
      "epoch 25 loss: 0.11307317763566971\n",
      "epoch 26 loss: 0.1008167490363121\n",
      "epoch 27 loss: 0.15051890909671783\n",
      "epoch 28 loss: 0.12572596967220306\n",
      "epoch 29 loss: 0.137384295463562\n",
      "epoch 30 loss: 0.11742296814918518\n",
      "41\n",
      "epoch 1 loss: 0.9731045961380005\n",
      "epoch 2 loss: 0.6025088429450989\n",
      "epoch 3 loss: 0.388612300157547\n",
      "epoch 4 loss: 0.252933144569397\n",
      "epoch 5 loss: 0.2965458333492279\n",
      "epoch 6 loss: 0.15023617446422577\n",
      "epoch 7 loss: 0.20032231509685516\n",
      "epoch 8 loss: 0.17530928552150726\n",
      "epoch 9 loss: 0.13756854832172394\n",
      "epoch 10 loss: 0.11741971224546432\n",
      "epoch 11 loss: 0.15080247819423676\n",
      "epoch 12 loss: 0.14962878823280334\n",
      "epoch 13 loss: 0.15009723603725433\n",
      "epoch 14 loss: 0.1600729376077652\n",
      "epoch 15 loss: 0.15192660689353943\n",
      "epoch 16 loss: 0.14018991589546204\n",
      "epoch 17 loss: 0.11759547889232635\n",
      "epoch 18 loss: 0.17007671296596527\n",
      "epoch 19 loss: 0.11918962746858597\n",
      "epoch 20 loss: 0.0986817330121994\n",
      "epoch 21 loss: 0.12182321399450302\n",
      "epoch 22 loss: 0.14106111228466034\n",
      "epoch 23 loss: 0.1431075483560562\n",
      "epoch 24 loss: 0.12946532666683197\n",
      "epoch 25 loss: 0.1308521032333374\n",
      "epoch 26 loss: 0.12066042423248291\n",
      "epoch 27 loss: 0.0895862877368927\n",
      "epoch 28 loss: 0.10925423353910446\n",
      "epoch 29 loss: 0.1041686087846756\n",
      "epoch 30 loss: 0.1260354369878769\n",
      "42\n",
      "epoch 1 loss: 0.8858309388160706\n",
      "epoch 2 loss: 0.83711838722229\n",
      "epoch 3 loss: 0.3811914324760437\n",
      "epoch 4 loss: 0.28610098361968994\n",
      "epoch 5 loss: 0.18768416345119476\n",
      "epoch 6 loss: 0.18440105020999908\n",
      "epoch 7 loss: 0.19372420012950897\n",
      "epoch 8 loss: 0.14503534138202667\n",
      "epoch 9 loss: 0.13552531599998474\n",
      "epoch 10 loss: 0.1597805917263031\n",
      "epoch 11 loss: 0.14422199130058289\n",
      "epoch 12 loss: 0.1828860193490982\n",
      "epoch 13 loss: 0.10281354933977127\n",
      "epoch 14 loss: 0.11664401739835739\n",
      "epoch 15 loss: 0.12880676984786987\n",
      "epoch 16 loss: 0.12717659771442413\n",
      "epoch 17 loss: 0.1343284547328949\n",
      "epoch 18 loss: 0.14783591032028198\n",
      "epoch 19 loss: 0.13289615511894226\n",
      "epoch 20 loss: 0.11181237548589706\n",
      "epoch 21 loss: 0.11069823801517487\n",
      "epoch 22 loss: 0.12699176371097565\n",
      "epoch 23 loss: 0.10968689620494843\n",
      "epoch 24 loss: 0.10592518001794815\n",
      "epoch 25 loss: 0.13067717850208282\n",
      "epoch 26 loss: 0.1262233555316925\n",
      "epoch 27 loss: 0.11078210175037384\n",
      "epoch 28 loss: 0.10212376713752747\n",
      "epoch 29 loss: 0.10740701109170914\n",
      "epoch 30 loss: 0.1158645823597908\n",
      "43\n",
      "epoch 1 loss: 0.9545850157737732\n",
      "epoch 2 loss: 0.5630955100059509\n",
      "epoch 3 loss: 0.5417708158493042\n",
      "epoch 4 loss: 0.2805790901184082\n",
      "epoch 5 loss: 0.2833769619464874\n",
      "epoch 6 loss: 0.1447763442993164\n",
      "epoch 7 loss: 0.15395388007164001\n",
      "epoch 8 loss: 0.17694692313671112\n",
      "epoch 9 loss: 0.12284158915281296\n",
      "epoch 10 loss: 0.19048066437244415\n",
      "epoch 11 loss: 0.1611209511756897\n",
      "epoch 12 loss: 0.1750270128250122\n",
      "epoch 13 loss: 0.16262833774089813\n",
      "epoch 14 loss: 0.12445750087499619\n",
      "epoch 15 loss: 0.11778581887483597\n",
      "epoch 16 loss: 0.17676308751106262\n",
      "epoch 17 loss: 0.139304056763649\n",
      "epoch 18 loss: 0.13541048765182495\n",
      "epoch 19 loss: 0.11676311492919922\n",
      "epoch 20 loss: 0.12300378829240799\n",
      "epoch 21 loss: 0.16233377158641815\n",
      "epoch 22 loss: 0.12750311195850372\n",
      "epoch 23 loss: 0.13318262994289398\n",
      "epoch 24 loss: 0.12522852420806885\n",
      "epoch 25 loss: 0.11927901953458786\n",
      "epoch 26 loss: 0.1267160177230835\n",
      "epoch 27 loss: 0.11443988978862762\n",
      "epoch 28 loss: 0.12038718163967133\n",
      "epoch 29 loss: 0.1352386772632599\n",
      "epoch 30 loss: 0.135295107960701\n",
      "44\n",
      "epoch 1 loss: 0.8443282842636108\n",
      "epoch 2 loss: 0.7804270386695862\n",
      "epoch 3 loss: 0.6143487691879272\n",
      "epoch 4 loss: 0.38218602538108826\n",
      "epoch 5 loss: 0.23665618896484375\n",
      "epoch 6 loss: 0.2093319594860077\n",
      "epoch 7 loss: 0.15307721495628357\n",
      "epoch 8 loss: 0.18291576206684113\n",
      "epoch 9 loss: 0.18486198782920837\n",
      "epoch 10 loss: 0.15736855566501617\n",
      "epoch 11 loss: 0.13391077518463135\n",
      "epoch 12 loss: 0.10839030146598816\n",
      "epoch 13 loss: 0.1575564295053482\n",
      "epoch 14 loss: 0.1446225792169571\n",
      "epoch 15 loss: 0.14201177656650543\n",
      "epoch 16 loss: 0.11169493943452835\n",
      "epoch 17 loss: 0.12362776696681976\n",
      "epoch 18 loss: 0.17161999642848969\n",
      "epoch 19 loss: 0.11839521676301956\n",
      "epoch 20 loss: 0.12897233664989471\n",
      "epoch 21 loss: 0.12774758040905\n",
      "epoch 22 loss: 0.16069817543029785\n",
      "epoch 23 loss: 0.1243843138217926\n",
      "epoch 24 loss: 0.12381478399038315\n",
      "epoch 25 loss: 0.11109565198421478\n",
      "epoch 26 loss: 0.10632488876581192\n",
      "epoch 27 loss: 0.1096351370215416\n",
      "epoch 28 loss: 0.12841679155826569\n",
      "epoch 29 loss: 0.09761622548103333\n",
      "epoch 30 loss: 0.11252722889184952\n",
      "45\n",
      "epoch 1 loss: 1.2328394651412964\n",
      "epoch 2 loss: 0.9912857413291931\n",
      "epoch 3 loss: 0.8527895212173462\n",
      "epoch 4 loss: 0.4587768018245697\n",
      "epoch 5 loss: 0.25712549686431885\n",
      "epoch 6 loss: 0.16665546596050262\n",
      "epoch 7 loss: 0.158173605799675\n",
      "epoch 8 loss: 0.13666686415672302\n",
      "epoch 9 loss: 0.14093534648418427\n",
      "epoch 10 loss: 0.1681804656982422\n",
      "epoch 11 loss: 0.14919447898864746\n",
      "epoch 12 loss: 0.1506863683462143\n",
      "epoch 13 loss: 0.14266306161880493\n",
      "epoch 14 loss: 0.15601478517055511\n",
      "epoch 15 loss: 0.13984940946102142\n",
      "epoch 16 loss: 0.12042386829853058\n",
      "epoch 17 loss: 0.1388489007949829\n",
      "epoch 18 loss: 0.12246962636709213\n",
      "epoch 19 loss: 0.10152921825647354\n",
      "epoch 20 loss: 0.10819739103317261\n",
      "epoch 21 loss: 0.10852862149477005\n",
      "epoch 22 loss: 0.10881698131561279\n",
      "epoch 23 loss: 0.13169927895069122\n",
      "epoch 24 loss: 0.14249774813652039\n",
      "epoch 25 loss: 0.13765214383602142\n",
      "epoch 26 loss: 0.13754354417324066\n",
      "epoch 27 loss: 0.11488298326730728\n",
      "epoch 28 loss: 0.08919826149940491\n",
      "epoch 29 loss: 0.10921899229288101\n",
      "epoch 30 loss: 0.12155803292989731\n",
      "46\n",
      "epoch 1 loss: 1.058643102645874\n",
      "epoch 2 loss: 0.9053950309753418\n",
      "epoch 3 loss: 0.4437781274318695\n",
      "epoch 4 loss: 0.2673516571521759\n",
      "epoch 5 loss: 0.22115977108478546\n",
      "epoch 6 loss: 0.18376508355140686\n",
      "epoch 7 loss: 0.1983940154314041\n",
      "epoch 8 loss: 0.1758936494588852\n",
      "epoch 9 loss: 0.122098408639431\n",
      "epoch 10 loss: 0.10442620515823364\n",
      "epoch 11 loss: 0.11843819171190262\n",
      "epoch 12 loss: 0.1367126703262329\n",
      "epoch 13 loss: 0.16449321806430817\n",
      "epoch 14 loss: 0.1361919492483139\n",
      "epoch 15 loss: 0.15226663649082184\n",
      "epoch 16 loss: 0.12860825657844543\n",
      "epoch 17 loss: 0.14460358023643494\n",
      "epoch 18 loss: 0.13757111132144928\n",
      "epoch 19 loss: 0.1007302924990654\n",
      "epoch 20 loss: 0.11992494016885757\n",
      "epoch 21 loss: 0.1252322494983673\n",
      "epoch 22 loss: 0.10001350939273834\n",
      "epoch 23 loss: 0.10424619913101196\n",
      "epoch 24 loss: 0.11892279982566833\n",
      "epoch 25 loss: 0.1218157634139061\n",
      "epoch 26 loss: 0.13787446916103363\n",
      "epoch 27 loss: 0.12594866752624512\n",
      "epoch 28 loss: 0.1160903349518776\n",
      "epoch 29 loss: 0.11745899170637131\n",
      "epoch 30 loss: 0.13981609046459198\n",
      "47\n",
      "epoch 1 loss: 0.9522068500518799\n",
      "epoch 2 loss: 0.6234523057937622\n",
      "epoch 3 loss: 0.5229649543762207\n",
      "epoch 4 loss: 0.24463622272014618\n",
      "epoch 5 loss: 0.19477054476737976\n",
      "epoch 6 loss: 0.18331733345985413\n",
      "epoch 7 loss: 0.146004781126976\n",
      "epoch 8 loss: 0.1626615822315216\n",
      "epoch 9 loss: 0.1578722447156906\n",
      "epoch 10 loss: 0.14342015981674194\n",
      "epoch 11 loss: 0.13918964564800262\n",
      "epoch 12 loss: 0.13322442770004272\n",
      "epoch 13 loss: 0.10646826028823853\n",
      "epoch 14 loss: 0.12802891433238983\n",
      "epoch 15 loss: 0.1394117772579193\n",
      "epoch 16 loss: 0.1356758177280426\n",
      "epoch 17 loss: 0.1576320379972458\n",
      "epoch 18 loss: 0.11157083511352539\n",
      "epoch 19 loss: 0.09928707778453827\n",
      "epoch 20 loss: 0.13745304942131042\n",
      "epoch 21 loss: 0.14563103020191193\n",
      "epoch 22 loss: 0.0945541188120842\n",
      "epoch 23 loss: 0.12201644480228424\n",
      "epoch 24 loss: 0.11409231275320053\n",
      "epoch 25 loss: 0.09741377085447311\n",
      "epoch 26 loss: 0.14291970431804657\n",
      "epoch 27 loss: 0.09513118863105774\n",
      "epoch 28 loss: 0.0901423990726471\n",
      "epoch 29 loss: 0.09837982803583145\n",
      "epoch 30 loss: 0.1091943010687828\n",
      "48\n",
      "epoch 1 loss: 0.8452484011650085\n",
      "epoch 2 loss: 0.862329363822937\n",
      "epoch 3 loss: 0.5700680017471313\n",
      "epoch 4 loss: 0.2701190412044525\n",
      "epoch 5 loss: 0.2445247918367386\n",
      "epoch 6 loss: 0.19253145158290863\n",
      "epoch 7 loss: 0.14402592182159424\n",
      "epoch 8 loss: 0.14893566071987152\n",
      "epoch 9 loss: 0.14153216779232025\n",
      "epoch 10 loss: 0.11959310621023178\n",
      "epoch 11 loss: 0.13847148418426514\n",
      "epoch 12 loss: 0.11419457942247391\n",
      "epoch 13 loss: 0.1273982971906662\n",
      "epoch 14 loss: 0.1351318359375\n",
      "epoch 15 loss: 0.1836620271205902\n",
      "epoch 16 loss: 0.15377117693424225\n",
      "epoch 17 loss: 0.10968847572803497\n",
      "epoch 18 loss: 0.1306753009557724\n",
      "epoch 19 loss: 0.14955094456672668\n",
      "epoch 20 loss: 0.12364024668931961\n",
      "epoch 21 loss: 0.11497167497873306\n",
      "epoch 22 loss: 0.105741485953331\n",
      "epoch 23 loss: 0.12148232012987137\n",
      "epoch 24 loss: 0.11747399717569351\n",
      "epoch 25 loss: 0.12634196877479553\n",
      "epoch 26 loss: 0.10000361502170563\n",
      "epoch 27 loss: 0.12385588139295578\n",
      "epoch 28 loss: 0.11183806508779526\n",
      "epoch 29 loss: 0.12026820331811905\n",
      "epoch 30 loss: 0.11516489088535309\n",
      "49\n",
      "epoch 1 loss: 1.149699091911316\n",
      "epoch 2 loss: 0.9037231802940369\n",
      "epoch 3 loss: 0.3509877622127533\n",
      "epoch 4 loss: 0.32213932275772095\n",
      "epoch 5 loss: 0.21499082446098328\n",
      "epoch 6 loss: 0.16223962604999542\n",
      "epoch 7 loss: 0.16135714948177338\n",
      "epoch 8 loss: 0.14182732999324799\n",
      "epoch 9 loss: 0.13968434929847717\n",
      "epoch 10 loss: 0.13000760972499847\n",
      "epoch 11 loss: 0.1561710089445114\n",
      "epoch 12 loss: 0.1595010906457901\n",
      "epoch 13 loss: 0.12258455902338028\n",
      "epoch 14 loss: 0.10180801898241043\n",
      "epoch 15 loss: 0.1466701328754425\n",
      "epoch 16 loss: 0.13886921107769012\n",
      "epoch 17 loss: 0.13724882900714874\n",
      "epoch 18 loss: 0.15035325288772583\n",
      "epoch 19 loss: 0.12910698354244232\n",
      "epoch 20 loss: 0.14523258805274963\n",
      "epoch 21 loss: 0.15277697145938873\n",
      "epoch 22 loss: 0.19391602277755737\n",
      "epoch 23 loss: 0.10840173810720444\n",
      "epoch 24 loss: 0.12421303987503052\n",
      "epoch 25 loss: 0.1409624218940735\n",
      "epoch 26 loss: 0.12390043586492538\n",
      "epoch 27 loss: 0.12058643996715546\n",
      "epoch 28 loss: 0.11664752662181854\n",
      "epoch 29 loss: 0.10959617793560028\n",
      "epoch 30 loss: 0.10121084749698639\n",
      "50\n",
      "epoch 1 loss: 0.9690145254135132\n",
      "epoch 2 loss: 0.6701972484588623\n",
      "epoch 3 loss: 0.4172903001308441\n",
      "epoch 4 loss: 0.29003897309303284\n",
      "epoch 5 loss: 0.2114768922328949\n",
      "epoch 6 loss: 0.26958411931991577\n",
      "epoch 7 loss: 0.17527088522911072\n",
      "epoch 8 loss: 0.16655759513378143\n",
      "epoch 9 loss: 0.17592723667621613\n",
      "epoch 10 loss: 0.15170176327228546\n",
      "epoch 11 loss: 0.1612718552350998\n",
      "epoch 12 loss: 0.10865698754787445\n",
      "epoch 13 loss: 0.13259361684322357\n",
      "epoch 14 loss: 0.1350131630897522\n",
      "epoch 15 loss: 0.13934741914272308\n",
      "epoch 16 loss: 0.16116774082183838\n",
      "epoch 17 loss: 0.13435524702072144\n",
      "epoch 18 loss: 0.1372930109500885\n",
      "epoch 19 loss: 0.1285615712404251\n",
      "epoch 20 loss: 0.1187695860862732\n",
      "epoch 21 loss: 0.11361975967884064\n",
      "epoch 22 loss: 0.12267182022333145\n",
      "epoch 23 loss: 0.11682198196649551\n",
      "epoch 24 loss: 0.11619377136230469\n",
      "epoch 25 loss: 0.12183123081922531\n",
      "epoch 26 loss: 0.10511032491922379\n",
      "epoch 27 loss: 0.10747653245925903\n",
      "epoch 28 loss: 0.10057438164949417\n",
      "epoch 29 loss: 0.13608692586421967\n",
      "epoch 30 loss: 0.1062985211610794\n",
      "51\n",
      "epoch 1 loss: 0.8537824153900146\n",
      "epoch 2 loss: 0.6382367014884949\n",
      "epoch 3 loss: 0.5045515894889832\n",
      "epoch 4 loss: 0.323442280292511\n",
      "epoch 5 loss: 0.23842038214206696\n",
      "epoch 6 loss: 0.1893465220928192\n",
      "epoch 7 loss: 0.1746775060892105\n",
      "epoch 8 loss: 0.14435382187366486\n",
      "epoch 9 loss: 0.16119548678398132\n",
      "epoch 10 loss: 0.14066381752490997\n",
      "epoch 11 loss: 0.12762504816055298\n",
      "epoch 12 loss: 0.13437607884407043\n",
      "epoch 13 loss: 0.13763445615768433\n",
      "epoch 14 loss: 0.12879282236099243\n",
      "epoch 15 loss: 0.12917256355285645\n",
      "epoch 16 loss: 0.17477087676525116\n",
      "epoch 17 loss: 0.166830912232399\n",
      "epoch 18 loss: 0.12086334824562073\n",
      "epoch 19 loss: 0.11343845725059509\n",
      "epoch 20 loss: 0.13466763496398926\n",
      "epoch 21 loss: 0.11930987983942032\n",
      "epoch 22 loss: 0.11658674478530884\n",
      "epoch 23 loss: 0.10777109116315842\n",
      "epoch 24 loss: 0.12284306436777115\n",
      "epoch 25 loss: 0.11804641038179398\n",
      "epoch 26 loss: 0.13904865086078644\n",
      "epoch 27 loss: 0.12472116947174072\n",
      "epoch 28 loss: 0.16582489013671875\n",
      "epoch 29 loss: 0.1146945059299469\n",
      "epoch 30 loss: 0.09748225659132004\n",
      "52\n",
      "epoch 1 loss: 0.7982102632522583\n",
      "epoch 2 loss: 0.7878510355949402\n",
      "epoch 3 loss: 0.5422202944755554\n",
      "epoch 4 loss: 0.3090861439704895\n",
      "epoch 5 loss: 0.1694580316543579\n",
      "epoch 6 loss: 0.17153140902519226\n",
      "epoch 7 loss: 0.1637534201145172\n",
      "epoch 8 loss: 0.18277397751808167\n",
      "epoch 9 loss: 0.1578809916973114\n",
      "epoch 10 loss: 0.19439378380775452\n",
      "epoch 11 loss: 0.15453557670116425\n",
      "epoch 12 loss: 0.1126483753323555\n",
      "epoch 13 loss: 0.15174651145935059\n",
      "epoch 14 loss: 0.12788520753383636\n",
      "epoch 15 loss: 0.10978249460458755\n",
      "epoch 16 loss: 0.13264967501163483\n",
      "epoch 17 loss: 0.0902460366487503\n",
      "epoch 18 loss: 0.13155679404735565\n",
      "epoch 19 loss: 0.11066998541355133\n",
      "epoch 20 loss: 0.09885262697935104\n",
      "epoch 21 loss: 0.08992567658424377\n",
      "epoch 22 loss: 0.16668030619621277\n",
      "epoch 23 loss: 0.14104603230953217\n",
      "epoch 24 loss: 0.09938373416662216\n",
      "epoch 25 loss: 0.10169566422700882\n",
      "epoch 26 loss: 0.0960487574338913\n",
      "epoch 27 loss: 0.11103881150484085\n",
      "epoch 28 loss: 0.14961135387420654\n",
      "epoch 29 loss: 0.11344416439533234\n",
      "epoch 30 loss: 0.09749727696180344\n",
      "53\n",
      "epoch 1 loss: 1.0919362306594849\n",
      "epoch 2 loss: 0.7315862774848938\n",
      "epoch 3 loss: 0.581874430179596\n",
      "epoch 4 loss: 0.33516329526901245\n",
      "epoch 5 loss: 0.24294045567512512\n",
      "epoch 6 loss: 0.17664062976837158\n",
      "epoch 7 loss: 0.17683687806129456\n",
      "epoch 8 loss: 0.14023296535015106\n",
      "epoch 9 loss: 0.16167770326137543\n",
      "epoch 10 loss: 0.19490259885787964\n",
      "epoch 11 loss: 0.12344831228256226\n",
      "epoch 12 loss: 0.1173095554113388\n",
      "epoch 13 loss: 0.12442069500684738\n",
      "epoch 14 loss: 0.15557286143302917\n",
      "epoch 15 loss: 0.14443501830101013\n",
      "epoch 16 loss: 0.14924083650112152\n",
      "epoch 17 loss: 0.14065460860729218\n",
      "epoch 18 loss: 0.12668786942958832\n",
      "epoch 19 loss: 0.12749505043029785\n",
      "epoch 20 loss: 0.14452368021011353\n",
      "epoch 21 loss: 0.14353494346141815\n",
      "epoch 22 loss: 0.11209073662757874\n",
      "epoch 23 loss: 0.09875882416963577\n",
      "epoch 24 loss: 0.13593712449073792\n",
      "epoch 25 loss: 0.1290089339017868\n",
      "epoch 26 loss: 0.14460138976573944\n",
      "epoch 27 loss: 0.11360473185777664\n",
      "epoch 28 loss: 0.14928939938545227\n",
      "epoch 29 loss: 0.15532760322093964\n",
      "epoch 30 loss: 0.10849004238843918\n",
      "54\n",
      "epoch 1 loss: 0.7085780501365662\n",
      "epoch 2 loss: 0.6269108057022095\n",
      "epoch 3 loss: 0.6514757871627808\n",
      "epoch 4 loss: 0.3533856272697449\n",
      "epoch 5 loss: 0.28324437141418457\n",
      "epoch 6 loss: 0.18152576684951782\n",
      "epoch 7 loss: 0.1545577347278595\n",
      "epoch 8 loss: 0.18023519217967987\n",
      "epoch 9 loss: 0.1378369927406311\n",
      "epoch 10 loss: 0.16641740500926971\n",
      "epoch 11 loss: 0.15277090668678284\n",
      "epoch 12 loss: 0.13896557688713074\n",
      "epoch 13 loss: 0.15825961530208588\n",
      "epoch 14 loss: 0.13903969526290894\n",
      "epoch 15 loss: 0.14471012353897095\n",
      "epoch 16 loss: 0.14273320138454437\n",
      "epoch 17 loss: 0.1325845867395401\n",
      "epoch 18 loss: 0.13249032199382782\n",
      "epoch 19 loss: 0.11573907732963562\n",
      "epoch 20 loss: 0.1300058364868164\n",
      "epoch 21 loss: 0.13071309030056\n",
      "epoch 22 loss: 0.10754575580358505\n",
      "epoch 23 loss: 0.14006397128105164\n",
      "epoch 24 loss: 0.12584123015403748\n",
      "epoch 25 loss: 0.11866863816976547\n",
      "epoch 26 loss: 0.15530703961849213\n",
      "epoch 27 loss: 0.09813051670789719\n",
      "epoch 28 loss: 0.16148893535137177\n",
      "epoch 29 loss: 0.10864736139774323\n",
      "epoch 30 loss: 0.09278656542301178\n",
      "55\n",
      "epoch 1 loss: 1.403212070465088\n",
      "epoch 2 loss: 0.9460236430168152\n",
      "epoch 3 loss: 0.6504037976264954\n",
      "epoch 4 loss: 0.4505068361759186\n",
      "epoch 5 loss: 0.25371429324150085\n",
      "epoch 6 loss: 0.1726803183555603\n",
      "epoch 7 loss: 0.16481338441371918\n",
      "epoch 8 loss: 0.1854996532201767\n",
      "epoch 9 loss: 0.1311052441596985\n",
      "epoch 10 loss: 0.17136862874031067\n",
      "epoch 11 loss: 0.16135194897651672\n",
      "epoch 12 loss: 0.15966616570949554\n",
      "epoch 13 loss: 0.14959588646888733\n",
      "epoch 14 loss: 0.15115083754062653\n",
      "epoch 15 loss: 0.1380929797887802\n",
      "epoch 16 loss: 0.12484202533960342\n",
      "epoch 17 loss: 0.15130746364593506\n",
      "epoch 18 loss: 0.1461973488330841\n",
      "epoch 19 loss: 0.1688471883535385\n",
      "epoch 20 loss: 0.12563881278038025\n",
      "epoch 21 loss: 0.12494561076164246\n",
      "epoch 22 loss: 0.12931211292743683\n",
      "epoch 23 loss: 0.14503426849842072\n",
      "epoch 24 loss: 0.12957166135311127\n",
      "epoch 25 loss: 0.13815362751483917\n",
      "epoch 26 loss: 0.12116219848394394\n",
      "epoch 27 loss: 0.09340330213308334\n",
      "epoch 28 loss: 0.13166676461696625\n",
      "epoch 29 loss: 0.18446889519691467\n",
      "epoch 30 loss: 0.12152320146560669\n",
      "56\n",
      "epoch 1 loss: 0.9578987956047058\n",
      "epoch 2 loss: 0.7180655598640442\n",
      "epoch 3 loss: 0.4763776957988739\n",
      "epoch 4 loss: 0.4739397466182709\n",
      "epoch 5 loss: 0.24827206134796143\n",
      "epoch 6 loss: 0.25163930654525757\n",
      "epoch 7 loss: 0.18353085219860077\n",
      "epoch 8 loss: 0.13590095937252045\n",
      "epoch 9 loss: 0.13101178407669067\n",
      "epoch 10 loss: 0.14965233206748962\n",
      "epoch 11 loss: 0.1366610825061798\n",
      "epoch 12 loss: 0.10922197252511978\n",
      "epoch 13 loss: 0.1524646133184433\n",
      "epoch 14 loss: 0.13447044789791107\n",
      "epoch 15 loss: 0.13374526798725128\n",
      "epoch 16 loss: 0.11709385365247726\n",
      "epoch 17 loss: 0.1301001012325287\n",
      "epoch 18 loss: 0.13063260912895203\n",
      "epoch 19 loss: 0.16596418619155884\n",
      "epoch 20 loss: 0.12260005623102188\n",
      "epoch 21 loss: 0.1178588792681694\n",
      "epoch 22 loss: 0.09423044323921204\n",
      "epoch 23 loss: 0.11517684906721115\n",
      "epoch 24 loss: 0.11906739324331284\n",
      "epoch 25 loss: 0.10190237313508987\n",
      "epoch 26 loss: 0.11389472335577011\n",
      "epoch 27 loss: 0.10897813737392426\n",
      "epoch 28 loss: 0.10554855316877365\n",
      "epoch 29 loss: 0.17538416385650635\n",
      "epoch 30 loss: 0.14194175601005554\n",
      "57\n",
      "epoch 1 loss: 1.0529935359954834\n",
      "epoch 2 loss: 0.6072534322738647\n",
      "epoch 3 loss: 0.5054821372032166\n",
      "epoch 4 loss: 0.40370702743530273\n",
      "epoch 5 loss: 0.25568413734436035\n",
      "epoch 6 loss: 0.24406103789806366\n",
      "epoch 7 loss: 0.13940206170082092\n",
      "epoch 8 loss: 0.18250443041324615\n",
      "epoch 9 loss: 0.12850013375282288\n",
      "epoch 10 loss: 0.11493295431137085\n",
      "epoch 11 loss: 0.150094136595726\n",
      "epoch 12 loss: 0.14514636993408203\n",
      "epoch 13 loss: 0.11805830895900726\n",
      "epoch 14 loss: 0.1306503862142563\n",
      "epoch 15 loss: 0.16725213825702667\n",
      "epoch 16 loss: 0.12920492887496948\n",
      "epoch 17 loss: 0.11697714775800705\n",
      "epoch 18 loss: 0.17119957506656647\n",
      "epoch 19 loss: 0.1266987919807434\n",
      "epoch 20 loss: 0.09732671827077866\n",
      "epoch 21 loss: 0.12702402472496033\n",
      "epoch 22 loss: 0.10387979447841644\n",
      "epoch 23 loss: 0.12283678352832794\n",
      "epoch 24 loss: 0.12084484845399857\n",
      "epoch 25 loss: 0.12706731259822845\n",
      "epoch 26 loss: 0.12476564198732376\n",
      "epoch 27 loss: 0.1088947132229805\n",
      "epoch 28 loss: 0.11173322051763535\n",
      "epoch 29 loss: 0.15906266868114471\n",
      "epoch 30 loss: 0.08981244266033173\n",
      "58\n",
      "epoch 1 loss: 1.2003259658813477\n",
      "epoch 2 loss: 0.6600295901298523\n",
      "epoch 3 loss: 0.5020164251327515\n",
      "epoch 4 loss: 0.3164953291416168\n",
      "epoch 5 loss: 0.2308897227048874\n",
      "epoch 6 loss: 0.15076109766960144\n",
      "epoch 7 loss: 0.18183429539203644\n",
      "epoch 8 loss: 0.17386503517627716\n",
      "epoch 9 loss: 0.12916027009487152\n",
      "epoch 10 loss: 0.14390265941619873\n",
      "epoch 11 loss: 0.14560896158218384\n",
      "epoch 12 loss: 0.13423067331314087\n",
      "epoch 13 loss: 0.12721002101898193\n",
      "epoch 14 loss: 0.1522439420223236\n",
      "epoch 15 loss: 0.13736025989055634\n",
      "epoch 16 loss: 0.15137234330177307\n",
      "epoch 17 loss: 0.12518933415412903\n",
      "epoch 18 loss: 0.11763747036457062\n",
      "epoch 19 loss: 0.11341872811317444\n",
      "epoch 20 loss: 0.10188449919223785\n",
      "epoch 21 loss: 0.1052892804145813\n",
      "epoch 22 loss: 0.15333692729473114\n",
      "epoch 23 loss: 0.12575633823871613\n",
      "epoch 24 loss: 0.12199056893587112\n",
      "epoch 25 loss: 0.10972359776496887\n",
      "epoch 26 loss: 0.10618896782398224\n",
      "epoch 27 loss: 0.12442049384117126\n",
      "epoch 28 loss: 0.12951864302158356\n",
      "epoch 29 loss: 0.13078327476978302\n",
      "epoch 30 loss: 0.12999041378498077\n",
      "59\n",
      "epoch 1 loss: 0.7468388676643372\n",
      "epoch 2 loss: 0.853891134262085\n",
      "epoch 3 loss: 0.7964022755622864\n",
      "epoch 4 loss: 0.32234930992126465\n",
      "epoch 5 loss: 0.2118101418018341\n",
      "epoch 6 loss: 0.17130765318870544\n",
      "epoch 7 loss: 0.19848418235778809\n",
      "epoch 8 loss: 0.18510936200618744\n",
      "epoch 9 loss: 0.12620064616203308\n",
      "epoch 10 loss: 0.16019751131534576\n",
      "epoch 11 loss: 0.15958981215953827\n",
      "epoch 12 loss: 0.11843390017747879\n",
      "epoch 13 loss: 0.12582415342330933\n",
      "epoch 14 loss: 0.1565059870481491\n",
      "epoch 15 loss: 0.13139766454696655\n",
      "epoch 16 loss: 0.1453770101070404\n",
      "epoch 17 loss: 0.1367858499288559\n",
      "epoch 18 loss: 0.12503689527511597\n",
      "epoch 19 loss: 0.14265502989292145\n",
      "epoch 20 loss: 0.14432813227176666\n",
      "epoch 21 loss: 0.12729008495807648\n",
      "epoch 22 loss: 0.1393394023180008\n",
      "epoch 23 loss: 0.12479536980390549\n",
      "epoch 24 loss: 0.11818809807300568\n",
      "epoch 25 loss: 0.11870668083429337\n",
      "epoch 26 loss: 0.11388799548149109\n",
      "epoch 27 loss: 0.13445548713207245\n",
      "epoch 28 loss: 0.1382407397031784\n",
      "epoch 29 loss: 0.12392304092645645\n",
      "epoch 30 loss: 0.10581074655056\n",
      "60\n",
      "epoch 1 loss: 0.7739097476005554\n",
      "epoch 2 loss: 0.8462551236152649\n",
      "epoch 3 loss: 0.49850696325302124\n",
      "epoch 4 loss: 0.3249532878398895\n",
      "epoch 5 loss: 0.2431119978427887\n",
      "epoch 6 loss: 0.1615859419107437\n",
      "epoch 7 loss: 0.11851337552070618\n",
      "epoch 8 loss: 0.17806142568588257\n",
      "epoch 9 loss: 0.15654031932353973\n",
      "epoch 10 loss: 0.1613267958164215\n",
      "epoch 11 loss: 0.20066000521183014\n",
      "epoch 12 loss: 0.1352573037147522\n",
      "epoch 13 loss: 0.12414185702800751\n",
      "epoch 14 loss: 0.11771675199270248\n",
      "epoch 15 loss: 0.1726931631565094\n",
      "epoch 16 loss: 0.1379065215587616\n",
      "epoch 17 loss: 0.1384490579366684\n",
      "epoch 18 loss: 0.11341486871242523\n",
      "epoch 19 loss: 0.1488376408815384\n",
      "epoch 20 loss: 0.13391512632369995\n",
      "epoch 21 loss: 0.112950399518013\n",
      "epoch 22 loss: 0.11823505908250809\n",
      "epoch 23 loss: 0.12045785784721375\n",
      "epoch 24 loss: 0.09784984588623047\n",
      "epoch 25 loss: 0.12775123119354248\n",
      "epoch 26 loss: 0.11469481885433197\n",
      "epoch 27 loss: 0.17597422003746033\n",
      "epoch 28 loss: 0.16400034725666046\n",
      "epoch 29 loss: 0.11070480942726135\n",
      "epoch 30 loss: 0.13377609848976135\n",
      "61\n",
      "epoch 1 loss: 0.9946879744529724\n",
      "epoch 2 loss: 0.8600073456764221\n",
      "epoch 3 loss: 0.6918216347694397\n",
      "epoch 4 loss: 0.4887275695800781\n",
      "epoch 5 loss: 0.28884321451187134\n",
      "epoch 6 loss: 0.24053837358951569\n",
      "epoch 7 loss: 0.1604449450969696\n",
      "epoch 8 loss: 0.15182943642139435\n",
      "epoch 9 loss: 0.16947197914123535\n",
      "epoch 10 loss: 0.15033991634845734\n",
      "epoch 11 loss: 0.13499416410923004\n",
      "epoch 12 loss: 0.12115413695573807\n",
      "epoch 13 loss: 0.13264641165733337\n",
      "epoch 14 loss: 0.12460910528898239\n",
      "epoch 15 loss: 0.1220182552933693\n",
      "epoch 16 loss: 0.13725700974464417\n",
      "epoch 17 loss: 0.1258188635110855\n",
      "epoch 18 loss: 0.14926226437091827\n",
      "epoch 19 loss: 0.11575242877006531\n",
      "epoch 20 loss: 0.1194533109664917\n",
      "epoch 21 loss: 0.12502029538154602\n",
      "epoch 22 loss: 0.09932883828878403\n",
      "epoch 23 loss: 0.12999990582466125\n",
      "epoch 24 loss: 0.12233854085206985\n",
      "epoch 25 loss: 0.1339154690504074\n",
      "epoch 26 loss: 0.13399754464626312\n",
      "epoch 27 loss: 0.08109503984451294\n",
      "epoch 28 loss: 0.11903411895036697\n",
      "epoch 29 loss: 0.09618967771530151\n",
      "epoch 30 loss: 0.12166206538677216\n",
      "62\n",
      "epoch 1 loss: 1.0415598154067993\n",
      "epoch 2 loss: 0.743740439414978\n",
      "epoch 3 loss: 0.5832238793373108\n",
      "epoch 4 loss: 0.3859420120716095\n",
      "epoch 5 loss: 0.2692641317844391\n",
      "epoch 6 loss: 0.18619230389595032\n",
      "epoch 7 loss: 0.1337558776140213\n",
      "epoch 8 loss: 0.1542765349149704\n",
      "epoch 9 loss: 0.19725584983825684\n",
      "epoch 10 loss: 0.1413360834121704\n",
      "epoch 11 loss: 0.11987143754959106\n",
      "epoch 12 loss: 0.15729153156280518\n",
      "epoch 13 loss: 0.14939624071121216\n",
      "epoch 14 loss: 0.13384416699409485\n",
      "epoch 15 loss: 0.12281837314367294\n",
      "epoch 16 loss: 0.1343737691640854\n",
      "epoch 17 loss: 0.11301268637180328\n",
      "epoch 18 loss: 0.11376045644283295\n",
      "epoch 19 loss: 0.0977405533194542\n",
      "epoch 20 loss: 0.12203769385814667\n",
      "epoch 21 loss: 0.13595373928546906\n",
      "epoch 22 loss: 0.1444845348596573\n",
      "epoch 23 loss: 0.09856129437685013\n",
      "epoch 24 loss: 0.13873687386512756\n",
      "epoch 25 loss: 0.14245353639125824\n",
      "epoch 26 loss: 0.14683830738067627\n",
      "epoch 27 loss: 0.10277558863162994\n",
      "epoch 28 loss: 0.12338636815547943\n",
      "epoch 29 loss: 0.12779107689857483\n",
      "epoch 30 loss: 0.12609435617923737\n",
      "63\n",
      "epoch 1 loss: 1.0018012523651123\n",
      "epoch 2 loss: 0.8607321381568909\n",
      "epoch 3 loss: 0.4293000102043152\n",
      "epoch 4 loss: 0.36807385087013245\n",
      "epoch 5 loss: 0.25730231404304504\n",
      "epoch 6 loss: 0.19072863459587097\n",
      "epoch 7 loss: 0.20085205137729645\n",
      "epoch 8 loss: 0.13718293607234955\n",
      "epoch 9 loss: 0.1508900374174118\n",
      "epoch 10 loss: 0.11757389456033707\n",
      "epoch 11 loss: 0.12234354019165039\n",
      "epoch 12 loss: 0.14904364943504333\n",
      "epoch 13 loss: 0.1162576824426651\n",
      "epoch 14 loss: 0.10507044196128845\n",
      "epoch 15 loss: 0.1197863519191742\n",
      "epoch 16 loss: 0.1507234275341034\n",
      "epoch 17 loss: 0.14590254426002502\n",
      "epoch 18 loss: 0.15807151794433594\n",
      "epoch 19 loss: 0.10337286442518234\n",
      "epoch 20 loss: 0.15500997006893158\n",
      "epoch 21 loss: 0.13742400705814362\n",
      "epoch 22 loss: 0.10382737219333649\n",
      "epoch 23 loss: 0.15183794498443604\n",
      "epoch 24 loss: 0.14019669592380524\n",
      "epoch 25 loss: 0.14250124990940094\n",
      "epoch 26 loss: 0.15069030225276947\n",
      "epoch 27 loss: 0.1702045053243637\n",
      "epoch 28 loss: 0.15144486725330353\n",
      "epoch 29 loss: 0.11897040903568268\n",
      "epoch 30 loss: 0.09266671538352966\n",
      "64\n",
      "epoch 1 loss: 0.924140989780426\n",
      "epoch 2 loss: 0.794558584690094\n",
      "epoch 3 loss: 0.4929426312446594\n",
      "epoch 4 loss: 0.3271629214286804\n",
      "epoch 5 loss: 0.13906492292881012\n",
      "epoch 6 loss: 0.16733232140541077\n",
      "epoch 7 loss: 0.14683562517166138\n",
      "epoch 8 loss: 0.18164511024951935\n",
      "epoch 9 loss: 0.14630943536758423\n",
      "epoch 10 loss: 0.160355344414711\n",
      "epoch 11 loss: 0.14841727912425995\n",
      "epoch 12 loss: 0.14908893406391144\n",
      "epoch 13 loss: 0.14015227556228638\n",
      "epoch 14 loss: 0.14735621213912964\n",
      "epoch 15 loss: 0.13523811101913452\n",
      "epoch 16 loss: 0.13397198915481567\n",
      "epoch 17 loss: 0.13352996110916138\n",
      "epoch 18 loss: 0.13524934649467468\n",
      "epoch 19 loss: 0.12822622060775757\n",
      "epoch 20 loss: 0.12973515689373016\n",
      "epoch 21 loss: 0.14828388392925262\n",
      "epoch 22 loss: 0.10175682604312897\n",
      "epoch 23 loss: 0.1287221610546112\n",
      "epoch 24 loss: 0.15096619725227356\n",
      "epoch 25 loss: 0.14140398800373077\n",
      "epoch 26 loss: 0.11187086254358292\n",
      "epoch 27 loss: 0.1458723545074463\n",
      "epoch 28 loss: 0.15609323978424072\n",
      "epoch 29 loss: 0.13734862208366394\n",
      "epoch 30 loss: 0.11120171844959259\n",
      "65\n",
      "epoch 1 loss: 0.9576270580291748\n",
      "epoch 2 loss: 0.8070204854011536\n",
      "epoch 3 loss: 0.6112251877784729\n",
      "epoch 4 loss: 0.32000821828842163\n",
      "epoch 5 loss: 0.28499913215637207\n",
      "epoch 6 loss: 0.2353556752204895\n",
      "epoch 7 loss: 0.17923714220523834\n",
      "epoch 8 loss: 0.1441410630941391\n",
      "epoch 9 loss: 0.10069490224123001\n",
      "epoch 10 loss: 0.13287681341171265\n",
      "epoch 11 loss: 0.1381227672100067\n",
      "epoch 12 loss: 0.1438911408185959\n",
      "epoch 13 loss: 0.14901430904865265\n",
      "epoch 14 loss: 0.1344558149576187\n",
      "epoch 15 loss: 0.15705232322216034\n",
      "epoch 16 loss: 0.1350579708814621\n",
      "epoch 17 loss: 0.12677329778671265\n",
      "epoch 18 loss: 0.1253250688314438\n",
      "epoch 19 loss: 0.11420193314552307\n",
      "epoch 20 loss: 0.11461730301380157\n",
      "epoch 21 loss: 0.12771640717983246\n",
      "epoch 22 loss: 0.139165997505188\n",
      "epoch 23 loss: 0.11831146478652954\n",
      "epoch 24 loss: 0.11940325051546097\n",
      "epoch 25 loss: 0.13498683273792267\n",
      "epoch 26 loss: 0.10384738445281982\n",
      "epoch 27 loss: 0.10828796774148941\n",
      "epoch 28 loss: 0.11375327408313751\n",
      "epoch 29 loss: 0.09922189265489578\n",
      "epoch 30 loss: 0.128050297498703\n",
      "66\n",
      "epoch 1 loss: 0.7400572299957275\n",
      "epoch 2 loss: 0.6932424902915955\n",
      "epoch 3 loss: 0.5325501561164856\n",
      "epoch 4 loss: 0.5075234174728394\n",
      "epoch 5 loss: 0.26715975999832153\n",
      "epoch 6 loss: 0.23494547605514526\n",
      "epoch 7 loss: 0.1539650559425354\n",
      "epoch 8 loss: 0.13911987841129303\n",
      "epoch 9 loss: 0.139404296875\n",
      "epoch 10 loss: 0.15565238893032074\n",
      "epoch 11 loss: 0.09445236623287201\n",
      "epoch 12 loss: 0.13144457340240479\n",
      "epoch 13 loss: 0.12253782153129578\n",
      "epoch 14 loss: 0.17032848298549652\n",
      "epoch 15 loss: 0.13235212862491608\n",
      "epoch 16 loss: 0.13352076709270477\n",
      "epoch 17 loss: 0.1300303190946579\n",
      "epoch 18 loss: 0.12407800555229187\n",
      "epoch 19 loss: 0.09366798400878906\n",
      "epoch 20 loss: 0.11614156514406204\n",
      "epoch 21 loss: 0.10420738160610199\n",
      "epoch 22 loss: 0.12447433918714523\n",
      "epoch 23 loss: 0.11812344938516617\n",
      "epoch 24 loss: 0.13210780918598175\n",
      "epoch 25 loss: 0.11395753920078278\n",
      "epoch 26 loss: 0.1042669415473938\n",
      "epoch 27 loss: 0.11169533431529999\n",
      "epoch 28 loss: 0.1009240597486496\n",
      "epoch 29 loss: 0.0936741903424263\n",
      "epoch 30 loss: 0.15349280834197998\n",
      "67\n",
      "epoch 1 loss: 0.9317650198936462\n",
      "epoch 2 loss: 0.7598669528961182\n",
      "epoch 3 loss: 0.637596070766449\n",
      "epoch 4 loss: 0.28799936175346375\n",
      "epoch 5 loss: 0.1749761402606964\n",
      "epoch 6 loss: 0.20402830839157104\n",
      "epoch 7 loss: 0.1818142831325531\n",
      "epoch 8 loss: 0.17436279356479645\n",
      "epoch 9 loss: 0.1423928439617157\n",
      "epoch 10 loss: 0.12927265465259552\n",
      "epoch 11 loss: 0.14348238706588745\n",
      "epoch 12 loss: 0.12936975061893463\n",
      "epoch 13 loss: 0.1302185356616974\n",
      "epoch 14 loss: 0.12661497294902802\n",
      "epoch 15 loss: 0.12204644083976746\n",
      "epoch 16 loss: 0.13098905980587006\n",
      "epoch 17 loss: 0.09778503328561783\n",
      "epoch 18 loss: 0.12943322956562042\n",
      "epoch 19 loss: 0.13274578750133514\n",
      "epoch 20 loss: 0.13144224882125854\n",
      "epoch 21 loss: 0.11829442530870438\n",
      "epoch 22 loss: 0.12934115529060364\n",
      "epoch 23 loss: 0.159505695104599\n",
      "epoch 24 loss: 0.13947944343090057\n",
      "epoch 25 loss: 0.09716171026229858\n",
      "epoch 26 loss: 0.1194753497838974\n",
      "epoch 27 loss: 0.10613049566745758\n",
      "epoch 28 loss: 0.1267153024673462\n",
      "epoch 29 loss: 0.12148120254278183\n",
      "epoch 30 loss: 0.12420151382684708\n",
      "68\n",
      "epoch 1 loss: 1.228830099105835\n",
      "epoch 2 loss: 0.7792419791221619\n",
      "epoch 3 loss: 0.5450310111045837\n",
      "epoch 4 loss: 0.2883686423301697\n",
      "epoch 5 loss: 0.21983125805854797\n",
      "epoch 6 loss: 0.22311416268348694\n",
      "epoch 7 loss: 0.1986522674560547\n",
      "epoch 8 loss: 0.14473937451839447\n",
      "epoch 9 loss: 0.15577025711536407\n",
      "epoch 10 loss: 0.1386418491601944\n",
      "epoch 11 loss: 0.1596049964427948\n",
      "epoch 12 loss: 0.14502733945846558\n",
      "epoch 13 loss: 0.1380738765001297\n",
      "epoch 14 loss: 0.13076576590538025\n",
      "epoch 15 loss: 0.1447397619485855\n",
      "epoch 16 loss: 0.09706428647041321\n",
      "epoch 17 loss: 0.12064366042613983\n",
      "epoch 18 loss: 0.12079189717769623\n",
      "epoch 19 loss: 0.10666683316230774\n",
      "epoch 20 loss: 0.11053575575351715\n",
      "epoch 21 loss: 0.17662987112998962\n",
      "epoch 22 loss: 0.11292635649442673\n",
      "epoch 23 loss: 0.13676820695400238\n",
      "epoch 24 loss: 0.11475332826375961\n",
      "epoch 25 loss: 0.12907975912094116\n",
      "epoch 26 loss: 0.1343645304441452\n",
      "epoch 27 loss: 0.12045381218194962\n",
      "epoch 28 loss: 0.14234846830368042\n",
      "epoch 29 loss: 0.09748219698667526\n",
      "epoch 30 loss: 0.1490049511194229\n",
      "69\n",
      "epoch 1 loss: 1.2491931915283203\n",
      "epoch 2 loss: 0.5407849550247192\n",
      "epoch 3 loss: 0.406755268573761\n",
      "epoch 4 loss: 0.28621184825897217\n",
      "epoch 5 loss: 0.2349359095096588\n",
      "epoch 6 loss: 0.22242258489131927\n",
      "epoch 7 loss: 0.1824566125869751\n",
      "epoch 8 loss: 0.15201061964035034\n",
      "epoch 9 loss: 0.16493703424930573\n",
      "epoch 10 loss: 0.15328530967235565\n",
      "epoch 11 loss: 0.14761918783187866\n",
      "epoch 12 loss: 0.10000744462013245\n",
      "epoch 13 loss: 0.11407884955406189\n",
      "epoch 14 loss: 0.11736925691366196\n",
      "epoch 15 loss: 0.13021276891231537\n",
      "epoch 16 loss: 0.127179816365242\n",
      "epoch 17 loss: 0.13532283902168274\n",
      "epoch 18 loss: 0.10077814012765884\n",
      "epoch 19 loss: 0.1384619176387787\n",
      "epoch 20 loss: 0.1148819848895073\n",
      "epoch 21 loss: 0.11322584748268127\n",
      "epoch 22 loss: 0.12257792800664902\n",
      "epoch 23 loss: 0.12819279730319977\n",
      "epoch 24 loss: 0.13315525650978088\n",
      "epoch 25 loss: 0.14656859636306763\n",
      "epoch 26 loss: 0.10228560864925385\n",
      "epoch 27 loss: 0.11195249110460281\n",
      "epoch 28 loss: 0.0968027338385582\n",
      "epoch 29 loss: 0.14323458075523376\n",
      "epoch 30 loss: 0.11364097148180008\n",
      "70\n",
      "epoch 1 loss: 0.8571505546569824\n",
      "epoch 2 loss: 0.66375732421875\n",
      "epoch 3 loss: 0.44919973611831665\n",
      "epoch 4 loss: 0.28695204854011536\n",
      "epoch 5 loss: 0.20091691613197327\n",
      "epoch 6 loss: 0.19586190581321716\n",
      "epoch 7 loss: 0.19250933825969696\n",
      "epoch 8 loss: 0.13545916974544525\n",
      "epoch 9 loss: 0.15135999023914337\n",
      "epoch 10 loss: 0.12815484404563904\n",
      "epoch 11 loss: 0.16563169658184052\n",
      "epoch 12 loss: 0.1699056476354599\n",
      "epoch 13 loss: 0.15123525261878967\n",
      "epoch 14 loss: 0.1496799737215042\n",
      "epoch 15 loss: 0.10126015543937683\n",
      "epoch 16 loss: 0.13149689137935638\n",
      "epoch 17 loss: 0.1393737494945526\n",
      "epoch 18 loss: 0.13466952741146088\n",
      "epoch 19 loss: 0.12017177045345306\n",
      "epoch 20 loss: 0.10345885902643204\n",
      "epoch 21 loss: 0.1481553018093109\n",
      "epoch 22 loss: 0.10518850386142731\n",
      "epoch 23 loss: 0.13555224239826202\n",
      "epoch 24 loss: 0.13482238352298737\n",
      "epoch 25 loss: 0.11949880421161652\n",
      "epoch 26 loss: 0.13909901678562164\n",
      "epoch 27 loss: 0.11288681626319885\n",
      "epoch 28 loss: 0.11221186071634293\n",
      "epoch 29 loss: 0.13472937047481537\n",
      "epoch 30 loss: 0.09412851929664612\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test Dirich",
   "id": "f033d8578ca1b48b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T18:13:38.883410Z",
     "start_time": "2025-10-10T17:19:41.314043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import model_dich\n",
    "\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.device = \"mps\"\n",
    "cfg.n_epochs = 90\n",
    "cfg.lr = 5e-4\n",
    "cfg.x_col = \"x\"\n",
    "cfg.y_cols = [f\"y_{i}\" for i in range(24)]\n",
    "cfg.T_hist = 32\n",
    "cfg.batch_size = 64\n",
    "cfg.test_ratio = 0.2\n",
    "cfg.kl_coeff = 1.0\n",
    "\n",
    "\n",
    "train_config = model_class.training_config(n_epochs = 3, device = torch.device(\"cpu\"))\n",
    "results_prob_dich = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_comed.loc[(df_comed['ds'] >= date_start) & (df_comed['ds'] < date_end)].copy()\n",
    "    model = model_dich.DirichletComposerRNN(device=torch.device(\"cpu\"))\n",
    "    trainer = model_dich.RNN_train(model, cfg)\n",
    "    ret = trainer(df_reduced)\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': ret['Y_pred'].flatten(), 'y': ret['Y_test'].flatten()})\n",
    "\n",
    "    results_prob_dich = pd.concat([results_prob_dich, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prob_dich.to_csv(out_dir + '/results_prob_dich_90epoch.csv', index=False)"
   ],
   "id": "767da83a436cca0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[Epoch 001] loss=1.0702 recon=0.9303 kl=0.1400\n",
      "[Epoch 002] loss=0.9483 recon=0.9464 kl=0.0019\n",
      "[Epoch 003] loss=0.9297 recon=0.9294 kl=0.0002\n",
      "[Epoch 004] loss=0.9247 recon=0.9245 kl=0.0002\n",
      "[Epoch 005] loss=0.9286 recon=0.9283 kl=0.0004\n",
      "[Epoch 006] loss=0.9334 recon=0.9333 kl=0.0002\n",
      "[Epoch 007] loss=0.9247 recon=0.9241 kl=0.0006\n",
      "[Epoch 008] loss=0.9194 recon=0.9191 kl=0.0003\n",
      "[Epoch 009] loss=0.9282 recon=0.9281 kl=0.0002\n",
      "[Epoch 010] loss=0.9294 recon=0.9289 kl=0.0005\n",
      "[Epoch 011] loss=0.9349 recon=0.9346 kl=0.0003\n",
      "[Epoch 012] loss=0.9354 recon=0.9349 kl=0.0004\n",
      "[Epoch 013] loss=0.9190 recon=0.9185 kl=0.0005\n",
      "[Epoch 014] loss=0.9227 recon=0.9221 kl=0.0006\n",
      "[Epoch 015] loss=0.9263 recon=0.9255 kl=0.0008\n",
      "[Epoch 016] loss=0.9289 recon=0.9286 kl=0.0003\n",
      "[Epoch 017] loss=0.9252 recon=0.9245 kl=0.0007\n",
      "[Epoch 018] loss=0.9251 recon=0.9246 kl=0.0005\n",
      "[Epoch 019] loss=0.9473 recon=0.9466 kl=0.0007\n",
      "[Epoch 020] loss=0.9483 recon=0.9481 kl=0.0002\n",
      "[Epoch 021] loss=0.9282 recon=0.9274 kl=0.0009\n",
      "[Epoch 022] loss=0.9308 recon=0.9300 kl=0.0008\n",
      "[Epoch 023] loss=0.9213 recon=0.9210 kl=0.0004\n",
      "[Epoch 024] loss=0.9183 recon=0.9176 kl=0.0007\n",
      "[Epoch 025] loss=0.9478 recon=0.9474 kl=0.0005\n",
      "[Epoch 026] loss=0.9337 recon=0.9329 kl=0.0008\n",
      "[Epoch 027] loss=0.9313 recon=0.9310 kl=0.0004\n",
      "[Epoch 028] loss=0.9339 recon=0.9331 kl=0.0008\n",
      "[Epoch 029] loss=0.9332 recon=0.9329 kl=0.0004\n",
      "[Epoch 030] loss=0.9296 recon=0.9287 kl=0.0008\n",
      "[Epoch 031] loss=0.9181 recon=0.9176 kl=0.0005\n",
      "[Epoch 032] loss=0.9154 recon=0.9148 kl=0.0006\n",
      "[Epoch 033] loss=0.9244 recon=0.9238 kl=0.0007\n",
      "[Epoch 034] loss=0.9343 recon=0.9340 kl=0.0003\n",
      "[Epoch 035] loss=0.9433 recon=0.9424 kl=0.0009\n",
      "[Epoch 036] loss=0.9328 recon=0.9320 kl=0.0009\n",
      "[Epoch 037] loss=0.9245 recon=0.9240 kl=0.0005\n",
      "[Epoch 038] loss=0.9406 recon=0.9375 kl=0.0031\n",
      "[Epoch 039] loss=0.9247 recon=0.9223 kl=0.0024\n",
      "[Epoch 040] loss=0.9304 recon=0.9287 kl=0.0018\n",
      "[Epoch 041] loss=0.9205 recon=0.9201 kl=0.0004\n",
      "[Epoch 042] loss=0.9181 recon=0.9181 kl=0.0000\n",
      "[Epoch 043] loss=0.9239 recon=0.9239 kl=0.0000\n",
      "[Epoch 044] loss=0.9131 recon=0.9128 kl=0.0004\n",
      "[Epoch 045] loss=0.9354 recon=0.9350 kl=0.0004\n",
      "[Epoch 046] loss=0.9287 recon=0.9280 kl=0.0007\n",
      "[Epoch 047] loss=0.9291 recon=0.9290 kl=0.0001\n",
      "[Epoch 048] loss=0.9277 recon=0.9251 kl=0.0026\n",
      "[Epoch 049] loss=0.9290 recon=0.9268 kl=0.0022\n",
      "[Epoch 050] loss=0.9256 recon=0.9243 kl=0.0013\n",
      "[Epoch 051] loss=0.9202 recon=0.9201 kl=0.0002\n",
      "[Epoch 052] loss=0.9541 recon=0.9541 kl=0.0000\n",
      "[Epoch 053] loss=0.9207 recon=0.9199 kl=0.0008\n",
      "[Epoch 054] loss=0.9249 recon=0.9206 kl=0.0043\n",
      "[Epoch 055] loss=0.9309 recon=0.9256 kl=0.0053\n",
      "[Epoch 056] loss=0.9298 recon=0.9294 kl=0.0004\n",
      "[Epoch 057] loss=0.9223 recon=0.9223 kl=0.0000\n",
      "[Epoch 058] loss=0.9186 recon=0.9185 kl=0.0002\n",
      "[Epoch 059] loss=0.9229 recon=0.9223 kl=0.0006\n",
      "[Epoch 060] loss=0.9354 recon=0.9351 kl=0.0003\n",
      "[Epoch 061] loss=0.9369 recon=0.9364 kl=0.0006\n",
      "[Epoch 062] loss=0.9271 recon=0.9256 kl=0.0015\n",
      "[Epoch 063] loss=0.9427 recon=0.9384 kl=0.0043\n",
      "[Epoch 064] loss=0.9439 recon=0.9422 kl=0.0017\n",
      "[Epoch 065] loss=0.9264 recon=0.9262 kl=0.0002\n",
      "[Epoch 066] loss=0.9472 recon=0.9471 kl=0.0000\n",
      "[Epoch 067] loss=0.9594 recon=0.9588 kl=0.0006\n",
      "[Epoch 068] loss=0.9256 recon=0.9253 kl=0.0003\n",
      "[Epoch 069] loss=0.9323 recon=0.9316 kl=0.0006\n",
      "[Epoch 070] loss=0.9403 recon=0.9315 kl=0.0088\n",
      "[Epoch 071] loss=0.9261 recon=0.9207 kl=0.0054\n",
      "[Epoch 072] loss=0.9291 recon=0.9271 kl=0.0020\n",
      "[Epoch 073] loss=0.9498 recon=0.9493 kl=0.0004\n",
      "[Epoch 074] loss=0.9218 recon=0.9218 kl=0.0000\n",
      "[Epoch 075] loss=0.9295 recon=0.9295 kl=0.0000\n",
      "[Epoch 076] loss=0.9322 recon=0.9322 kl=0.0000\n",
      "[Epoch 077] loss=0.9290 recon=0.9290 kl=0.0000\n",
      "[Epoch 078] loss=0.9265 recon=0.9261 kl=0.0004\n",
      "[Epoch 079] loss=0.9324 recon=0.9316 kl=0.0007\n",
      "[Epoch 080] loss=0.9383 recon=0.9378 kl=0.0005\n",
      "[Epoch 081] loss=0.9237 recon=0.9236 kl=0.0001\n",
      "[Epoch 082] loss=0.9185 recon=0.9173 kl=0.0012\n",
      "[Epoch 083] loss=0.9497 recon=0.9489 kl=0.0008\n",
      "[Epoch 084] loss=0.9145 recon=0.9141 kl=0.0004\n",
      "[Epoch 085] loss=0.9276 recon=0.9271 kl=0.0005\n",
      "[Epoch 086] loss=0.9336 recon=0.9331 kl=0.0005\n",
      "[Epoch 087] loss=0.9248 recon=0.9244 kl=0.0004\n",
      "[Epoch 088] loss=0.9229 recon=0.9222 kl=0.0007\n",
      "[Epoch 089] loss=0.9209 recon=0.9204 kl=0.0005\n",
      "[Epoch 090] loss=0.9190 recon=0.9189 kl=0.0001\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_34746/540361106.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_prob_dich = pd.concat([results_prob_dich, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] loss=1.3480 recon=0.9291 kl=0.4189\n",
      "[Epoch 002] loss=0.9318 recon=0.9280 kl=0.0038\n",
      "[Epoch 003] loss=0.9355 recon=0.9351 kl=0.0003\n",
      "[Epoch 004] loss=0.9239 recon=0.9237 kl=0.0002\n",
      "[Epoch 005] loss=0.9379 recon=0.9378 kl=0.0002\n",
      "[Epoch 006] loss=0.9190 recon=0.9188 kl=0.0001\n",
      "[Epoch 007] loss=0.9273 recon=0.9270 kl=0.0003\n",
      "[Epoch 008] loss=0.9449 recon=0.9447 kl=0.0003\n",
      "[Epoch 009] loss=0.9207 recon=0.9198 kl=0.0009\n",
      "[Epoch 010] loss=0.9349 recon=0.9347 kl=0.0002\n",
      "[Epoch 011] loss=0.9334 recon=0.9331 kl=0.0003\n",
      "[Epoch 012] loss=0.9285 recon=0.9280 kl=0.0004\n",
      "[Epoch 013] loss=0.9212 recon=0.9209 kl=0.0003\n",
      "[Epoch 014] loss=0.9331 recon=0.9327 kl=0.0005\n",
      "[Epoch 015] loss=0.9286 recon=0.9284 kl=0.0002\n",
      "[Epoch 016] loss=0.9334 recon=0.9329 kl=0.0005\n",
      "[Epoch 017] loss=0.9385 recon=0.9382 kl=0.0004\n",
      "[Epoch 018] loss=0.9268 recon=0.9262 kl=0.0005\n",
      "[Epoch 019] loss=0.9196 recon=0.9194 kl=0.0002\n",
      "[Epoch 020] loss=0.9595 recon=0.9588 kl=0.0007\n",
      "[Epoch 021] loss=0.9332 recon=0.9329 kl=0.0003\n",
      "[Epoch 022] loss=0.9374 recon=0.9369 kl=0.0005\n",
      "[Epoch 023] loss=0.9319 recon=0.9315 kl=0.0004\n",
      "[Epoch 024] loss=0.9464 recon=0.9399 kl=0.0066\n",
      "[Epoch 025] loss=0.9327 recon=0.9309 kl=0.0018\n",
      "[Epoch 026] loss=0.9210 recon=0.9208 kl=0.0002\n",
      "[Epoch 027] loss=0.9234 recon=0.9233 kl=0.0001\n",
      "[Epoch 028] loss=0.9267 recon=0.9263 kl=0.0004\n",
      "[Epoch 029] loss=0.9487 recon=0.9485 kl=0.0003\n",
      "[Epoch 030] loss=0.9325 recon=0.9317 kl=0.0008\n",
      "[Epoch 031] loss=0.9398 recon=0.9395 kl=0.0003\n",
      "[Epoch 032] loss=0.9236 recon=0.9230 kl=0.0006\n",
      "[Epoch 033] loss=0.9236 recon=0.9230 kl=0.0006\n",
      "[Epoch 034] loss=0.9368 recon=0.9362 kl=0.0006\n",
      "[Epoch 035] loss=0.9231 recon=0.9227 kl=0.0004\n",
      "[Epoch 036] loss=0.9341 recon=0.9335 kl=0.0005\n",
      "[Epoch 037] loss=0.9298 recon=0.9293 kl=0.0005\n",
      "[Epoch 038] loss=0.9338 recon=0.9331 kl=0.0007\n",
      "[Epoch 039] loss=0.9511 recon=0.9506 kl=0.0006\n",
      "[Epoch 040] loss=0.9257 recon=0.9251 kl=0.0007\n",
      "[Epoch 041] loss=0.9198 recon=0.9194 kl=0.0004\n",
      "[Epoch 042] loss=0.9252 recon=0.9244 kl=0.0008\n",
      "[Epoch 043] loss=0.9197 recon=0.9196 kl=0.0002\n",
      "[Epoch 044] loss=0.9397 recon=0.9390 kl=0.0007\n",
      "[Epoch 045] loss=0.9386 recon=0.9319 kl=0.0068\n",
      "[Epoch 046] loss=0.9292 recon=0.9276 kl=0.0016\n",
      "[Epoch 047] loss=0.9276 recon=0.9274 kl=0.0002\n",
      "[Epoch 048] loss=0.9318 recon=0.9317 kl=0.0000\n",
      "[Epoch 049] loss=0.9278 recon=0.9261 kl=0.0017\n",
      "[Epoch 050] loss=0.9333 recon=0.9300 kl=0.0033\n",
      "[Epoch 051] loss=0.9260 recon=0.9237 kl=0.0023\n",
      "[Epoch 052] loss=0.9187 recon=0.9169 kl=0.0018\n",
      "[Epoch 053] loss=0.9207 recon=0.9201 kl=0.0006\n",
      "[Epoch 054] loss=0.9284 recon=0.9283 kl=0.0001\n",
      "[Epoch 055] loss=0.9259 recon=0.9259 kl=0.0000\n",
      "[Epoch 056] loss=0.9174 recon=0.9172 kl=0.0002\n",
      "[Epoch 057] loss=0.9227 recon=0.9221 kl=0.0006\n",
      "[Epoch 058] loss=0.9193 recon=0.9189 kl=0.0004\n",
      "[Epoch 059] loss=0.9331 recon=0.9326 kl=0.0005\n",
      "[Epoch 060] loss=0.9559 recon=0.9553 kl=0.0006\n",
      "[Epoch 061] loss=0.9209 recon=0.9203 kl=0.0006\n",
      "[Epoch 062] loss=0.9297 recon=0.9294 kl=0.0002\n",
      "[Epoch 063] loss=0.9269 recon=0.9262 kl=0.0007\n",
      "[Epoch 064] loss=0.9407 recon=0.9404 kl=0.0002\n",
      "[Epoch 065] loss=0.9221 recon=0.9214 kl=0.0007\n",
      "[Epoch 066] loss=0.9386 recon=0.9381 kl=0.0005\n",
      "[Epoch 067] loss=0.9328 recon=0.9326 kl=0.0003\n",
      "[Epoch 068] loss=0.9233 recon=0.9227 kl=0.0006\n",
      "[Epoch 069] loss=0.9546 recon=0.9540 kl=0.0006\n",
      "[Epoch 070] loss=0.9429 recon=0.9425 kl=0.0004\n",
      "[Epoch 071] loss=0.9215 recon=0.9208 kl=0.0008\n",
      "[Epoch 072] loss=0.9351 recon=0.9345 kl=0.0005\n",
      "[Epoch 073] loss=0.9316 recon=0.9311 kl=0.0005\n",
      "[Epoch 074] loss=0.9457 recon=0.9453 kl=0.0004\n",
      "[Epoch 075] loss=0.9280 recon=0.9273 kl=0.0007\n",
      "[Epoch 076] loss=0.9151 recon=0.9144 kl=0.0007\n",
      "[Epoch 077] loss=0.9272 recon=0.9267 kl=0.0005\n",
      "[Epoch 078] loss=0.9263 recon=0.9258 kl=0.0005\n",
      "[Epoch 079] loss=0.9386 recon=0.9376 kl=0.0009\n",
      "[Epoch 080] loss=0.9263 recon=0.9259 kl=0.0004\n",
      "[Epoch 081] loss=0.9202 recon=0.9197 kl=0.0005\n",
      "[Epoch 082] loss=0.9387 recon=0.9384 kl=0.0003\n",
      "[Epoch 083] loss=0.9279 recon=0.9273 kl=0.0006\n",
      "[Epoch 084] loss=0.9349 recon=0.9346 kl=0.0003\n",
      "[Epoch 085] loss=0.9249 recon=0.9239 kl=0.0009\n",
      "[Epoch 086] loss=0.9259 recon=0.9251 kl=0.0008\n",
      "[Epoch 087] loss=0.9204 recon=0.9203 kl=0.0001\n",
      "[Epoch 088] loss=0.9286 recon=0.9280 kl=0.0006\n",
      "[Epoch 089] loss=0.9434 recon=0.9427 kl=0.0007\n",
      "[Epoch 090] loss=0.9330 recon=0.9324 kl=0.0006\n",
      "3\n",
      "[Epoch 001] loss=1.3524 recon=0.9304 kl=0.4220\n",
      "[Epoch 002] loss=0.9414 recon=0.9386 kl=0.0028\n",
      "[Epoch 003] loss=0.9388 recon=0.9385 kl=0.0002\n",
      "[Epoch 004] loss=0.9371 recon=0.9370 kl=0.0001\n",
      "[Epoch 005] loss=0.9337 recon=0.9336 kl=0.0001\n",
      "[Epoch 006] loss=0.9242 recon=0.9240 kl=0.0002\n",
      "[Epoch 007] loss=0.9467 recon=0.9464 kl=0.0003\n",
      "[Epoch 008] loss=0.9290 recon=0.9287 kl=0.0002\n",
      "[Epoch 009] loss=0.9343 recon=0.9338 kl=0.0004\n",
      "[Epoch 010] loss=0.9279 recon=0.9275 kl=0.0003\n",
      "[Epoch 011] loss=0.9292 recon=0.9286 kl=0.0006\n",
      "[Epoch 012] loss=0.9244 recon=0.9242 kl=0.0002\n",
      "[Epoch 013] loss=0.9304 recon=0.9297 kl=0.0008\n",
      "[Epoch 014] loss=0.9404 recon=0.9403 kl=0.0001\n",
      "[Epoch 015] loss=0.9346 recon=0.9337 kl=0.0009\n",
      "[Epoch 016] loss=0.9257 recon=0.9254 kl=0.0003\n",
      "[Epoch 017] loss=0.9365 recon=0.9358 kl=0.0006\n",
      "[Epoch 018] loss=0.9175 recon=0.9171 kl=0.0004\n",
      "[Epoch 019] loss=0.9322 recon=0.9317 kl=0.0004\n",
      "[Epoch 020] loss=0.9278 recon=0.9273 kl=0.0005\n",
      "[Epoch 021] loss=0.9293 recon=0.9288 kl=0.0005\n",
      "[Epoch 022] loss=0.9305 recon=0.9300 kl=0.0005\n",
      "[Epoch 023] loss=0.9230 recon=0.9223 kl=0.0007\n",
      "[Epoch 024] loss=0.9261 recon=0.9257 kl=0.0004\n",
      "[Epoch 025] loss=0.9225 recon=0.9217 kl=0.0008\n",
      "[Epoch 026] loss=0.9272 recon=0.9268 kl=0.0004\n",
      "[Epoch 027] loss=0.9251 recon=0.9246 kl=0.0005\n",
      "[Epoch 028] loss=0.9300 recon=0.9293 kl=0.0007\n",
      "[Epoch 029] loss=0.9325 recon=0.9321 kl=0.0004\n",
      "[Epoch 030] loss=0.9265 recon=0.9255 kl=0.0009\n",
      "[Epoch 031] loss=0.9259 recon=0.9256 kl=0.0002\n",
      "[Epoch 032] loss=0.9299 recon=0.9291 kl=0.0008\n",
      "[Epoch 033] loss=0.9220 recon=0.9213 kl=0.0007\n",
      "[Epoch 034] loss=0.9259 recon=0.9254 kl=0.0005\n",
      "[Epoch 035] loss=0.9204 recon=0.9199 kl=0.0005\n",
      "[Epoch 036] loss=0.9305 recon=0.9300 kl=0.0005\n",
      "[Epoch 037] loss=0.9394 recon=0.9389 kl=0.0005\n",
      "[Epoch 038] loss=0.9133 recon=0.9127 kl=0.0006\n",
      "[Epoch 039] loss=0.9285 recon=0.9264 kl=0.0021\n",
      "[Epoch 040] loss=0.9336 recon=0.9303 kl=0.0033\n",
      "[Epoch 041] loss=0.9219 recon=0.9198 kl=0.0020\n",
      "[Epoch 042] loss=0.9278 recon=0.9274 kl=0.0004\n",
      "[Epoch 043] loss=0.9291 recon=0.9290 kl=0.0000\n",
      "[Epoch 044] loss=0.9510 recon=0.9509 kl=0.0000\n",
      "[Epoch 045] loss=0.9421 recon=0.9421 kl=0.0001\n",
      "[Epoch 046] loss=0.9175 recon=0.9168 kl=0.0007\n",
      "[Epoch 047] loss=0.9228 recon=0.9219 kl=0.0009\n",
      "[Epoch 048] loss=0.9150 recon=0.9148 kl=0.0002\n",
      "[Epoch 049] loss=0.9429 recon=0.9410 kl=0.0020\n",
      "[Epoch 050] loss=0.9344 recon=0.9307 kl=0.0037\n",
      "[Epoch 051] loss=0.9347 recon=0.9335 kl=0.0012\n",
      "[Epoch 052] loss=0.9140 recon=0.9139 kl=0.0001\n",
      "[Epoch 053] loss=0.9274 recon=0.9274 kl=0.0000\n",
      "[Epoch 054] loss=0.9190 recon=0.9190 kl=0.0000\n",
      "[Epoch 055] loss=0.9354 recon=0.9349 kl=0.0005\n",
      "[Epoch 056] loss=0.9192 recon=0.9185 kl=0.0006\n",
      "[Epoch 057] loss=0.9341 recon=0.9311 kl=0.0029\n",
      "[Epoch 058] loss=0.9224 recon=0.9213 kl=0.0011\n",
      "[Epoch 059] loss=0.9261 recon=0.9260 kl=0.0001\n",
      "[Epoch 060] loss=0.9300 recon=0.9300 kl=0.0001\n",
      "[Epoch 061] loss=0.9263 recon=0.9256 kl=0.0007\n",
      "[Epoch 062] loss=0.9337 recon=0.9333 kl=0.0004\n",
      "[Epoch 063] loss=0.9220 recon=0.9215 kl=0.0005\n",
      "[Epoch 064] loss=0.9242 recon=0.9239 kl=0.0003\n",
      "[Epoch 065] loss=0.9319 recon=0.9313 kl=0.0006\n",
      "[Epoch 066] loss=0.9388 recon=0.9381 kl=0.0006\n",
      "[Epoch 067] loss=0.9364 recon=0.9361 kl=0.0003\n",
      "[Epoch 068] loss=0.9259 recon=0.9239 kl=0.0020\n",
      "[Epoch 069] loss=0.9309 recon=0.9240 kl=0.0070\n",
      "[Epoch 070] loss=0.9217 recon=0.9208 kl=0.0008\n",
      "[Epoch 071] loss=0.9474 recon=0.9474 kl=0.0001\n",
      "[Epoch 072] loss=0.9202 recon=0.9202 kl=0.0000\n",
      "[Epoch 073] loss=0.9205 recon=0.9205 kl=0.0000\n",
      "[Epoch 074] loss=0.9407 recon=0.9380 kl=0.0026\n",
      "[Epoch 075] loss=0.9472 recon=0.9387 kl=0.0085\n",
      "[Epoch 076] loss=0.9408 recon=0.9394 kl=0.0015\n",
      "[Epoch 077] loss=0.9212 recon=0.9210 kl=0.0002\n",
      "[Epoch 078] loss=0.9306 recon=0.9305 kl=0.0000\n",
      "[Epoch 079] loss=0.9279 recon=0.9279 kl=0.0000\n",
      "[Epoch 080] loss=0.9250 recon=0.9250 kl=0.0000\n",
      "[Epoch 081] loss=0.9306 recon=0.9305 kl=0.0001\n",
      "[Epoch 082] loss=0.9314 recon=0.9308 kl=0.0006\n",
      "[Epoch 083] loss=0.9388 recon=0.9385 kl=0.0003\n",
      "[Epoch 084] loss=0.9228 recon=0.9221 kl=0.0006\n",
      "[Epoch 085] loss=0.9246 recon=0.9242 kl=0.0004\n",
      "[Epoch 086] loss=0.9405 recon=0.9398 kl=0.0007\n",
      "[Epoch 087] loss=0.9114 recon=0.9111 kl=0.0003\n",
      "[Epoch 088] loss=0.9357 recon=0.9351 kl=0.0006\n",
      "[Epoch 089] loss=0.9546 recon=0.9539 kl=0.0006\n",
      "[Epoch 090] loss=0.9415 recon=0.9388 kl=0.0027\n",
      "4\n",
      "[Epoch 001] loss=1.2619 recon=0.9284 kl=0.3335\n",
      "[Epoch 002] loss=0.9359 recon=0.9334 kl=0.0025\n",
      "[Epoch 003] loss=0.9269 recon=0.9266 kl=0.0002\n",
      "[Epoch 004] loss=0.9501 recon=0.9500 kl=0.0002\n",
      "[Epoch 005] loss=0.9345 recon=0.9343 kl=0.0001\n",
      "[Epoch 006] loss=0.9298 recon=0.9297 kl=0.0001\n",
      "[Epoch 007] loss=0.9205 recon=0.9201 kl=0.0004\n",
      "[Epoch 008] loss=0.9181 recon=0.9180 kl=0.0001\n",
      "[Epoch 009] loss=0.9371 recon=0.9366 kl=0.0005\n",
      "[Epoch 010] loss=0.9268 recon=0.9266 kl=0.0002\n",
      "[Epoch 011] loss=0.9283 recon=0.9281 kl=0.0002\n",
      "[Epoch 012] loss=0.9445 recon=0.9442 kl=0.0003\n",
      "[Epoch 013] loss=0.9280 recon=0.9276 kl=0.0004\n",
      "[Epoch 014] loss=0.9320 recon=0.9317 kl=0.0003\n",
      "[Epoch 015] loss=0.9310 recon=0.9304 kl=0.0006\n",
      "[Epoch 016] loss=0.9408 recon=0.9405 kl=0.0003\n",
      "[Epoch 017] loss=0.9407 recon=0.9400 kl=0.0007\n",
      "[Epoch 018] loss=0.9311 recon=0.9306 kl=0.0004\n",
      "[Epoch 019] loss=0.9365 recon=0.9363 kl=0.0003\n",
      "[Epoch 020] loss=0.9280 recon=0.9276 kl=0.0004\n",
      "[Epoch 021] loss=0.9210 recon=0.9204 kl=0.0006\n",
      "[Epoch 022] loss=0.9314 recon=0.9309 kl=0.0005\n",
      "[Epoch 023] loss=0.9279 recon=0.9274 kl=0.0004\n",
      "[Epoch 024] loss=0.9339 recon=0.9332 kl=0.0007\n",
      "[Epoch 025] loss=0.9168 recon=0.9166 kl=0.0003\n",
      "[Epoch 026] loss=0.9169 recon=0.9144 kl=0.0025\n",
      "[Epoch 027] loss=0.9233 recon=0.9228 kl=0.0005\n",
      "[Epoch 028] loss=0.9272 recon=0.9271 kl=0.0001\n",
      "[Epoch 029] loss=0.9394 recon=0.9390 kl=0.0004\n",
      "[Epoch 030] loss=0.9384 recon=0.9376 kl=0.0008\n",
      "[Epoch 031] loss=0.9496 recon=0.9491 kl=0.0005\n",
      "[Epoch 032] loss=0.9271 recon=0.9264 kl=0.0007\n",
      "[Epoch 033] loss=0.9317 recon=0.9313 kl=0.0004\n",
      "[Epoch 034] loss=0.9293 recon=0.9277 kl=0.0016\n",
      "[Epoch 035] loss=0.9342 recon=0.9311 kl=0.0032\n",
      "[Epoch 036] loss=0.9327 recon=0.9324 kl=0.0004\n",
      "[Epoch 037] loss=0.9411 recon=0.9411 kl=0.0000\n",
      "[Epoch 038] loss=0.9188 recon=0.9181 kl=0.0007\n",
      "[Epoch 039] loss=0.9398 recon=0.9394 kl=0.0003\n",
      "[Epoch 040] loss=0.9197 recon=0.9194 kl=0.0003\n",
      "[Epoch 041] loss=0.9226 recon=0.9218 kl=0.0009\n",
      "[Epoch 042] loss=0.9317 recon=0.9310 kl=0.0006\n",
      "[Epoch 043] loss=0.9517 recon=0.9512 kl=0.0005\n",
      "[Epoch 044] loss=0.9243 recon=0.9195 kl=0.0047\n",
      "[Epoch 045] loss=0.9407 recon=0.9371 kl=0.0036\n",
      "[Epoch 046] loss=0.9206 recon=0.9202 kl=0.0004\n",
      "[Epoch 047] loss=0.9281 recon=0.9281 kl=0.0000\n",
      "[Epoch 048] loss=0.9273 recon=0.9273 kl=0.0000\n",
      "[Epoch 049] loss=0.9206 recon=0.9199 kl=0.0007\n",
      "[Epoch 050] loss=0.9190 recon=0.9185 kl=0.0005\n",
      "[Epoch 051] loss=0.9220 recon=0.9216 kl=0.0004\n",
      "[Epoch 052] loss=0.9341 recon=0.9336 kl=0.0005\n",
      "[Epoch 053] loss=0.9441 recon=0.9434 kl=0.0006\n",
      "[Epoch 054] loss=0.9236 recon=0.9228 kl=0.0008\n",
      "[Epoch 055] loss=0.9240 recon=0.9233 kl=0.0007\n",
      "[Epoch 056] loss=0.9183 recon=0.9181 kl=0.0002\n",
      "[Epoch 057] loss=0.9293 recon=0.9286 kl=0.0007\n",
      "[Epoch 058] loss=0.9367 recon=0.9361 kl=0.0006\n",
      "[Epoch 059] loss=0.9361 recon=0.9354 kl=0.0007\n",
      "[Epoch 060] loss=0.9248 recon=0.9243 kl=0.0005\n",
      "[Epoch 061] loss=0.9317 recon=0.9314 kl=0.0002\n",
      "[Epoch 062] loss=0.9229 recon=0.9220 kl=0.0009\n",
      "[Epoch 063] loss=0.9664 recon=0.9658 kl=0.0007\n",
      "[Epoch 064] loss=0.9243 recon=0.9241 kl=0.0002\n",
      "[Epoch 065] loss=0.9283 recon=0.9277 kl=0.0006\n",
      "[Epoch 066] loss=0.9321 recon=0.9313 kl=0.0008\n",
      "[Epoch 067] loss=0.9195 recon=0.9192 kl=0.0003\n",
      "[Epoch 068] loss=0.9270 recon=0.9230 kl=0.0040\n",
      "[Epoch 069] loss=0.9265 recon=0.9237 kl=0.0028\n",
      "[Epoch 070] loss=0.9214 recon=0.9207 kl=0.0007\n",
      "[Epoch 071] loss=0.9234 recon=0.9233 kl=0.0001\n",
      "[Epoch 072] loss=0.9349 recon=0.9349 kl=0.0000\n",
      "[Epoch 073] loss=0.9364 recon=0.9364 kl=0.0000\n",
      "[Epoch 074] loss=0.9195 recon=0.9193 kl=0.0002\n",
      "[Epoch 075] loss=0.9264 recon=0.9254 kl=0.0009\n",
      "[Epoch 076] loss=0.9235 recon=0.9228 kl=0.0007\n",
      "[Epoch 077] loss=0.9311 recon=0.9305 kl=0.0006\n",
      "[Epoch 078] loss=0.9396 recon=0.9392 kl=0.0004\n",
      "[Epoch 079] loss=0.9317 recon=0.9314 kl=0.0003\n",
      "[Epoch 080] loss=0.9242 recon=0.9235 kl=0.0007\n",
      "[Epoch 081] loss=0.9212 recon=0.9201 kl=0.0010\n",
      "[Epoch 082] loss=0.9333 recon=0.9329 kl=0.0003\n",
      "[Epoch 083] loss=0.9241 recon=0.9238 kl=0.0004\n",
      "[Epoch 084] loss=0.9545 recon=0.9540 kl=0.0005\n",
      "[Epoch 085] loss=0.9235 recon=0.9233 kl=0.0002\n",
      "[Epoch 086] loss=0.9306 recon=0.9298 kl=0.0008\n",
      "[Epoch 087] loss=0.9413 recon=0.9371 kl=0.0041\n",
      "[Epoch 088] loss=0.9247 recon=0.9230 kl=0.0017\n",
      "[Epoch 089] loss=0.9431 recon=0.9429 kl=0.0003\n",
      "[Epoch 090] loss=0.9368 recon=0.9368 kl=0.0000\n",
      "5\n",
      "[Epoch 001] loss=1.2852 recon=0.9461 kl=0.3391\n",
      "[Epoch 002] loss=0.9289 recon=0.9265 kl=0.0024\n",
      "[Epoch 003] loss=0.9334 recon=0.9332 kl=0.0002\n",
      "[Epoch 004] loss=0.9492 recon=0.9491 kl=0.0001\n",
      "[Epoch 005] loss=0.9567 recon=0.9566 kl=0.0002\n",
      "[Epoch 006] loss=0.9258 recon=0.9256 kl=0.0002\n",
      "[Epoch 007] loss=0.9345 recon=0.9342 kl=0.0003\n",
      "[Epoch 008] loss=0.9210 recon=0.9207 kl=0.0003\n",
      "[Epoch 009] loss=0.9232 recon=0.9227 kl=0.0004\n",
      "[Epoch 010] loss=0.9255 recon=0.9252 kl=0.0002\n",
      "[Epoch 011] loss=0.9217 recon=0.9214 kl=0.0004\n",
      "[Epoch 012] loss=0.9239 recon=0.9235 kl=0.0004\n",
      "[Epoch 013] loss=0.9292 recon=0.9287 kl=0.0005\n",
      "[Epoch 014] loss=0.9342 recon=0.9336 kl=0.0006\n",
      "[Epoch 015] loss=0.9369 recon=0.9365 kl=0.0004\n",
      "[Epoch 016] loss=0.9334 recon=0.9330 kl=0.0004\n",
      "[Epoch 017] loss=0.9281 recon=0.9277 kl=0.0003\n",
      "[Epoch 018] loss=0.9252 recon=0.9246 kl=0.0006\n",
      "[Epoch 019] loss=0.9366 recon=0.9363 kl=0.0003\n",
      "[Epoch 020] loss=0.9484 recon=0.9480 kl=0.0005\n",
      "[Epoch 021] loss=0.9265 recon=0.9258 kl=0.0007\n",
      "[Epoch 022] loss=0.9337 recon=0.9334 kl=0.0003\n",
      "[Epoch 023] loss=0.9251 recon=0.9245 kl=0.0006\n",
      "[Epoch 024] loss=0.9226 recon=0.9223 kl=0.0002\n",
      "[Epoch 025] loss=0.9264 recon=0.9200 kl=0.0064\n",
      "[Epoch 026] loss=0.9166 recon=0.9136 kl=0.0029\n",
      "[Epoch 027] loss=0.9326 recon=0.9323 kl=0.0003\n",
      "[Epoch 028] loss=0.9253 recon=0.9252 kl=0.0000\n",
      "[Epoch 029] loss=0.9329 recon=0.9328 kl=0.0000\n",
      "[Epoch 030] loss=0.9209 recon=0.9201 kl=0.0008\n",
      "[Epoch 031] loss=0.9423 recon=0.9417 kl=0.0006\n",
      "[Epoch 032] loss=0.9262 recon=0.9256 kl=0.0006\n",
      "[Epoch 033] loss=0.9318 recon=0.9314 kl=0.0004\n",
      "[Epoch 034] loss=0.9316 recon=0.9309 kl=0.0006\n",
      "[Epoch 035] loss=0.9264 recon=0.9260 kl=0.0005\n",
      "[Epoch 036] loss=0.9379 recon=0.9374 kl=0.0005\n",
      "[Epoch 037] loss=0.9313 recon=0.9306 kl=0.0007\n",
      "[Epoch 038] loss=0.9316 recon=0.9311 kl=0.0005\n",
      "[Epoch 039] loss=0.9251 recon=0.9243 kl=0.0008\n",
      "[Epoch 040] loss=0.9291 recon=0.9283 kl=0.0008\n",
      "[Epoch 041] loss=0.9138 recon=0.9137 kl=0.0001\n",
      "[Epoch 042] loss=0.9350 recon=0.9343 kl=0.0007\n",
      "[Epoch 043] loss=0.9115 recon=0.9107 kl=0.0007\n",
      "[Epoch 044] loss=0.9170 recon=0.9166 kl=0.0005\n",
      "[Epoch 045] loss=0.9230 recon=0.9227 kl=0.0003\n",
      "[Epoch 046] loss=0.9168 recon=0.9156 kl=0.0011\n",
      "[Epoch 047] loss=0.9294 recon=0.9291 kl=0.0003\n",
      "[Epoch 048] loss=0.9309 recon=0.9304 kl=0.0005\n",
      "[Epoch 049] loss=0.9271 recon=0.9267 kl=0.0004\n",
      "[Epoch 050] loss=0.9238 recon=0.9233 kl=0.0005\n",
      "[Epoch 051] loss=0.9479 recon=0.9469 kl=0.0010\n",
      "[Epoch 052] loss=0.9202 recon=0.9185 kl=0.0017\n",
      "[Epoch 053] loss=0.9260 recon=0.9227 kl=0.0033\n",
      "[Epoch 054] loss=0.9302 recon=0.9281 kl=0.0021\n",
      "[Epoch 055] loss=0.9335 recon=0.9320 kl=0.0015\n",
      "[Epoch 056] loss=0.9367 recon=0.9365 kl=0.0002\n",
      "[Epoch 057] loss=0.9171 recon=0.9171 kl=0.0000\n",
      "[Epoch 058] loss=0.9207 recon=0.9207 kl=0.0000\n",
      "[Epoch 059] loss=0.9282 recon=0.9282 kl=0.0000\n",
      "[Epoch 060] loss=0.9234 recon=0.9230 kl=0.0004\n",
      "[Epoch 061] loss=0.9229 recon=0.9224 kl=0.0006\n",
      "[Epoch 062] loss=0.9253 recon=0.9248 kl=0.0005\n",
      "[Epoch 063] loss=0.9287 recon=0.9284 kl=0.0003\n",
      "[Epoch 064] loss=0.9150 recon=0.9146 kl=0.0005\n",
      "[Epoch 065] loss=0.9360 recon=0.9355 kl=0.0005\n",
      "[Epoch 066] loss=0.9358 recon=0.9352 kl=0.0006\n",
      "[Epoch 067] loss=0.9444 recon=0.9439 kl=0.0004\n",
      "[Epoch 068] loss=0.9312 recon=0.9278 kl=0.0034\n",
      "[Epoch 069] loss=0.9324 recon=0.9320 kl=0.0004\n",
      "[Epoch 070] loss=0.9257 recon=0.9256 kl=0.0000\n",
      "[Epoch 071] loss=0.9196 recon=0.9194 kl=0.0002\n",
      "[Epoch 072] loss=0.9200 recon=0.9177 kl=0.0023\n",
      "[Epoch 073] loss=0.9231 recon=0.9197 kl=0.0034\n",
      "[Epoch 074] loss=0.9328 recon=0.9303 kl=0.0025\n",
      "[Epoch 075] loss=0.9316 recon=0.9296 kl=0.0020\n",
      "[Epoch 076] loss=0.9237 recon=0.9222 kl=0.0014\n",
      "[Epoch 077] loss=0.9386 recon=0.9383 kl=0.0002\n",
      "[Epoch 078] loss=0.9176 recon=0.9176 kl=0.0000\n",
      "[Epoch 079] loss=0.9349 recon=0.9349 kl=0.0000\n",
      "[Epoch 080] loss=0.9192 recon=0.9192 kl=0.0000\n",
      "[Epoch 081] loss=0.9220 recon=0.9220 kl=0.0000\n",
      "[Epoch 082] loss=0.9234 recon=0.9229 kl=0.0005\n",
      "[Epoch 083] loss=0.9421 recon=0.9340 kl=0.0082\n",
      "[Epoch 084] loss=0.9225 recon=0.9209 kl=0.0016\n",
      "[Epoch 085] loss=0.9275 recon=0.9273 kl=0.0002\n",
      "[Epoch 086] loss=0.9304 recon=0.9304 kl=0.0000\n",
      "[Epoch 087] loss=0.9194 recon=0.9194 kl=0.0000\n",
      "[Epoch 088] loss=0.9321 recon=0.9321 kl=0.0000\n",
      "[Epoch 089] loss=0.9275 recon=0.9270 kl=0.0004\n",
      "[Epoch 090] loss=0.9254 recon=0.9249 kl=0.0006\n",
      "6\n",
      "[Epoch 001] loss=1.3040 recon=0.9257 kl=0.3783\n",
      "[Epoch 002] loss=0.9262 recon=0.9236 kl=0.0026\n",
      "[Epoch 003] loss=0.9280 recon=0.9277 kl=0.0002\n",
      "[Epoch 004] loss=0.9408 recon=0.9406 kl=0.0003\n",
      "[Epoch 005] loss=0.9242 recon=0.9240 kl=0.0001\n",
      "[Epoch 006] loss=0.9402 recon=0.9400 kl=0.0001\n",
      "[Epoch 007] loss=0.9391 recon=0.9388 kl=0.0004\n",
      "[Epoch 008] loss=0.9220 recon=0.9217 kl=0.0003\n",
      "[Epoch 009] loss=0.9387 recon=0.9386 kl=0.0002\n",
      "[Epoch 010] loss=0.9408 recon=0.9403 kl=0.0005\n",
      "[Epoch 011] loss=0.9381 recon=0.9379 kl=0.0001\n",
      "[Epoch 012] loss=0.9353 recon=0.9346 kl=0.0006\n",
      "[Epoch 013] loss=0.9316 recon=0.9315 kl=0.0002\n",
      "[Epoch 014] loss=0.9298 recon=0.9292 kl=0.0007\n",
      "[Epoch 015] loss=0.9314 recon=0.9311 kl=0.0004\n",
      "[Epoch 016] loss=0.9477 recon=0.9468 kl=0.0009\n",
      "[Epoch 017] loss=0.9275 recon=0.9273 kl=0.0002\n",
      "[Epoch 018] loss=0.9299 recon=0.9292 kl=0.0007\n",
      "[Epoch 019] loss=0.9335 recon=0.9332 kl=0.0003\n",
      "[Epoch 020] loss=0.9529 recon=0.9488 kl=0.0041\n",
      "[Epoch 021] loss=0.9298 recon=0.9279 kl=0.0019\n",
      "[Epoch 022] loss=0.9255 recon=0.9252 kl=0.0003\n",
      "[Epoch 023] loss=0.9461 recon=0.9461 kl=0.0000\n",
      "[Epoch 024] loss=0.9239 recon=0.9237 kl=0.0002\n",
      "[Epoch 025] loss=0.9176 recon=0.9171 kl=0.0005\n",
      "[Epoch 026] loss=0.9265 recon=0.9261 kl=0.0004\n",
      "[Epoch 027] loss=0.9305 recon=0.9299 kl=0.0006\n",
      "[Epoch 028] loss=0.9339 recon=0.9334 kl=0.0005\n",
      "[Epoch 029] loss=0.9190 recon=0.9167 kl=0.0023\n",
      "[Epoch 030] loss=0.9290 recon=0.9283 kl=0.0007\n",
      "[Epoch 031] loss=0.9391 recon=0.9390 kl=0.0001\n",
      "[Epoch 032] loss=0.9415 recon=0.9404 kl=0.0011\n",
      "[Epoch 033] loss=0.9292 recon=0.9257 kl=0.0035\n",
      "[Epoch 034] loss=0.9335 recon=0.9327 kl=0.0008\n",
      "[Epoch 035] loss=0.9246 recon=0.9245 kl=0.0001\n",
      "[Epoch 036] loss=0.9298 recon=0.9297 kl=0.0000\n",
      "[Epoch 037] loss=0.9271 recon=0.9261 kl=0.0010\n",
      "[Epoch 038] loss=0.9387 recon=0.9384 kl=0.0003\n",
      "[Epoch 039] loss=0.9296 recon=0.9266 kl=0.0030\n",
      "[Epoch 040] loss=0.9210 recon=0.9198 kl=0.0011\n",
      "[Epoch 041] loss=0.9177 recon=0.9176 kl=0.0001\n",
      "[Epoch 042] loss=0.9274 recon=0.9274 kl=0.0000\n",
      "[Epoch 043] loss=0.9515 recon=0.9510 kl=0.0005\n",
      "[Epoch 044] loss=0.9603 recon=0.9526 kl=0.0076\n",
      "[Epoch 045] loss=0.9302 recon=0.9237 kl=0.0064\n",
      "[Epoch 046] loss=0.9208 recon=0.9197 kl=0.0011\n",
      "[Epoch 047] loss=0.9374 recon=0.9373 kl=0.0001\n",
      "[Epoch 048] loss=0.9427 recon=0.9427 kl=0.0000\n",
      "[Epoch 049] loss=0.9166 recon=0.9166 kl=0.0000\n",
      "[Epoch 050] loss=0.9207 recon=0.9207 kl=0.0000\n",
      "[Epoch 051] loss=0.9211 recon=0.9204 kl=0.0008\n",
      "[Epoch 052] loss=0.9269 recon=0.9225 kl=0.0044\n",
      "[Epoch 053] loss=0.9299 recon=0.9282 kl=0.0017\n",
      "[Epoch 054] loss=0.9202 recon=0.9198 kl=0.0003\n",
      "[Epoch 055] loss=0.9405 recon=0.9405 kl=0.0000\n",
      "[Epoch 056] loss=0.9353 recon=0.9353 kl=0.0000\n",
      "[Epoch 057] loss=0.9269 recon=0.9261 kl=0.0008\n",
      "[Epoch 058] loss=0.9229 recon=0.9227 kl=0.0002\n",
      "[Epoch 059] loss=0.9241 recon=0.9231 kl=0.0010\n",
      "[Epoch 060] loss=0.9231 recon=0.9227 kl=0.0004\n",
      "[Epoch 061] loss=0.9314 recon=0.9307 kl=0.0006\n",
      "[Epoch 062] loss=0.9182 recon=0.9177 kl=0.0004\n",
      "[Epoch 063] loss=0.9233 recon=0.9228 kl=0.0005\n",
      "[Epoch 064] loss=0.9235 recon=0.9231 kl=0.0004\n",
      "[Epoch 065] loss=0.9197 recon=0.9192 kl=0.0005\n",
      "[Epoch 066] loss=0.9441 recon=0.9437 kl=0.0004\n",
      "[Epoch 067] loss=0.9266 recon=0.9260 kl=0.0006\n",
      "[Epoch 068] loss=0.9350 recon=0.9346 kl=0.0005\n",
      "[Epoch 069] loss=0.9240 recon=0.9234 kl=0.0005\n",
      "[Epoch 070] loss=0.9320 recon=0.9316 kl=0.0004\n",
      "[Epoch 071] loss=0.9167 recon=0.9162 kl=0.0006\n",
      "[Epoch 072] loss=0.9307 recon=0.9302 kl=0.0005\n",
      "[Epoch 073] loss=0.9512 recon=0.9507 kl=0.0005\n",
      "[Epoch 074] loss=0.9176 recon=0.9171 kl=0.0005\n",
      "[Epoch 075] loss=0.9168 recon=0.9163 kl=0.0005\n",
      "[Epoch 076] loss=0.9346 recon=0.9341 kl=0.0005\n",
      "[Epoch 077] loss=0.9320 recon=0.9317 kl=0.0003\n",
      "[Epoch 078] loss=0.9313 recon=0.9307 kl=0.0007\n",
      "[Epoch 079] loss=0.9256 recon=0.9250 kl=0.0006\n",
      "[Epoch 080] loss=0.9367 recon=0.9364 kl=0.0003\n",
      "[Epoch 081] loss=0.9217 recon=0.9213 kl=0.0004\n",
      "[Epoch 082] loss=0.9290 recon=0.9285 kl=0.0005\n",
      "[Epoch 083] loss=0.9243 recon=0.9238 kl=0.0004\n",
      "[Epoch 084] loss=0.9302 recon=0.9297 kl=0.0005\n",
      "[Epoch 085] loss=0.9288 recon=0.9283 kl=0.0005\n",
      "[Epoch 086] loss=0.9259 recon=0.9252 kl=0.0007\n",
      "[Epoch 087] loss=0.9214 recon=0.9211 kl=0.0003\n",
      "[Epoch 088] loss=0.9232 recon=0.9226 kl=0.0006\n",
      "[Epoch 089] loss=0.9206 recon=0.9202 kl=0.0004\n",
      "[Epoch 090] loss=0.9171 recon=0.9165 kl=0.0006\n",
      "7\n",
      "[Epoch 001] loss=1.1781 recon=0.9379 kl=0.2402\n",
      "[Epoch 002] loss=0.9448 recon=0.9424 kl=0.0024\n",
      "[Epoch 003] loss=0.9521 recon=0.9518 kl=0.0003\n",
      "[Epoch 004] loss=0.9313 recon=0.9311 kl=0.0002\n",
      "[Epoch 005] loss=0.9259 recon=0.9257 kl=0.0002\n",
      "[Epoch 006] loss=0.9230 recon=0.9228 kl=0.0002\n",
      "[Epoch 007] loss=0.9295 recon=0.9293 kl=0.0002\n",
      "[Epoch 008] loss=0.9250 recon=0.9247 kl=0.0003\n",
      "[Epoch 009] loss=0.9272 recon=0.9270 kl=0.0002\n",
      "[Epoch 010] loss=0.9211 recon=0.9206 kl=0.0005\n",
      "[Epoch 011] loss=0.9329 recon=0.9327 kl=0.0002\n",
      "[Epoch 012] loss=0.9223 recon=0.9219 kl=0.0004\n",
      "[Epoch 013] loss=0.9219 recon=0.9218 kl=0.0001\n",
      "[Epoch 014] loss=0.9308 recon=0.9302 kl=0.0006\n",
      "[Epoch 015] loss=0.9249 recon=0.9246 kl=0.0003\n",
      "[Epoch 016] loss=0.9258 recon=0.9237 kl=0.0021\n",
      "[Epoch 017] loss=0.9401 recon=0.9345 kl=0.0056\n",
      "[Epoch 018] loss=0.9305 recon=0.9298 kl=0.0006\n",
      "[Epoch 019] loss=0.9239 recon=0.9238 kl=0.0001\n",
      "[Epoch 020] loss=0.9301 recon=0.9300 kl=0.0000\n",
      "[Epoch 021] loss=0.9283 recon=0.9282 kl=0.0001\n",
      "[Epoch 022] loss=0.9245 recon=0.9240 kl=0.0005\n",
      "[Epoch 023] loss=0.9217 recon=0.9213 kl=0.0005\n",
      "[Epoch 024] loss=0.9366 recon=0.9362 kl=0.0004\n",
      "[Epoch 025] loss=0.9389 recon=0.9385 kl=0.0004\n",
      "[Epoch 026] loss=0.9285 recon=0.9245 kl=0.0040\n",
      "[Epoch 027] loss=0.9252 recon=0.9234 kl=0.0019\n",
      "[Epoch 028] loss=0.9333 recon=0.9330 kl=0.0003\n",
      "[Epoch 029] loss=0.9316 recon=0.9315 kl=0.0000\n",
      "[Epoch 030] loss=0.9271 recon=0.9268 kl=0.0003\n",
      "[Epoch 031] loss=0.9356 recon=0.9354 kl=0.0002\n",
      "[Epoch 032] loss=0.9428 recon=0.9424 kl=0.0004\n",
      "[Epoch 033] loss=0.9405 recon=0.9398 kl=0.0007\n",
      "[Epoch 034] loss=0.9299 recon=0.9296 kl=0.0004\n",
      "[Epoch 035] loss=0.9210 recon=0.9207 kl=0.0003\n",
      "[Epoch 036] loss=0.9154 recon=0.9150 kl=0.0004\n",
      "[Epoch 037] loss=0.9410 recon=0.9405 kl=0.0005\n",
      "[Epoch 038] loss=0.9326 recon=0.9315 kl=0.0010\n",
      "[Epoch 039] loss=0.9385 recon=0.9382 kl=0.0002\n",
      "[Epoch 040] loss=0.9563 recon=0.9559 kl=0.0004\n",
      "[Epoch 041] loss=0.9384 recon=0.9358 kl=0.0026\n",
      "[Epoch 042] loss=0.9451 recon=0.9348 kl=0.0103\n",
      "[Epoch 043] loss=0.9189 recon=0.9181 kl=0.0008\n",
      "[Epoch 044] loss=0.9608 recon=0.9607 kl=0.0001\n",
      "[Epoch 045] loss=0.9289 recon=0.9289 kl=0.0000\n",
      "[Epoch 046] loss=0.9233 recon=0.9233 kl=0.0000\n",
      "[Epoch 047] loss=0.9341 recon=0.9340 kl=0.0001\n",
      "[Epoch 048] loss=0.9225 recon=0.9219 kl=0.0006\n",
      "[Epoch 049] loss=0.9178 recon=0.9171 kl=0.0006\n",
      "[Epoch 050] loss=0.9256 recon=0.9253 kl=0.0004\n",
      "[Epoch 051] loss=0.9164 recon=0.9157 kl=0.0007\n",
      "[Epoch 052] loss=0.9269 recon=0.9268 kl=0.0001\n",
      "[Epoch 053] loss=0.9265 recon=0.9260 kl=0.0005\n",
      "[Epoch 054] loss=0.9239 recon=0.9230 kl=0.0009\n",
      "[Epoch 055] loss=0.9252 recon=0.9245 kl=0.0007\n",
      "[Epoch 056] loss=0.9213 recon=0.9210 kl=0.0003\n",
      "[Epoch 057] loss=0.9241 recon=0.9235 kl=0.0006\n",
      "[Epoch 058] loss=0.9199 recon=0.9198 kl=0.0001\n",
      "[Epoch 059] loss=0.9173 recon=0.9165 kl=0.0008\n",
      "[Epoch 060] loss=0.9417 recon=0.9409 kl=0.0008\n",
      "[Epoch 061] loss=0.9215 recon=0.9210 kl=0.0005\n",
      "[Epoch 062] loss=0.9254 recon=0.9252 kl=0.0002\n",
      "[Epoch 063] loss=0.9351 recon=0.9345 kl=0.0006\n",
      "[Epoch 064] loss=0.9313 recon=0.9306 kl=0.0006\n",
      "[Epoch 065] loss=0.9224 recon=0.9221 kl=0.0004\n",
      "[Epoch 066] loss=0.9214 recon=0.9207 kl=0.0007\n",
      "[Epoch 067] loss=0.9235 recon=0.9231 kl=0.0004\n",
      "[Epoch 068] loss=0.9212 recon=0.9207 kl=0.0006\n",
      "[Epoch 069] loss=0.9316 recon=0.9313 kl=0.0004\n",
      "[Epoch 070] loss=0.9425 recon=0.9420 kl=0.0005\n",
      "[Epoch 071] loss=0.9213 recon=0.9208 kl=0.0005\n",
      "[Epoch 072] loss=0.9289 recon=0.9284 kl=0.0005\n",
      "[Epoch 073] loss=0.9307 recon=0.9298 kl=0.0009\n",
      "[Epoch 074] loss=0.9286 recon=0.9283 kl=0.0002\n",
      "[Epoch 075] loss=0.9181 recon=0.9174 kl=0.0006\n",
      "[Epoch 076] loss=0.9229 recon=0.9223 kl=0.0005\n",
      "[Epoch 077] loss=0.9391 recon=0.9388 kl=0.0003\n",
      "[Epoch 078] loss=0.9226 recon=0.9219 kl=0.0007\n",
      "[Epoch 079] loss=0.9242 recon=0.9238 kl=0.0004\n",
      "[Epoch 080] loss=0.9274 recon=0.9270 kl=0.0003\n",
      "[Epoch 081] loss=0.9309 recon=0.9303 kl=0.0006\n",
      "[Epoch 082] loss=0.9198 recon=0.9192 kl=0.0007\n",
      "[Epoch 083] loss=0.9225 recon=0.9224 kl=0.0001\n",
      "[Epoch 084] loss=0.9255 recon=0.9247 kl=0.0008\n",
      "[Epoch 085] loss=0.9335 recon=0.9332 kl=0.0004\n",
      "[Epoch 086] loss=0.9290 recon=0.9286 kl=0.0004\n",
      "[Epoch 087] loss=0.9421 recon=0.9415 kl=0.0006\n",
      "[Epoch 088] loss=0.9483 recon=0.9478 kl=0.0004\n",
      "[Epoch 089] loss=0.9253 recon=0.9245 kl=0.0008\n",
      "[Epoch 090] loss=0.9256 recon=0.9252 kl=0.0003\n",
      "8\n",
      "[Epoch 001] loss=1.3819 recon=0.9412 kl=0.4407\n",
      "[Epoch 002] loss=0.9363 recon=0.9332 kl=0.0031\n",
      "[Epoch 003] loss=0.9408 recon=0.9405 kl=0.0002\n",
      "[Epoch 004] loss=0.9357 recon=0.9356 kl=0.0001\n",
      "[Epoch 005] loss=0.9421 recon=0.9420 kl=0.0001\n",
      "[Epoch 006] loss=0.9356 recon=0.9355 kl=0.0001\n",
      "[Epoch 007] loss=0.9384 recon=0.9382 kl=0.0002\n",
      "[Epoch 008] loss=0.9384 recon=0.9383 kl=0.0001\n",
      "[Epoch 009] loss=0.9254 recon=0.9252 kl=0.0002\n",
      "[Epoch 010] loss=0.9227 recon=0.9224 kl=0.0003\n",
      "[Epoch 011] loss=0.9453 recon=0.9443 kl=0.0010\n",
      "[Epoch 012] loss=0.9413 recon=0.9411 kl=0.0002\n",
      "[Epoch 013] loss=0.9241 recon=0.9241 kl=0.0000\n",
      "[Epoch 014] loss=0.9267 recon=0.9261 kl=0.0005\n",
      "[Epoch 015] loss=0.9505 recon=0.9504 kl=0.0001\n",
      "[Epoch 016] loss=0.9336 recon=0.9330 kl=0.0005\n",
      "[Epoch 017] loss=0.9398 recon=0.9394 kl=0.0003\n",
      "[Epoch 018] loss=0.9548 recon=0.9545 kl=0.0003\n",
      "[Epoch 019] loss=0.9292 recon=0.9287 kl=0.0005\n",
      "[Epoch 020] loss=0.9511 recon=0.9508 kl=0.0004\n",
      "[Epoch 021] loss=0.9492 recon=0.9488 kl=0.0004\n",
      "[Epoch 022] loss=0.9269 recon=0.9263 kl=0.0006\n",
      "[Epoch 023] loss=0.9213 recon=0.9211 kl=0.0002\n",
      "[Epoch 024] loss=0.9389 recon=0.9385 kl=0.0005\n",
      "[Epoch 025] loss=0.9296 recon=0.9290 kl=0.0006\n",
      "[Epoch 026] loss=0.9330 recon=0.9327 kl=0.0003\n",
      "[Epoch 027] loss=0.9220 recon=0.9212 kl=0.0007\n",
      "[Epoch 028] loss=0.9327 recon=0.9321 kl=0.0006\n",
      "[Epoch 029] loss=0.9421 recon=0.9416 kl=0.0005\n",
      "[Epoch 030] loss=0.9394 recon=0.9390 kl=0.0004\n",
      "[Epoch 031] loss=0.9207 recon=0.9201 kl=0.0006\n",
      "[Epoch 032] loss=0.9310 recon=0.9308 kl=0.0003\n",
      "[Epoch 033] loss=0.9283 recon=0.9274 kl=0.0009\n",
      "[Epoch 034] loss=0.9371 recon=0.9366 kl=0.0005\n",
      "[Epoch 035] loss=0.9288 recon=0.9285 kl=0.0003\n",
      "[Epoch 036] loss=0.9268 recon=0.9263 kl=0.0005\n",
      "[Epoch 037] loss=0.9278 recon=0.9272 kl=0.0007\n",
      "[Epoch 038] loss=0.9275 recon=0.9268 kl=0.0008\n",
      "[Epoch 039] loss=0.9223 recon=0.9221 kl=0.0002\n",
      "[Epoch 040] loss=0.9332 recon=0.9327 kl=0.0006\n",
      "[Epoch 041] loss=0.9555 recon=0.9551 kl=0.0004\n",
      "[Epoch 042] loss=0.9223 recon=0.9211 kl=0.0012\n",
      "[Epoch 043] loss=0.9351 recon=0.9345 kl=0.0005\n",
      "[Epoch 044] loss=0.9300 recon=0.9297 kl=0.0003\n",
      "[Epoch 045] loss=0.9270 recon=0.9265 kl=0.0005\n",
      "[Epoch 046] loss=0.9403 recon=0.9397 kl=0.0006\n",
      "[Epoch 047] loss=0.9284 recon=0.9280 kl=0.0004\n",
      "[Epoch 048] loss=0.9251 recon=0.9246 kl=0.0005\n",
      "[Epoch 049] loss=0.9281 recon=0.9275 kl=0.0006\n",
      "[Epoch 050] loss=0.9372 recon=0.9366 kl=0.0006\n",
      "[Epoch 051] loss=0.9277 recon=0.9274 kl=0.0003\n",
      "[Epoch 052] loss=0.9352 recon=0.9344 kl=0.0008\n",
      "[Epoch 053] loss=0.9348 recon=0.9345 kl=0.0004\n",
      "[Epoch 054] loss=0.9241 recon=0.9237 kl=0.0004\n",
      "[Epoch 055] loss=0.9283 recon=0.9274 kl=0.0009\n",
      "[Epoch 056] loss=0.9313 recon=0.9279 kl=0.0034\n",
      "[Epoch 057] loss=0.9296 recon=0.9278 kl=0.0018\n",
      "[Epoch 058] loss=0.9324 recon=0.9322 kl=0.0001\n",
      "[Epoch 059] loss=0.9220 recon=0.9220 kl=0.0000\n",
      "[Epoch 060] loss=0.9360 recon=0.9357 kl=0.0003\n",
      "[Epoch 061] loss=0.9349 recon=0.9295 kl=0.0054\n",
      "[Epoch 062] loss=0.9360 recon=0.9276 kl=0.0085\n",
      "[Epoch 063] loss=0.9447 recon=0.9405 kl=0.0043\n",
      "[Epoch 064] loss=0.9213 recon=0.9209 kl=0.0004\n",
      "[Epoch 065] loss=0.9289 recon=0.9288 kl=0.0000\n",
      "[Epoch 066] loss=0.9400 recon=0.9400 kl=0.0000\n",
      "[Epoch 067] loss=0.9290 recon=0.9290 kl=0.0000\n",
      "[Epoch 068] loss=0.9209 recon=0.9209 kl=0.0000\n",
      "[Epoch 069] loss=0.9324 recon=0.9323 kl=0.0000\n",
      "[Epoch 070] loss=0.9395 recon=0.9389 kl=0.0005\n",
      "[Epoch 071] loss=0.9488 recon=0.9485 kl=0.0003\n",
      "[Epoch 072] loss=0.9227 recon=0.9223 kl=0.0004\n",
      "[Epoch 073] loss=0.9289 recon=0.9286 kl=0.0003\n",
      "[Epoch 074] loss=0.9305 recon=0.9302 kl=0.0004\n",
      "[Epoch 075] loss=0.9206 recon=0.9200 kl=0.0006\n",
      "[Epoch 076] loss=0.9284 recon=0.9280 kl=0.0004\n",
      "[Epoch 077] loss=0.9241 recon=0.9238 kl=0.0003\n",
      "[Epoch 078] loss=0.9310 recon=0.9305 kl=0.0005\n",
      "[Epoch 079] loss=0.9307 recon=0.9301 kl=0.0006\n",
      "[Epoch 080] loss=0.9260 recon=0.9255 kl=0.0005\n",
      "[Epoch 081] loss=0.9305 recon=0.9301 kl=0.0004\n",
      "[Epoch 082] loss=0.9422 recon=0.9420 kl=0.0002\n",
      "[Epoch 083] loss=0.9408 recon=0.9404 kl=0.0005\n",
      "[Epoch 084] loss=0.9346 recon=0.9342 kl=0.0005\n",
      "[Epoch 085] loss=0.9278 recon=0.9272 kl=0.0006\n",
      "[Epoch 086] loss=0.9245 recon=0.9243 kl=0.0002\n",
      "[Epoch 087] loss=0.9361 recon=0.9353 kl=0.0008\n",
      "[Epoch 088] loss=0.9404 recon=0.9402 kl=0.0002\n",
      "[Epoch 089] loss=0.9180 recon=0.9177 kl=0.0003\n",
      "[Epoch 090] loss=0.9261 recon=0.9255 kl=0.0007\n",
      "9\n",
      "[Epoch 001] loss=1.2900 recon=0.9643 kl=0.3258\n",
      "[Epoch 002] loss=0.9386 recon=0.9355 kl=0.0031\n",
      "[Epoch 003] loss=0.9437 recon=0.9435 kl=0.0003\n",
      "[Epoch 004] loss=0.9326 recon=0.9325 kl=0.0001\n",
      "[Epoch 005] loss=0.9407 recon=0.9404 kl=0.0003\n",
      "[Epoch 006] loss=0.9360 recon=0.9359 kl=0.0001\n",
      "[Epoch 007] loss=0.9297 recon=0.9295 kl=0.0002\n",
      "[Epoch 008] loss=0.9252 recon=0.9246 kl=0.0006\n",
      "[Epoch 009] loss=0.9388 recon=0.9387 kl=0.0001\n",
      "[Epoch 010] loss=0.9269 recon=0.9265 kl=0.0004\n",
      "[Epoch 011] loss=0.9223 recon=0.9219 kl=0.0004\n",
      "[Epoch 012] loss=0.9245 recon=0.9243 kl=0.0002\n",
      "[Epoch 013] loss=0.9269 recon=0.9264 kl=0.0005\n",
      "[Epoch 014] loss=0.9300 recon=0.9297 kl=0.0003\n",
      "[Epoch 015] loss=0.9389 recon=0.9384 kl=0.0005\n",
      "[Epoch 016] loss=0.9178 recon=0.9173 kl=0.0004\n",
      "[Epoch 017] loss=0.9213 recon=0.9209 kl=0.0004\n",
      "[Epoch 018] loss=0.9380 recon=0.9373 kl=0.0007\n",
      "[Epoch 019] loss=0.9264 recon=0.9263 kl=0.0002\n",
      "[Epoch 020] loss=0.9246 recon=0.9239 kl=0.0007\n",
      "[Epoch 021] loss=0.9288 recon=0.9285 kl=0.0003\n",
      "[Epoch 022] loss=0.9404 recon=0.9400 kl=0.0004\n",
      "[Epoch 023] loss=0.9275 recon=0.9248 kl=0.0027\n",
      "[Epoch 024] loss=0.9183 recon=0.9177 kl=0.0006\n",
      "[Epoch 025] loss=0.9319 recon=0.9318 kl=0.0001\n",
      "[Epoch 026] loss=0.9409 recon=0.9405 kl=0.0004\n",
      "[Epoch 027] loss=0.9375 recon=0.9372 kl=0.0003\n",
      "[Epoch 028] loss=0.9260 recon=0.9254 kl=0.0006\n",
      "[Epoch 029] loss=0.9393 recon=0.9389 kl=0.0004\n",
      "[Epoch 030] loss=0.9373 recon=0.9366 kl=0.0008\n",
      "[Epoch 031] loss=0.9265 recon=0.9260 kl=0.0006\n",
      "[Epoch 032] loss=0.9356 recon=0.9352 kl=0.0003\n",
      "[Epoch 033] loss=0.9400 recon=0.9392 kl=0.0008\n",
      "[Epoch 034] loss=0.9384 recon=0.9379 kl=0.0005\n",
      "[Epoch 035] loss=0.9242 recon=0.9241 kl=0.0002\n",
      "[Epoch 036] loss=0.9263 recon=0.9253 kl=0.0010\n",
      "[Epoch 037] loss=0.9322 recon=0.9314 kl=0.0008\n",
      "[Epoch 038] loss=0.9458 recon=0.9453 kl=0.0005\n",
      "[Epoch 039] loss=0.9173 recon=0.9169 kl=0.0005\n",
      "[Epoch 040] loss=0.9487 recon=0.9482 kl=0.0005\n",
      "[Epoch 041] loss=0.9273 recon=0.9265 kl=0.0008\n",
      "[Epoch 042] loss=0.9261 recon=0.9258 kl=0.0003\n",
      "[Epoch 043] loss=0.9254 recon=0.9249 kl=0.0005\n",
      "[Epoch 044] loss=0.9192 recon=0.9181 kl=0.0011\n",
      "[Epoch 045] loss=0.9204 recon=0.9200 kl=0.0003\n",
      "[Epoch 046] loss=0.9283 recon=0.9276 kl=0.0006\n",
      "[Epoch 047] loss=0.9176 recon=0.9170 kl=0.0005\n",
      "[Epoch 048] loss=0.9322 recon=0.9313 kl=0.0008\n",
      "[Epoch 049] loss=0.9490 recon=0.9484 kl=0.0006\n",
      "[Epoch 050] loss=0.9204 recon=0.9197 kl=0.0007\n",
      "[Epoch 051] loss=0.9286 recon=0.9284 kl=0.0002\n",
      "[Epoch 052] loss=0.9379 recon=0.9368 kl=0.0011\n",
      "[Epoch 053] loss=0.9341 recon=0.9339 kl=0.0002\n",
      "[Epoch 054] loss=0.9340 recon=0.9332 kl=0.0008\n",
      "[Epoch 055] loss=0.9416 recon=0.9410 kl=0.0005\n",
      "[Epoch 056] loss=0.9271 recon=0.9270 kl=0.0001\n",
      "[Epoch 057] loss=0.9368 recon=0.9361 kl=0.0006\n",
      "[Epoch 058] loss=0.9425 recon=0.9386 kl=0.0039\n",
      "[Epoch 059] loss=0.9327 recon=0.9302 kl=0.0025\n",
      "[Epoch 060] loss=0.9247 recon=0.9244 kl=0.0003\n",
      "[Epoch 061] loss=0.9174 recon=0.9173 kl=0.0000\n",
      "[Epoch 062] loss=0.9473 recon=0.9473 kl=0.0000\n",
      "[Epoch 063] loss=0.9180 recon=0.9175 kl=0.0005\n",
      "[Epoch 064] loss=0.9206 recon=0.9201 kl=0.0006\n",
      "[Epoch 065] loss=0.9357 recon=0.9353 kl=0.0005\n",
      "[Epoch 066] loss=0.9313 recon=0.9309 kl=0.0004\n",
      "[Epoch 067] loss=0.9268 recon=0.9263 kl=0.0005\n",
      "[Epoch 068] loss=0.9337 recon=0.9332 kl=0.0005\n",
      "[Epoch 069] loss=0.9238 recon=0.9234 kl=0.0005\n",
      "[Epoch 070] loss=0.9466 recon=0.9462 kl=0.0004\n",
      "[Epoch 071] loss=0.9227 recon=0.9220 kl=0.0007\n",
      "[Epoch 072] loss=0.9202 recon=0.9199 kl=0.0003\n",
      "[Epoch 073] loss=0.9217 recon=0.9211 kl=0.0006\n",
      "[Epoch 074] loss=0.9319 recon=0.9312 kl=0.0007\n",
      "[Epoch 075] loss=0.9216 recon=0.9212 kl=0.0004\n",
      "[Epoch 076] loss=0.9419 recon=0.9415 kl=0.0004\n",
      "[Epoch 077] loss=0.9317 recon=0.9312 kl=0.0005\n",
      "[Epoch 078] loss=0.9346 recon=0.9335 kl=0.0011\n",
      "[Epoch 079] loss=0.9282 recon=0.9280 kl=0.0002\n",
      "[Epoch 080] loss=0.9210 recon=0.9209 kl=0.0001\n",
      "[Epoch 081] loss=0.9223 recon=0.9214 kl=0.0008\n",
      "[Epoch 082] loss=0.9416 recon=0.9408 kl=0.0008\n",
      "[Epoch 083] loss=0.9531 recon=0.9526 kl=0.0005\n",
      "[Epoch 084] loss=0.9229 recon=0.9226 kl=0.0003\n",
      "[Epoch 085] loss=0.9246 recon=0.9240 kl=0.0007\n",
      "[Epoch 086] loss=0.9212 recon=0.9207 kl=0.0005\n",
      "[Epoch 087] loss=0.9536 recon=0.9533 kl=0.0003\n",
      "[Epoch 088] loss=0.9248 recon=0.9240 kl=0.0008\n",
      "[Epoch 089] loss=0.9234 recon=0.9230 kl=0.0004\n",
      "[Epoch 090] loss=0.9338 recon=0.9331 kl=0.0007\n",
      "10\n",
      "[Epoch 001] loss=1.5214 recon=0.9331 kl=0.5883\n",
      "[Epoch 002] loss=0.9338 recon=0.9306 kl=0.0033\n",
      "[Epoch 003] loss=0.9291 recon=0.9289 kl=0.0003\n",
      "[Epoch 004] loss=0.9236 recon=0.9235 kl=0.0000\n",
      "[Epoch 005] loss=0.9219 recon=0.9218 kl=0.0001\n",
      "[Epoch 006] loss=0.9266 recon=0.9264 kl=0.0002\n",
      "[Epoch 007] loss=0.9329 recon=0.9327 kl=0.0002\n",
      "[Epoch 008] loss=0.9393 recon=0.9387 kl=0.0006\n",
      "[Epoch 009] loss=0.9318 recon=0.9317 kl=0.0001\n",
      "[Epoch 010] loss=0.9250 recon=0.9245 kl=0.0005\n",
      "[Epoch 011] loss=0.9254 recon=0.9253 kl=0.0001\n",
      "[Epoch 012] loss=0.9292 recon=0.9290 kl=0.0002\n",
      "[Epoch 013] loss=0.9267 recon=0.9263 kl=0.0004\n",
      "[Epoch 014] loss=0.9335 recon=0.9332 kl=0.0003\n",
      "[Epoch 015] loss=0.9234 recon=0.9230 kl=0.0004\n",
      "[Epoch 016] loss=0.9404 recon=0.9395 kl=0.0009\n",
      "[Epoch 017] loss=0.9305 recon=0.9303 kl=0.0001\n",
      "[Epoch 018] loss=0.9612 recon=0.9605 kl=0.0007\n",
      "[Epoch 019] loss=0.9264 recon=0.9262 kl=0.0002\n",
      "[Epoch 020] loss=0.9498 recon=0.9480 kl=0.0019\n",
      "[Epoch 021] loss=0.9218 recon=0.9191 kl=0.0026\n",
      "[Epoch 022] loss=0.9289 recon=0.9286 kl=0.0003\n",
      "[Epoch 023] loss=0.9206 recon=0.9206 kl=0.0000\n",
      "[Epoch 024] loss=0.9207 recon=0.9205 kl=0.0001\n",
      "[Epoch 025] loss=0.9378 recon=0.9372 kl=0.0006\n",
      "[Epoch 026] loss=0.9508 recon=0.9504 kl=0.0004\n",
      "[Epoch 027] loss=0.9355 recon=0.9352 kl=0.0003\n",
      "[Epoch 028] loss=0.9615 recon=0.9605 kl=0.0011\n",
      "[Epoch 029] loss=0.9351 recon=0.9350 kl=0.0001\n",
      "[Epoch 030] loss=0.9404 recon=0.9396 kl=0.0008\n",
      "[Epoch 031] loss=0.9212 recon=0.9209 kl=0.0003\n",
      "[Epoch 032] loss=0.9357 recon=0.9339 kl=0.0018\n",
      "[Epoch 033] loss=0.9498 recon=0.9474 kl=0.0024\n",
      "[Epoch 034] loss=0.9467 recon=0.9464 kl=0.0003\n",
      "[Epoch 035] loss=0.9430 recon=0.9430 kl=0.0000\n",
      "[Epoch 036] loss=0.9288 recon=0.9287 kl=0.0001\n",
      "[Epoch 037] loss=0.9319 recon=0.9312 kl=0.0007\n",
      "[Epoch 038] loss=0.9313 recon=0.9306 kl=0.0007\n",
      "[Epoch 039] loss=0.9314 recon=0.9310 kl=0.0004\n",
      "[Epoch 040] loss=0.9270 recon=0.9268 kl=0.0002\n",
      "[Epoch 041] loss=0.9247 recon=0.9239 kl=0.0008\n",
      "[Epoch 042] loss=0.9227 recon=0.9224 kl=0.0003\n",
      "[Epoch 043] loss=0.9221 recon=0.9214 kl=0.0007\n",
      "[Epoch 044] loss=0.9276 recon=0.9271 kl=0.0005\n",
      "[Epoch 045] loss=0.9366 recon=0.9358 kl=0.0008\n",
      "[Epoch 046] loss=0.9439 recon=0.9435 kl=0.0004\n",
      "[Epoch 047] loss=0.9343 recon=0.9337 kl=0.0006\n",
      "[Epoch 048] loss=0.9273 recon=0.9271 kl=0.0001\n",
      "[Epoch 049] loss=0.9315 recon=0.9307 kl=0.0008\n",
      "[Epoch 050] loss=0.9275 recon=0.9273 kl=0.0002\n",
      "[Epoch 051] loss=0.9344 recon=0.9338 kl=0.0006\n",
      "[Epoch 052] loss=0.9323 recon=0.9314 kl=0.0008\n",
      "[Epoch 053] loss=0.9302 recon=0.9299 kl=0.0003\n",
      "[Epoch 054] loss=0.9402 recon=0.9396 kl=0.0006\n",
      "[Epoch 055] loss=0.9515 recon=0.9510 kl=0.0004\n",
      "[Epoch 056] loss=0.9323 recon=0.9319 kl=0.0004\n",
      "[Epoch 057] loss=0.9272 recon=0.9267 kl=0.0004\n",
      "[Epoch 058] loss=0.9401 recon=0.9397 kl=0.0005\n",
      "[Epoch 059] loss=0.9180 recon=0.9171 kl=0.0009\n",
      "[Epoch 060] loss=0.9287 recon=0.9281 kl=0.0006\n",
      "[Epoch 061] loss=0.9392 recon=0.9386 kl=0.0005\n",
      "[Epoch 062] loss=0.9277 recon=0.9274 kl=0.0003\n",
      "[Epoch 063] loss=0.9207 recon=0.9202 kl=0.0005\n",
      "[Epoch 064] loss=0.9372 recon=0.9366 kl=0.0006\n",
      "[Epoch 065] loss=0.9306 recon=0.9304 kl=0.0002\n",
      "[Epoch 066] loss=0.9590 recon=0.9583 kl=0.0007\n",
      "[Epoch 067] loss=0.9304 recon=0.9296 kl=0.0008\n",
      "[Epoch 068] loss=0.9253 recon=0.9248 kl=0.0005\n",
      "[Epoch 069] loss=0.9246 recon=0.9240 kl=0.0006\n",
      "[Epoch 070] loss=0.9326 recon=0.9324 kl=0.0001\n",
      "[Epoch 071] loss=0.9343 recon=0.9337 kl=0.0006\n",
      "[Epoch 072] loss=0.9262 recon=0.9256 kl=0.0006\n",
      "[Epoch 073] loss=0.9294 recon=0.9274 kl=0.0020\n",
      "[Epoch 074] loss=0.9325 recon=0.9299 kl=0.0026\n",
      "[Epoch 075] loss=0.9432 recon=0.9418 kl=0.0013\n",
      "[Epoch 076] loss=0.9313 recon=0.9312 kl=0.0001\n",
      "[Epoch 077] loss=0.9365 recon=0.9365 kl=0.0000\n",
      "[Epoch 078] loss=0.9354 recon=0.9354 kl=0.0000\n",
      "[Epoch 079] loss=0.9343 recon=0.9341 kl=0.0002\n",
      "[Epoch 080] loss=0.9256 recon=0.9251 kl=0.0006\n",
      "[Epoch 081] loss=0.9245 recon=0.9238 kl=0.0006\n",
      "[Epoch 082] loss=0.9306 recon=0.9302 kl=0.0003\n",
      "[Epoch 083] loss=0.9329 recon=0.9327 kl=0.0003\n",
      "[Epoch 084] loss=0.9241 recon=0.9234 kl=0.0007\n",
      "[Epoch 085] loss=0.9487 recon=0.9486 kl=0.0001\n",
      "[Epoch 086] loss=0.9300 recon=0.9294 kl=0.0006\n",
      "[Epoch 087] loss=0.9318 recon=0.9313 kl=0.0005\n",
      "[Epoch 088] loss=0.9344 recon=0.9340 kl=0.0004\n",
      "[Epoch 089] loss=0.9486 recon=0.9481 kl=0.0005\n",
      "[Epoch 090] loss=0.9232 recon=0.9228 kl=0.0004\n",
      "11\n",
      "[Epoch 001] loss=1.2109 recon=0.9396 kl=0.2714\n",
      "[Epoch 002] loss=0.9334 recon=0.9307 kl=0.0026\n",
      "[Epoch 003] loss=0.9424 recon=0.9421 kl=0.0002\n",
      "[Epoch 004] loss=0.9537 recon=0.9535 kl=0.0001\n",
      "[Epoch 005] loss=0.9272 recon=0.9270 kl=0.0002\n",
      "[Epoch 006] loss=0.9275 recon=0.9275 kl=0.0001\n",
      "[Epoch 007] loss=0.9381 recon=0.9376 kl=0.0004\n",
      "[Epoch 008] loss=0.9439 recon=0.9438 kl=0.0002\n",
      "[Epoch 009] loss=0.9334 recon=0.9332 kl=0.0003\n",
      "[Epoch 010] loss=0.9325 recon=0.9323 kl=0.0001\n",
      "[Epoch 011] loss=0.9281 recon=0.9274 kl=0.0007\n",
      "[Epoch 012] loss=0.9268 recon=0.9267 kl=0.0001\n",
      "[Epoch 013] loss=0.9504 recon=0.9501 kl=0.0003\n",
      "[Epoch 014] loss=0.9318 recon=0.9314 kl=0.0004\n",
      "[Epoch 015] loss=0.9259 recon=0.9257 kl=0.0002\n",
      "[Epoch 016] loss=0.9285 recon=0.9280 kl=0.0006\n",
      "[Epoch 017] loss=0.9355 recon=0.9351 kl=0.0004\n",
      "[Epoch 018] loss=0.9402 recon=0.9399 kl=0.0003\n",
      "[Epoch 019] loss=0.9378 recon=0.9373 kl=0.0004\n",
      "[Epoch 020] loss=0.9427 recon=0.9422 kl=0.0005\n",
      "[Epoch 021] loss=0.9318 recon=0.9310 kl=0.0008\n",
      "[Epoch 022] loss=0.9315 recon=0.9286 kl=0.0028\n",
      "[Epoch 023] loss=0.9438 recon=0.9434 kl=0.0003\n",
      "[Epoch 024] loss=0.9332 recon=0.9331 kl=0.0000\n",
      "[Epoch 025] loss=0.9304 recon=0.9303 kl=0.0000\n",
      "[Epoch 026] loss=0.9379 recon=0.9367 kl=0.0012\n",
      "[Epoch 027] loss=0.9291 recon=0.9289 kl=0.0002\n",
      "[Epoch 028] loss=0.9351 recon=0.9348 kl=0.0003\n",
      "[Epoch 029] loss=0.9513 recon=0.9504 kl=0.0009\n",
      "[Epoch 030] loss=0.9337 recon=0.9334 kl=0.0004\n",
      "[Epoch 031] loss=0.9358 recon=0.9353 kl=0.0004\n",
      "[Epoch 032] loss=0.9307 recon=0.9303 kl=0.0004\n",
      "[Epoch 033] loss=0.9274 recon=0.9270 kl=0.0004\n",
      "[Epoch 034] loss=0.9331 recon=0.9329 kl=0.0002\n",
      "[Epoch 035] loss=0.9397 recon=0.9388 kl=0.0008\n",
      "[Epoch 036] loss=0.9302 recon=0.9298 kl=0.0004\n",
      "[Epoch 037] loss=0.9224 recon=0.9220 kl=0.0004\n",
      "[Epoch 038] loss=0.9512 recon=0.9509 kl=0.0003\n",
      "[Epoch 039] loss=0.9189 recon=0.9179 kl=0.0010\n",
      "[Epoch 040] loss=0.9316 recon=0.9313 kl=0.0003\n",
      "[Epoch 041] loss=0.9384 recon=0.9378 kl=0.0005\n",
      "[Epoch 042] loss=0.9294 recon=0.9289 kl=0.0005\n",
      "[Epoch 043] loss=0.9311 recon=0.9302 kl=0.0009\n",
      "[Epoch 044] loss=0.9253 recon=0.9250 kl=0.0004\n",
      "[Epoch 045] loss=0.9411 recon=0.9376 kl=0.0035\n",
      "[Epoch 046] loss=0.9311 recon=0.9303 kl=0.0008\n",
      "[Epoch 047] loss=0.9445 recon=0.9444 kl=0.0001\n",
      "[Epoch 048] loss=0.9281 recon=0.9277 kl=0.0004\n",
      "[Epoch 049] loss=0.9235 recon=0.9233 kl=0.0002\n",
      "[Epoch 050] loss=0.9663 recon=0.9657 kl=0.0006\n",
      "[Epoch 051] loss=0.9280 recon=0.9276 kl=0.0004\n",
      "[Epoch 052] loss=0.9289 recon=0.9285 kl=0.0005\n",
      "[Epoch 053] loss=0.9296 recon=0.9290 kl=0.0006\n",
      "[Epoch 054] loss=0.9354 recon=0.9351 kl=0.0003\n",
      "[Epoch 055] loss=0.9192 recon=0.9188 kl=0.0005\n",
      "[Epoch 056] loss=0.9274 recon=0.9269 kl=0.0004\n",
      "[Epoch 057] loss=0.9456 recon=0.9401 kl=0.0055\n",
      "[Epoch 058] loss=0.9319 recon=0.9262 kl=0.0057\n",
      "[Epoch 059] loss=0.9359 recon=0.9355 kl=0.0004\n",
      "[Epoch 060] loss=0.9374 recon=0.9373 kl=0.0000\n",
      "[Epoch 061] loss=0.9348 recon=0.9348 kl=0.0000\n",
      "[Epoch 062] loss=0.9410 recon=0.9410 kl=0.0000\n",
      "[Epoch 063] loss=0.9360 recon=0.9359 kl=0.0000\n",
      "[Epoch 064] loss=0.9357 recon=0.9348 kl=0.0009\n",
      "[Epoch 065] loss=0.9358 recon=0.9356 kl=0.0002\n",
      "[Epoch 066] loss=0.9293 recon=0.9288 kl=0.0004\n",
      "[Epoch 067] loss=0.9234 recon=0.9227 kl=0.0007\n",
      "[Epoch 068] loss=0.9312 recon=0.9305 kl=0.0007\n",
      "[Epoch 069] loss=0.9197 recon=0.9195 kl=0.0001\n",
      "[Epoch 070] loss=0.9206 recon=0.9201 kl=0.0005\n",
      "[Epoch 071] loss=0.9294 recon=0.9289 kl=0.0005\n",
      "[Epoch 072] loss=0.9378 recon=0.9370 kl=0.0007\n",
      "[Epoch 073] loss=0.9251 recon=0.9249 kl=0.0002\n",
      "[Epoch 074] loss=0.9331 recon=0.9327 kl=0.0005\n",
      "[Epoch 075] loss=0.9516 recon=0.9505 kl=0.0011\n",
      "[Epoch 076] loss=0.9312 recon=0.9304 kl=0.0008\n",
      "[Epoch 077] loss=0.9227 recon=0.9226 kl=0.0001\n",
      "[Epoch 078] loss=0.9353 recon=0.9348 kl=0.0005\n",
      "[Epoch 079] loss=0.9250 recon=0.9247 kl=0.0004\n",
      "[Epoch 080] loss=0.9253 recon=0.9249 kl=0.0004\n",
      "[Epoch 081] loss=0.9300 recon=0.9292 kl=0.0008\n",
      "[Epoch 082] loss=0.9429 recon=0.9427 kl=0.0002\n",
      "[Epoch 083] loss=0.9311 recon=0.9308 kl=0.0003\n",
      "[Epoch 084] loss=0.9332 recon=0.9324 kl=0.0008\n",
      "[Epoch 085] loss=0.9260 recon=0.9256 kl=0.0005\n",
      "[Epoch 086] loss=0.9286 recon=0.9275 kl=0.0012\n",
      "[Epoch 087] loss=0.9269 recon=0.9235 kl=0.0034\n",
      "[Epoch 088] loss=0.9258 recon=0.9248 kl=0.0009\n",
      "[Epoch 089] loss=0.9422 recon=0.9421 kl=0.0001\n",
      "[Epoch 090] loss=0.9348 recon=0.9348 kl=0.0000\n",
      "12\n",
      "[Epoch 001] loss=1.2384 recon=0.9408 kl=0.2976\n",
      "[Epoch 002] loss=0.9453 recon=0.9431 kl=0.0022\n",
      "[Epoch 003] loss=0.9404 recon=0.9402 kl=0.0002\n",
      "[Epoch 004] loss=0.9367 recon=0.9366 kl=0.0001\n",
      "[Epoch 005] loss=0.9271 recon=0.9269 kl=0.0002\n",
      "[Epoch 006] loss=0.9332 recon=0.9330 kl=0.0002\n",
      "[Epoch 007] loss=0.9210 recon=0.9209 kl=0.0001\n",
      "[Epoch 008] loss=0.9386 recon=0.9383 kl=0.0002\n",
      "[Epoch 009] loss=0.9251 recon=0.9250 kl=0.0002\n",
      "[Epoch 010] loss=0.9308 recon=0.9304 kl=0.0004\n",
      "[Epoch 011] loss=0.9539 recon=0.9538 kl=0.0001\n",
      "[Epoch 012] loss=0.9345 recon=0.9341 kl=0.0004\n",
      "[Epoch 013] loss=0.9343 recon=0.9341 kl=0.0002\n",
      "[Epoch 014] loss=0.9272 recon=0.9266 kl=0.0006\n",
      "[Epoch 015] loss=0.9297 recon=0.9295 kl=0.0001\n",
      "[Epoch 016] loss=0.9213 recon=0.9208 kl=0.0005\n",
      "[Epoch 017] loss=0.9190 recon=0.9189 kl=0.0001\n",
      "[Epoch 018] loss=0.9232 recon=0.9224 kl=0.0008\n",
      "[Epoch 019] loss=0.9610 recon=0.9607 kl=0.0003\n",
      "[Epoch 020] loss=0.9467 recon=0.9462 kl=0.0006\n",
      "[Epoch 021] loss=0.9313 recon=0.9311 kl=0.0002\n",
      "[Epoch 022] loss=0.9418 recon=0.9408 kl=0.0010\n",
      "[Epoch 023] loss=0.9197 recon=0.9196 kl=0.0001\n",
      "[Epoch 024] loss=0.9297 recon=0.9289 kl=0.0008\n",
      "[Epoch 025] loss=0.9362 recon=0.9332 kl=0.0030\n",
      "[Epoch 026] loss=0.9209 recon=0.9206 kl=0.0003\n",
      "[Epoch 027] loss=0.9343 recon=0.9342 kl=0.0000\n",
      "[Epoch 028] loss=0.9214 recon=0.9211 kl=0.0002\n",
      "[Epoch 029] loss=0.9299 recon=0.9294 kl=0.0005\n",
      "[Epoch 030] loss=0.9364 recon=0.9360 kl=0.0004\n",
      "[Epoch 031] loss=0.9229 recon=0.9224 kl=0.0005\n",
      "[Epoch 032] loss=0.9190 recon=0.9184 kl=0.0006\n",
      "[Epoch 033] loss=0.9342 recon=0.9338 kl=0.0004\n",
      "[Epoch 034] loss=0.9299 recon=0.9296 kl=0.0003\n",
      "[Epoch 035] loss=0.9485 recon=0.9453 kl=0.0032\n",
      "[Epoch 036] loss=0.9330 recon=0.9314 kl=0.0016\n",
      "[Epoch 037] loss=0.9218 recon=0.9217 kl=0.0002\n",
      "[Epoch 038] loss=0.9527 recon=0.9527 kl=0.0000\n",
      "[Epoch 039] loss=0.9386 recon=0.9385 kl=0.0000\n",
      "[Epoch 040] loss=0.9351 recon=0.9343 kl=0.0008\n",
      "[Epoch 041] loss=0.9188 recon=0.9186 kl=0.0002\n",
      "[Epoch 042] loss=0.9188 recon=0.9160 kl=0.0029\n",
      "[Epoch 043] loss=0.9444 recon=0.9316 kl=0.0128\n",
      "[Epoch 044] loss=0.9162 recon=0.9151 kl=0.0011\n",
      "[Epoch 045] loss=0.9262 recon=0.9261 kl=0.0001\n",
      "[Epoch 046] loss=0.9258 recon=0.9258 kl=0.0000\n",
      "[Epoch 047] loss=0.9528 recon=0.9528 kl=0.0000\n",
      "[Epoch 048] loss=0.9331 recon=0.9330 kl=0.0000\n",
      "[Epoch 049] loss=0.9220 recon=0.9212 kl=0.0008\n",
      "[Epoch 050] loss=0.9448 recon=0.9433 kl=0.0015\n",
      "[Epoch 051] loss=0.9288 recon=0.9285 kl=0.0003\n",
      "[Epoch 052] loss=0.9219 recon=0.9218 kl=0.0000\n",
      "[Epoch 053] loss=0.9374 recon=0.9373 kl=0.0000\n",
      "[Epoch 054] loss=0.9492 recon=0.9486 kl=0.0006\n",
      "[Epoch 055] loss=0.9289 recon=0.9288 kl=0.0001\n",
      "[Epoch 056] loss=0.9345 recon=0.9336 kl=0.0009\n",
      "[Epoch 057] loss=0.9237 recon=0.9233 kl=0.0004\n",
      "[Epoch 058] loss=0.9341 recon=0.9338 kl=0.0003\n",
      "[Epoch 059] loss=0.9240 recon=0.9229 kl=0.0011\n",
      "[Epoch 060] loss=0.9308 recon=0.9304 kl=0.0003\n",
      "[Epoch 061] loss=0.9252 recon=0.9252 kl=0.0001\n",
      "[Epoch 062] loss=0.9326 recon=0.9317 kl=0.0009\n",
      "[Epoch 063] loss=0.9190 recon=0.9184 kl=0.0006\n",
      "[Epoch 064] loss=0.9327 recon=0.9326 kl=0.0001\n",
      "[Epoch 065] loss=0.9199 recon=0.9196 kl=0.0003\n",
      "[Epoch 066] loss=0.9523 recon=0.9516 kl=0.0008\n",
      "[Epoch 067] loss=0.9232 recon=0.9228 kl=0.0004\n",
      "[Epoch 068] loss=0.9263 recon=0.9256 kl=0.0007\n",
      "[Epoch 069] loss=0.9313 recon=0.9309 kl=0.0004\n",
      "[Epoch 070] loss=0.9181 recon=0.9176 kl=0.0005\n",
      "[Epoch 071] loss=0.9260 recon=0.9256 kl=0.0003\n",
      "[Epoch 072] loss=0.9255 recon=0.9250 kl=0.0005\n",
      "[Epoch 073] loss=0.9390 recon=0.9381 kl=0.0009\n",
      "[Epoch 074] loss=0.9232 recon=0.9229 kl=0.0002\n",
      "[Epoch 075] loss=0.9232 recon=0.9211 kl=0.0021\n",
      "[Epoch 076] loss=0.9224 recon=0.9185 kl=0.0039\n",
      "[Epoch 077] loss=0.9303 recon=0.9280 kl=0.0023\n",
      "[Epoch 078] loss=0.9296 recon=0.9293 kl=0.0004\n",
      "[Epoch 079] loss=0.9237 recon=0.9237 kl=0.0000\n",
      "[Epoch 080] loss=0.9244 recon=0.9244 kl=0.0000\n",
      "[Epoch 081] loss=0.9248 recon=0.9248 kl=0.0000\n",
      "[Epoch 082] loss=0.9261 recon=0.9259 kl=0.0002\n",
      "[Epoch 083] loss=0.9364 recon=0.9357 kl=0.0006\n",
      "[Epoch 084] loss=0.9376 recon=0.9374 kl=0.0002\n",
      "[Epoch 085] loss=0.9257 recon=0.9252 kl=0.0005\n",
      "[Epoch 086] loss=0.9211 recon=0.9207 kl=0.0004\n",
      "[Epoch 087] loss=0.9393 recon=0.9392 kl=0.0001\n",
      "[Epoch 088] loss=0.9311 recon=0.9293 kl=0.0017\n",
      "[Epoch 089] loss=0.9184 recon=0.9170 kl=0.0014\n",
      "[Epoch 090] loss=0.9301 recon=0.9300 kl=0.0002\n",
      "13\n",
      "[Epoch 001] loss=1.4368 recon=0.9312 kl=0.5056\n",
      "[Epoch 002] loss=0.9413 recon=0.9383 kl=0.0030\n",
      "[Epoch 003] loss=0.9311 recon=0.9309 kl=0.0003\n",
      "[Epoch 004] loss=0.9399 recon=0.9398 kl=0.0000\n",
      "[Epoch 005] loss=0.9310 recon=0.9309 kl=0.0001\n",
      "[Epoch 006] loss=0.9315 recon=0.9314 kl=0.0001\n",
      "[Epoch 007] loss=0.9293 recon=0.9292 kl=0.0001\n",
      "[Epoch 008] loss=0.9239 recon=0.9235 kl=0.0004\n",
      "[Epoch 009] loss=0.9307 recon=0.9303 kl=0.0004\n",
      "[Epoch 010] loss=0.9373 recon=0.9372 kl=0.0001\n",
      "[Epoch 011] loss=0.9365 recon=0.9362 kl=0.0002\n",
      "[Epoch 012] loss=0.9232 recon=0.9229 kl=0.0002\n",
      "[Epoch 013] loss=0.9217 recon=0.9213 kl=0.0004\n",
      "[Epoch 014] loss=0.9299 recon=0.9298 kl=0.0001\n",
      "[Epoch 015] loss=0.9281 recon=0.9274 kl=0.0006\n",
      "[Epoch 016] loss=0.9274 recon=0.9271 kl=0.0003\n",
      "[Epoch 017] loss=0.9257 recon=0.9253 kl=0.0005\n",
      "[Epoch 018] loss=0.9377 recon=0.9374 kl=0.0003\n",
      "[Epoch 019] loss=0.9390 recon=0.9385 kl=0.0005\n",
      "[Epoch 020] loss=0.9362 recon=0.9356 kl=0.0006\n",
      "[Epoch 021] loss=0.9358 recon=0.9354 kl=0.0004\n",
      "[Epoch 022] loss=0.9381 recon=0.9377 kl=0.0004\n",
      "[Epoch 023] loss=0.9331 recon=0.9322 kl=0.0009\n",
      "[Epoch 024] loss=0.9340 recon=0.9339 kl=0.0001\n",
      "[Epoch 025] loss=0.9402 recon=0.9394 kl=0.0007\n",
      "[Epoch 026] loss=0.9281 recon=0.9255 kl=0.0026\n",
      "[Epoch 027] loss=0.9298 recon=0.9252 kl=0.0045\n",
      "[Epoch 028] loss=0.9151 recon=0.9144 kl=0.0007\n",
      "[Epoch 029] loss=0.9237 recon=0.9236 kl=0.0001\n",
      "[Epoch 030] loss=0.9303 recon=0.9303 kl=0.0000\n",
      "[Epoch 031] loss=0.9280 recon=0.9277 kl=0.0003\n",
      "[Epoch 032] loss=0.9237 recon=0.9231 kl=0.0005\n",
      "[Epoch 033] loss=0.9306 recon=0.9305 kl=0.0001\n",
      "[Epoch 034] loss=0.9410 recon=0.9403 kl=0.0006\n",
      "[Epoch 035] loss=0.9156 recon=0.9151 kl=0.0005\n",
      "[Epoch 036] loss=0.9313 recon=0.9310 kl=0.0003\n",
      "[Epoch 037] loss=0.9194 recon=0.9188 kl=0.0007\n",
      "[Epoch 038] loss=0.9549 recon=0.9545 kl=0.0004\n",
      "[Epoch 039] loss=0.9558 recon=0.9516 kl=0.0042\n",
      "[Epoch 040] loss=0.9301 recon=0.9275 kl=0.0025\n",
      "[Epoch 041] loss=0.9244 recon=0.9241 kl=0.0004\n",
      "[Epoch 042] loss=0.9228 recon=0.9228 kl=0.0000\n",
      "[Epoch 043] loss=0.9310 recon=0.9310 kl=0.0000\n",
      "[Epoch 044] loss=0.9310 recon=0.9302 kl=0.0008\n",
      "[Epoch 045] loss=0.9308 recon=0.9268 kl=0.0039\n",
      "[Epoch 046] loss=0.9299 recon=0.9296 kl=0.0004\n",
      "[Epoch 047] loss=0.9369 recon=0.9369 kl=0.0000\n",
      "[Epoch 048] loss=0.9257 recon=0.9257 kl=0.0000\n",
      "[Epoch 049] loss=0.9227 recon=0.9208 kl=0.0019\n",
      "[Epoch 050] loss=0.9378 recon=0.9376 kl=0.0002\n",
      "[Epoch 051] loss=0.9377 recon=0.9377 kl=0.0000\n",
      "[Epoch 052] loss=0.9244 recon=0.9239 kl=0.0005\n",
      "[Epoch 053] loss=0.9406 recon=0.9395 kl=0.0011\n",
      "[Epoch 054] loss=0.9192 recon=0.9191 kl=0.0002\n",
      "[Epoch 055] loss=0.9218 recon=0.9214 kl=0.0003\n",
      "[Epoch 056] loss=0.9336 recon=0.9329 kl=0.0007\n",
      "[Epoch 057] loss=0.9405 recon=0.9390 kl=0.0014\n",
      "[Epoch 058] loss=0.9346 recon=0.9319 kl=0.0027\n",
      "[Epoch 059] loss=0.9320 recon=0.9303 kl=0.0017\n",
      "[Epoch 060] loss=0.9267 recon=0.9265 kl=0.0002\n",
      "[Epoch 061] loss=0.9372 recon=0.9372 kl=0.0000\n",
      "[Epoch 062] loss=0.9237 recon=0.9237 kl=0.0000\n",
      "[Epoch 063] loss=0.9350 recon=0.9345 kl=0.0006\n",
      "[Epoch 064] loss=0.9203 recon=0.9199 kl=0.0004\n",
      "[Epoch 065] loss=0.9353 recon=0.9316 kl=0.0037\n",
      "[Epoch 066] loss=0.9371 recon=0.9346 kl=0.0025\n",
      "[Epoch 067] loss=0.9185 recon=0.9172 kl=0.0014\n",
      "[Epoch 068] loss=0.9402 recon=0.9400 kl=0.0002\n",
      "[Epoch 069] loss=0.9327 recon=0.9327 kl=0.0000\n",
      "[Epoch 070] loss=0.9231 recon=0.9231 kl=0.0000\n",
      "[Epoch 071] loss=0.9276 recon=0.9276 kl=0.0000\n",
      "[Epoch 072] loss=0.9259 recon=0.9254 kl=0.0004\n",
      "[Epoch 073] loss=0.9356 recon=0.9332 kl=0.0024\n",
      "[Epoch 074] loss=0.9365 recon=0.9324 kl=0.0041\n",
      "[Epoch 075] loss=0.9445 recon=0.9436 kl=0.0009\n",
      "[Epoch 076] loss=0.9313 recon=0.9312 kl=0.0001\n",
      "[Epoch 077] loss=0.9358 recon=0.9357 kl=0.0000\n",
      "[Epoch 078] loss=0.9205 recon=0.9205 kl=0.0000\n",
      "[Epoch 079] loss=0.9381 recon=0.9381 kl=0.0000\n",
      "[Epoch 080] loss=0.9270 recon=0.9267 kl=0.0003\n",
      "[Epoch 081] loss=0.9349 recon=0.9345 kl=0.0004\n",
      "[Epoch 082] loss=0.9217 recon=0.9212 kl=0.0005\n",
      "[Epoch 083] loss=0.9358 recon=0.9354 kl=0.0004\n",
      "[Epoch 084] loss=0.9221 recon=0.9217 kl=0.0004\n",
      "[Epoch 085] loss=0.9394 recon=0.9390 kl=0.0004\n",
      "[Epoch 086] loss=0.9359 recon=0.9353 kl=0.0006\n",
      "[Epoch 087] loss=0.9327 recon=0.9323 kl=0.0004\n",
      "[Epoch 088] loss=0.9179 recon=0.9175 kl=0.0004\n",
      "[Epoch 089] loss=0.9197 recon=0.9189 kl=0.0008\n",
      "[Epoch 090] loss=0.9330 recon=0.9328 kl=0.0002\n",
      "14\n",
      "[Epoch 001] loss=1.4860 recon=0.9319 kl=0.5541\n",
      "[Epoch 002] loss=0.9336 recon=0.9302 kl=0.0033\n",
      "[Epoch 003] loss=0.9395 recon=0.9392 kl=0.0003\n",
      "[Epoch 004] loss=0.9323 recon=0.9322 kl=0.0002\n",
      "[Epoch 005] loss=0.9282 recon=0.9282 kl=0.0000\n",
      "[Epoch 006] loss=0.9197 recon=0.9193 kl=0.0004\n",
      "[Epoch 007] loss=0.9564 recon=0.9561 kl=0.0002\n",
      "[Epoch 008] loss=0.9347 recon=0.9346 kl=0.0001\n",
      "[Epoch 009] loss=0.9361 recon=0.9361 kl=0.0001\n",
      "[Epoch 010] loss=0.9277 recon=0.9272 kl=0.0005\n",
      "[Epoch 011] loss=0.9468 recon=0.9464 kl=0.0004\n",
      "[Epoch 012] loss=0.9225 recon=0.9224 kl=0.0001\n",
      "[Epoch 013] loss=0.9325 recon=0.9319 kl=0.0006\n",
      "[Epoch 014] loss=0.9389 recon=0.9387 kl=0.0002\n",
      "[Epoch 015] loss=0.9211 recon=0.9210 kl=0.0001\n",
      "[Epoch 016] loss=0.9245 recon=0.9241 kl=0.0004\n",
      "[Epoch 017] loss=0.9223 recon=0.9222 kl=0.0001\n",
      "[Epoch 018] loss=0.9241 recon=0.9234 kl=0.0007\n",
      "[Epoch 019] loss=0.9236 recon=0.9235 kl=0.0001\n",
      "[Epoch 020] loss=0.9342 recon=0.9335 kl=0.0007\n",
      "[Epoch 021] loss=0.9417 recon=0.9416 kl=0.0001\n",
      "[Epoch 022] loss=0.9397 recon=0.9389 kl=0.0008\n",
      "[Epoch 023] loss=0.9255 recon=0.9252 kl=0.0003\n",
      "[Epoch 024] loss=0.9315 recon=0.9308 kl=0.0007\n",
      "[Epoch 025] loss=0.9337 recon=0.9334 kl=0.0003\n",
      "[Epoch 026] loss=0.9433 recon=0.9392 kl=0.0041\n",
      "[Epoch 027] loss=0.9242 recon=0.9220 kl=0.0022\n",
      "[Epoch 028] loss=0.9231 recon=0.9229 kl=0.0002\n",
      "[Epoch 029] loss=0.9188 recon=0.9188 kl=0.0000\n",
      "[Epoch 030] loss=0.9262 recon=0.9262 kl=0.0000\n",
      "[Epoch 031] loss=0.9217 recon=0.9210 kl=0.0007\n",
      "[Epoch 032] loss=0.9235 recon=0.9231 kl=0.0004\n",
      "[Epoch 033] loss=0.9214 recon=0.9211 kl=0.0004\n",
      "[Epoch 034] loss=0.9508 recon=0.9503 kl=0.0005\n",
      "[Epoch 035] loss=0.9183 recon=0.9177 kl=0.0007\n",
      "[Epoch 036] loss=0.9302 recon=0.9298 kl=0.0004\n",
      "[Epoch 037] loss=0.9402 recon=0.9396 kl=0.0005\n",
      "[Epoch 038] loss=0.9339 recon=0.9326 kl=0.0014\n",
      "[Epoch 039] loss=0.9267 recon=0.9263 kl=0.0004\n",
      "[Epoch 040] loss=0.9260 recon=0.9257 kl=0.0004\n",
      "[Epoch 041] loss=0.9223 recon=0.9218 kl=0.0006\n",
      "[Epoch 042] loss=0.9336 recon=0.9331 kl=0.0005\n",
      "[Epoch 043] loss=0.9205 recon=0.9202 kl=0.0003\n",
      "[Epoch 044] loss=0.9506 recon=0.9496 kl=0.0010\n",
      "[Epoch 045] loss=0.9224 recon=0.9220 kl=0.0004\n",
      "[Epoch 046] loss=0.9539 recon=0.9534 kl=0.0005\n",
      "[Epoch 047] loss=0.9506 recon=0.9502 kl=0.0003\n",
      "[Epoch 048] loss=0.9197 recon=0.9188 kl=0.0009\n",
      "[Epoch 049] loss=0.9207 recon=0.9203 kl=0.0004\n",
      "[Epoch 050] loss=0.9319 recon=0.9312 kl=0.0007\n",
      "[Epoch 051] loss=0.9442 recon=0.9439 kl=0.0004\n",
      "[Epoch 052] loss=0.9216 recon=0.9208 kl=0.0007\n",
      "[Epoch 053] loss=0.9368 recon=0.9363 kl=0.0005\n",
      "[Epoch 054] loss=0.9447 recon=0.9442 kl=0.0005\n",
      "[Epoch 055] loss=0.9167 recon=0.9161 kl=0.0006\n",
      "[Epoch 056] loss=0.9243 recon=0.9239 kl=0.0005\n",
      "[Epoch 057] loss=0.9395 recon=0.9385 kl=0.0010\n",
      "[Epoch 058] loss=0.9225 recon=0.9220 kl=0.0005\n",
      "[Epoch 059] loss=0.9196 recon=0.9194 kl=0.0002\n",
      "[Epoch 060] loss=0.9278 recon=0.9268 kl=0.0011\n",
      "[Epoch 061] loss=0.9314 recon=0.9307 kl=0.0007\n",
      "[Epoch 062] loss=0.9261 recon=0.9256 kl=0.0005\n",
      "[Epoch 063] loss=0.9389 recon=0.9382 kl=0.0006\n",
      "[Epoch 064] loss=0.9204 recon=0.9200 kl=0.0004\n",
      "[Epoch 065] loss=0.9267 recon=0.9261 kl=0.0006\n",
      "[Epoch 066] loss=0.9242 recon=0.9240 kl=0.0002\n",
      "[Epoch 067] loss=0.9163 recon=0.9156 kl=0.0007\n",
      "[Epoch 068] loss=0.9357 recon=0.9352 kl=0.0006\n",
      "[Epoch 069] loss=0.9313 recon=0.9309 kl=0.0005\n",
      "[Epoch 070] loss=0.9300 recon=0.9294 kl=0.0006\n",
      "[Epoch 071] loss=0.9243 recon=0.9239 kl=0.0003\n",
      "[Epoch 072] loss=0.9339 recon=0.9337 kl=0.0002\n",
      "[Epoch 073] loss=0.9322 recon=0.9313 kl=0.0009\n",
      "[Epoch 074] loss=0.9370 recon=0.9364 kl=0.0006\n",
      "[Epoch 075] loss=0.9326 recon=0.9322 kl=0.0005\n",
      "[Epoch 076] loss=0.9164 recon=0.9159 kl=0.0005\n",
      "[Epoch 077] loss=0.9306 recon=0.9301 kl=0.0005\n",
      "[Epoch 078] loss=0.9224 recon=0.9219 kl=0.0005\n",
      "[Epoch 079] loss=0.9379 recon=0.9374 kl=0.0005\n",
      "[Epoch 080] loss=0.9260 recon=0.9252 kl=0.0007\n",
      "[Epoch 081] loss=0.9315 recon=0.9312 kl=0.0004\n",
      "[Epoch 082] loss=0.9375 recon=0.9374 kl=0.0001\n",
      "[Epoch 083] loss=0.9375 recon=0.9367 kl=0.0007\n",
      "[Epoch 084] loss=0.9227 recon=0.9218 kl=0.0009\n",
      "[Epoch 085] loss=0.9243 recon=0.9239 kl=0.0004\n",
      "[Epoch 086] loss=0.9230 recon=0.9228 kl=0.0002\n",
      "[Epoch 087] loss=0.9284 recon=0.9280 kl=0.0005\n",
      "[Epoch 088] loss=0.9269 recon=0.9259 kl=0.0010\n",
      "[Epoch 089] loss=0.9208 recon=0.9204 kl=0.0004\n",
      "[Epoch 090] loss=0.9366 recon=0.9362 kl=0.0004\n",
      "15\n",
      "[Epoch 001] loss=1.1660 recon=0.9361 kl=0.2300\n",
      "[Epoch 002] loss=0.9372 recon=0.9348 kl=0.0024\n",
      "[Epoch 003] loss=0.9353 recon=0.9351 kl=0.0002\n",
      "[Epoch 004] loss=0.9395 recon=0.9393 kl=0.0003\n",
      "[Epoch 005] loss=0.9276 recon=0.9274 kl=0.0002\n",
      "[Epoch 006] loss=0.9312 recon=0.9311 kl=0.0002\n",
      "[Epoch 007] loss=0.9216 recon=0.9214 kl=0.0002\n",
      "[Epoch 008] loss=0.9413 recon=0.9410 kl=0.0003\n",
      "[Epoch 009] loss=0.9323 recon=0.9319 kl=0.0004\n",
      "[Epoch 010] loss=0.9323 recon=0.9321 kl=0.0002\n",
      "[Epoch 011] loss=0.9304 recon=0.9300 kl=0.0004\n",
      "[Epoch 012] loss=0.9429 recon=0.9428 kl=0.0001\n",
      "[Epoch 013] loss=0.9334 recon=0.9330 kl=0.0005\n",
      "[Epoch 014] loss=0.9370 recon=0.9369 kl=0.0001\n",
      "[Epoch 015] loss=0.9257 recon=0.9250 kl=0.0006\n",
      "[Epoch 016] loss=0.9414 recon=0.9412 kl=0.0002\n",
      "[Epoch 017] loss=0.9436 recon=0.9431 kl=0.0005\n",
      "[Epoch 018] loss=0.9422 recon=0.9397 kl=0.0025\n",
      "[Epoch 019] loss=0.9322 recon=0.9319 kl=0.0003\n",
      "[Epoch 020] loss=0.9281 recon=0.9281 kl=0.0000\n",
      "[Epoch 021] loss=0.9372 recon=0.9368 kl=0.0004\n",
      "[Epoch 022] loss=0.9315 recon=0.9310 kl=0.0005\n",
      "[Epoch 023] loss=0.9294 recon=0.9292 kl=0.0002\n",
      "[Epoch 024] loss=0.9248 recon=0.9240 kl=0.0008\n",
      "[Epoch 025] loss=0.9364 recon=0.9362 kl=0.0002\n",
      "[Epoch 026] loss=0.9395 recon=0.9386 kl=0.0009\n",
      "[Epoch 027] loss=0.9251 recon=0.9247 kl=0.0005\n",
      "[Epoch 028] loss=0.9277 recon=0.9252 kl=0.0025\n",
      "[Epoch 029] loss=0.9359 recon=0.9337 kl=0.0023\n",
      "[Epoch 030] loss=0.9253 recon=0.9245 kl=0.0008\n",
      "[Epoch 031] loss=0.9468 recon=0.9467 kl=0.0001\n",
      "[Epoch 032] loss=0.9368 recon=0.9367 kl=0.0000\n",
      "[Epoch 033] loss=0.9336 recon=0.9330 kl=0.0006\n",
      "[Epoch 034] loss=0.9248 recon=0.9242 kl=0.0006\n",
      "[Epoch 035] loss=0.9379 recon=0.9375 kl=0.0004\n",
      "[Epoch 036] loss=0.9280 recon=0.9275 kl=0.0005\n",
      "[Epoch 037] loss=0.9182 recon=0.9176 kl=0.0006\n",
      "[Epoch 038] loss=0.9208 recon=0.9202 kl=0.0006\n",
      "[Epoch 039] loss=0.9456 recon=0.9452 kl=0.0004\n",
      "[Epoch 040] loss=0.9212 recon=0.9206 kl=0.0006\n",
      "[Epoch 041] loss=0.9214 recon=0.9208 kl=0.0006\n",
      "[Epoch 042] loss=0.9296 recon=0.9289 kl=0.0008\n",
      "[Epoch 043] loss=0.9353 recon=0.9309 kl=0.0045\n",
      "[Epoch 044] loss=0.9299 recon=0.9280 kl=0.0019\n",
      "[Epoch 045] loss=0.9200 recon=0.9197 kl=0.0003\n",
      "[Epoch 046] loss=0.9310 recon=0.9310 kl=0.0000\n",
      "[Epoch 047] loss=0.9372 recon=0.9369 kl=0.0003\n",
      "[Epoch 048] loss=0.9297 recon=0.9292 kl=0.0005\n",
      "[Epoch 049] loss=0.9283 recon=0.9278 kl=0.0005\n",
      "[Epoch 050] loss=0.9243 recon=0.9241 kl=0.0002\n",
      "[Epoch 051] loss=0.9378 recon=0.9370 kl=0.0008\n",
      "[Epoch 052] loss=0.9324 recon=0.9319 kl=0.0005\n",
      "[Epoch 053] loss=0.9249 recon=0.9228 kl=0.0020\n",
      "[Epoch 054] loss=0.9342 recon=0.9307 kl=0.0035\n",
      "[Epoch 055] loss=0.9296 recon=0.9273 kl=0.0024\n",
      "[Epoch 056] loss=0.9410 recon=0.9394 kl=0.0016\n",
      "[Epoch 057] loss=0.9262 recon=0.9259 kl=0.0002\n",
      "[Epoch 058] loss=0.9276 recon=0.9275 kl=0.0000\n",
      "[Epoch 059] loss=0.9401 recon=0.9401 kl=0.0000\n",
      "[Epoch 060] loss=0.9218 recon=0.9218 kl=0.0000\n",
      "[Epoch 061] loss=0.9512 recon=0.9507 kl=0.0005\n",
      "[Epoch 062] loss=0.9199 recon=0.9197 kl=0.0002\n",
      "[Epoch 063] loss=0.9308 recon=0.9300 kl=0.0008\n",
      "[Epoch 064] loss=0.9231 recon=0.9224 kl=0.0006\n",
      "[Epoch 065] loss=0.9290 recon=0.9288 kl=0.0002\n",
      "[Epoch 066] loss=0.9235 recon=0.9228 kl=0.0008\n",
      "[Epoch 067] loss=0.9337 recon=0.9331 kl=0.0005\n",
      "[Epoch 068] loss=0.9480 recon=0.9476 kl=0.0004\n",
      "[Epoch 069] loss=0.9296 recon=0.9243 kl=0.0053\n",
      "[Epoch 070] loss=0.9311 recon=0.9258 kl=0.0053\n",
      "[Epoch 071] loss=0.9216 recon=0.9200 kl=0.0016\n",
      "[Epoch 072] loss=0.9418 recon=0.9416 kl=0.0002\n",
      "[Epoch 073] loss=0.9250 recon=0.9249 kl=0.0000\n",
      "[Epoch 074] loss=0.9266 recon=0.9266 kl=0.0000\n",
      "[Epoch 075] loss=0.9651 recon=0.9643 kl=0.0008\n",
      "[Epoch 076] loss=0.9354 recon=0.9331 kl=0.0023\n",
      "[Epoch 077] loss=0.9312 recon=0.9307 kl=0.0005\n",
      "[Epoch 078] loss=0.9287 recon=0.9287 kl=0.0001\n",
      "[Epoch 079] loss=0.9331 recon=0.9326 kl=0.0006\n",
      "[Epoch 080] loss=0.9203 recon=0.9200 kl=0.0003\n",
      "[Epoch 081] loss=0.9288 recon=0.9271 kl=0.0017\n",
      "[Epoch 082] loss=0.9256 recon=0.9220 kl=0.0036\n",
      "[Epoch 083] loss=0.9405 recon=0.9392 kl=0.0013\n",
      "[Epoch 084] loss=0.9329 recon=0.9327 kl=0.0001\n",
      "[Epoch 085] loss=0.9378 recon=0.9378 kl=0.0000\n",
      "[Epoch 086] loss=0.9258 recon=0.9258 kl=0.0000\n",
      "[Epoch 087] loss=0.9370 recon=0.9366 kl=0.0004\n",
      "[Epoch 088] loss=0.9253 recon=0.9247 kl=0.0006\n",
      "[Epoch 089] loss=0.9362 recon=0.9357 kl=0.0006\n",
      "[Epoch 090] loss=0.9462 recon=0.9460 kl=0.0002\n",
      "16\n",
      "[Epoch 001] loss=1.5174 recon=0.9347 kl=0.5827\n",
      "[Epoch 002] loss=0.9353 recon=0.9318 kl=0.0035\n",
      "[Epoch 003] loss=0.9488 recon=0.9485 kl=0.0003\n",
      "[Epoch 004] loss=0.9284 recon=0.9283 kl=0.0001\n",
      "[Epoch 005] loss=0.9343 recon=0.9342 kl=0.0001\n",
      "[Epoch 006] loss=0.9326 recon=0.9324 kl=0.0001\n",
      "[Epoch 007] loss=0.9399 recon=0.9396 kl=0.0003\n",
      "[Epoch 008] loss=0.9316 recon=0.9313 kl=0.0002\n",
      "[Epoch 009] loss=0.9466 recon=0.9462 kl=0.0005\n",
      "[Epoch 010] loss=0.9352 recon=0.9349 kl=0.0003\n",
      "[Epoch 011] loss=0.9220 recon=0.9219 kl=0.0001\n",
      "[Epoch 012] loss=0.9232 recon=0.9226 kl=0.0006\n",
      "[Epoch 013] loss=0.9225 recon=0.9222 kl=0.0002\n",
      "[Epoch 014] loss=0.9256 recon=0.9252 kl=0.0004\n",
      "[Epoch 015] loss=0.9228 recon=0.9225 kl=0.0002\n",
      "[Epoch 016] loss=0.9319 recon=0.9313 kl=0.0005\n",
      "[Epoch 017] loss=0.9308 recon=0.9304 kl=0.0005\n",
      "[Epoch 018] loss=0.9313 recon=0.9312 kl=0.0002\n",
      "[Epoch 019] loss=0.9431 recon=0.9423 kl=0.0008\n",
      "[Epoch 020] loss=0.9364 recon=0.9357 kl=0.0007\n",
      "[Epoch 021] loss=0.9585 recon=0.9584 kl=0.0001\n",
      "[Epoch 022] loss=0.9325 recon=0.9318 kl=0.0008\n",
      "[Epoch 023] loss=0.9323 recon=0.9318 kl=0.0006\n",
      "[Epoch 024] loss=0.9198 recon=0.9195 kl=0.0004\n",
      "[Epoch 025] loss=0.9320 recon=0.9315 kl=0.0006\n",
      "[Epoch 026] loss=0.9350 recon=0.9347 kl=0.0003\n",
      "[Epoch 027] loss=0.9393 recon=0.9386 kl=0.0007\n",
      "[Epoch 028] loss=0.9269 recon=0.9258 kl=0.0011\n",
      "[Epoch 029] loss=0.9372 recon=0.9370 kl=0.0002\n",
      "[Epoch 030] loss=0.9438 recon=0.9387 kl=0.0051\n",
      "[Epoch 031] loss=0.9342 recon=0.9293 kl=0.0049\n",
      "[Epoch 032] loss=0.9384 recon=0.9381 kl=0.0003\n",
      "[Epoch 033] loss=0.9345 recon=0.9344 kl=0.0000\n",
      "[Epoch 034] loss=0.9273 recon=0.9273 kl=0.0000\n",
      "[Epoch 035] loss=0.9276 recon=0.9272 kl=0.0004\n",
      "[Epoch 036] loss=0.9592 recon=0.9586 kl=0.0006\n",
      "[Epoch 037] loss=0.9375 recon=0.9370 kl=0.0005\n",
      "[Epoch 038] loss=0.9225 recon=0.9220 kl=0.0005\n",
      "[Epoch 039] loss=0.9479 recon=0.9474 kl=0.0005\n",
      "[Epoch 040] loss=0.9284 recon=0.9276 kl=0.0009\n",
      "[Epoch 041] loss=0.9476 recon=0.9475 kl=0.0001\n",
      "[Epoch 042] loss=0.9393 recon=0.9352 kl=0.0041\n",
      "[Epoch 043] loss=0.9316 recon=0.9292 kl=0.0024\n",
      "[Epoch 044] loss=0.9284 recon=0.9277 kl=0.0007\n",
      "[Epoch 045] loss=0.9312 recon=0.9311 kl=0.0001\n",
      "[Epoch 046] loss=0.9298 recon=0.9298 kl=0.0000\n",
      "[Epoch 047] loss=0.9303 recon=0.9303 kl=0.0000\n",
      "[Epoch 048] loss=0.9331 recon=0.9325 kl=0.0006\n",
      "[Epoch 049] loss=0.9470 recon=0.9462 kl=0.0008\n",
      "[Epoch 050] loss=0.9201 recon=0.9199 kl=0.0002\n",
      "[Epoch 051] loss=0.9335 recon=0.9328 kl=0.0007\n",
      "[Epoch 052] loss=0.9358 recon=0.9354 kl=0.0004\n",
      "[Epoch 053] loss=0.9387 recon=0.9381 kl=0.0005\n",
      "[Epoch 054] loss=0.9202 recon=0.9197 kl=0.0004\n",
      "[Epoch 055] loss=0.9343 recon=0.9334 kl=0.0008\n",
      "[Epoch 056] loss=0.9268 recon=0.9263 kl=0.0005\n",
      "[Epoch 057] loss=0.9341 recon=0.9333 kl=0.0008\n",
      "[Epoch 058] loss=0.9309 recon=0.9305 kl=0.0004\n",
      "[Epoch 059] loss=0.9564 recon=0.9553 kl=0.0010\n",
      "[Epoch 060] loss=0.9304 recon=0.9302 kl=0.0002\n",
      "[Epoch 061] loss=0.9380 recon=0.9373 kl=0.0007\n",
      "[Epoch 062] loss=0.9309 recon=0.9299 kl=0.0010\n",
      "[Epoch 063] loss=0.9204 recon=0.9202 kl=0.0002\n",
      "[Epoch 064] loss=0.9328 recon=0.9316 kl=0.0013\n",
      "[Epoch 065] loss=0.9277 recon=0.9242 kl=0.0034\n",
      "[Epoch 066] loss=0.9316 recon=0.9308 kl=0.0008\n",
      "[Epoch 067] loss=0.9281 recon=0.9280 kl=0.0001\n",
      "[Epoch 068] loss=0.9570 recon=0.9570 kl=0.0000\n",
      "[Epoch 069] loss=0.9398 recon=0.9393 kl=0.0005\n",
      "[Epoch 070] loss=0.9720 recon=0.9712 kl=0.0008\n",
      "[Epoch 071] loss=0.9520 recon=0.9513 kl=0.0007\n",
      "[Epoch 072] loss=0.9332 recon=0.9330 kl=0.0002\n",
      "[Epoch 073] loss=0.9411 recon=0.9406 kl=0.0004\n",
      "[Epoch 074] loss=0.9234 recon=0.9230 kl=0.0005\n",
      "[Epoch 075] loss=0.9259 recon=0.9255 kl=0.0005\n",
      "[Epoch 076] loss=0.9275 recon=0.9272 kl=0.0003\n",
      "[Epoch 077] loss=0.9230 recon=0.9224 kl=0.0006\n",
      "[Epoch 078] loss=0.9261 recon=0.9256 kl=0.0004\n",
      "[Epoch 079] loss=0.9458 recon=0.9455 kl=0.0003\n",
      "[Epoch 080] loss=0.9329 recon=0.9322 kl=0.0007\n",
      "[Epoch 081] loss=0.9246 recon=0.9242 kl=0.0004\n",
      "[Epoch 082] loss=0.9444 recon=0.9430 kl=0.0014\n",
      "[Epoch 083] loss=0.9338 recon=0.9317 kl=0.0021\n",
      "[Epoch 084] loss=0.9350 recon=0.9342 kl=0.0008\n",
      "[Epoch 085] loss=0.9378 recon=0.9376 kl=0.0001\n",
      "[Epoch 086] loss=0.9254 recon=0.9254 kl=0.0000\n",
      "[Epoch 087] loss=0.9419 recon=0.9416 kl=0.0003\n",
      "[Epoch 088] loss=0.9417 recon=0.9412 kl=0.0005\n",
      "[Epoch 089] loss=0.9239 recon=0.9234 kl=0.0005\n",
      "[Epoch 090] loss=0.9290 recon=0.9285 kl=0.0005\n",
      "17\n",
      "[Epoch 001] loss=1.3331 recon=0.9613 kl=0.3718\n",
      "[Epoch 002] loss=0.9277 recon=0.9255 kl=0.0022\n",
      "[Epoch 003] loss=0.9373 recon=0.9371 kl=0.0002\n",
      "[Epoch 004] loss=0.9284 recon=0.9283 kl=0.0001\n",
      "[Epoch 005] loss=0.9374 recon=0.9373 kl=0.0001\n",
      "[Epoch 006] loss=0.9295 recon=0.9294 kl=0.0001\n",
      "[Epoch 007] loss=0.9282 recon=0.9280 kl=0.0002\n",
      "[Epoch 008] loss=0.9272 recon=0.9271 kl=0.0001\n",
      "[Epoch 009] loss=0.9439 recon=0.9436 kl=0.0003\n",
      "[Epoch 010] loss=0.9281 recon=0.9279 kl=0.0003\n",
      "[Epoch 011] loss=0.9285 recon=0.9283 kl=0.0001\n",
      "[Epoch 012] loss=0.9286 recon=0.9285 kl=0.0001\n",
      "[Epoch 013] loss=0.9224 recon=0.9218 kl=0.0007\n",
      "[Epoch 014] loss=0.9438 recon=0.9437 kl=0.0001\n",
      "[Epoch 015] loss=0.9628 recon=0.9624 kl=0.0003\n",
      "[Epoch 016] loss=0.9185 recon=0.9183 kl=0.0003\n",
      "[Epoch 017] loss=0.9297 recon=0.9296 kl=0.0001\n",
      "[Epoch 018] loss=0.9381 recon=0.9375 kl=0.0006\n",
      "[Epoch 019] loss=0.9318 recon=0.9313 kl=0.0004\n",
      "[Epoch 020] loss=0.9264 recon=0.9262 kl=0.0002\n",
      "[Epoch 021] loss=0.9516 recon=0.9511 kl=0.0005\n",
      "[Epoch 022] loss=0.9261 recon=0.9258 kl=0.0004\n",
      "[Epoch 023] loss=0.9426 recon=0.9419 kl=0.0006\n",
      "[Epoch 024] loss=0.9355 recon=0.9352 kl=0.0004\n",
      "[Epoch 025] loss=0.9376 recon=0.9372 kl=0.0004\n",
      "[Epoch 026] loss=0.9312 recon=0.9307 kl=0.0005\n",
      "[Epoch 027] loss=0.9261 recon=0.9256 kl=0.0005\n",
      "[Epoch 028] loss=0.9276 recon=0.9272 kl=0.0005\n",
      "[Epoch 029] loss=0.9472 recon=0.9466 kl=0.0007\n",
      "[Epoch 030] loss=0.9362 recon=0.9359 kl=0.0003\n",
      "[Epoch 031] loss=0.9249 recon=0.9240 kl=0.0009\n",
      "[Epoch 032] loss=0.9281 recon=0.9278 kl=0.0003\n",
      "[Epoch 033] loss=0.9571 recon=0.9563 kl=0.0008\n",
      "[Epoch 034] loss=0.9334 recon=0.9331 kl=0.0002\n",
      "[Epoch 035] loss=0.9262 recon=0.9252 kl=0.0010\n",
      "[Epoch 036] loss=0.9337 recon=0.9330 kl=0.0007\n",
      "[Epoch 037] loss=0.9287 recon=0.9286 kl=0.0001\n",
      "[Epoch 038] loss=0.9275 recon=0.9268 kl=0.0007\n",
      "[Epoch 039] loss=0.9203 recon=0.9198 kl=0.0004\n",
      "[Epoch 040] loss=0.9334 recon=0.9332 kl=0.0002\n",
      "[Epoch 041] loss=0.9215 recon=0.9208 kl=0.0007\n",
      "[Epoch 042] loss=0.9272 recon=0.9263 kl=0.0009\n",
      "[Epoch 043] loss=0.9362 recon=0.9361 kl=0.0002\n",
      "[Epoch 044] loss=0.9360 recon=0.9355 kl=0.0005\n",
      "[Epoch 045] loss=0.9264 recon=0.9257 kl=0.0007\n",
      "[Epoch 046] loss=0.9383 recon=0.9379 kl=0.0004\n",
      "[Epoch 047] loss=0.9377 recon=0.9369 kl=0.0008\n",
      "[Epoch 048] loss=0.9243 recon=0.9240 kl=0.0003\n",
      "[Epoch 049] loss=0.9310 recon=0.9305 kl=0.0005\n",
      "[Epoch 050] loss=0.9351 recon=0.9344 kl=0.0007\n",
      "[Epoch 051] loss=0.9400 recon=0.9395 kl=0.0005\n",
      "[Epoch 052] loss=0.9412 recon=0.9408 kl=0.0004\n",
      "[Epoch 053] loss=0.9274 recon=0.9268 kl=0.0006\n",
      "[Epoch 054] loss=0.9465 recon=0.9461 kl=0.0003\n",
      "[Epoch 055] loss=0.9290 recon=0.9261 kl=0.0029\n",
      "[Epoch 056] loss=0.9195 recon=0.9176 kl=0.0020\n",
      "[Epoch 057] loss=0.9330 recon=0.9327 kl=0.0002\n",
      "[Epoch 058] loss=0.9306 recon=0.9305 kl=0.0000\n",
      "[Epoch 059] loss=0.9237 recon=0.9235 kl=0.0002\n",
      "[Epoch 060] loss=0.9313 recon=0.9306 kl=0.0007\n",
      "[Epoch 061] loss=0.9326 recon=0.9325 kl=0.0002\n",
      "[Epoch 062] loss=0.9235 recon=0.9171 kl=0.0064\n",
      "[Epoch 063] loss=0.9208 recon=0.9170 kl=0.0038\n",
      "[Epoch 064] loss=0.9285 recon=0.9282 kl=0.0003\n",
      "[Epoch 065] loss=0.9387 recon=0.9387 kl=0.0000\n",
      "[Epoch 066] loss=0.9315 recon=0.9315 kl=0.0000\n",
      "[Epoch 067] loss=0.9379 recon=0.9379 kl=0.0000\n",
      "[Epoch 068] loss=0.9362 recon=0.9357 kl=0.0005\n",
      "[Epoch 069] loss=0.9408 recon=0.9402 kl=0.0006\n",
      "[Epoch 070] loss=0.9452 recon=0.9450 kl=0.0002\n",
      "[Epoch 071] loss=0.9672 recon=0.9661 kl=0.0012\n",
      "[Epoch 072] loss=0.9339 recon=0.9335 kl=0.0004\n",
      "[Epoch 073] loss=0.9516 recon=0.9516 kl=0.0000\n",
      "[Epoch 074] loss=0.9451 recon=0.9416 kl=0.0035\n",
      "[Epoch 075] loss=0.9274 recon=0.9236 kl=0.0038\n",
      "[Epoch 076] loss=0.9367 recon=0.9342 kl=0.0024\n",
      "[Epoch 077] loss=0.9271 recon=0.9254 kl=0.0017\n",
      "[Epoch 078] loss=0.9247 recon=0.9244 kl=0.0003\n",
      "[Epoch 079] loss=0.9268 recon=0.9268 kl=0.0000\n",
      "[Epoch 080] loss=0.9380 recon=0.9379 kl=0.0000\n",
      "[Epoch 081] loss=0.9379 recon=0.9379 kl=0.0000\n",
      "[Epoch 082] loss=0.9461 recon=0.9461 kl=0.0000\n",
      "[Epoch 083] loss=0.9246 recon=0.9246 kl=0.0000\n",
      "[Epoch 084] loss=0.9340 recon=0.9335 kl=0.0004\n",
      "[Epoch 085] loss=0.9386 recon=0.9385 kl=0.0001\n",
      "[Epoch 086] loss=0.9368 recon=0.9360 kl=0.0008\n",
      "[Epoch 087] loss=0.9240 recon=0.9238 kl=0.0003\n",
      "[Epoch 088] loss=0.9183 recon=0.9179 kl=0.0004\n",
      "[Epoch 089] loss=0.9340 recon=0.9335 kl=0.0006\n",
      "[Epoch 090] loss=0.9352 recon=0.9350 kl=0.0002\n",
      "18\n",
      "[Epoch 001] loss=1.3347 recon=0.9307 kl=0.4041\n",
      "[Epoch 002] loss=0.9460 recon=0.9436 kl=0.0024\n",
      "[Epoch 003] loss=0.9477 recon=0.9474 kl=0.0002\n",
      "[Epoch 004] loss=0.9453 recon=0.9452 kl=0.0000\n",
      "[Epoch 005] loss=0.9541 recon=0.9540 kl=0.0001\n",
      "[Epoch 006] loss=0.9559 recon=0.9558 kl=0.0001\n",
      "[Epoch 007] loss=0.9560 recon=0.9559 kl=0.0001\n",
      "[Epoch 008] loss=0.9323 recon=0.9320 kl=0.0003\n",
      "[Epoch 009] loss=0.9311 recon=0.9308 kl=0.0003\n",
      "[Epoch 010] loss=0.9283 recon=0.9281 kl=0.0002\n",
      "[Epoch 011] loss=0.9373 recon=0.9367 kl=0.0006\n",
      "[Epoch 012] loss=0.9346 recon=0.9346 kl=0.0001\n",
      "[Epoch 013] loss=0.9237 recon=0.9233 kl=0.0004\n",
      "[Epoch 014] loss=0.9254 recon=0.9252 kl=0.0002\n",
      "[Epoch 015] loss=0.9299 recon=0.9294 kl=0.0005\n",
      "[Epoch 016] loss=0.9373 recon=0.9369 kl=0.0003\n",
      "[Epoch 017] loss=0.9314 recon=0.9310 kl=0.0004\n",
      "[Epoch 018] loss=0.9391 recon=0.9386 kl=0.0004\n",
      "[Epoch 019] loss=0.9323 recon=0.9318 kl=0.0005\n",
      "[Epoch 020] loss=0.9547 recon=0.9543 kl=0.0004\n",
      "[Epoch 021] loss=0.9318 recon=0.9315 kl=0.0003\n",
      "[Epoch 022] loss=0.9203 recon=0.9197 kl=0.0006\n",
      "[Epoch 023] loss=0.9314 recon=0.9309 kl=0.0006\n",
      "[Epoch 024] loss=0.9438 recon=0.9412 kl=0.0026\n",
      "[Epoch 025] loss=0.9334 recon=0.9330 kl=0.0003\n",
      "[Epoch 026] loss=0.9262 recon=0.9261 kl=0.0000\n",
      "[Epoch 027] loss=0.9417 recon=0.9411 kl=0.0006\n",
      "[Epoch 028] loss=0.9379 recon=0.9376 kl=0.0003\n",
      "[Epoch 029] loss=0.9430 recon=0.9334 kl=0.0096\n",
      "[Epoch 030] loss=0.9299 recon=0.9267 kl=0.0032\n",
      "[Epoch 031] loss=0.9282 recon=0.9280 kl=0.0003\n",
      "[Epoch 032] loss=0.9408 recon=0.9408 kl=0.0000\n",
      "[Epoch 033] loss=0.9541 recon=0.9541 kl=0.0000\n",
      "[Epoch 034] loss=0.9385 recon=0.9382 kl=0.0003\n",
      "[Epoch 035] loss=0.9377 recon=0.9372 kl=0.0005\n",
      "[Epoch 036] loss=0.9292 recon=0.9291 kl=0.0001\n",
      "[Epoch 037] loss=0.9285 recon=0.9274 kl=0.0011\n",
      "[Epoch 038] loss=0.9396 recon=0.9395 kl=0.0002\n",
      "[Epoch 039] loss=0.9302 recon=0.9298 kl=0.0005\n",
      "[Epoch 040] loss=0.9376 recon=0.9370 kl=0.0006\n",
      "[Epoch 041] loss=0.9207 recon=0.9205 kl=0.0002\n",
      "[Epoch 042] loss=0.9289 recon=0.9281 kl=0.0008\n",
      "[Epoch 043] loss=0.9297 recon=0.9293 kl=0.0005\n",
      "[Epoch 044] loss=0.9361 recon=0.9310 kl=0.0051\n",
      "[Epoch 045] loss=0.9207 recon=0.9200 kl=0.0008\n",
      "[Epoch 046] loss=0.9256 recon=0.9255 kl=0.0001\n",
      "[Epoch 047] loss=0.9588 recon=0.9588 kl=0.0000\n",
      "[Epoch 048] loss=0.9251 recon=0.9247 kl=0.0004\n",
      "[Epoch 049] loss=0.9498 recon=0.9490 kl=0.0008\n",
      "[Epoch 050] loss=0.9297 recon=0.9295 kl=0.0002\n",
      "[Epoch 051] loss=0.9283 recon=0.9277 kl=0.0006\n",
      "[Epoch 052] loss=0.9366 recon=0.9364 kl=0.0002\n",
      "[Epoch 053] loss=0.9463 recon=0.9422 kl=0.0040\n",
      "[Epoch 054] loss=0.9478 recon=0.9442 kl=0.0035\n",
      "[Epoch 055] loss=0.9330 recon=0.9306 kl=0.0024\n",
      "[Epoch 056] loss=0.9334 recon=0.9328 kl=0.0006\n",
      "[Epoch 057] loss=0.9317 recon=0.9316 kl=0.0001\n",
      "[Epoch 058] loss=0.9330 recon=0.9330 kl=0.0000\n",
      "[Epoch 059] loss=0.9368 recon=0.9368 kl=0.0000\n",
      "[Epoch 060] loss=0.9468 recon=0.9465 kl=0.0003\n",
      "[Epoch 061] loss=0.9269 recon=0.9264 kl=0.0005\n",
      "[Epoch 062] loss=0.9276 recon=0.9270 kl=0.0005\n",
      "[Epoch 063] loss=0.9607 recon=0.9603 kl=0.0003\n",
      "[Epoch 064] loss=0.9279 recon=0.9272 kl=0.0008\n",
      "[Epoch 065] loss=0.9359 recon=0.9358 kl=0.0002\n",
      "[Epoch 066] loss=0.9640 recon=0.9637 kl=0.0003\n",
      "[Epoch 067] loss=0.9321 recon=0.9257 kl=0.0064\n",
      "[Epoch 068] loss=0.9340 recon=0.9302 kl=0.0038\n",
      "[Epoch 069] loss=0.9338 recon=0.9335 kl=0.0003\n",
      "[Epoch 070] loss=0.9223 recon=0.9222 kl=0.0000\n",
      "[Epoch 071] loss=0.9549 recon=0.9549 kl=0.0000\n",
      "[Epoch 072] loss=0.9363 recon=0.9363 kl=0.0000\n",
      "[Epoch 073] loss=0.9257 recon=0.9250 kl=0.0006\n",
      "[Epoch 074] loss=0.9346 recon=0.9342 kl=0.0004\n",
      "[Epoch 075] loss=0.9411 recon=0.9408 kl=0.0003\n",
      "[Epoch 076] loss=0.9328 recon=0.9320 kl=0.0008\n",
      "[Epoch 077] loss=0.9280 recon=0.9270 kl=0.0009\n",
      "[Epoch 078] loss=0.9329 recon=0.9322 kl=0.0007\n",
      "[Epoch 079] loss=0.9296 recon=0.9295 kl=0.0001\n",
      "[Epoch 080] loss=0.9375 recon=0.9375 kl=0.0001\n",
      "[Epoch 081] loss=0.9357 recon=0.9352 kl=0.0006\n",
      "[Epoch 082] loss=0.9415 recon=0.9411 kl=0.0003\n",
      "[Epoch 083] loss=0.9336 recon=0.9330 kl=0.0006\n",
      "[Epoch 084] loss=0.9354 recon=0.9350 kl=0.0004\n",
      "[Epoch 085] loss=0.9340 recon=0.9336 kl=0.0004\n",
      "[Epoch 086] loss=0.9398 recon=0.9392 kl=0.0006\n",
      "[Epoch 087] loss=0.9200 recon=0.9192 kl=0.0007\n",
      "[Epoch 088] loss=0.9264 recon=0.9261 kl=0.0003\n",
      "[Epoch 089] loss=0.9283 recon=0.9281 kl=0.0001\n",
      "[Epoch 090] loss=0.9422 recon=0.9414 kl=0.0008\n",
      "19\n",
      "[Epoch 001] loss=1.4073 recon=0.9288 kl=0.4785\n",
      "[Epoch 002] loss=0.9491 recon=0.9469 kl=0.0023\n",
      "[Epoch 003] loss=0.9226 recon=0.9224 kl=0.0002\n",
      "[Epoch 004] loss=0.9262 recon=0.9261 kl=0.0001\n",
      "[Epoch 005] loss=0.9414 recon=0.9414 kl=0.0000\n",
      "[Epoch 006] loss=0.9265 recon=0.9263 kl=0.0002\n",
      "[Epoch 007] loss=0.9304 recon=0.9303 kl=0.0002\n",
      "[Epoch 008] loss=0.9296 recon=0.9294 kl=0.0002\n",
      "[Epoch 009] loss=0.9302 recon=0.9300 kl=0.0002\n",
      "[Epoch 010] loss=0.9238 recon=0.9235 kl=0.0003\n",
      "[Epoch 011] loss=0.9385 recon=0.9383 kl=0.0002\n",
      "[Epoch 012] loss=0.9351 recon=0.9346 kl=0.0005\n",
      "[Epoch 013] loss=0.9242 recon=0.9240 kl=0.0002\n",
      "[Epoch 014] loss=0.9413 recon=0.9408 kl=0.0005\n",
      "[Epoch 015] loss=0.9262 recon=0.9258 kl=0.0005\n",
      "[Epoch 016] loss=0.9343 recon=0.9337 kl=0.0006\n",
      "[Epoch 017] loss=0.9514 recon=0.9514 kl=0.0001\n",
      "[Epoch 018] loss=0.9289 recon=0.9282 kl=0.0007\n",
      "[Epoch 019] loss=0.9466 recon=0.9464 kl=0.0002\n",
      "[Epoch 020] loss=0.9181 recon=0.9171 kl=0.0010\n",
      "[Epoch 021] loss=0.9185 recon=0.9184 kl=0.0001\n",
      "[Epoch 022] loss=0.9248 recon=0.9239 kl=0.0010\n",
      "[Epoch 023] loss=0.9233 recon=0.9229 kl=0.0003\n",
      "[Epoch 024] loss=0.9460 recon=0.9450 kl=0.0011\n",
      "[Epoch 025] loss=0.9349 recon=0.9347 kl=0.0001\n",
      "[Epoch 026] loss=0.9333 recon=0.9320 kl=0.0013\n",
      "[Epoch 027] loss=0.9429 recon=0.9426 kl=0.0004\n",
      "[Epoch 028] loss=0.9352 recon=0.9350 kl=0.0001\n",
      "[Epoch 029] loss=0.9361 recon=0.9351 kl=0.0010\n",
      "[Epoch 030] loss=0.9261 recon=0.9256 kl=0.0005\n",
      "[Epoch 031] loss=0.9380 recon=0.9373 kl=0.0007\n",
      "[Epoch 032] loss=0.9305 recon=0.9299 kl=0.0006\n",
      "[Epoch 033] loss=0.9186 recon=0.9183 kl=0.0003\n",
      "[Epoch 034] loss=0.9356 recon=0.9350 kl=0.0006\n",
      "[Epoch 035] loss=0.9351 recon=0.9345 kl=0.0006\n",
      "[Epoch 036] loss=0.9456 recon=0.9452 kl=0.0003\n",
      "[Epoch 037] loss=0.9361 recon=0.9345 kl=0.0016\n",
      "[Epoch 038] loss=0.9290 recon=0.9285 kl=0.0004\n",
      "[Epoch 039] loss=0.9218 recon=0.9205 kl=0.0013\n",
      "[Epoch 040] loss=0.9335 recon=0.9286 kl=0.0049\n",
      "[Epoch 041] loss=0.9304 recon=0.9281 kl=0.0022\n",
      "[Epoch 042] loss=0.9250 recon=0.9240 kl=0.0009\n",
      "[Epoch 043] loss=0.9351 recon=0.9350 kl=0.0001\n",
      "[Epoch 044] loss=0.9272 recon=0.9272 kl=0.0000\n",
      "[Epoch 045] loss=0.9378 recon=0.9377 kl=0.0000\n",
      "[Epoch 046] loss=0.9382 recon=0.9381 kl=0.0001\n",
      "[Epoch 047] loss=0.9454 recon=0.9448 kl=0.0006\n",
      "[Epoch 048] loss=0.9358 recon=0.9283 kl=0.0075\n",
      "[Epoch 049] loss=0.9509 recon=0.9470 kl=0.0039\n",
      "[Epoch 050] loss=0.9286 recon=0.9282 kl=0.0004\n",
      "[Epoch 051] loss=0.9374 recon=0.9373 kl=0.0000\n",
      "[Epoch 052] loss=0.9478 recon=0.9478 kl=0.0000\n",
      "[Epoch 053] loss=0.9149 recon=0.9149 kl=0.0000\n",
      "[Epoch 054] loss=0.9247 recon=0.9245 kl=0.0002\n",
      "[Epoch 055] loss=0.9321 recon=0.9314 kl=0.0007\n",
      "[Epoch 056] loss=0.9297 recon=0.9264 kl=0.0033\n",
      "[Epoch 057] loss=0.9302 recon=0.9298 kl=0.0004\n",
      "[Epoch 058] loss=0.9240 recon=0.9239 kl=0.0000\n",
      "[Epoch 059] loss=0.9326 recon=0.9325 kl=0.0000\n",
      "[Epoch 060] loss=0.9315 recon=0.9276 kl=0.0039\n",
      "[Epoch 061] loss=0.9457 recon=0.9436 kl=0.0021\n",
      "[Epoch 062] loss=0.9261 recon=0.9257 kl=0.0005\n",
      "[Epoch 063] loss=0.9307 recon=0.9306 kl=0.0000\n",
      "[Epoch 064] loss=0.9418 recon=0.9418 kl=0.0000\n",
      "[Epoch 065] loss=0.9248 recon=0.9240 kl=0.0007\n",
      "[Epoch 066] loss=0.9220 recon=0.9213 kl=0.0007\n",
      "[Epoch 067] loss=0.9231 recon=0.9229 kl=0.0002\n",
      "[Epoch 068] loss=0.9295 recon=0.9255 kl=0.0040\n",
      "[Epoch 069] loss=0.9375 recon=0.9362 kl=0.0013\n",
      "[Epoch 070] loss=0.9227 recon=0.9226 kl=0.0001\n",
      "[Epoch 071] loss=0.9380 recon=0.9379 kl=0.0000\n",
      "[Epoch 072] loss=0.9287 recon=0.9286 kl=0.0001\n",
      "[Epoch 073] loss=0.9378 recon=0.9373 kl=0.0005\n",
      "[Epoch 074] loss=0.9468 recon=0.9463 kl=0.0006\n",
      "[Epoch 075] loss=0.9281 recon=0.9276 kl=0.0005\n",
      "[Epoch 076] loss=0.9157 recon=0.9156 kl=0.0001\n",
      "[Epoch 077] loss=0.9580 recon=0.9568 kl=0.0012\n",
      "[Epoch 078] loss=0.9344 recon=0.9335 kl=0.0009\n",
      "[Epoch 079] loss=0.9613 recon=0.9609 kl=0.0004\n",
      "[Epoch 080] loss=0.9317 recon=0.9284 kl=0.0033\n",
      "[Epoch 081] loss=0.9286 recon=0.9253 kl=0.0033\n",
      "[Epoch 082] loss=0.9289 recon=0.9264 kl=0.0025\n",
      "[Epoch 083] loss=0.9214 recon=0.9194 kl=0.0020\n",
      "[Epoch 084] loss=0.9228 recon=0.9220 kl=0.0008\n",
      "[Epoch 085] loss=0.9366 recon=0.9365 kl=0.0001\n",
      "[Epoch 086] loss=0.9205 recon=0.9205 kl=0.0000\n",
      "[Epoch 087] loss=0.9374 recon=0.9374 kl=0.0000\n",
      "[Epoch 088] loss=0.9322 recon=0.9322 kl=0.0000\n",
      "[Epoch 089] loss=0.9294 recon=0.9294 kl=0.0000\n",
      "[Epoch 090] loss=0.9357 recon=0.9355 kl=0.0002\n",
      "20\n",
      "[Epoch 001] loss=1.2388 recon=0.9349 kl=0.3039\n",
      "[Epoch 002] loss=0.9456 recon=0.9430 kl=0.0025\n",
      "[Epoch 003] loss=0.9316 recon=0.9314 kl=0.0003\n",
      "[Epoch 004] loss=0.9352 recon=0.9351 kl=0.0001\n",
      "[Epoch 005] loss=0.9496 recon=0.9493 kl=0.0003\n",
      "[Epoch 006] loss=0.9253 recon=0.9251 kl=0.0002\n",
      "[Epoch 007] loss=0.9481 recon=0.9478 kl=0.0003\n",
      "[Epoch 008] loss=0.9304 recon=0.9300 kl=0.0003\n",
      "[Epoch 009] loss=0.9395 recon=0.9393 kl=0.0002\n",
      "[Epoch 010] loss=0.9351 recon=0.9347 kl=0.0003\n",
      "[Epoch 011] loss=0.9256 recon=0.9253 kl=0.0003\n",
      "[Epoch 012] loss=0.9218 recon=0.9215 kl=0.0003\n",
      "[Epoch 013] loss=0.9257 recon=0.9253 kl=0.0004\n",
      "[Epoch 014] loss=0.9314 recon=0.9311 kl=0.0003\n",
      "[Epoch 015] loss=0.9344 recon=0.9338 kl=0.0006\n",
      "[Epoch 016] loss=0.9262 recon=0.9258 kl=0.0004\n",
      "[Epoch 017] loss=0.9233 recon=0.9228 kl=0.0005\n",
      "[Epoch 018] loss=0.9397 recon=0.9395 kl=0.0002\n",
      "[Epoch 019] loss=0.9306 recon=0.9299 kl=0.0007\n",
      "[Epoch 020] loss=0.9238 recon=0.9236 kl=0.0002\n",
      "[Epoch 021] loss=0.9346 recon=0.9340 kl=0.0006\n",
      "[Epoch 022] loss=0.9212 recon=0.9208 kl=0.0004\n",
      "[Epoch 023] loss=0.9316 recon=0.9312 kl=0.0004\n",
      "[Epoch 024] loss=0.9280 recon=0.9272 kl=0.0008\n",
      "[Epoch 025] loss=0.9371 recon=0.9366 kl=0.0005\n",
      "[Epoch 026] loss=0.9171 recon=0.9169 kl=0.0003\n",
      "[Epoch 027] loss=0.9383 recon=0.9374 kl=0.0008\n",
      "[Epoch 028] loss=0.9281 recon=0.9277 kl=0.0004\n",
      "[Epoch 029] loss=0.9288 recon=0.9283 kl=0.0004\n",
      "[Epoch 030] loss=0.9371 recon=0.9365 kl=0.0006\n",
      "[Epoch 031] loss=0.9221 recon=0.9218 kl=0.0003\n",
      "[Epoch 032] loss=0.9390 recon=0.9381 kl=0.0008\n",
      "[Epoch 033] loss=0.9314 recon=0.9312 kl=0.0003\n",
      "[Epoch 034] loss=0.9247 recon=0.9240 kl=0.0007\n",
      "[Epoch 035] loss=0.9316 recon=0.9308 kl=0.0007\n",
      "[Epoch 036] loss=0.9194 recon=0.9188 kl=0.0006\n",
      "[Epoch 037] loss=0.9370 recon=0.9366 kl=0.0005\n",
      "[Epoch 038] loss=0.9503 recon=0.9497 kl=0.0005\n",
      "[Epoch 039] loss=0.9256 recon=0.9249 kl=0.0007\n",
      "[Epoch 040] loss=0.9283 recon=0.9280 kl=0.0003\n",
      "[Epoch 041] loss=0.9436 recon=0.9427 kl=0.0009\n",
      "[Epoch 042] loss=0.9292 recon=0.9286 kl=0.0006\n",
      "[Epoch 043] loss=0.9363 recon=0.9356 kl=0.0006\n",
      "[Epoch 044] loss=0.9325 recon=0.9321 kl=0.0004\n",
      "[Epoch 045] loss=0.9384 recon=0.9378 kl=0.0006\n",
      "[Epoch 046] loss=0.9305 recon=0.9297 kl=0.0008\n",
      "[Epoch 047] loss=0.9541 recon=0.9537 kl=0.0004\n",
      "[Epoch 048] loss=0.9266 recon=0.9262 kl=0.0004\n",
      "[Epoch 049] loss=0.9393 recon=0.9385 kl=0.0008\n",
      "[Epoch 050] loss=0.9239 recon=0.9237 kl=0.0002\n",
      "[Epoch 051] loss=0.9546 recon=0.9480 kl=0.0066\n",
      "[Epoch 052] loss=0.9428 recon=0.9404 kl=0.0024\n",
      "[Epoch 053] loss=0.9198 recon=0.9195 kl=0.0003\n",
      "[Epoch 054] loss=0.9240 recon=0.9240 kl=0.0000\n",
      "[Epoch 055] loss=0.9393 recon=0.9393 kl=0.0000\n",
      "[Epoch 056] loss=0.9240 recon=0.9236 kl=0.0005\n",
      "[Epoch 057] loss=0.9483 recon=0.9428 kl=0.0054\n",
      "[Epoch 058] loss=0.9389 recon=0.9365 kl=0.0025\n",
      "[Epoch 059] loss=0.9394 recon=0.9391 kl=0.0004\n",
      "[Epoch 060] loss=0.9333 recon=0.9332 kl=0.0000\n",
      "[Epoch 061] loss=0.9377 recon=0.9376 kl=0.0000\n",
      "[Epoch 062] loss=0.9367 recon=0.9363 kl=0.0004\n",
      "[Epoch 063] loss=0.9261 recon=0.9256 kl=0.0005\n",
      "[Epoch 064] loss=0.9297 recon=0.9295 kl=0.0001\n",
      "[Epoch 065] loss=0.9497 recon=0.9477 kl=0.0020\n",
      "[Epoch 066] loss=0.9492 recon=0.9216 kl=0.0276\n",
      "[Epoch 067] loss=0.9354 recon=0.9323 kl=0.0031\n",
      "[Epoch 068] loss=0.9344 recon=0.9341 kl=0.0003\n",
      "[Epoch 069] loss=0.9338 recon=0.9338 kl=0.0000\n",
      "[Epoch 070] loss=0.9394 recon=0.9394 kl=0.0000\n",
      "[Epoch 071] loss=0.9372 recon=0.9372 kl=0.0000\n",
      "[Epoch 072] loss=0.9293 recon=0.9293 kl=0.0000\n",
      "[Epoch 073] loss=0.9303 recon=0.9278 kl=0.0025\n",
      "[Epoch 074] loss=0.9216 recon=0.9181 kl=0.0035\n",
      "[Epoch 075] loss=0.9273 recon=0.9250 kl=0.0023\n",
      "[Epoch 076] loss=0.9198 recon=0.9186 kl=0.0012\n",
      "[Epoch 077] loss=0.9492 recon=0.9490 kl=0.0001\n",
      "[Epoch 078] loss=0.9251 recon=0.9250 kl=0.0000\n",
      "[Epoch 079] loss=0.9239 recon=0.9239 kl=0.0000\n",
      "[Epoch 080] loss=0.9657 recon=0.9657 kl=0.0000\n",
      "[Epoch 081] loss=0.9313 recon=0.9313 kl=0.0000\n",
      "[Epoch 082] loss=0.9515 recon=0.9510 kl=0.0006\n",
      "[Epoch 083] loss=0.9358 recon=0.9355 kl=0.0004\n",
      "[Epoch 084] loss=0.9352 recon=0.9349 kl=0.0003\n",
      "[Epoch 085] loss=0.9360 recon=0.9354 kl=0.0007\n",
      "[Epoch 086] loss=0.9175 recon=0.9173 kl=0.0002\n",
      "[Epoch 087] loss=0.9236 recon=0.9229 kl=0.0007\n",
      "[Epoch 088] loss=0.9297 recon=0.9294 kl=0.0004\n",
      "[Epoch 089] loss=0.9186 recon=0.9182 kl=0.0003\n",
      "[Epoch 090] loss=0.9378 recon=0.9373 kl=0.0005\n",
      "21\n",
      "[Epoch 001] loss=1.1567 recon=0.9350 kl=0.2216\n",
      "[Epoch 002] loss=0.9285 recon=0.9266 kl=0.0019\n",
      "[Epoch 003] loss=0.9306 recon=0.9304 kl=0.0002\n",
      "[Epoch 004] loss=0.9260 recon=0.9259 kl=0.0001\n",
      "[Epoch 005] loss=0.9287 recon=0.9285 kl=0.0002\n",
      "[Epoch 006] loss=0.9286 recon=0.9284 kl=0.0002\n",
      "[Epoch 007] loss=0.9307 recon=0.9306 kl=0.0001\n",
      "[Epoch 008] loss=0.9348 recon=0.9345 kl=0.0003\n",
      "[Epoch 009] loss=0.9350 recon=0.9347 kl=0.0004\n",
      "[Epoch 010] loss=0.9351 recon=0.9349 kl=0.0002\n",
      "[Epoch 011] loss=0.9194 recon=0.9191 kl=0.0003\n",
      "[Epoch 012] loss=0.9447 recon=0.9445 kl=0.0002\n",
      "[Epoch 013] loss=0.9510 recon=0.9504 kl=0.0005\n",
      "[Epoch 014] loss=0.9289 recon=0.9286 kl=0.0003\n",
      "[Epoch 015] loss=0.9308 recon=0.9304 kl=0.0003\n",
      "[Epoch 016] loss=0.9381 recon=0.9376 kl=0.0005\n",
      "[Epoch 017] loss=0.9431 recon=0.9428 kl=0.0003\n",
      "[Epoch 018] loss=0.9591 recon=0.9589 kl=0.0002\n",
      "[Epoch 019] loss=0.9291 recon=0.9280 kl=0.0011\n",
      "[Epoch 020] loss=0.9417 recon=0.9415 kl=0.0002\n",
      "[Epoch 021] loss=0.9315 recon=0.9311 kl=0.0004\n",
      "[Epoch 022] loss=0.9306 recon=0.9301 kl=0.0005\n",
      "[Epoch 023] loss=0.9427 recon=0.9421 kl=0.0006\n",
      "[Epoch 024] loss=0.9197 recon=0.9194 kl=0.0003\n",
      "[Epoch 025] loss=0.9304 recon=0.9298 kl=0.0006\n",
      "[Epoch 026] loss=0.9382 recon=0.9376 kl=0.0006\n",
      "[Epoch 027] loss=0.9260 recon=0.9255 kl=0.0005\n",
      "[Epoch 028] loss=0.9365 recon=0.9360 kl=0.0006\n",
      "[Epoch 029] loss=0.9233 recon=0.9229 kl=0.0004\n",
      "[Epoch 030] loss=0.9331 recon=0.9324 kl=0.0007\n",
      "[Epoch 031] loss=0.9359 recon=0.9344 kl=0.0016\n",
      "[Epoch 032] loss=0.9299 recon=0.9261 kl=0.0038\n",
      "[Epoch 033] loss=0.9335 recon=0.9313 kl=0.0021\n",
      "[Epoch 034] loss=0.9240 recon=0.9234 kl=0.0006\n",
      "[Epoch 035] loss=0.9313 recon=0.9312 kl=0.0001\n",
      "[Epoch 036] loss=0.9626 recon=0.9626 kl=0.0000\n",
      "[Epoch 037] loss=0.9309 recon=0.9309 kl=0.0000\n",
      "[Epoch 038] loss=0.9524 recon=0.9521 kl=0.0002\n",
      "[Epoch 039] loss=0.9261 recon=0.9218 kl=0.0044\n",
      "[Epoch 040] loss=0.9366 recon=0.9334 kl=0.0033\n",
      "[Epoch 041] loss=0.9256 recon=0.9239 kl=0.0017\n",
      "[Epoch 042] loss=0.9518 recon=0.9515 kl=0.0002\n",
      "[Epoch 043] loss=0.9273 recon=0.9273 kl=0.0000\n",
      "[Epoch 044] loss=0.9344 recon=0.9344 kl=0.0000\n",
      "[Epoch 045] loss=0.9305 recon=0.9304 kl=0.0001\n",
      "[Epoch 046] loss=0.9285 recon=0.9282 kl=0.0002\n",
      "[Epoch 047] loss=0.9278 recon=0.9271 kl=0.0007\n",
      "[Epoch 048] loss=0.9471 recon=0.9461 kl=0.0010\n",
      "[Epoch 049] loss=0.9259 recon=0.9257 kl=0.0002\n",
      "[Epoch 050] loss=0.9286 recon=0.9281 kl=0.0005\n",
      "[Epoch 051] loss=0.9295 recon=0.9292 kl=0.0004\n",
      "[Epoch 052] loss=0.9294 recon=0.9290 kl=0.0004\n",
      "[Epoch 053] loss=0.9345 recon=0.9341 kl=0.0003\n",
      "[Epoch 054] loss=0.9388 recon=0.9380 kl=0.0008\n",
      "[Epoch 055] loss=0.9469 recon=0.9461 kl=0.0008\n",
      "[Epoch 056] loss=0.9264 recon=0.9262 kl=0.0002\n",
      "[Epoch 057] loss=0.9392 recon=0.9383 kl=0.0009\n",
      "[Epoch 058] loss=0.9395 recon=0.9386 kl=0.0009\n",
      "[Epoch 059] loss=0.9540 recon=0.9539 kl=0.0001\n",
      "[Epoch 060] loss=0.9162 recon=0.9155 kl=0.0007\n",
      "[Epoch 061] loss=0.9211 recon=0.9208 kl=0.0004\n",
      "[Epoch 062] loss=0.9322 recon=0.9316 kl=0.0006\n",
      "[Epoch 063] loss=0.9435 recon=0.9428 kl=0.0007\n",
      "[Epoch 064] loss=0.9444 recon=0.9394 kl=0.0050\n",
      "[Epoch 065] loss=0.9445 recon=0.9416 kl=0.0029\n",
      "[Epoch 066] loss=0.9305 recon=0.9283 kl=0.0022\n",
      "[Epoch 067] loss=0.9264 recon=0.9244 kl=0.0020\n",
      "[Epoch 068] loss=0.9485 recon=0.9482 kl=0.0003\n",
      "[Epoch 069] loss=0.9295 recon=0.9294 kl=0.0000\n",
      "[Epoch 070] loss=0.9240 recon=0.9240 kl=0.0000\n",
      "[Epoch 071] loss=0.9337 recon=0.9337 kl=0.0000\n",
      "[Epoch 072] loss=0.9249 recon=0.9249 kl=0.0000\n",
      "[Epoch 073] loss=0.9202 recon=0.9202 kl=0.0000\n",
      "[Epoch 074] loss=0.9184 recon=0.9178 kl=0.0006\n",
      "[Epoch 075] loss=0.9344 recon=0.9334 kl=0.0010\n",
      "[Epoch 076] loss=0.9242 recon=0.9240 kl=0.0002\n",
      "[Epoch 077] loss=0.9540 recon=0.9536 kl=0.0004\n",
      "[Epoch 078] loss=0.9332 recon=0.9289 kl=0.0043\n",
      "[Epoch 079] loss=0.9294 recon=0.9273 kl=0.0021\n",
      "[Epoch 080] loss=0.9225 recon=0.9222 kl=0.0003\n",
      "[Epoch 081] loss=0.9256 recon=0.9256 kl=0.0000\n",
      "[Epoch 082] loss=0.9282 recon=0.9282 kl=0.0000\n",
      "[Epoch 083] loss=0.9336 recon=0.9335 kl=0.0000\n",
      "[Epoch 084] loss=0.9236 recon=0.9229 kl=0.0007\n",
      "[Epoch 085] loss=0.9292 recon=0.9285 kl=0.0007\n",
      "[Epoch 086] loss=0.9341 recon=0.9340 kl=0.0001\n",
      "[Epoch 087] loss=0.9319 recon=0.9309 kl=0.0010\n",
      "[Epoch 088] loss=0.9365 recon=0.9356 kl=0.0009\n",
      "[Epoch 089] loss=0.9228 recon=0.9227 kl=0.0001\n",
      "[Epoch 090] loss=0.9288 recon=0.9286 kl=0.0002\n",
      "22\n",
      "[Epoch 001] loss=1.3111 recon=0.9466 kl=0.3645\n",
      "[Epoch 002] loss=0.9503 recon=0.9478 kl=0.0025\n",
      "[Epoch 003] loss=0.9227 recon=0.9225 kl=0.0002\n",
      "[Epoch 004] loss=0.9407 recon=0.9407 kl=0.0000\n",
      "[Epoch 005] loss=0.9397 recon=0.9395 kl=0.0003\n",
      "[Epoch 006] loss=0.9304 recon=0.9303 kl=0.0001\n",
      "[Epoch 007] loss=0.9402 recon=0.9400 kl=0.0003\n",
      "[Epoch 008] loss=0.9447 recon=0.9444 kl=0.0003\n",
      "[Epoch 009] loss=0.9322 recon=0.9318 kl=0.0003\n",
      "[Epoch 010] loss=0.9219 recon=0.9216 kl=0.0003\n",
      "[Epoch 011] loss=0.9500 recon=0.9496 kl=0.0004\n",
      "[Epoch 012] loss=0.9340 recon=0.9338 kl=0.0003\n",
      "[Epoch 013] loss=0.9459 recon=0.9453 kl=0.0006\n",
      "[Epoch 014] loss=0.9264 recon=0.9261 kl=0.0003\n",
      "[Epoch 015] loss=0.9420 recon=0.9416 kl=0.0004\n",
      "[Epoch 016] loss=0.9276 recon=0.9270 kl=0.0006\n",
      "[Epoch 017] loss=0.9418 recon=0.9414 kl=0.0005\n",
      "[Epoch 018] loss=0.9224 recon=0.9197 kl=0.0027\n",
      "[Epoch 019] loss=0.9220 recon=0.9208 kl=0.0012\n",
      "[Epoch 020] loss=0.9289 recon=0.9288 kl=0.0001\n",
      "[Epoch 021] loss=0.9337 recon=0.9337 kl=0.0001\n",
      "[Epoch 022] loss=0.9223 recon=0.9217 kl=0.0006\n",
      "[Epoch 023] loss=0.9363 recon=0.9360 kl=0.0003\n",
      "[Epoch 024] loss=0.9267 recon=0.9261 kl=0.0006\n",
      "[Epoch 025] loss=0.9382 recon=0.9378 kl=0.0004\n",
      "[Epoch 026] loss=0.9382 recon=0.9378 kl=0.0004\n",
      "[Epoch 027] loss=0.9231 recon=0.9221 kl=0.0010\n",
      "[Epoch 028] loss=0.9402 recon=0.9399 kl=0.0003\n",
      "[Epoch 029] loss=0.9309 recon=0.9303 kl=0.0006\n",
      "[Epoch 030] loss=0.9225 recon=0.9215 kl=0.0010\n",
      "[Epoch 031] loss=0.9189 recon=0.9184 kl=0.0005\n",
      "[Epoch 032] loss=0.9355 recon=0.9351 kl=0.0004\n",
      "[Epoch 033] loss=0.9248 recon=0.9243 kl=0.0005\n",
      "[Epoch 034] loss=0.9388 recon=0.9382 kl=0.0007\n",
      "[Epoch 035] loss=0.9232 recon=0.9228 kl=0.0004\n",
      "[Epoch 036] loss=0.9269 recon=0.9264 kl=0.0005\n",
      "[Epoch 037] loss=0.9289 recon=0.9282 kl=0.0007\n",
      "[Epoch 038] loss=0.9277 recon=0.9269 kl=0.0007\n",
      "[Epoch 039] loss=0.9250 recon=0.9244 kl=0.0006\n",
      "[Epoch 040] loss=0.9423 recon=0.9418 kl=0.0005\n",
      "[Epoch 041] loss=0.9382 recon=0.9375 kl=0.0007\n",
      "[Epoch 042] loss=0.9241 recon=0.9237 kl=0.0004\n",
      "[Epoch 043] loss=0.9385 recon=0.9379 kl=0.0006\n",
      "[Epoch 044] loss=0.9326 recon=0.9300 kl=0.0026\n",
      "[Epoch 045] loss=0.9436 recon=0.9404 kl=0.0032\n",
      "[Epoch 046] loss=0.9388 recon=0.9365 kl=0.0023\n",
      "[Epoch 047] loss=0.9298 recon=0.9294 kl=0.0004\n",
      "[Epoch 048] loss=0.9469 recon=0.9468 kl=0.0000\n",
      "[Epoch 049] loss=0.9375 recon=0.9375 kl=0.0000\n",
      "[Epoch 050] loss=0.9318 recon=0.9318 kl=0.0000\n",
      "[Epoch 051] loss=0.9305 recon=0.9295 kl=0.0009\n",
      "[Epoch 052] loss=0.9266 recon=0.9252 kl=0.0014\n",
      "[Epoch 053] loss=0.9260 recon=0.9257 kl=0.0004\n",
      "[Epoch 054] loss=0.9423 recon=0.9420 kl=0.0004\n",
      "[Epoch 055] loss=0.9421 recon=0.9417 kl=0.0004\n",
      "[Epoch 056] loss=0.9300 recon=0.9293 kl=0.0007\n",
      "[Epoch 057] loss=0.9318 recon=0.9315 kl=0.0003\n",
      "[Epoch 058] loss=0.9248 recon=0.9240 kl=0.0009\n",
      "[Epoch 059] loss=0.9267 recon=0.9261 kl=0.0006\n",
      "[Epoch 060] loss=0.9339 recon=0.9335 kl=0.0004\n",
      "[Epoch 061] loss=0.9404 recon=0.9369 kl=0.0034\n",
      "[Epoch 062] loss=0.9349 recon=0.9344 kl=0.0005\n",
      "[Epoch 063] loss=0.9393 recon=0.9392 kl=0.0001\n",
      "[Epoch 064] loss=0.9285 recon=0.9285 kl=0.0000\n",
      "[Epoch 065] loss=0.9355 recon=0.9347 kl=0.0008\n",
      "[Epoch 066] loss=0.9409 recon=0.9399 kl=0.0009\n",
      "[Epoch 067] loss=0.9278 recon=0.9272 kl=0.0006\n",
      "[Epoch 068] loss=0.9310 recon=0.9306 kl=0.0004\n",
      "[Epoch 069] loss=0.9420 recon=0.9414 kl=0.0006\n",
      "[Epoch 070] loss=0.9328 recon=0.9318 kl=0.0010\n",
      "[Epoch 071] loss=0.9312 recon=0.9309 kl=0.0003\n",
      "[Epoch 072] loss=0.9279 recon=0.9278 kl=0.0001\n",
      "[Epoch 073] loss=0.9578 recon=0.9573 kl=0.0006\n",
      "[Epoch 074] loss=0.9278 recon=0.9271 kl=0.0007\n",
      "[Epoch 075] loss=0.9309 recon=0.9306 kl=0.0004\n",
      "[Epoch 076] loss=0.9319 recon=0.9315 kl=0.0004\n",
      "[Epoch 077] loss=0.9418 recon=0.9414 kl=0.0005\n",
      "[Epoch 078] loss=0.9420 recon=0.9414 kl=0.0006\n",
      "[Epoch 079] loss=0.9240 recon=0.9234 kl=0.0006\n",
      "[Epoch 080] loss=0.9288 recon=0.9287 kl=0.0001\n",
      "[Epoch 081] loss=0.9242 recon=0.9237 kl=0.0005\n",
      "[Epoch 082] loss=0.9395 recon=0.9387 kl=0.0009\n",
      "[Epoch 083] loss=0.9391 recon=0.9386 kl=0.0005\n",
      "[Epoch 084] loss=0.9391 recon=0.9388 kl=0.0003\n",
      "[Epoch 085] loss=0.9490 recon=0.9484 kl=0.0006\n",
      "[Epoch 086] loss=0.9261 recon=0.9256 kl=0.0006\n",
      "[Epoch 087] loss=0.9240 recon=0.9236 kl=0.0005\n",
      "[Epoch 088] loss=0.9373 recon=0.9370 kl=0.0003\n",
      "[Epoch 089] loss=0.9345 recon=0.9342 kl=0.0002\n",
      "[Epoch 090] loss=0.9432 recon=0.9425 kl=0.0007\n",
      "23\n",
      "[Epoch 001] loss=1.3512 recon=0.9477 kl=0.4035\n",
      "[Epoch 002] loss=0.9546 recon=0.9519 kl=0.0028\n",
      "[Epoch 003] loss=0.9298 recon=0.9296 kl=0.0003\n",
      "[Epoch 004] loss=0.9435 recon=0.9434 kl=0.0001\n",
      "[Epoch 005] loss=0.9532 recon=0.9530 kl=0.0002\n",
      "[Epoch 006] loss=0.9351 recon=0.9349 kl=0.0002\n",
      "[Epoch 007] loss=0.9287 recon=0.9286 kl=0.0001\n",
      "[Epoch 008] loss=0.9498 recon=0.9491 kl=0.0007\n",
      "[Epoch 009] loss=0.9417 recon=0.9416 kl=0.0001\n",
      "[Epoch 010] loss=0.9331 recon=0.9325 kl=0.0006\n",
      "[Epoch 011] loss=0.9366 recon=0.9361 kl=0.0005\n",
      "[Epoch 012] loss=0.9372 recon=0.9371 kl=0.0001\n",
      "[Epoch 013] loss=0.9310 recon=0.9305 kl=0.0004\n",
      "[Epoch 014] loss=0.9331 recon=0.9329 kl=0.0002\n",
      "[Epoch 015] loss=0.9498 recon=0.9494 kl=0.0004\n",
      "[Epoch 016] loss=0.9213 recon=0.9208 kl=0.0005\n",
      "[Epoch 017] loss=0.9284 recon=0.9282 kl=0.0002\n",
      "[Epoch 018] loss=0.9363 recon=0.9358 kl=0.0005\n",
      "[Epoch 019] loss=0.9428 recon=0.9422 kl=0.0005\n",
      "[Epoch 020] loss=0.9328 recon=0.9323 kl=0.0005\n",
      "[Epoch 021] loss=0.9223 recon=0.9219 kl=0.0004\n",
      "[Epoch 022] loss=0.9546 recon=0.9541 kl=0.0006\n",
      "[Epoch 023] loss=0.9415 recon=0.9413 kl=0.0002\n",
      "[Epoch 024] loss=0.9346 recon=0.9339 kl=0.0006\n",
      "[Epoch 025] loss=0.9281 recon=0.9277 kl=0.0004\n",
      "[Epoch 026] loss=0.9368 recon=0.9363 kl=0.0006\n",
      "[Epoch 027] loss=0.9337 recon=0.9331 kl=0.0007\n",
      "[Epoch 028] loss=0.9354 recon=0.9349 kl=0.0005\n",
      "[Epoch 029] loss=0.9384 recon=0.9381 kl=0.0003\n",
      "[Epoch 030] loss=0.9393 recon=0.9384 kl=0.0009\n",
      "[Epoch 031] loss=0.9434 recon=0.9433 kl=0.0002\n",
      "[Epoch 032] loss=0.9370 recon=0.9350 kl=0.0020\n",
      "[Epoch 033] loss=0.9507 recon=0.9467 kl=0.0040\n",
      "[Epoch 034] loss=0.9274 recon=0.9266 kl=0.0008\n",
      "[Epoch 035] loss=0.9331 recon=0.9330 kl=0.0001\n",
      "[Epoch 036] loss=0.9311 recon=0.9311 kl=0.0000\n",
      "[Epoch 037] loss=0.9349 recon=0.9346 kl=0.0003\n",
      "[Epoch 038] loss=0.9386 recon=0.9380 kl=0.0006\n",
      "[Epoch 039] loss=0.9297 recon=0.9274 kl=0.0023\n",
      "[Epoch 040] loss=0.9475 recon=0.9444 kl=0.0031\n",
      "[Epoch 041] loss=0.9629 recon=0.9625 kl=0.0005\n",
      "[Epoch 042] loss=0.9307 recon=0.9307 kl=0.0001\n",
      "[Epoch 043] loss=0.9216 recon=0.9216 kl=0.0000\n",
      "[Epoch 044] loss=0.9625 recon=0.9620 kl=0.0005\n",
      "[Epoch 045] loss=0.9432 recon=0.9407 kl=0.0025\n",
      "[Epoch 046] loss=0.9576 recon=0.9535 kl=0.0041\n",
      "[Epoch 047] loss=0.9494 recon=0.9472 kl=0.0022\n",
      "[Epoch 048] loss=0.9483 recon=0.9480 kl=0.0003\n",
      "[Epoch 049] loss=0.9385 recon=0.9385 kl=0.0000\n",
      "[Epoch 050] loss=0.9390 recon=0.9390 kl=0.0000\n",
      "[Epoch 051] loss=0.9199 recon=0.9199 kl=0.0000\n",
      "[Epoch 052] loss=0.9266 recon=0.9263 kl=0.0003\n",
      "[Epoch 053] loss=0.9542 recon=0.9438 kl=0.0104\n",
      "[Epoch 054] loss=0.9263 recon=0.9234 kl=0.0029\n",
      "[Epoch 055] loss=0.9230 recon=0.9208 kl=0.0021\n",
      "[Epoch 056] loss=0.9437 recon=0.9430 kl=0.0007\n",
      "[Epoch 057] loss=0.9328 recon=0.9328 kl=0.0001\n",
      "[Epoch 058] loss=0.9290 recon=0.9290 kl=0.0000\n",
      "[Epoch 059] loss=0.9268 recon=0.9268 kl=0.0000\n",
      "[Epoch 060] loss=0.9198 recon=0.9198 kl=0.0000\n",
      "[Epoch 061] loss=0.9300 recon=0.9300 kl=0.0000\n",
      "[Epoch 062] loss=0.9354 recon=0.9351 kl=0.0004\n",
      "[Epoch 063] loss=0.9244 recon=0.9242 kl=0.0002\n",
      "[Epoch 064] loss=0.9341 recon=0.9336 kl=0.0005\n",
      "[Epoch 065] loss=0.9267 recon=0.9263 kl=0.0004\n",
      "[Epoch 066] loss=0.9388 recon=0.9379 kl=0.0009\n",
      "[Epoch 067] loss=0.9529 recon=0.9528 kl=0.0001\n",
      "[Epoch 068] loss=0.9362 recon=0.9356 kl=0.0007\n",
      "[Epoch 069] loss=0.9388 recon=0.9384 kl=0.0003\n",
      "[Epoch 070] loss=0.9359 recon=0.9330 kl=0.0029\n",
      "[Epoch 071] loss=0.9340 recon=0.9321 kl=0.0019\n",
      "[Epoch 072] loss=0.9364 recon=0.9362 kl=0.0002\n",
      "[Epoch 073] loss=0.9233 recon=0.9232 kl=0.0000\n",
      "[Epoch 074] loss=0.9356 recon=0.9355 kl=0.0001\n",
      "[Epoch 075] loss=0.9271 recon=0.9265 kl=0.0006\n",
      "[Epoch 076] loss=0.9311 recon=0.9306 kl=0.0005\n",
      "[Epoch 077] loss=0.9292 recon=0.9288 kl=0.0003\n",
      "[Epoch 078] loss=0.9369 recon=0.9365 kl=0.0004\n",
      "[Epoch 079] loss=0.9324 recon=0.9318 kl=0.0006\n",
      "[Epoch 080] loss=0.9489 recon=0.9486 kl=0.0002\n",
      "[Epoch 081] loss=0.9214 recon=0.9196 kl=0.0018\n",
      "[Epoch 082] loss=0.9416 recon=0.9378 kl=0.0039\n",
      "[Epoch 083] loss=0.9369 recon=0.9343 kl=0.0026\n",
      "[Epoch 084] loss=0.9345 recon=0.9333 kl=0.0012\n",
      "[Epoch 085] loss=0.9254 recon=0.9253 kl=0.0001\n",
      "[Epoch 086] loss=0.9399 recon=0.9398 kl=0.0000\n",
      "[Epoch 087] loss=0.9405 recon=0.9405 kl=0.0000\n",
      "[Epoch 088] loss=0.9394 recon=0.9394 kl=0.0000\n",
      "[Epoch 089] loss=0.9266 recon=0.9266 kl=0.0000\n",
      "[Epoch 090] loss=0.9407 recon=0.9399 kl=0.0008\n",
      "24\n",
      "[Epoch 001] loss=1.2077 recon=0.9312 kl=0.2766\n",
      "[Epoch 002] loss=0.9297 recon=0.9279 kl=0.0018\n",
      "[Epoch 003] loss=0.9462 recon=0.9460 kl=0.0002\n",
      "[Epoch 004] loss=0.9347 recon=0.9346 kl=0.0001\n",
      "[Epoch 005] loss=0.9544 recon=0.9542 kl=0.0002\n",
      "[Epoch 006] loss=0.9434 recon=0.9432 kl=0.0002\n",
      "[Epoch 007] loss=0.9394 recon=0.9393 kl=0.0001\n",
      "[Epoch 008] loss=0.9366 recon=0.9362 kl=0.0004\n",
      "[Epoch 009] loss=0.9333 recon=0.9332 kl=0.0001\n",
      "[Epoch 010] loss=0.9227 recon=0.9222 kl=0.0005\n",
      "[Epoch 011] loss=0.9441 recon=0.9439 kl=0.0002\n",
      "[Epoch 012] loss=0.9275 recon=0.9271 kl=0.0004\n",
      "[Epoch 013] loss=0.9358 recon=0.9353 kl=0.0005\n",
      "[Epoch 014] loss=0.9608 recon=0.9606 kl=0.0002\n",
      "[Epoch 015] loss=0.9214 recon=0.9207 kl=0.0007\n",
      "[Epoch 016] loss=0.9259 recon=0.9256 kl=0.0003\n",
      "[Epoch 017] loss=0.9337 recon=0.9333 kl=0.0005\n",
      "[Epoch 018] loss=0.9390 recon=0.9379 kl=0.0011\n",
      "[Epoch 019] loss=0.9292 recon=0.9288 kl=0.0004\n",
      "[Epoch 020] loss=0.9311 recon=0.9309 kl=0.0002\n",
      "[Epoch 021] loss=0.9294 recon=0.9274 kl=0.0021\n",
      "[Epoch 022] loss=0.9327 recon=0.9304 kl=0.0023\n",
      "[Epoch 023] loss=0.9315 recon=0.9313 kl=0.0002\n",
      "[Epoch 024] loss=0.9578 recon=0.9578 kl=0.0000\n",
      "[Epoch 025] loss=0.9619 recon=0.9619 kl=0.0000\n",
      "[Epoch 026] loss=0.9663 recon=0.9654 kl=0.0009\n",
      "[Epoch 027] loss=0.9313 recon=0.9308 kl=0.0005\n",
      "[Epoch 028] loss=0.9214 recon=0.9213 kl=0.0001\n",
      "[Epoch 029] loss=0.9395 recon=0.9385 kl=0.0010\n",
      "[Epoch 030] loss=0.9449 recon=0.9443 kl=0.0006\n",
      "[Epoch 031] loss=0.9384 recon=0.9380 kl=0.0003\n",
      "[Epoch 032] loss=0.9369 recon=0.9360 kl=0.0009\n",
      "[Epoch 033] loss=0.9308 recon=0.9305 kl=0.0003\n",
      "[Epoch 034] loss=0.9267 recon=0.9259 kl=0.0008\n",
      "[Epoch 035] loss=0.9344 recon=0.9342 kl=0.0002\n",
      "[Epoch 036] loss=0.9291 recon=0.9285 kl=0.0005\n",
      "[Epoch 037] loss=0.9396 recon=0.9390 kl=0.0005\n",
      "[Epoch 038] loss=0.9289 recon=0.9284 kl=0.0005\n",
      "[Epoch 039] loss=0.9260 recon=0.9253 kl=0.0006\n",
      "[Epoch 040] loss=0.9246 recon=0.9242 kl=0.0004\n",
      "[Epoch 041] loss=0.9351 recon=0.9346 kl=0.0005\n",
      "[Epoch 042] loss=0.9255 recon=0.9249 kl=0.0006\n",
      "[Epoch 043] loss=0.9371 recon=0.9361 kl=0.0010\n",
      "[Epoch 044] loss=0.9250 recon=0.9248 kl=0.0002\n",
      "[Epoch 045] loss=0.9445 recon=0.9413 kl=0.0031\n",
      "[Epoch 046] loss=0.9355 recon=0.9336 kl=0.0020\n",
      "[Epoch 047] loss=0.9250 recon=0.9248 kl=0.0002\n",
      "[Epoch 048] loss=0.9337 recon=0.9337 kl=0.0000\n",
      "[Epoch 049] loss=0.9307 recon=0.9307 kl=0.0000\n",
      "[Epoch 050] loss=0.9332 recon=0.9309 kl=0.0023\n",
      "[Epoch 051] loss=0.9327 recon=0.9292 kl=0.0036\n",
      "[Epoch 052] loss=0.9262 recon=0.9243 kl=0.0019\n",
      "[Epoch 053] loss=0.9244 recon=0.9241 kl=0.0003\n",
      "[Epoch 054] loss=0.9268 recon=0.9267 kl=0.0000\n",
      "[Epoch 055] loss=0.9264 recon=0.9264 kl=0.0000\n",
      "[Epoch 056] loss=0.9496 recon=0.9496 kl=0.0000\n",
      "[Epoch 057] loss=0.9368 recon=0.9360 kl=0.0007\n",
      "[Epoch 058] loss=0.9294 recon=0.9293 kl=0.0001\n",
      "[Epoch 059] loss=0.9292 recon=0.9285 kl=0.0007\n",
      "[Epoch 060] loss=0.9225 recon=0.9218 kl=0.0007\n",
      "[Epoch 061] loss=0.9280 recon=0.9277 kl=0.0003\n",
      "[Epoch 062] loss=0.9370 recon=0.9364 kl=0.0006\n",
      "[Epoch 063] loss=0.9324 recon=0.9315 kl=0.0009\n",
      "[Epoch 064] loss=0.9327 recon=0.9324 kl=0.0003\n",
      "[Epoch 065] loss=0.9250 recon=0.9245 kl=0.0004\n",
      "[Epoch 066] loss=0.9429 recon=0.9424 kl=0.0005\n",
      "[Epoch 067] loss=0.9307 recon=0.9302 kl=0.0004\n",
      "[Epoch 068] loss=0.9261 recon=0.9254 kl=0.0007\n",
      "[Epoch 069] loss=0.9210 recon=0.9208 kl=0.0002\n",
      "[Epoch 070] loss=0.9308 recon=0.9304 kl=0.0004\n",
      "[Epoch 071] loss=0.9323 recon=0.9316 kl=0.0006\n",
      "[Epoch 072] loss=0.9328 recon=0.9323 kl=0.0005\n",
      "[Epoch 073] loss=0.9239 recon=0.9237 kl=0.0002\n",
      "[Epoch 074] loss=0.9385 recon=0.9376 kl=0.0009\n",
      "[Epoch 075] loss=0.9797 recon=0.9786 kl=0.0011\n",
      "[Epoch 076] loss=0.9406 recon=0.9384 kl=0.0022\n",
      "[Epoch 077] loss=0.9316 recon=0.9284 kl=0.0031\n",
      "[Epoch 078] loss=0.9474 recon=0.9448 kl=0.0026\n",
      "[Epoch 079] loss=0.9327 recon=0.9310 kl=0.0017\n",
      "[Epoch 080] loss=0.9319 recon=0.9316 kl=0.0004\n",
      "[Epoch 081] loss=0.9456 recon=0.9456 kl=0.0000\n",
      "[Epoch 082] loss=0.9332 recon=0.9331 kl=0.0000\n",
      "[Epoch 083] loss=0.9280 recon=0.9278 kl=0.0002\n",
      "[Epoch 084] loss=0.9279 recon=0.9275 kl=0.0004\n",
      "[Epoch 085] loss=0.9192 recon=0.9190 kl=0.0002\n",
      "[Epoch 086] loss=0.9421 recon=0.9419 kl=0.0002\n",
      "[Epoch 087] loss=0.9159 recon=0.9157 kl=0.0002\n",
      "[Epoch 088] loss=0.9316 recon=0.9308 kl=0.0007\n",
      "[Epoch 089] loss=0.9385 recon=0.9378 kl=0.0007\n",
      "[Epoch 090] loss=0.9357 recon=0.9355 kl=0.0002\n",
      "25\n",
      "[Epoch 001] loss=1.7566 recon=0.9362 kl=0.8204\n",
      "[Epoch 002] loss=0.9456 recon=0.9399 kl=0.0057\n",
      "[Epoch 003] loss=0.9451 recon=0.9445 kl=0.0005\n",
      "[Epoch 004] loss=0.9323 recon=0.9322 kl=0.0001\n",
      "[Epoch 005] loss=0.9660 recon=0.9656 kl=0.0004\n",
      "[Epoch 006] loss=0.9442 recon=0.9441 kl=0.0001\n",
      "[Epoch 007] loss=0.9329 recon=0.9325 kl=0.0003\n",
      "[Epoch 008] loss=0.9230 recon=0.9227 kl=0.0003\n",
      "[Epoch 009] loss=0.9327 recon=0.9325 kl=0.0001\n",
      "[Epoch 010] loss=0.9383 recon=0.9378 kl=0.0005\n",
      "[Epoch 011] loss=0.9342 recon=0.9340 kl=0.0002\n",
      "[Epoch 012] loss=0.9187 recon=0.9182 kl=0.0004\n",
      "[Epoch 013] loss=0.9379 recon=0.9374 kl=0.0005\n",
      "[Epoch 014] loss=0.9200 recon=0.9199 kl=0.0001\n",
      "[Epoch 015] loss=0.9285 recon=0.9280 kl=0.0005\n",
      "[Epoch 016] loss=0.9515 recon=0.9509 kl=0.0006\n",
      "[Epoch 017] loss=0.9284 recon=0.9279 kl=0.0004\n",
      "[Epoch 018] loss=0.9207 recon=0.9203 kl=0.0004\n",
      "[Epoch 019] loss=0.9310 recon=0.9300 kl=0.0010\n",
      "[Epoch 020] loss=0.9322 recon=0.9320 kl=0.0002\n",
      "[Epoch 021] loss=0.9260 recon=0.9254 kl=0.0005\n",
      "[Epoch 022] loss=0.9218 recon=0.9214 kl=0.0004\n",
      "[Epoch 023] loss=0.9244 recon=0.9238 kl=0.0007\n",
      "[Epoch 024] loss=0.9488 recon=0.9485 kl=0.0002\n",
      "[Epoch 025] loss=0.9318 recon=0.9311 kl=0.0007\n",
      "[Epoch 026] loss=0.9267 recon=0.9261 kl=0.0006\n",
      "[Epoch 027] loss=0.9276 recon=0.9274 kl=0.0002\n",
      "[Epoch 028] loss=0.9292 recon=0.9284 kl=0.0007\n",
      "[Epoch 029] loss=0.9293 recon=0.9261 kl=0.0032\n",
      "[Epoch 030] loss=0.9555 recon=0.9494 kl=0.0061\n",
      "[Epoch 031] loss=0.9217 recon=0.9210 kl=0.0007\n",
      "[Epoch 032] loss=0.9175 recon=0.9174 kl=0.0001\n",
      "[Epoch 033] loss=0.9320 recon=0.9320 kl=0.0000\n",
      "[Epoch 034] loss=0.9466 recon=0.9462 kl=0.0004\n",
      "[Epoch 035] loss=0.9306 recon=0.9301 kl=0.0005\n",
      "[Epoch 036] loss=0.9290 recon=0.9284 kl=0.0007\n",
      "[Epoch 037] loss=0.9347 recon=0.9341 kl=0.0005\n",
      "[Epoch 038] loss=0.9321 recon=0.9314 kl=0.0007\n",
      "[Epoch 039] loss=0.9263 recon=0.9259 kl=0.0004\n",
      "[Epoch 040] loss=0.9451 recon=0.9413 kl=0.0039\n",
      "[Epoch 041] loss=0.9295 recon=0.9271 kl=0.0025\n",
      "[Epoch 042] loss=0.9333 recon=0.9320 kl=0.0013\n",
      "[Epoch 043] loss=0.9239 recon=0.9237 kl=0.0002\n",
      "[Epoch 044] loss=0.9328 recon=0.9328 kl=0.0000\n",
      "[Epoch 045] loss=0.9341 recon=0.9341 kl=0.0000\n",
      "[Epoch 046] loss=0.9225 recon=0.9218 kl=0.0007\n",
      "[Epoch 047] loss=0.9245 recon=0.9242 kl=0.0003\n",
      "[Epoch 048] loss=0.9605 recon=0.9595 kl=0.0010\n",
      "[Epoch 049] loss=0.9382 recon=0.9379 kl=0.0003\n",
      "[Epoch 050] loss=0.9406 recon=0.9399 kl=0.0008\n",
      "[Epoch 051] loss=0.9269 recon=0.9266 kl=0.0003\n",
      "[Epoch 052] loss=0.9263 recon=0.9256 kl=0.0007\n",
      "[Epoch 053] loss=0.9223 recon=0.9215 kl=0.0008\n",
      "[Epoch 054] loss=0.9233 recon=0.9229 kl=0.0004\n",
      "[Epoch 055] loss=0.9241 recon=0.9236 kl=0.0005\n",
      "[Epoch 056] loss=0.9374 recon=0.9365 kl=0.0009\n",
      "[Epoch 057] loss=0.9267 recon=0.9264 kl=0.0003\n",
      "[Epoch 058] loss=0.9345 recon=0.9290 kl=0.0055\n",
      "[Epoch 059] loss=0.9456 recon=0.9391 kl=0.0065\n",
      "[Epoch 060] loss=0.9383 recon=0.9364 kl=0.0019\n",
      "[Epoch 061] loss=0.9249 recon=0.9247 kl=0.0002\n",
      "[Epoch 062] loss=0.9290 recon=0.9290 kl=0.0000\n",
      "[Epoch 063] loss=0.9744 recon=0.9744 kl=0.0000\n",
      "[Epoch 064] loss=0.9264 recon=0.9263 kl=0.0000\n",
      "[Epoch 065] loss=0.9371 recon=0.9368 kl=0.0004\n",
      "[Epoch 066] loss=0.9329 recon=0.9323 kl=0.0006\n",
      "[Epoch 067] loss=0.9302 recon=0.9297 kl=0.0005\n",
      "[Epoch 068] loss=0.9277 recon=0.9268 kl=0.0008\n",
      "[Epoch 069] loss=0.9609 recon=0.9606 kl=0.0003\n",
      "[Epoch 070] loss=0.9510 recon=0.9506 kl=0.0004\n",
      "[Epoch 071] loss=0.9256 recon=0.9249 kl=0.0007\n",
      "[Epoch 072] loss=0.9347 recon=0.9344 kl=0.0003\n",
      "[Epoch 073] loss=0.9176 recon=0.9169 kl=0.0007\n",
      "[Epoch 074] loss=0.9254 recon=0.9246 kl=0.0009\n",
      "[Epoch 075] loss=0.9321 recon=0.9318 kl=0.0003\n",
      "[Epoch 076] loss=0.9349 recon=0.9348 kl=0.0000\n",
      "[Epoch 077] loss=0.9392 recon=0.9386 kl=0.0007\n",
      "[Epoch 078] loss=0.9353 recon=0.9346 kl=0.0007\n",
      "[Epoch 079] loss=0.9270 recon=0.9264 kl=0.0006\n",
      "[Epoch 080] loss=0.9244 recon=0.9237 kl=0.0007\n",
      "[Epoch 081] loss=0.9374 recon=0.9369 kl=0.0004\n",
      "[Epoch 082] loss=0.9331 recon=0.9324 kl=0.0007\n",
      "[Epoch 083] loss=0.9231 recon=0.9230 kl=0.0002\n",
      "[Epoch 084] loss=0.9230 recon=0.9224 kl=0.0007\n",
      "[Epoch 085] loss=0.9343 recon=0.9336 kl=0.0007\n",
      "[Epoch 086] loss=0.9274 recon=0.9272 kl=0.0002\n",
      "[Epoch 087] loss=0.9191 recon=0.9185 kl=0.0006\n",
      "[Epoch 088] loss=0.9226 recon=0.9218 kl=0.0007\n",
      "[Epoch 089] loss=0.9318 recon=0.9280 kl=0.0038\n",
      "[Epoch 090] loss=0.9351 recon=0.9328 kl=0.0024\n",
      "26\n",
      "[Epoch 001] loss=1.4061 recon=0.9347 kl=0.4714\n",
      "[Epoch 002] loss=0.9400 recon=0.9370 kl=0.0031\n",
      "[Epoch 003] loss=0.9304 recon=0.9301 kl=0.0003\n",
      "[Epoch 004] loss=0.9320 recon=0.9320 kl=0.0001\n",
      "[Epoch 005] loss=0.9334 recon=0.9331 kl=0.0002\n",
      "[Epoch 006] loss=0.9357 recon=0.9356 kl=0.0001\n",
      "[Epoch 007] loss=0.9414 recon=0.9410 kl=0.0004\n",
      "[Epoch 008] loss=0.9646 recon=0.9642 kl=0.0004\n",
      "[Epoch 009] loss=0.9248 recon=0.9246 kl=0.0002\n",
      "[Epoch 010] loss=0.9248 recon=0.9246 kl=0.0002\n",
      "[Epoch 011] loss=0.9219 recon=0.9215 kl=0.0004\n",
      "[Epoch 012] loss=0.9228 recon=0.9225 kl=0.0003\n",
      "[Epoch 013] loss=0.9234 recon=0.9231 kl=0.0003\n",
      "[Epoch 014] loss=0.9387 recon=0.9382 kl=0.0005\n",
      "[Epoch 015] loss=0.9321 recon=0.9319 kl=0.0003\n",
      "[Epoch 016] loss=0.9293 recon=0.9283 kl=0.0010\n",
      "[Epoch 017] loss=0.9334 recon=0.9328 kl=0.0006\n",
      "[Epoch 018] loss=0.9319 recon=0.9317 kl=0.0001\n",
      "[Epoch 019] loss=0.9397 recon=0.9391 kl=0.0006\n",
      "[Epoch 020] loss=0.9292 recon=0.9289 kl=0.0003\n",
      "[Epoch 021] loss=0.9263 recon=0.9256 kl=0.0007\n",
      "[Epoch 022] loss=0.9242 recon=0.9240 kl=0.0002\n",
      "[Epoch 023] loss=0.9248 recon=0.9244 kl=0.0005\n",
      "[Epoch 024] loss=0.9279 recon=0.9277 kl=0.0002\n",
      "[Epoch 025] loss=0.9244 recon=0.9230 kl=0.0014\n",
      "[Epoch 026] loss=0.9349 recon=0.9314 kl=0.0036\n",
      "[Epoch 027] loss=0.9260 recon=0.9239 kl=0.0021\n",
      "[Epoch 028] loss=0.9326 recon=0.9320 kl=0.0006\n",
      "[Epoch 029] loss=0.9385 recon=0.9385 kl=0.0001\n",
      "[Epoch 030] loss=0.9444 recon=0.9444 kl=0.0000\n",
      "[Epoch 031] loss=0.9180 recon=0.9175 kl=0.0005\n",
      "[Epoch 032] loss=0.9249 recon=0.9247 kl=0.0002\n",
      "[Epoch 033] loss=0.9485 recon=0.9482 kl=0.0004\n",
      "[Epoch 034] loss=0.9337 recon=0.9335 kl=0.0002\n",
      "[Epoch 035] loss=0.9413 recon=0.9406 kl=0.0007\n",
      "[Epoch 036] loss=0.9341 recon=0.9339 kl=0.0003\n",
      "[Epoch 037] loss=0.9332 recon=0.9326 kl=0.0006\n",
      "[Epoch 038] loss=0.9318 recon=0.9314 kl=0.0004\n",
      "[Epoch 039] loss=0.9246 recon=0.9242 kl=0.0004\n",
      "[Epoch 040] loss=0.9286 recon=0.9281 kl=0.0006\n",
      "[Epoch 041] loss=0.9328 recon=0.9327 kl=0.0001\n",
      "[Epoch 042] loss=0.9392 recon=0.9383 kl=0.0009\n",
      "[Epoch 043] loss=0.9186 recon=0.9179 kl=0.0007\n",
      "[Epoch 044] loss=0.9296 recon=0.9295 kl=0.0002\n",
      "[Epoch 045] loss=0.9309 recon=0.9304 kl=0.0005\n",
      "[Epoch 046] loss=0.9236 recon=0.9225 kl=0.0011\n",
      "[Epoch 047] loss=0.9315 recon=0.9277 kl=0.0038\n",
      "[Epoch 048] loss=0.9237 recon=0.9213 kl=0.0024\n",
      "[Epoch 049] loss=0.9272 recon=0.9266 kl=0.0006\n",
      "[Epoch 050] loss=0.9347 recon=0.9346 kl=0.0001\n",
      "[Epoch 051] loss=0.9283 recon=0.9283 kl=0.0000\n",
      "[Epoch 052] loss=0.9416 recon=0.9415 kl=0.0001\n",
      "[Epoch 053] loss=0.9205 recon=0.9200 kl=0.0006\n",
      "[Epoch 054] loss=0.9383 recon=0.9382 kl=0.0001\n",
      "[Epoch 055] loss=0.9296 recon=0.9290 kl=0.0006\n",
      "[Epoch 056] loss=0.9281 recon=0.9273 kl=0.0008\n",
      "[Epoch 057] loss=0.9357 recon=0.9353 kl=0.0003\n",
      "[Epoch 058] loss=0.9249 recon=0.9244 kl=0.0005\n",
      "[Epoch 059] loss=0.9457 recon=0.9449 kl=0.0008\n",
      "[Epoch 060] loss=0.9492 recon=0.9490 kl=0.0002\n",
      "[Epoch 061] loss=0.9213 recon=0.9206 kl=0.0007\n",
      "[Epoch 062] loss=0.9252 recon=0.9247 kl=0.0006\n",
      "[Epoch 063] loss=0.9579 recon=0.9577 kl=0.0002\n",
      "[Epoch 064] loss=0.9180 recon=0.9176 kl=0.0004\n",
      "[Epoch 065] loss=0.9222 recon=0.9216 kl=0.0007\n",
      "[Epoch 066] loss=0.9271 recon=0.9269 kl=0.0001\n",
      "[Epoch 067] loss=0.9391 recon=0.9387 kl=0.0004\n",
      "[Epoch 068] loss=0.9327 recon=0.9321 kl=0.0006\n",
      "[Epoch 069] loss=0.9250 recon=0.9242 kl=0.0007\n",
      "[Epoch 070] loss=0.9176 recon=0.9172 kl=0.0004\n",
      "[Epoch 071] loss=0.9458 recon=0.9455 kl=0.0003\n",
      "[Epoch 072] loss=0.9453 recon=0.9442 kl=0.0011\n",
      "[Epoch 073] loss=0.9216 recon=0.9214 kl=0.0002\n",
      "[Epoch 074] loss=0.9302 recon=0.9296 kl=0.0006\n",
      "[Epoch 075] loss=0.9197 recon=0.9196 kl=0.0001\n",
      "[Epoch 076] loss=0.9208 recon=0.9206 kl=0.0002\n",
      "[Epoch 077] loss=0.9351 recon=0.9338 kl=0.0013\n",
      "[Epoch 078] loss=0.9258 recon=0.9252 kl=0.0006\n",
      "[Epoch 079] loss=0.9239 recon=0.9238 kl=0.0001\n",
      "[Epoch 080] loss=0.9376 recon=0.9371 kl=0.0004\n",
      "[Epoch 081] loss=0.9396 recon=0.9389 kl=0.0007\n",
      "[Epoch 082] loss=0.9202 recon=0.9195 kl=0.0006\n",
      "[Epoch 083] loss=0.9203 recon=0.9201 kl=0.0002\n",
      "[Epoch 084] loss=0.9399 recon=0.9393 kl=0.0006\n",
      "[Epoch 085] loss=0.9310 recon=0.9302 kl=0.0008\n",
      "[Epoch 086] loss=0.9383 recon=0.9379 kl=0.0004\n",
      "[Epoch 087] loss=0.9336 recon=0.9336 kl=0.0001\n",
      "[Epoch 088] loss=0.9236 recon=0.9218 kl=0.0018\n",
      "[Epoch 089] loss=0.9383 recon=0.9347 kl=0.0036\n",
      "[Epoch 090] loss=0.9301 recon=0.9276 kl=0.0026\n",
      "27\n",
      "[Epoch 001] loss=1.2161 recon=0.9283 kl=0.2878\n",
      "[Epoch 002] loss=0.9339 recon=0.9310 kl=0.0029\n",
      "[Epoch 003] loss=0.9329 recon=0.9327 kl=0.0002\n",
      "[Epoch 004] loss=0.9297 recon=0.9296 kl=0.0002\n",
      "[Epoch 005] loss=0.9355 recon=0.9355 kl=0.0001\n",
      "[Epoch 006] loss=0.9280 recon=0.9276 kl=0.0004\n",
      "[Epoch 007] loss=0.9305 recon=0.9301 kl=0.0004\n",
      "[Epoch 008] loss=0.9240 recon=0.9238 kl=0.0002\n",
      "[Epoch 009] loss=0.9354 recon=0.9352 kl=0.0003\n",
      "[Epoch 010] loss=0.9346 recon=0.9341 kl=0.0004\n",
      "[Epoch 011] loss=0.9315 recon=0.9313 kl=0.0002\n",
      "[Epoch 012] loss=0.9282 recon=0.9279 kl=0.0004\n",
      "[Epoch 013] loss=0.9296 recon=0.9288 kl=0.0008\n",
      "[Epoch 014] loss=0.9306 recon=0.9305 kl=0.0001\n",
      "[Epoch 015] loss=0.9356 recon=0.9351 kl=0.0005\n",
      "[Epoch 016] loss=0.9380 recon=0.9375 kl=0.0006\n",
      "[Epoch 017] loss=0.9345 recon=0.9343 kl=0.0002\n",
      "[Epoch 018] loss=0.9302 recon=0.9296 kl=0.0006\n",
      "[Epoch 019] loss=0.9475 recon=0.9469 kl=0.0006\n",
      "[Epoch 020] loss=0.9525 recon=0.9522 kl=0.0003\n",
      "[Epoch 021] loss=0.9420 recon=0.9415 kl=0.0005\n",
      "[Epoch 022] loss=0.9306 recon=0.9302 kl=0.0004\n",
      "[Epoch 023] loss=0.9360 recon=0.9354 kl=0.0007\n",
      "[Epoch 024] loss=0.9250 recon=0.9246 kl=0.0004\n",
      "[Epoch 025] loss=0.9325 recon=0.9319 kl=0.0006\n",
      "[Epoch 026] loss=0.9323 recon=0.9315 kl=0.0009\n",
      "[Epoch 027] loss=0.9200 recon=0.9199 kl=0.0002\n",
      "[Epoch 028] loss=0.9318 recon=0.9314 kl=0.0004\n",
      "[Epoch 029] loss=0.9285 recon=0.9276 kl=0.0009\n",
      "[Epoch 030] loss=0.9226 recon=0.9222 kl=0.0003\n",
      "[Epoch 031] loss=0.9226 recon=0.9221 kl=0.0006\n",
      "[Epoch 032] loss=0.9214 recon=0.9209 kl=0.0005\n",
      "[Epoch 033] loss=0.9247 recon=0.9243 kl=0.0005\n",
      "[Epoch 034] loss=0.9376 recon=0.9371 kl=0.0005\n",
      "[Epoch 035] loss=0.9355 recon=0.9348 kl=0.0007\n",
      "[Epoch 036] loss=0.9307 recon=0.9300 kl=0.0007\n",
      "[Epoch 037] loss=0.9439 recon=0.9434 kl=0.0005\n",
      "[Epoch 038] loss=0.9282 recon=0.9275 kl=0.0007\n",
      "[Epoch 039] loss=0.9286 recon=0.9280 kl=0.0006\n",
      "[Epoch 040] loss=0.9305 recon=0.9299 kl=0.0006\n",
      "[Epoch 041] loss=0.9440 recon=0.9434 kl=0.0006\n",
      "[Epoch 042] loss=0.9313 recon=0.9309 kl=0.0003\n",
      "[Epoch 043] loss=0.9295 recon=0.9286 kl=0.0009\n",
      "[Epoch 044] loss=0.9485 recon=0.9446 kl=0.0039\n",
      "[Epoch 045] loss=0.9296 recon=0.9270 kl=0.0025\n",
      "[Epoch 046] loss=0.9229 recon=0.9219 kl=0.0010\n",
      "[Epoch 047] loss=0.9246 recon=0.9245 kl=0.0001\n",
      "[Epoch 048] loss=0.9284 recon=0.9284 kl=0.0000\n",
      "[Epoch 049] loss=0.9266 recon=0.9266 kl=0.0000\n",
      "[Epoch 050] loss=0.9235 recon=0.9229 kl=0.0006\n",
      "[Epoch 051] loss=0.9323 recon=0.9314 kl=0.0009\n",
      "[Epoch 052] loss=0.9266 recon=0.9265 kl=0.0001\n",
      "[Epoch 053] loss=0.9408 recon=0.9403 kl=0.0005\n",
      "[Epoch 054] loss=0.9324 recon=0.9315 kl=0.0009\n",
      "[Epoch 055] loss=0.9270 recon=0.9264 kl=0.0006\n",
      "[Epoch 056] loss=0.9333 recon=0.9330 kl=0.0004\n",
      "[Epoch 057] loss=0.9584 recon=0.9577 kl=0.0007\n",
      "[Epoch 058] loss=0.9273 recon=0.9270 kl=0.0003\n",
      "[Epoch 059] loss=0.9396 recon=0.9313 kl=0.0083\n",
      "[Epoch 060] loss=0.9270 recon=0.9257 kl=0.0013\n",
      "[Epoch 061] loss=0.9432 recon=0.9431 kl=0.0001\n",
      "[Epoch 062] loss=0.9149 recon=0.9148 kl=0.0000\n",
      "[Epoch 063] loss=0.9262 recon=0.9262 kl=0.0000\n",
      "[Epoch 064] loss=0.9288 recon=0.9283 kl=0.0005\n",
      "[Epoch 065] loss=0.9250 recon=0.9244 kl=0.0006\n",
      "[Epoch 066] loss=0.9304 recon=0.9298 kl=0.0005\n",
      "[Epoch 067] loss=0.9302 recon=0.9297 kl=0.0005\n",
      "[Epoch 068] loss=0.9175 recon=0.9171 kl=0.0003\n",
      "[Epoch 069] loss=0.9314 recon=0.9306 kl=0.0008\n",
      "[Epoch 070] loss=0.9242 recon=0.9241 kl=0.0001\n",
      "[Epoch 071] loss=0.9252 recon=0.9247 kl=0.0004\n",
      "[Epoch 072] loss=0.9391 recon=0.9385 kl=0.0006\n",
      "[Epoch 073] loss=0.9245 recon=0.9237 kl=0.0008\n",
      "[Epoch 074] loss=0.9429 recon=0.9421 kl=0.0008\n",
      "[Epoch 075] loss=0.9336 recon=0.9334 kl=0.0002\n",
      "[Epoch 076] loss=0.9332 recon=0.9327 kl=0.0005\n",
      "[Epoch 077] loss=0.9232 recon=0.9226 kl=0.0005\n",
      "[Epoch 078] loss=0.9362 recon=0.9357 kl=0.0005\n",
      "[Epoch 079] loss=0.9372 recon=0.9367 kl=0.0006\n",
      "[Epoch 080] loss=0.9267 recon=0.9262 kl=0.0005\n",
      "[Epoch 081] loss=0.9484 recon=0.9479 kl=0.0006\n",
      "[Epoch 082] loss=0.9235 recon=0.9229 kl=0.0006\n",
      "[Epoch 083] loss=0.9308 recon=0.9289 kl=0.0019\n",
      "[Epoch 084] loss=0.9270 recon=0.9209 kl=0.0061\n",
      "[Epoch 085] loss=0.9256 recon=0.9213 kl=0.0043\n",
      "[Epoch 086] loss=0.9351 recon=0.9330 kl=0.0021\n",
      "[Epoch 087] loss=0.9277 recon=0.9273 kl=0.0004\n",
      "[Epoch 088] loss=0.9221 recon=0.9220 kl=0.0000\n",
      "[Epoch 089] loss=0.9239 recon=0.9239 kl=0.0000\n",
      "[Epoch 090] loss=0.9447 recon=0.9447 kl=0.0000\n",
      "28\n",
      "[Epoch 001] loss=1.5677 recon=0.9331 kl=0.6346\n",
      "[Epoch 002] loss=0.9417 recon=0.9382 kl=0.0035\n",
      "[Epoch 003] loss=0.9229 recon=0.9226 kl=0.0003\n",
      "[Epoch 004] loss=0.9687 recon=0.9686 kl=0.0001\n",
      "[Epoch 005] loss=0.9511 recon=0.9509 kl=0.0003\n",
      "[Epoch 006] loss=0.9445 recon=0.9444 kl=0.0001\n",
      "[Epoch 007] loss=0.9286 recon=0.9283 kl=0.0003\n",
      "[Epoch 008] loss=0.9357 recon=0.9356 kl=0.0001\n",
      "[Epoch 009] loss=0.9308 recon=0.9304 kl=0.0004\n",
      "[Epoch 010] loss=0.9306 recon=0.9302 kl=0.0004\n",
      "[Epoch 011] loss=0.9512 recon=0.9511 kl=0.0002\n",
      "[Epoch 012] loss=0.9213 recon=0.9207 kl=0.0006\n",
      "[Epoch 013] loss=0.9295 recon=0.9293 kl=0.0002\n",
      "[Epoch 014] loss=0.9309 recon=0.9303 kl=0.0006\n",
      "[Epoch 015] loss=0.9311 recon=0.9297 kl=0.0014\n",
      "[Epoch 016] loss=0.9341 recon=0.9310 kl=0.0031\n",
      "[Epoch 017] loss=0.9342 recon=0.9332 kl=0.0010\n",
      "[Epoch 018] loss=0.9262 recon=0.9261 kl=0.0001\n",
      "[Epoch 019] loss=0.9268 recon=0.9267 kl=0.0000\n",
      "[Epoch 020] loss=0.9318 recon=0.9317 kl=0.0001\n",
      "[Epoch 021] loss=0.9398 recon=0.9390 kl=0.0008\n",
      "[Epoch 022] loss=0.9337 recon=0.9334 kl=0.0002\n",
      "[Epoch 023] loss=0.9226 recon=0.9223 kl=0.0004\n",
      "[Epoch 024] loss=0.9588 recon=0.9582 kl=0.0006\n",
      "[Epoch 025] loss=0.9254 recon=0.9251 kl=0.0002\n",
      "[Epoch 026] loss=0.9227 recon=0.9221 kl=0.0006\n",
      "[Epoch 027] loss=0.9405 recon=0.9401 kl=0.0005\n",
      "[Epoch 028] loss=0.9268 recon=0.9262 kl=0.0005\n",
      "[Epoch 029] loss=0.9299 recon=0.9296 kl=0.0003\n",
      "[Epoch 030] loss=0.9267 recon=0.9259 kl=0.0007\n",
      "[Epoch 031] loss=0.9208 recon=0.9205 kl=0.0003\n",
      "[Epoch 032] loss=0.9461 recon=0.9455 kl=0.0007\n",
      "[Epoch 033] loss=0.9290 recon=0.9283 kl=0.0007\n",
      "[Epoch 034] loss=0.9288 recon=0.9286 kl=0.0003\n",
      "[Epoch 035] loss=0.9255 recon=0.9228 kl=0.0027\n",
      "[Epoch 036] loss=0.9653 recon=0.9625 kl=0.0028\n",
      "[Epoch 037] loss=0.9300 recon=0.9293 kl=0.0007\n",
      "[Epoch 038] loss=0.9489 recon=0.9489 kl=0.0001\n",
      "[Epoch 039] loss=0.9254 recon=0.9254 kl=0.0000\n",
      "[Epoch 040] loss=0.9428 recon=0.9422 kl=0.0006\n",
      "[Epoch 041] loss=0.9427 recon=0.9422 kl=0.0005\n",
      "[Epoch 042] loss=0.9375 recon=0.9359 kl=0.0016\n",
      "[Epoch 043] loss=0.9280 recon=0.9275 kl=0.0005\n",
      "[Epoch 044] loss=0.9311 recon=0.9310 kl=0.0001\n",
      "[Epoch 045] loss=0.9392 recon=0.9385 kl=0.0007\n",
      "[Epoch 046] loss=0.9242 recon=0.9237 kl=0.0005\n",
      "[Epoch 047] loss=0.9297 recon=0.9296 kl=0.0001\n",
      "[Epoch 048] loss=0.9315 recon=0.9306 kl=0.0009\n",
      "[Epoch 049] loss=0.9295 recon=0.9290 kl=0.0005\n",
      "[Epoch 050] loss=0.9324 recon=0.9317 kl=0.0007\n",
      "[Epoch 051] loss=0.9305 recon=0.9301 kl=0.0004\n",
      "[Epoch 052] loss=0.9221 recon=0.9216 kl=0.0005\n",
      "[Epoch 053] loss=0.9273 recon=0.9269 kl=0.0004\n",
      "[Epoch 054] loss=0.9283 recon=0.9270 kl=0.0013\n",
      "[Epoch 055] loss=0.9556 recon=0.9525 kl=0.0031\n",
      "[Epoch 056] loss=0.9204 recon=0.9192 kl=0.0012\n",
      "[Epoch 057] loss=0.9471 recon=0.9470 kl=0.0001\n",
      "[Epoch 058] loss=0.9229 recon=0.9229 kl=0.0000\n",
      "[Epoch 059] loss=0.9439 recon=0.9435 kl=0.0004\n",
      "[Epoch 060] loss=0.9348 recon=0.9312 kl=0.0035\n",
      "[Epoch 061] loss=0.9315 recon=0.9283 kl=0.0032\n",
      "[Epoch 062] loss=0.9363 recon=0.9338 kl=0.0024\n",
      "[Epoch 063] loss=0.9286 recon=0.9268 kl=0.0018\n",
      "[Epoch 064] loss=0.9301 recon=0.9290 kl=0.0011\n",
      "[Epoch 065] loss=0.9271 recon=0.9270 kl=0.0001\n",
      "[Epoch 066] loss=0.9389 recon=0.9389 kl=0.0000\n",
      "[Epoch 067] loss=0.9210 recon=0.9210 kl=0.0000\n",
      "[Epoch 068] loss=0.9308 recon=0.9308 kl=0.0000\n",
      "[Epoch 069] loss=0.9393 recon=0.9393 kl=0.0000\n",
      "[Epoch 070] loss=0.9375 recon=0.9372 kl=0.0002\n",
      "[Epoch 071] loss=0.9289 recon=0.9282 kl=0.0007\n",
      "[Epoch 072] loss=0.9246 recon=0.9244 kl=0.0002\n",
      "[Epoch 073] loss=0.9191 recon=0.9190 kl=0.0001\n",
      "[Epoch 074] loss=0.9292 recon=0.9286 kl=0.0007\n",
      "[Epoch 075] loss=0.9340 recon=0.9334 kl=0.0006\n",
      "[Epoch 076] loss=0.9337 recon=0.9336 kl=0.0001\n",
      "[Epoch 077] loss=0.9237 recon=0.9232 kl=0.0006\n",
      "[Epoch 078] loss=0.9266 recon=0.9261 kl=0.0005\n",
      "[Epoch 079] loss=0.9287 recon=0.9286 kl=0.0001\n",
      "[Epoch 080] loss=0.9323 recon=0.9317 kl=0.0006\n",
      "[Epoch 081] loss=0.9498 recon=0.9490 kl=0.0009\n",
      "[Epoch 082] loss=0.9195 recon=0.9190 kl=0.0005\n",
      "[Epoch 083] loss=0.9217 recon=0.9215 kl=0.0002\n",
      "[Epoch 084] loss=0.9280 recon=0.9265 kl=0.0015\n",
      "[Epoch 085] loss=0.9375 recon=0.9335 kl=0.0040\n",
      "[Epoch 086] loss=0.9211 recon=0.9185 kl=0.0026\n",
      "[Epoch 087] loss=0.9597 recon=0.9577 kl=0.0020\n",
      "[Epoch 088] loss=0.9452 recon=0.9446 kl=0.0006\n",
      "[Epoch 089] loss=0.9287 recon=0.9287 kl=0.0001\n",
      "[Epoch 090] loss=0.9256 recon=0.9256 kl=0.0000\n",
      "29\n",
      "[Epoch 001] loss=1.5650 recon=0.9286 kl=0.6364\n",
      "[Epoch 002] loss=0.9364 recon=0.9320 kl=0.0044\n",
      "[Epoch 003] loss=0.9311 recon=0.9307 kl=0.0004\n",
      "[Epoch 004] loss=0.9301 recon=0.9300 kl=0.0001\n",
      "[Epoch 005] loss=0.9334 recon=0.9332 kl=0.0002\n",
      "[Epoch 006] loss=0.9381 recon=0.9378 kl=0.0003\n",
      "[Epoch 007] loss=0.9531 recon=0.9529 kl=0.0002\n",
      "[Epoch 008] loss=0.9470 recon=0.9467 kl=0.0003\n",
      "[Epoch 009] loss=0.9426 recon=0.9425 kl=0.0001\n",
      "[Epoch 010] loss=0.9252 recon=0.9247 kl=0.0005\n",
      "[Epoch 011] loss=0.9333 recon=0.9329 kl=0.0003\n",
      "[Epoch 012] loss=0.9311 recon=0.9308 kl=0.0003\n",
      "[Epoch 013] loss=0.9302 recon=0.9298 kl=0.0004\n",
      "[Epoch 014] loss=0.9326 recon=0.9325 kl=0.0002\n",
      "[Epoch 015] loss=0.9532 recon=0.9527 kl=0.0004\n",
      "[Epoch 016] loss=0.9380 recon=0.9375 kl=0.0004\n",
      "[Epoch 017] loss=0.9262 recon=0.9258 kl=0.0005\n",
      "[Epoch 018] loss=0.9297 recon=0.9293 kl=0.0004\n",
      "[Epoch 019] loss=0.9377 recon=0.9371 kl=0.0005\n",
      "[Epoch 020] loss=0.9330 recon=0.9325 kl=0.0005\n",
      "[Epoch 021] loss=0.9317 recon=0.9312 kl=0.0005\n",
      "[Epoch 022] loss=0.9331 recon=0.9326 kl=0.0005\n",
      "[Epoch 023] loss=0.9419 recon=0.9414 kl=0.0004\n",
      "[Epoch 024] loss=0.9255 recon=0.9249 kl=0.0006\n",
      "[Epoch 025] loss=0.9318 recon=0.9313 kl=0.0006\n",
      "[Epoch 026] loss=0.9302 recon=0.9295 kl=0.0008\n",
      "[Epoch 027] loss=0.9248 recon=0.9246 kl=0.0002\n",
      "[Epoch 028] loss=0.9317 recon=0.9307 kl=0.0010\n",
      "[Epoch 029] loss=0.9252 recon=0.9250 kl=0.0002\n",
      "[Epoch 030] loss=0.9295 recon=0.9285 kl=0.0010\n",
      "[Epoch 031] loss=0.9281 recon=0.9274 kl=0.0007\n",
      "[Epoch 032] loss=0.9303 recon=0.9299 kl=0.0004\n",
      "[Epoch 033] loss=0.9341 recon=0.9330 kl=0.0011\n",
      "[Epoch 034] loss=0.9474 recon=0.9470 kl=0.0004\n",
      "[Epoch 035] loss=0.9253 recon=0.9246 kl=0.0007\n",
      "[Epoch 036] loss=0.9272 recon=0.9236 kl=0.0036\n",
      "[Epoch 037] loss=0.9421 recon=0.9379 kl=0.0042\n",
      "[Epoch 038] loss=0.9324 recon=0.9312 kl=0.0012\n",
      "[Epoch 039] loss=0.9352 recon=0.9348 kl=0.0004\n",
      "[Epoch 040] loss=0.9411 recon=0.9411 kl=0.0000\n",
      "[Epoch 041] loss=0.9281 recon=0.9277 kl=0.0005\n",
      "[Epoch 042] loss=0.9429 recon=0.9426 kl=0.0003\n",
      "[Epoch 043] loss=0.9280 recon=0.9274 kl=0.0006\n",
      "[Epoch 044] loss=0.9255 recon=0.9253 kl=0.0002\n",
      "[Epoch 045] loss=0.9351 recon=0.9344 kl=0.0007\n",
      "[Epoch 046] loss=0.9331 recon=0.9323 kl=0.0009\n",
      "[Epoch 047] loss=0.9395 recon=0.9392 kl=0.0003\n",
      "[Epoch 048] loss=0.9390 recon=0.9381 kl=0.0009\n",
      "[Epoch 049] loss=0.9376 recon=0.9339 kl=0.0036\n",
      "[Epoch 050] loss=0.9417 recon=0.9391 kl=0.0026\n",
      "[Epoch 051] loss=0.9406 recon=0.9389 kl=0.0017\n",
      "[Epoch 052] loss=0.9344 recon=0.9338 kl=0.0006\n",
      "[Epoch 053] loss=0.9210 recon=0.9209 kl=0.0001\n",
      "[Epoch 054] loss=0.9465 recon=0.9465 kl=0.0000\n",
      "[Epoch 055] loss=0.9357 recon=0.9351 kl=0.0006\n",
      "[Epoch 056] loss=0.9321 recon=0.9316 kl=0.0005\n",
      "[Epoch 057] loss=0.9587 recon=0.9583 kl=0.0004\n",
      "[Epoch 058] loss=0.9339 recon=0.9334 kl=0.0004\n",
      "[Epoch 059] loss=0.9296 recon=0.9288 kl=0.0008\n",
      "[Epoch 060] loss=0.9421 recon=0.9414 kl=0.0007\n",
      "[Epoch 061] loss=0.9353 recon=0.9344 kl=0.0009\n",
      "[Epoch 062] loss=0.9355 recon=0.9350 kl=0.0005\n",
      "[Epoch 063] loss=0.9261 recon=0.9255 kl=0.0006\n",
      "[Epoch 064] loss=0.9377 recon=0.9374 kl=0.0004\n",
      "[Epoch 065] loss=0.9288 recon=0.9281 kl=0.0007\n",
      "[Epoch 066] loss=0.9562 recon=0.9557 kl=0.0005\n",
      "[Epoch 067] loss=0.9310 recon=0.9301 kl=0.0009\n",
      "[Epoch 068] loss=0.9229 recon=0.9222 kl=0.0007\n",
      "[Epoch 069] loss=0.9231 recon=0.9230 kl=0.0001\n",
      "[Epoch 070] loss=0.9327 recon=0.9321 kl=0.0006\n",
      "[Epoch 071] loss=0.9452 recon=0.9446 kl=0.0007\n",
      "[Epoch 072] loss=0.9479 recon=0.9471 kl=0.0008\n",
      "[Epoch 073] loss=0.9268 recon=0.9263 kl=0.0006\n",
      "[Epoch 074] loss=0.9351 recon=0.9336 kl=0.0015\n",
      "[Epoch 075] loss=0.9294 recon=0.9264 kl=0.0031\n",
      "[Epoch 076] loss=0.9194 recon=0.9185 kl=0.0009\n",
      "[Epoch 077] loss=0.9545 recon=0.9544 kl=0.0001\n",
      "[Epoch 078] loss=0.9304 recon=0.9303 kl=0.0000\n",
      "[Epoch 079] loss=0.9378 recon=0.9372 kl=0.0006\n",
      "[Epoch 080] loss=0.9418 recon=0.9374 kl=0.0044\n",
      "[Epoch 081] loss=0.9393 recon=0.9362 kl=0.0031\n",
      "[Epoch 082] loss=0.9514 recon=0.9489 kl=0.0025\n",
      "[Epoch 083] loss=0.9363 recon=0.9360 kl=0.0003\n",
      "[Epoch 084] loss=0.9286 recon=0.9285 kl=0.0000\n",
      "[Epoch 085] loss=0.9292 recon=0.9292 kl=0.0000\n",
      "[Epoch 086] loss=0.9322 recon=0.9322 kl=0.0000\n",
      "[Epoch 087] loss=0.9391 recon=0.9391 kl=0.0000\n",
      "[Epoch 088] loss=0.9353 recon=0.9347 kl=0.0006\n",
      "[Epoch 089] loss=0.9272 recon=0.9267 kl=0.0005\n",
      "[Epoch 090] loss=0.9261 recon=0.9258 kl=0.0003\n",
      "30\n",
      "[Epoch 001] loss=1.2919 recon=0.9385 kl=0.3534\n",
      "[Epoch 002] loss=0.9610 recon=0.9587 kl=0.0023\n",
      "[Epoch 003] loss=0.9392 recon=0.9390 kl=0.0002\n",
      "[Epoch 004] loss=0.9395 recon=0.9394 kl=0.0001\n",
      "[Epoch 005] loss=0.9397 recon=0.9395 kl=0.0002\n",
      "[Epoch 006] loss=0.9382 recon=0.9380 kl=0.0002\n",
      "[Epoch 007] loss=0.9255 recon=0.9254 kl=0.0001\n",
      "[Epoch 008] loss=0.9327 recon=0.9324 kl=0.0003\n",
      "[Epoch 009] loss=0.9315 recon=0.9313 kl=0.0003\n",
      "[Epoch 010] loss=0.9556 recon=0.9553 kl=0.0002\n",
      "[Epoch 011] loss=0.9316 recon=0.9313 kl=0.0003\n",
      "[Epoch 012] loss=0.9405 recon=0.9402 kl=0.0003\n",
      "[Epoch 013] loss=0.9397 recon=0.9394 kl=0.0003\n",
      "[Epoch 014] loss=0.9335 recon=0.9331 kl=0.0004\n",
      "[Epoch 015] loss=0.9245 recon=0.9243 kl=0.0002\n",
      "[Epoch 016] loss=0.9260 recon=0.9256 kl=0.0004\n",
      "[Epoch 017] loss=0.9401 recon=0.9396 kl=0.0005\n",
      "[Epoch 018] loss=0.9544 recon=0.9539 kl=0.0004\n",
      "[Epoch 019] loss=0.9480 recon=0.9475 kl=0.0004\n",
      "[Epoch 020] loss=0.9247 recon=0.9243 kl=0.0004\n",
      "[Epoch 021] loss=0.9289 recon=0.9287 kl=0.0002\n",
      "[Epoch 022] loss=0.9400 recon=0.9386 kl=0.0014\n",
      "[Epoch 023] loss=0.9328 recon=0.9325 kl=0.0003\n",
      "[Epoch 024] loss=0.9412 recon=0.9412 kl=0.0000\n",
      "[Epoch 025] loss=0.9276 recon=0.9269 kl=0.0006\n",
      "[Epoch 026] loss=0.9287 recon=0.9282 kl=0.0006\n",
      "[Epoch 027] loss=0.9221 recon=0.9217 kl=0.0004\n",
      "[Epoch 028] loss=0.9524 recon=0.9520 kl=0.0004\n",
      "[Epoch 029] loss=0.9296 recon=0.9291 kl=0.0005\n",
      "[Epoch 030] loss=0.9312 recon=0.9304 kl=0.0008\n",
      "[Epoch 031] loss=0.9311 recon=0.9308 kl=0.0002\n",
      "[Epoch 032] loss=0.9632 recon=0.9621 kl=0.0011\n",
      "[Epoch 033] loss=0.9233 recon=0.9195 kl=0.0039\n",
      "[Epoch 034] loss=0.9247 recon=0.9232 kl=0.0015\n",
      "[Epoch 035] loss=0.9201 recon=0.9200 kl=0.0001\n",
      "[Epoch 036] loss=0.9408 recon=0.9408 kl=0.0000\n",
      "[Epoch 037] loss=0.9355 recon=0.9354 kl=0.0000\n",
      "[Epoch 038] loss=0.9319 recon=0.9318 kl=0.0001\n",
      "[Epoch 039] loss=0.9327 recon=0.9321 kl=0.0006\n",
      "[Epoch 040] loss=0.9394 recon=0.9390 kl=0.0003\n",
      "[Epoch 041] loss=0.9300 recon=0.9294 kl=0.0006\n",
      "[Epoch 042] loss=0.9343 recon=0.9339 kl=0.0004\n",
      "[Epoch 043] loss=0.9348 recon=0.9341 kl=0.0007\n",
      "[Epoch 044] loss=0.9440 recon=0.9437 kl=0.0002\n",
      "[Epoch 045] loss=0.9319 recon=0.9311 kl=0.0008\n",
      "[Epoch 046] loss=0.9417 recon=0.9415 kl=0.0002\n",
      "[Epoch 047] loss=0.9480 recon=0.9472 kl=0.0008\n",
      "[Epoch 048] loss=0.9277 recon=0.9275 kl=0.0003\n",
      "[Epoch 049] loss=0.9391 recon=0.9381 kl=0.0010\n",
      "[Epoch 050] loss=0.9258 recon=0.9254 kl=0.0005\n",
      "[Epoch 051] loss=0.9331 recon=0.9328 kl=0.0003\n",
      "[Epoch 052] loss=0.9340 recon=0.9329 kl=0.0011\n",
      "[Epoch 053] loss=0.9312 recon=0.9309 kl=0.0003\n",
      "[Epoch 054] loss=0.9390 recon=0.9386 kl=0.0004\n",
      "[Epoch 055] loss=0.9355 recon=0.9350 kl=0.0004\n",
      "[Epoch 056] loss=0.9241 recon=0.9235 kl=0.0006\n",
      "[Epoch 057] loss=0.9374 recon=0.9369 kl=0.0004\n",
      "[Epoch 058] loss=0.9232 recon=0.9222 kl=0.0011\n",
      "[Epoch 059] loss=0.9350 recon=0.9348 kl=0.0002\n",
      "[Epoch 060] loss=0.9372 recon=0.9371 kl=0.0001\n",
      "[Epoch 061] loss=0.9265 recon=0.9258 kl=0.0008\n",
      "[Epoch 062] loss=0.9381 recon=0.9377 kl=0.0004\n",
      "[Epoch 063] loss=0.9440 recon=0.9435 kl=0.0004\n",
      "[Epoch 064] loss=0.9397 recon=0.9386 kl=0.0011\n",
      "[Epoch 065] loss=0.9390 recon=0.9358 kl=0.0032\n",
      "[Epoch 066] loss=0.9361 recon=0.9352 kl=0.0010\n",
      "[Epoch 067] loss=0.9313 recon=0.9312 kl=0.0001\n",
      "[Epoch 068] loss=0.9315 recon=0.9315 kl=0.0000\n",
      "[Epoch 069] loss=0.9324 recon=0.9324 kl=0.0001\n",
      "[Epoch 070] loss=0.9376 recon=0.9361 kl=0.0015\n",
      "[Epoch 071] loss=0.9492 recon=0.9364 kl=0.0128\n",
      "[Epoch 072] loss=0.9386 recon=0.9355 kl=0.0031\n",
      "[Epoch 073] loss=0.9453 recon=0.9450 kl=0.0003\n",
      "[Epoch 074] loss=0.9331 recon=0.9330 kl=0.0000\n",
      "[Epoch 075] loss=0.9437 recon=0.9437 kl=0.0000\n",
      "[Epoch 076] loss=0.9208 recon=0.9208 kl=0.0000\n",
      "[Epoch 077] loss=0.9316 recon=0.9316 kl=0.0000\n",
      "[Epoch 078] loss=0.9222 recon=0.9222 kl=0.0000\n",
      "[Epoch 079] loss=0.9574 recon=0.9574 kl=0.0000\n",
      "[Epoch 080] loss=0.9260 recon=0.9234 kl=0.0026\n",
      "[Epoch 081] loss=0.9456 recon=0.9430 kl=0.0026\n",
      "[Epoch 082] loss=0.9213 recon=0.9197 kl=0.0016\n",
      "[Epoch 083] loss=0.9340 recon=0.9337 kl=0.0004\n",
      "[Epoch 084] loss=0.9266 recon=0.9265 kl=0.0000\n",
      "[Epoch 085] loss=0.9298 recon=0.9298 kl=0.0000\n",
      "[Epoch 086] loss=0.9469 recon=0.9464 kl=0.0005\n",
      "[Epoch 087] loss=0.9409 recon=0.9405 kl=0.0004\n",
      "[Epoch 088] loss=0.9352 recon=0.9348 kl=0.0004\n",
      "[Epoch 089] loss=0.9273 recon=0.9270 kl=0.0003\n",
      "[Epoch 090] loss=0.9294 recon=0.9263 kl=0.0031\n",
      "31\n",
      "[Epoch 001] loss=1.5456 recon=0.9366 kl=0.6091\n",
      "[Epoch 002] loss=0.9387 recon=0.9356 kl=0.0031\n",
      "[Epoch 003] loss=0.9349 recon=0.9346 kl=0.0003\n",
      "[Epoch 004] loss=0.9464 recon=0.9464 kl=0.0001\n",
      "[Epoch 005] loss=0.9409 recon=0.9408 kl=0.0002\n",
      "[Epoch 006] loss=0.9427 recon=0.9425 kl=0.0002\n",
      "[Epoch 007] loss=0.9356 recon=0.9354 kl=0.0002\n",
      "[Epoch 008] loss=0.9553 recon=0.9549 kl=0.0004\n",
      "[Epoch 009] loss=0.9322 recon=0.9321 kl=0.0001\n",
      "[Epoch 010] loss=0.9302 recon=0.9299 kl=0.0003\n",
      "[Epoch 011] loss=0.9292 recon=0.9288 kl=0.0004\n",
      "[Epoch 012] loss=0.9293 recon=0.9289 kl=0.0004\n",
      "[Epoch 013] loss=0.9257 recon=0.9254 kl=0.0004\n",
      "[Epoch 014] loss=0.9273 recon=0.9267 kl=0.0005\n",
      "[Epoch 015] loss=0.9298 recon=0.9295 kl=0.0004\n",
      "[Epoch 016] loss=0.9402 recon=0.9397 kl=0.0005\n",
      "[Epoch 017] loss=0.9410 recon=0.9406 kl=0.0005\n",
      "[Epoch 018] loss=0.9293 recon=0.9289 kl=0.0004\n",
      "[Epoch 019] loss=0.9348 recon=0.9340 kl=0.0008\n",
      "[Epoch 020] loss=0.9287 recon=0.9283 kl=0.0004\n",
      "[Epoch 021] loss=0.9373 recon=0.9367 kl=0.0006\n",
      "[Epoch 022] loss=0.9545 recon=0.9541 kl=0.0004\n",
      "[Epoch 023] loss=0.9371 recon=0.9364 kl=0.0007\n",
      "[Epoch 024] loss=0.9297 recon=0.9290 kl=0.0007\n",
      "[Epoch 025] loss=0.9270 recon=0.9267 kl=0.0003\n",
      "[Epoch 026] loss=0.9369 recon=0.9362 kl=0.0007\n",
      "[Epoch 027] loss=0.9281 recon=0.9278 kl=0.0003\n",
      "[Epoch 028] loss=0.9273 recon=0.9261 kl=0.0012\n",
      "[Epoch 029] loss=0.9262 recon=0.9258 kl=0.0004\n",
      "[Epoch 030] loss=0.9340 recon=0.9318 kl=0.0022\n",
      "[Epoch 031] loss=0.9298 recon=0.9260 kl=0.0038\n",
      "[Epoch 032] loss=0.9408 recon=0.9405 kl=0.0003\n",
      "[Epoch 033] loss=0.9302 recon=0.9301 kl=0.0001\n",
      "[Epoch 034] loss=0.9244 recon=0.9242 kl=0.0002\n",
      "[Epoch 035] loss=0.9288 recon=0.9280 kl=0.0009\n",
      "[Epoch 036] loss=0.9336 recon=0.9332 kl=0.0005\n",
      "[Epoch 037] loss=0.9400 recon=0.9394 kl=0.0006\n",
      "[Epoch 038] loss=0.9476 recon=0.9468 kl=0.0008\n",
      "[Epoch 039] loss=0.9495 recon=0.9491 kl=0.0004\n",
      "[Epoch 040] loss=0.9376 recon=0.9367 kl=0.0008\n",
      "[Epoch 041] loss=0.9353 recon=0.9346 kl=0.0006\n",
      "[Epoch 042] loss=0.9466 recon=0.9392 kl=0.0074\n",
      "[Epoch 043] loss=0.9723 recon=0.9715 kl=0.0008\n",
      "[Epoch 044] loss=0.9355 recon=0.9354 kl=0.0001\n",
      "[Epoch 045] loss=0.9372 recon=0.9372 kl=0.0000\n",
      "[Epoch 046] loss=0.9337 recon=0.9334 kl=0.0003\n",
      "[Epoch 047] loss=0.9233 recon=0.9226 kl=0.0006\n",
      "[Epoch 048] loss=0.9328 recon=0.9319 kl=0.0009\n",
      "[Epoch 049] loss=0.9402 recon=0.9398 kl=0.0004\n",
      "[Epoch 050] loss=0.9310 recon=0.9305 kl=0.0004\n",
      "[Epoch 051] loss=0.9335 recon=0.9327 kl=0.0008\n",
      "[Epoch 052] loss=0.9436 recon=0.9432 kl=0.0004\n",
      "[Epoch 053] loss=0.9431 recon=0.9426 kl=0.0006\n",
      "[Epoch 054] loss=0.9435 recon=0.9429 kl=0.0005\n",
      "[Epoch 055] loss=0.9396 recon=0.9390 kl=0.0005\n",
      "[Epoch 056] loss=0.9370 recon=0.9363 kl=0.0007\n",
      "[Epoch 057] loss=0.9458 recon=0.9452 kl=0.0006\n",
      "[Epoch 058] loss=0.9228 recon=0.9224 kl=0.0004\n",
      "[Epoch 059] loss=0.9416 recon=0.9411 kl=0.0005\n",
      "[Epoch 060] loss=0.9292 recon=0.9286 kl=0.0006\n",
      "[Epoch 061] loss=0.9391 recon=0.9385 kl=0.0006\n",
      "[Epoch 062] loss=0.9286 recon=0.9285 kl=0.0002\n",
      "[Epoch 063] loss=0.9361 recon=0.9354 kl=0.0007\n",
      "[Epoch 064] loss=0.9583 recon=0.9577 kl=0.0006\n",
      "[Epoch 065] loss=0.9205 recon=0.9202 kl=0.0003\n",
      "[Epoch 066] loss=0.9239 recon=0.9230 kl=0.0009\n",
      "[Epoch 067] loss=0.9370 recon=0.9363 kl=0.0007\n",
      "[Epoch 068] loss=0.9489 recon=0.9486 kl=0.0003\n",
      "[Epoch 069] loss=0.9524 recon=0.9518 kl=0.0006\n",
      "[Epoch 070] loss=0.9247 recon=0.9246 kl=0.0001\n",
      "[Epoch 071] loss=0.9278 recon=0.9240 kl=0.0038\n",
      "[Epoch 072] loss=0.9229 recon=0.9194 kl=0.0035\n",
      "[Epoch 073] loss=0.9513 recon=0.9486 kl=0.0027\n",
      "[Epoch 074] loss=0.9320 recon=0.9298 kl=0.0022\n",
      "[Epoch 075] loss=0.9381 recon=0.9369 kl=0.0012\n",
      "[Epoch 076] loss=0.9471 recon=0.9469 kl=0.0001\n",
      "[Epoch 077] loss=0.9338 recon=0.9338 kl=0.0000\n",
      "[Epoch 078] loss=0.9335 recon=0.9335 kl=0.0000\n",
      "[Epoch 079] loss=0.9265 recon=0.9265 kl=0.0000\n",
      "[Epoch 080] loss=0.9264 recon=0.9264 kl=0.0000\n",
      "[Epoch 081] loss=0.9301 recon=0.9301 kl=0.0000\n",
      "[Epoch 082] loss=0.9204 recon=0.9196 kl=0.0009\n",
      "[Epoch 083] loss=0.9388 recon=0.9381 kl=0.0007\n",
      "[Epoch 084] loss=0.9454 recon=0.9452 kl=0.0001\n",
      "[Epoch 085] loss=0.9265 recon=0.9260 kl=0.0004\n",
      "[Epoch 086] loss=0.9304 recon=0.9301 kl=0.0003\n",
      "[Epoch 087] loss=0.9591 recon=0.9579 kl=0.0012\n",
      "[Epoch 088] loss=0.9487 recon=0.9473 kl=0.0015\n",
      "[Epoch 089] loss=0.9396 recon=0.9395 kl=0.0001\n",
      "[Epoch 090] loss=0.9298 recon=0.9294 kl=0.0004\n",
      "32\n",
      "[Epoch 001] loss=1.4513 recon=0.9427 kl=0.5086\n",
      "[Epoch 002] loss=0.9348 recon=0.9321 kl=0.0027\n",
      "[Epoch 003] loss=0.9387 recon=0.9384 kl=0.0002\n",
      "[Epoch 004] loss=0.9430 recon=0.9429 kl=0.0001\n",
      "[Epoch 005] loss=0.9333 recon=0.9332 kl=0.0001\n",
      "[Epoch 006] loss=0.9512 recon=0.9510 kl=0.0002\n",
      "[Epoch 007] loss=0.9328 recon=0.9327 kl=0.0000\n",
      "[Epoch 008] loss=0.9315 recon=0.9309 kl=0.0006\n",
      "[Epoch 009] loss=0.9367 recon=0.9365 kl=0.0001\n",
      "[Epoch 010] loss=0.9342 recon=0.9342 kl=0.0000\n",
      "[Epoch 011] loss=0.9359 recon=0.9357 kl=0.0003\n",
      "[Epoch 012] loss=0.9328 recon=0.9325 kl=0.0002\n",
      "[Epoch 013] loss=0.9383 recon=0.9381 kl=0.0001\n",
      "[Epoch 014] loss=0.9378 recon=0.9374 kl=0.0004\n",
      "[Epoch 015] loss=0.9347 recon=0.9344 kl=0.0003\n",
      "[Epoch 016] loss=0.9269 recon=0.9265 kl=0.0004\n",
      "[Epoch 017] loss=0.9412 recon=0.9410 kl=0.0002\n",
      "[Epoch 018] loss=0.9249 recon=0.9244 kl=0.0005\n",
      "[Epoch 019] loss=0.9301 recon=0.9298 kl=0.0003\n",
      "[Epoch 020] loss=0.9583 recon=0.9578 kl=0.0005\n",
      "[Epoch 021] loss=0.9305 recon=0.9302 kl=0.0002\n",
      "[Epoch 022] loss=0.9256 recon=0.9248 kl=0.0009\n",
      "[Epoch 023] loss=0.9206 recon=0.9205 kl=0.0001\n",
      "[Epoch 024] loss=0.9390 recon=0.9385 kl=0.0004\n",
      "[Epoch 025] loss=0.9264 recon=0.9255 kl=0.0009\n",
      "[Epoch 026] loss=0.9432 recon=0.9431 kl=0.0001\n",
      "[Epoch 027] loss=0.9485 recon=0.9481 kl=0.0004\n",
      "[Epoch 028] loss=0.9289 recon=0.9277 kl=0.0012\n",
      "[Epoch 029] loss=0.9310 recon=0.9306 kl=0.0004\n",
      "[Epoch 030] loss=0.9281 recon=0.9279 kl=0.0002\n",
      "[Epoch 031] loss=0.9420 recon=0.9418 kl=0.0003\n",
      "[Epoch 032] loss=0.9229 recon=0.9221 kl=0.0008\n",
      "[Epoch 033] loss=0.9473 recon=0.9471 kl=0.0002\n",
      "[Epoch 034] loss=0.9347 recon=0.9340 kl=0.0006\n",
      "[Epoch 035] loss=0.9322 recon=0.9292 kl=0.0031\n",
      "[Epoch 036] loss=0.9313 recon=0.9310 kl=0.0003\n",
      "[Epoch 037] loss=0.9302 recon=0.9302 kl=0.0000\n",
      "[Epoch 038] loss=0.9361 recon=0.9356 kl=0.0005\n",
      "[Epoch 039] loss=0.9258 recon=0.9253 kl=0.0005\n",
      "[Epoch 040] loss=0.9308 recon=0.9304 kl=0.0005\n",
      "[Epoch 041] loss=0.9359 recon=0.9304 kl=0.0055\n",
      "[Epoch 042] loss=0.9643 recon=0.9630 kl=0.0013\n",
      "[Epoch 043] loss=0.9305 recon=0.9304 kl=0.0001\n",
      "[Epoch 044] loss=0.9415 recon=0.9415 kl=0.0000\n",
      "[Epoch 045] loss=0.9385 recon=0.9385 kl=0.0000\n",
      "[Epoch 046] loss=0.9346 recon=0.9340 kl=0.0006\n",
      "[Epoch 047] loss=0.9650 recon=0.9643 kl=0.0007\n",
      "[Epoch 048] loss=0.9448 recon=0.9444 kl=0.0004\n",
      "[Epoch 049] loss=0.9354 recon=0.9354 kl=0.0001\n",
      "[Epoch 050] loss=0.9365 recon=0.9358 kl=0.0007\n",
      "[Epoch 051] loss=0.9264 recon=0.9260 kl=0.0004\n",
      "[Epoch 052] loss=0.9515 recon=0.9510 kl=0.0006\n",
      "[Epoch 053] loss=0.9271 recon=0.9265 kl=0.0006\n",
      "[Epoch 054] loss=0.9348 recon=0.9344 kl=0.0004\n",
      "[Epoch 055] loss=0.9252 recon=0.9251 kl=0.0001\n",
      "[Epoch 056] loss=0.9592 recon=0.9586 kl=0.0006\n",
      "[Epoch 057] loss=0.9301 recon=0.9295 kl=0.0006\n",
      "[Epoch 058] loss=0.9260 recon=0.9257 kl=0.0003\n",
      "[Epoch 059] loss=0.9178 recon=0.9170 kl=0.0007\n",
      "[Epoch 060] loss=0.9318 recon=0.9315 kl=0.0003\n",
      "[Epoch 061] loss=0.9508 recon=0.9507 kl=0.0002\n",
      "[Epoch 062] loss=0.9200 recon=0.9192 kl=0.0008\n",
      "[Epoch 063] loss=0.9345 recon=0.9342 kl=0.0003\n",
      "[Epoch 064] loss=0.9245 recon=0.9240 kl=0.0005\n",
      "[Epoch 065] loss=0.9339 recon=0.9334 kl=0.0006\n",
      "[Epoch 066] loss=0.9261 recon=0.9255 kl=0.0006\n",
      "[Epoch 067] loss=0.9386 recon=0.9382 kl=0.0004\n",
      "[Epoch 068] loss=0.9267 recon=0.9263 kl=0.0004\n",
      "[Epoch 069] loss=0.9495 recon=0.9451 kl=0.0044\n",
      "[Epoch 070] loss=0.9243 recon=0.9214 kl=0.0029\n",
      "[Epoch 071] loss=0.9325 recon=0.9316 kl=0.0008\n",
      "[Epoch 072] loss=0.9361 recon=0.9360 kl=0.0001\n",
      "[Epoch 073] loss=0.9318 recon=0.9318 kl=0.0000\n",
      "[Epoch 074] loss=0.9465 recon=0.9465 kl=0.0000\n",
      "[Epoch 075] loss=0.9208 recon=0.9208 kl=0.0000\n",
      "[Epoch 076] loss=0.9328 recon=0.9325 kl=0.0004\n",
      "[Epoch 077] loss=0.9193 recon=0.9189 kl=0.0005\n",
      "[Epoch 078] loss=0.9318 recon=0.9314 kl=0.0004\n",
      "[Epoch 079] loss=0.9357 recon=0.9347 kl=0.0010\n",
      "[Epoch 080] loss=0.9259 recon=0.9259 kl=0.0001\n",
      "[Epoch 081] loss=0.9300 recon=0.9297 kl=0.0002\n",
      "[Epoch 082] loss=0.9329 recon=0.9324 kl=0.0005\n",
      "[Epoch 083] loss=0.9544 recon=0.9541 kl=0.0003\n",
      "[Epoch 084] loss=0.9392 recon=0.9386 kl=0.0006\n",
      "[Epoch 085] loss=0.9382 recon=0.9380 kl=0.0001\n",
      "[Epoch 086] loss=0.9303 recon=0.9293 kl=0.0010\n",
      "[Epoch 087] loss=0.9372 recon=0.9369 kl=0.0002\n",
      "[Epoch 088] loss=0.9405 recon=0.9399 kl=0.0006\n",
      "[Epoch 089] loss=0.9268 recon=0.9266 kl=0.0002\n",
      "[Epoch 090] loss=0.9355 recon=0.9349 kl=0.0006\n",
      "33\n",
      "[Epoch 001] loss=1.2271 recon=0.9434 kl=0.2838\n",
      "[Epoch 002] loss=0.9473 recon=0.9449 kl=0.0024\n",
      "[Epoch 003] loss=0.9282 recon=0.9280 kl=0.0002\n",
      "[Epoch 004] loss=0.9302 recon=0.9301 kl=0.0001\n",
      "[Epoch 005] loss=0.9339 recon=0.9338 kl=0.0001\n",
      "[Epoch 006] loss=0.9569 recon=0.9565 kl=0.0004\n",
      "[Epoch 007] loss=0.9293 recon=0.9292 kl=0.0001\n",
      "[Epoch 008] loss=0.9370 recon=0.9367 kl=0.0003\n",
      "[Epoch 009] loss=0.9357 recon=0.9355 kl=0.0002\n",
      "[Epoch 010] loss=0.9274 recon=0.9270 kl=0.0004\n",
      "[Epoch 011] loss=0.9305 recon=0.9303 kl=0.0003\n",
      "[Epoch 012] loss=0.9296 recon=0.9292 kl=0.0004\n",
      "[Epoch 013] loss=0.9393 recon=0.9391 kl=0.0002\n",
      "[Epoch 014] loss=0.9294 recon=0.9290 kl=0.0004\n",
      "[Epoch 015] loss=0.9251 recon=0.9249 kl=0.0002\n",
      "[Epoch 016] loss=0.9431 recon=0.9424 kl=0.0007\n",
      "[Epoch 017] loss=0.9499 recon=0.9497 kl=0.0002\n",
      "[Epoch 018] loss=0.9192 recon=0.9185 kl=0.0007\n",
      "[Epoch 019] loss=0.9244 recon=0.9242 kl=0.0002\n",
      "[Epoch 020] loss=0.9318 recon=0.9311 kl=0.0007\n",
      "[Epoch 021] loss=0.9264 recon=0.9259 kl=0.0004\n",
      "[Epoch 022] loss=0.9343 recon=0.9341 kl=0.0002\n",
      "[Epoch 023] loss=0.9259 recon=0.9246 kl=0.0014\n",
      "[Epoch 024] loss=0.9208 recon=0.9205 kl=0.0003\n",
      "[Epoch 025] loss=0.9272 recon=0.9267 kl=0.0004\n",
      "[Epoch 026] loss=0.9374 recon=0.9326 kl=0.0048\n",
      "[Epoch 027] loss=0.9438 recon=0.9428 kl=0.0010\n",
      "[Epoch 028] loss=0.9502 recon=0.9501 kl=0.0001\n",
      "[Epoch 029] loss=0.9517 recon=0.9517 kl=0.0000\n",
      "[Epoch 030] loss=0.9347 recon=0.9341 kl=0.0006\n",
      "[Epoch 031] loss=0.9332 recon=0.9323 kl=0.0010\n",
      "[Epoch 032] loss=0.9285 recon=0.9281 kl=0.0003\n",
      "[Epoch 033] loss=0.9411 recon=0.9406 kl=0.0006\n",
      "[Epoch 034] loss=0.9273 recon=0.9265 kl=0.0008\n",
      "[Epoch 035] loss=0.9369 recon=0.9367 kl=0.0002\n",
      "[Epoch 036] loss=0.9359 recon=0.9352 kl=0.0006\n",
      "[Epoch 037] loss=0.9184 recon=0.9177 kl=0.0007\n",
      "[Epoch 038] loss=0.9238 recon=0.9233 kl=0.0006\n",
      "[Epoch 039] loss=0.9316 recon=0.9314 kl=0.0002\n",
      "[Epoch 040] loss=0.9469 recon=0.9460 kl=0.0008\n",
      "[Epoch 041] loss=0.9291 recon=0.9283 kl=0.0008\n",
      "[Epoch 042] loss=0.9293 recon=0.9291 kl=0.0002\n",
      "[Epoch 043] loss=0.9191 recon=0.9183 kl=0.0008\n",
      "[Epoch 044] loss=0.9534 recon=0.9532 kl=0.0002\n",
      "[Epoch 045] loss=0.9442 recon=0.9436 kl=0.0006\n",
      "[Epoch 046] loss=0.9455 recon=0.9449 kl=0.0007\n",
      "[Epoch 047] loss=0.9249 recon=0.9241 kl=0.0008\n",
      "[Epoch 048] loss=0.9287 recon=0.9284 kl=0.0002\n",
      "[Epoch 049] loss=0.9192 recon=0.9187 kl=0.0005\n",
      "[Epoch 050] loss=0.9342 recon=0.9312 kl=0.0030\n",
      "[Epoch 051] loss=0.9348 recon=0.9318 kl=0.0030\n",
      "[Epoch 052] loss=0.9283 recon=0.9278 kl=0.0006\n",
      "[Epoch 053] loss=0.9306 recon=0.9306 kl=0.0001\n",
      "[Epoch 054] loss=0.9277 recon=0.9277 kl=0.0000\n",
      "[Epoch 055] loss=0.9456 recon=0.9455 kl=0.0001\n",
      "[Epoch 056] loss=0.9353 recon=0.9347 kl=0.0006\n",
      "[Epoch 057] loss=0.9287 recon=0.9282 kl=0.0005\n",
      "[Epoch 058] loss=0.9431 recon=0.9426 kl=0.0005\n",
      "[Epoch 059] loss=0.9300 recon=0.9295 kl=0.0005\n",
      "[Epoch 060] loss=0.9484 recon=0.9480 kl=0.0005\n",
      "[Epoch 061] loss=0.9238 recon=0.9213 kl=0.0026\n",
      "[Epoch 062] loss=0.9346 recon=0.9314 kl=0.0032\n",
      "[Epoch 063] loss=0.9344 recon=0.9328 kl=0.0016\n",
      "[Epoch 064] loss=0.9339 recon=0.9337 kl=0.0002\n",
      "[Epoch 065] loss=0.9201 recon=0.9200 kl=0.0000\n",
      "[Epoch 066] loss=0.9287 recon=0.9287 kl=0.0000\n",
      "[Epoch 067] loss=0.9240 recon=0.9240 kl=0.0000\n",
      "[Epoch 068] loss=0.9403 recon=0.9397 kl=0.0005\n",
      "[Epoch 069] loss=0.9259 recon=0.9254 kl=0.0006\n",
      "[Epoch 070] loss=0.9201 recon=0.9196 kl=0.0006\n",
      "[Epoch 071] loss=0.9316 recon=0.9313 kl=0.0003\n",
      "[Epoch 072] loss=0.9167 recon=0.9160 kl=0.0007\n",
      "[Epoch 073] loss=0.9330 recon=0.9325 kl=0.0005\n",
      "[Epoch 074] loss=0.9539 recon=0.9536 kl=0.0002\n",
      "[Epoch 075] loss=0.9376 recon=0.9369 kl=0.0006\n",
      "[Epoch 076] loss=0.9286 recon=0.9283 kl=0.0004\n",
      "[Epoch 077] loss=0.9222 recon=0.9217 kl=0.0006\n",
      "[Epoch 078] loss=0.9305 recon=0.9300 kl=0.0006\n",
      "[Epoch 079] loss=0.9322 recon=0.9318 kl=0.0005\n",
      "[Epoch 080] loss=0.9260 recon=0.9256 kl=0.0003\n",
      "[Epoch 081] loss=0.9326 recon=0.9322 kl=0.0004\n",
      "[Epoch 082] loss=0.9514 recon=0.9504 kl=0.0010\n",
      "[Epoch 083] loss=0.9297 recon=0.9292 kl=0.0005\n",
      "[Epoch 084] loss=0.9341 recon=0.9338 kl=0.0002\n",
      "[Epoch 085] loss=0.9250 recon=0.9206 kl=0.0044\n",
      "[Epoch 086] loss=0.9367 recon=0.9334 kl=0.0034\n",
      "[Epoch 087] loss=0.9223 recon=0.9210 kl=0.0013\n",
      "[Epoch 088] loss=0.9509 recon=0.9508 kl=0.0001\n",
      "[Epoch 089] loss=0.9285 recon=0.9285 kl=0.0000\n",
      "[Epoch 090] loss=0.9256 recon=0.9256 kl=0.0000\n",
      "34\n",
      "[Epoch 001] loss=1.3236 recon=0.9309 kl=0.3927\n",
      "[Epoch 002] loss=0.9338 recon=0.9309 kl=0.0030\n",
      "[Epoch 003] loss=0.9334 recon=0.9331 kl=0.0003\n",
      "[Epoch 004] loss=0.9311 recon=0.9310 kl=0.0001\n",
      "[Epoch 005] loss=0.9361 recon=0.9360 kl=0.0001\n",
      "[Epoch 006] loss=0.9264 recon=0.9263 kl=0.0001\n",
      "[Epoch 007] loss=0.9404 recon=0.9401 kl=0.0003\n",
      "[Epoch 008] loss=0.9357 recon=0.9355 kl=0.0002\n",
      "[Epoch 009] loss=0.9327 recon=0.9323 kl=0.0003\n",
      "[Epoch 010] loss=0.9244 recon=0.9242 kl=0.0002\n",
      "[Epoch 011] loss=0.9221 recon=0.9218 kl=0.0003\n",
      "[Epoch 012] loss=0.9455 recon=0.9452 kl=0.0004\n",
      "[Epoch 013] loss=0.9688 recon=0.9683 kl=0.0005\n",
      "[Epoch 014] loss=0.9239 recon=0.9236 kl=0.0003\n",
      "[Epoch 015] loss=0.9270 recon=0.9267 kl=0.0003\n",
      "[Epoch 016] loss=0.9231 recon=0.9223 kl=0.0007\n",
      "[Epoch 017] loss=0.9241 recon=0.9240 kl=0.0001\n",
      "[Epoch 018] loss=0.9444 recon=0.9439 kl=0.0005\n",
      "[Epoch 019] loss=0.9368 recon=0.9362 kl=0.0006\n",
      "[Epoch 020] loss=0.9462 recon=0.9458 kl=0.0003\n",
      "[Epoch 021] loss=0.9328 recon=0.9323 kl=0.0005\n",
      "[Epoch 022] loss=0.9356 recon=0.9351 kl=0.0005\n",
      "[Epoch 023] loss=0.9502 recon=0.9496 kl=0.0006\n",
      "[Epoch 024] loss=0.9234 recon=0.9229 kl=0.0005\n",
      "[Epoch 025] loss=0.9331 recon=0.9327 kl=0.0004\n",
      "[Epoch 026] loss=0.9350 recon=0.9343 kl=0.0007\n",
      "[Epoch 027] loss=0.9406 recon=0.9401 kl=0.0005\n",
      "[Epoch 028] loss=0.9366 recon=0.9363 kl=0.0004\n",
      "[Epoch 029] loss=0.9274 recon=0.9270 kl=0.0004\n",
      "[Epoch 030] loss=0.9256 recon=0.9248 kl=0.0008\n",
      "[Epoch 031] loss=0.9253 recon=0.9250 kl=0.0003\n",
      "[Epoch 032] loss=0.9304 recon=0.9290 kl=0.0014\n",
      "[Epoch 033] loss=0.9245 recon=0.9241 kl=0.0004\n",
      "[Epoch 034] loss=0.9395 recon=0.9391 kl=0.0004\n",
      "[Epoch 035] loss=0.9331 recon=0.9326 kl=0.0005\n",
      "[Epoch 036] loss=0.9196 recon=0.9190 kl=0.0007\n",
      "[Epoch 037] loss=0.9358 recon=0.9352 kl=0.0007\n",
      "[Epoch 038] loss=0.9378 recon=0.9376 kl=0.0002\n",
      "[Epoch 039] loss=0.9265 recon=0.9260 kl=0.0006\n",
      "[Epoch 040] loss=0.9302 recon=0.9296 kl=0.0006\n",
      "[Epoch 041] loss=0.9182 recon=0.9177 kl=0.0005\n",
      "[Epoch 042] loss=0.9268 recon=0.9262 kl=0.0006\n",
      "[Epoch 043] loss=0.9329 recon=0.9325 kl=0.0005\n",
      "[Epoch 044] loss=0.9386 recon=0.9377 kl=0.0009\n",
      "[Epoch 045] loss=0.9503 recon=0.9495 kl=0.0008\n",
      "[Epoch 046] loss=0.9209 recon=0.9204 kl=0.0005\n",
      "[Epoch 047] loss=0.9289 recon=0.9285 kl=0.0004\n",
      "[Epoch 048] loss=0.9252 recon=0.9209 kl=0.0042\n",
      "[Epoch 049] loss=0.9332 recon=0.9298 kl=0.0034\n",
      "[Epoch 050] loss=0.9245 recon=0.9223 kl=0.0022\n",
      "[Epoch 051] loss=0.9352 recon=0.9342 kl=0.0010\n",
      "[Epoch 052] loss=0.9266 recon=0.9265 kl=0.0001\n",
      "[Epoch 053] loss=0.9315 recon=0.9315 kl=0.0000\n",
      "[Epoch 054] loss=0.9275 recon=0.9275 kl=0.0000\n",
      "[Epoch 055] loss=0.9497 recon=0.9497 kl=0.0000\n",
      "[Epoch 056] loss=0.9316 recon=0.9312 kl=0.0004\n",
      "[Epoch 057] loss=0.9470 recon=0.9467 kl=0.0003\n",
      "[Epoch 058] loss=0.9415 recon=0.9410 kl=0.0004\n",
      "[Epoch 059] loss=0.9305 recon=0.9280 kl=0.0025\n",
      "[Epoch 060] loss=0.9306 recon=0.9302 kl=0.0003\n",
      "[Epoch 061] loss=0.9236 recon=0.9236 kl=0.0000\n",
      "[Epoch 062] loss=0.9315 recon=0.9294 kl=0.0021\n",
      "[Epoch 063] loss=0.9345 recon=0.9309 kl=0.0035\n",
      "[Epoch 064] loss=0.9411 recon=0.9386 kl=0.0025\n",
      "[Epoch 065] loss=0.9391 recon=0.9373 kl=0.0019\n",
      "[Epoch 066] loss=0.9305 recon=0.9301 kl=0.0004\n",
      "[Epoch 067] loss=0.9498 recon=0.9498 kl=0.0000\n",
      "[Epoch 068] loss=0.9318 recon=0.9317 kl=0.0000\n",
      "[Epoch 069] loss=0.9423 recon=0.9422 kl=0.0000\n",
      "[Epoch 070] loss=0.9262 recon=0.9261 kl=0.0001\n",
      "[Epoch 071] loss=0.9272 recon=0.9265 kl=0.0007\n",
      "[Epoch 072] loss=0.9300 recon=0.9295 kl=0.0005\n",
      "[Epoch 073] loss=0.9349 recon=0.9348 kl=0.0001\n",
      "[Epoch 074] loss=0.9249 recon=0.9241 kl=0.0008\n",
      "[Epoch 075] loss=0.9236 recon=0.9231 kl=0.0004\n",
      "[Epoch 076] loss=0.9346 recon=0.9342 kl=0.0004\n",
      "[Epoch 077] loss=0.9261 recon=0.9253 kl=0.0008\n",
      "[Epoch 078] loss=0.9357 recon=0.9353 kl=0.0004\n",
      "[Epoch 079] loss=0.9413 recon=0.9408 kl=0.0005\n",
      "[Epoch 080] loss=0.9396 recon=0.9392 kl=0.0004\n",
      "[Epoch 081] loss=0.9223 recon=0.9220 kl=0.0004\n",
      "[Epoch 082] loss=0.9206 recon=0.9201 kl=0.0006\n",
      "[Epoch 083] loss=0.9459 recon=0.9457 kl=0.0002\n",
      "[Epoch 084] loss=0.9258 recon=0.9251 kl=0.0007\n",
      "[Epoch 085] loss=0.9183 recon=0.9177 kl=0.0006\n",
      "[Epoch 086] loss=0.9386 recon=0.9382 kl=0.0004\n",
      "[Epoch 087] loss=0.9199 recon=0.9193 kl=0.0006\n",
      "[Epoch 088] loss=0.9378 recon=0.9293 kl=0.0084\n",
      "[Epoch 089] loss=0.9313 recon=0.9249 kl=0.0064\n",
      "[Epoch 090] loss=0.9297 recon=0.9288 kl=0.0009\n",
      "35\n",
      "[Epoch 001] loss=1.1571 recon=0.9443 kl=0.2128\n",
      "[Epoch 002] loss=0.9276 recon=0.9258 kl=0.0018\n",
      "[Epoch 003] loss=0.9451 recon=0.9449 kl=0.0002\n",
      "[Epoch 004] loss=0.9402 recon=0.9401 kl=0.0001\n",
      "[Epoch 005] loss=0.9467 recon=0.9464 kl=0.0003\n",
      "[Epoch 006] loss=0.9252 recon=0.9250 kl=0.0001\n",
      "[Epoch 007] loss=0.9298 recon=0.9296 kl=0.0003\n",
      "[Epoch 008] loss=0.9232 recon=0.9230 kl=0.0002\n",
      "[Epoch 009] loss=0.9246 recon=0.9241 kl=0.0004\n",
      "[Epoch 010] loss=0.9402 recon=0.9399 kl=0.0003\n",
      "[Epoch 011] loss=0.9284 recon=0.9279 kl=0.0005\n",
      "[Epoch 012] loss=0.9300 recon=0.9298 kl=0.0002\n",
      "[Epoch 013] loss=0.9491 recon=0.9488 kl=0.0003\n",
      "[Epoch 014] loss=0.9264 recon=0.9259 kl=0.0005\n",
      "[Epoch 015] loss=0.9393 recon=0.9389 kl=0.0003\n",
      "[Epoch 016] loss=0.9235 recon=0.9233 kl=0.0002\n",
      "[Epoch 017] loss=0.9314 recon=0.9307 kl=0.0007\n",
      "[Epoch 018] loss=0.9350 recon=0.9346 kl=0.0005\n",
      "[Epoch 019] loss=0.9422 recon=0.9418 kl=0.0004\n",
      "[Epoch 020] loss=0.9294 recon=0.9293 kl=0.0001\n",
      "[Epoch 021] loss=0.9451 recon=0.9443 kl=0.0008\n",
      "[Epoch 022] loss=0.9407 recon=0.9402 kl=0.0005\n",
      "[Epoch 023] loss=0.9272 recon=0.9261 kl=0.0011\n",
      "[Epoch 024] loss=0.9408 recon=0.9406 kl=0.0002\n",
      "[Epoch 025] loss=0.9370 recon=0.9365 kl=0.0005\n",
      "[Epoch 026] loss=0.9400 recon=0.9395 kl=0.0005\n",
      "[Epoch 027] loss=0.9274 recon=0.9269 kl=0.0005\n",
      "[Epoch 028] loss=0.9402 recon=0.9399 kl=0.0003\n",
      "[Epoch 029] loss=0.9235 recon=0.9228 kl=0.0007\n",
      "[Epoch 030] loss=0.9398 recon=0.9386 kl=0.0012\n",
      "[Epoch 031] loss=0.9375 recon=0.9326 kl=0.0049\n",
      "[Epoch 032] loss=0.9365 recon=0.9348 kl=0.0017\n",
      "[Epoch 033] loss=0.9330 recon=0.9329 kl=0.0002\n",
      "[Epoch 034] loss=0.9360 recon=0.9360 kl=0.0000\n",
      "[Epoch 035] loss=0.9334 recon=0.9334 kl=0.0000\n",
      "[Epoch 036] loss=0.9237 recon=0.9229 kl=0.0007\n",
      "[Epoch 037] loss=0.9305 recon=0.9302 kl=0.0003\n",
      "[Epoch 038] loss=0.9298 recon=0.9297 kl=0.0001\n",
      "[Epoch 039] loss=0.9405 recon=0.9395 kl=0.0010\n",
      "[Epoch 040] loss=0.9327 recon=0.9325 kl=0.0002\n",
      "[Epoch 041] loss=0.9405 recon=0.9398 kl=0.0006\n",
      "[Epoch 042] loss=0.9314 recon=0.9311 kl=0.0003\n",
      "[Epoch 043] loss=0.9250 recon=0.9243 kl=0.0007\n",
      "[Epoch 044] loss=0.9377 recon=0.9371 kl=0.0006\n",
      "[Epoch 045] loss=0.9274 recon=0.9269 kl=0.0005\n",
      "[Epoch 046] loss=0.9427 recon=0.9422 kl=0.0005\n",
      "[Epoch 047] loss=0.9174 recon=0.9170 kl=0.0004\n",
      "[Epoch 048] loss=0.9308 recon=0.9300 kl=0.0008\n",
      "[Epoch 049] loss=0.9466 recon=0.9464 kl=0.0002\n",
      "[Epoch 050] loss=0.9447 recon=0.9439 kl=0.0008\n",
      "[Epoch 051] loss=0.9333 recon=0.9327 kl=0.0006\n",
      "[Epoch 052] loss=0.9313 recon=0.9311 kl=0.0003\n",
      "[Epoch 053] loss=0.9199 recon=0.9193 kl=0.0005\n",
      "[Epoch 054] loss=0.9372 recon=0.9364 kl=0.0008\n",
      "[Epoch 055] loss=0.9404 recon=0.9400 kl=0.0004\n",
      "[Epoch 056] loss=0.9379 recon=0.9372 kl=0.0007\n",
      "[Epoch 057] loss=0.9359 recon=0.9354 kl=0.0005\n",
      "[Epoch 058] loss=0.9234 recon=0.9226 kl=0.0008\n",
      "[Epoch 059] loss=0.9315 recon=0.9313 kl=0.0002\n",
      "[Epoch 060] loss=0.9252 recon=0.9244 kl=0.0009\n",
      "[Epoch 061] loss=0.9393 recon=0.9392 kl=0.0001\n",
      "[Epoch 062] loss=0.9346 recon=0.9340 kl=0.0006\n",
      "[Epoch 063] loss=0.9295 recon=0.9288 kl=0.0007\n",
      "[Epoch 064] loss=0.9439 recon=0.9433 kl=0.0005\n",
      "[Epoch 065] loss=0.9268 recon=0.9266 kl=0.0002\n",
      "[Epoch 066] loss=0.9280 recon=0.9274 kl=0.0006\n",
      "[Epoch 067] loss=0.9513 recon=0.9509 kl=0.0003\n",
      "[Epoch 068] loss=0.9497 recon=0.9491 kl=0.0006\n",
      "[Epoch 069] loss=0.9283 recon=0.9258 kl=0.0025\n",
      "[Epoch 070] loss=0.9311 recon=0.9291 kl=0.0020\n",
      "[Epoch 071] loss=0.9244 recon=0.9239 kl=0.0005\n",
      "[Epoch 072] loss=0.9256 recon=0.9256 kl=0.0001\n",
      "[Epoch 073] loss=0.9336 recon=0.9336 kl=0.0000\n",
      "[Epoch 074] loss=0.9354 recon=0.9348 kl=0.0006\n",
      "[Epoch 075] loss=0.9310 recon=0.9309 kl=0.0001\n",
      "[Epoch 076] loss=0.9412 recon=0.9407 kl=0.0006\n",
      "[Epoch 077] loss=0.9397 recon=0.9391 kl=0.0006\n",
      "[Epoch 078] loss=0.9426 recon=0.9424 kl=0.0002\n",
      "[Epoch 079] loss=0.9320 recon=0.9315 kl=0.0005\n",
      "[Epoch 080] loss=0.9322 recon=0.9259 kl=0.0063\n",
      "[Epoch 081] loss=0.9312 recon=0.9271 kl=0.0041\n",
      "[Epoch 082] loss=0.9262 recon=0.9258 kl=0.0005\n",
      "[Epoch 083] loss=0.9258 recon=0.9258 kl=0.0000\n",
      "[Epoch 084] loss=0.9356 recon=0.9356 kl=0.0000\n",
      "[Epoch 085] loss=0.9324 recon=0.9324 kl=0.0000\n",
      "[Epoch 086] loss=0.9410 recon=0.9408 kl=0.0002\n",
      "[Epoch 087] loss=0.9363 recon=0.9357 kl=0.0005\n",
      "[Epoch 088] loss=0.9464 recon=0.9456 kl=0.0008\n",
      "[Epoch 089] loss=0.9403 recon=0.9398 kl=0.0005\n",
      "[Epoch 090] loss=0.9248 recon=0.9246 kl=0.0002\n",
      "36\n",
      "[Epoch 001] loss=1.1743 recon=0.9232 kl=0.2511\n",
      "[Epoch 002] loss=0.9332 recon=0.9312 kl=0.0020\n",
      "[Epoch 003] loss=0.9340 recon=0.9338 kl=0.0002\n",
      "[Epoch 004] loss=0.9420 recon=0.9419 kl=0.0001\n",
      "[Epoch 005] loss=0.9562 recon=0.9560 kl=0.0002\n",
      "[Epoch 006] loss=0.9277 recon=0.9275 kl=0.0002\n",
      "[Epoch 007] loss=0.9352 recon=0.9348 kl=0.0004\n",
      "[Epoch 008] loss=0.9344 recon=0.9342 kl=0.0002\n",
      "[Epoch 009] loss=0.9290 recon=0.9288 kl=0.0001\n",
      "[Epoch 010] loss=0.9356 recon=0.9353 kl=0.0003\n",
      "[Epoch 011] loss=0.9434 recon=0.9430 kl=0.0004\n",
      "[Epoch 012] loss=0.9283 recon=0.9279 kl=0.0004\n",
      "[Epoch 013] loss=0.9304 recon=0.9301 kl=0.0003\n",
      "[Epoch 014] loss=0.9589 recon=0.9585 kl=0.0004\n",
      "[Epoch 015] loss=0.9389 recon=0.9386 kl=0.0003\n",
      "[Epoch 016] loss=0.9329 recon=0.9322 kl=0.0007\n",
      "[Epoch 017] loss=0.9272 recon=0.9270 kl=0.0002\n",
      "[Epoch 018] loss=0.9250 recon=0.9244 kl=0.0006\n",
      "[Epoch 019] loss=0.9499 recon=0.9493 kl=0.0006\n",
      "[Epoch 020] loss=0.9474 recon=0.9473 kl=0.0002\n",
      "[Epoch 021] loss=0.9292 recon=0.9285 kl=0.0007\n",
      "[Epoch 022] loss=0.9259 recon=0.9256 kl=0.0003\n",
      "[Epoch 023] loss=0.9301 recon=0.9279 kl=0.0023\n",
      "[Epoch 024] loss=0.9326 recon=0.9300 kl=0.0026\n",
      "[Epoch 025] loss=0.9386 recon=0.9381 kl=0.0004\n",
      "[Epoch 026] loss=0.9227 recon=0.9226 kl=0.0000\n",
      "[Epoch 027] loss=0.9411 recon=0.9411 kl=0.0000\n",
      "[Epoch 028] loss=0.9247 recon=0.9231 kl=0.0016\n",
      "[Epoch 029] loss=0.9604 recon=0.9543 kl=0.0061\n",
      "[Epoch 030] loss=0.9365 recon=0.9351 kl=0.0014\n",
      "[Epoch 031] loss=0.9257 recon=0.9256 kl=0.0001\n",
      "[Epoch 032] loss=0.9405 recon=0.9405 kl=0.0000\n",
      "[Epoch 033] loss=0.9202 recon=0.9202 kl=0.0000\n",
      "[Epoch 034] loss=0.9342 recon=0.9307 kl=0.0035\n",
      "[Epoch 035] loss=0.9321 recon=0.9313 kl=0.0008\n",
      "[Epoch 036] loss=0.9502 recon=0.9501 kl=0.0001\n",
      "[Epoch 037] loss=0.9276 recon=0.9276 kl=0.0000\n",
      "[Epoch 038] loss=0.9212 recon=0.9212 kl=0.0000\n",
      "[Epoch 039] loss=0.9502 recon=0.9496 kl=0.0006\n",
      "[Epoch 040] loss=0.9328 recon=0.9317 kl=0.0011\n",
      "[Epoch 041] loss=0.9297 recon=0.9293 kl=0.0004\n",
      "[Epoch 042] loss=0.9289 recon=0.9284 kl=0.0005\n",
      "[Epoch 043] loss=0.9334 recon=0.9328 kl=0.0006\n",
      "[Epoch 044] loss=0.9446 recon=0.9442 kl=0.0004\n",
      "[Epoch 045] loss=0.9306 recon=0.9300 kl=0.0006\n",
      "[Epoch 046] loss=0.9227 recon=0.9223 kl=0.0004\n",
      "[Epoch 047] loss=0.9261 recon=0.9255 kl=0.0006\n",
      "[Epoch 048] loss=0.9336 recon=0.9331 kl=0.0005\n",
      "[Epoch 049] loss=0.9384 recon=0.9377 kl=0.0007\n",
      "[Epoch 050] loss=0.9373 recon=0.9370 kl=0.0003\n",
      "[Epoch 051] loss=0.9284 recon=0.9278 kl=0.0006\n",
      "[Epoch 052] loss=0.9460 recon=0.9453 kl=0.0007\n",
      "[Epoch 053] loss=0.9226 recon=0.9219 kl=0.0007\n",
      "[Epoch 054] loss=0.9259 recon=0.9254 kl=0.0004\n",
      "[Epoch 055] loss=0.9379 recon=0.9375 kl=0.0004\n",
      "[Epoch 056] loss=0.9365 recon=0.9361 kl=0.0004\n",
      "[Epoch 057] loss=0.9359 recon=0.9354 kl=0.0005\n",
      "[Epoch 058] loss=0.9266 recon=0.9255 kl=0.0012\n",
      "[Epoch 059] loss=0.9240 recon=0.9235 kl=0.0005\n",
      "[Epoch 060] loss=0.9310 recon=0.9309 kl=0.0001\n",
      "[Epoch 061] loss=0.9282 recon=0.9274 kl=0.0008\n",
      "[Epoch 062] loss=0.9383 recon=0.9377 kl=0.0005\n",
      "[Epoch 063] loss=0.9334 recon=0.9331 kl=0.0003\n",
      "[Epoch 064] loss=0.9356 recon=0.9348 kl=0.0008\n",
      "[Epoch 065] loss=0.9375 recon=0.9370 kl=0.0005\n",
      "[Epoch 066] loss=0.9343 recon=0.9338 kl=0.0004\n",
      "[Epoch 067] loss=0.9292 recon=0.9287 kl=0.0005\n",
      "[Epoch 068] loss=0.9409 recon=0.9406 kl=0.0003\n",
      "[Epoch 069] loss=0.9431 recon=0.9423 kl=0.0008\n",
      "[Epoch 070] loss=0.9328 recon=0.9323 kl=0.0004\n",
      "[Epoch 071] loss=0.9290 recon=0.9287 kl=0.0002\n",
      "[Epoch 072] loss=0.9395 recon=0.9386 kl=0.0009\n",
      "[Epoch 073] loss=0.9319 recon=0.9314 kl=0.0005\n",
      "[Epoch 074] loss=0.9510 recon=0.9506 kl=0.0005\n",
      "[Epoch 075] loss=0.9298 recon=0.9294 kl=0.0005\n",
      "[Epoch 076] loss=0.9385 recon=0.9379 kl=0.0006\n",
      "[Epoch 077] loss=0.9412 recon=0.9408 kl=0.0004\n",
      "[Epoch 078] loss=0.9394 recon=0.9388 kl=0.0006\n",
      "[Epoch 079] loss=0.9451 recon=0.9447 kl=0.0004\n",
      "[Epoch 080] loss=0.9276 recon=0.9271 kl=0.0006\n",
      "[Epoch 081] loss=0.9464 recon=0.9460 kl=0.0004\n",
      "[Epoch 082] loss=0.9283 recon=0.9279 kl=0.0004\n",
      "[Epoch 083] loss=0.9293 recon=0.9289 kl=0.0004\n",
      "[Epoch 084] loss=0.9289 recon=0.9284 kl=0.0005\n",
      "[Epoch 085] loss=0.9251 recon=0.9245 kl=0.0006\n",
      "[Epoch 086] loss=0.9266 recon=0.9262 kl=0.0004\n",
      "[Epoch 087] loss=0.9361 recon=0.9357 kl=0.0005\n",
      "[Epoch 088] loss=0.9286 recon=0.9283 kl=0.0003\n",
      "[Epoch 089] loss=0.9266 recon=0.9260 kl=0.0007\n",
      "[Epoch 090] loss=0.9366 recon=0.9362 kl=0.0004\n",
      "37\n",
      "[Epoch 001] loss=1.3918 recon=0.9258 kl=0.4660\n",
      "[Epoch 002] loss=0.9436 recon=0.9403 kl=0.0033\n",
      "[Epoch 003] loss=0.9373 recon=0.9371 kl=0.0003\n",
      "[Epoch 004] loss=0.9436 recon=0.9435 kl=0.0001\n",
      "[Epoch 005] loss=0.9353 recon=0.9352 kl=0.0001\n",
      "[Epoch 006] loss=0.9465 recon=0.9465 kl=0.0000\n",
      "[Epoch 007] loss=0.9438 recon=0.9436 kl=0.0002\n",
      "[Epoch 008] loss=0.9247 recon=0.9244 kl=0.0003\n",
      "[Epoch 009] loss=0.9290 recon=0.9290 kl=0.0001\n",
      "[Epoch 010] loss=0.9235 recon=0.9231 kl=0.0004\n",
      "[Epoch 011] loss=0.9307 recon=0.9306 kl=0.0001\n",
      "[Epoch 012] loss=0.9237 recon=0.9233 kl=0.0005\n",
      "[Epoch 013] loss=0.9358 recon=0.9354 kl=0.0004\n",
      "[Epoch 014] loss=0.9279 recon=0.9278 kl=0.0002\n",
      "[Epoch 015] loss=0.9385 recon=0.9384 kl=0.0001\n",
      "[Epoch 016] loss=0.9393 recon=0.9387 kl=0.0006\n",
      "[Epoch 017] loss=0.9276 recon=0.9274 kl=0.0001\n",
      "[Epoch 018] loss=0.9241 recon=0.9235 kl=0.0007\n",
      "[Epoch 019] loss=0.9257 recon=0.9255 kl=0.0001\n",
      "[Epoch 020] loss=0.9367 recon=0.9363 kl=0.0004\n",
      "[Epoch 021] loss=0.9346 recon=0.9341 kl=0.0005\n",
      "[Epoch 022] loss=0.9425 recon=0.9422 kl=0.0003\n",
      "[Epoch 023] loss=0.9268 recon=0.9261 kl=0.0007\n",
      "[Epoch 024] loss=0.9350 recon=0.9346 kl=0.0003\n",
      "[Epoch 025] loss=0.9411 recon=0.9408 kl=0.0003\n",
      "[Epoch 026] loss=0.9233 recon=0.9224 kl=0.0008\n",
      "[Epoch 027] loss=0.9405 recon=0.9402 kl=0.0004\n",
      "[Epoch 028] loss=0.9464 recon=0.9461 kl=0.0002\n",
      "[Epoch 029] loss=0.9458 recon=0.9419 kl=0.0039\n",
      "[Epoch 030] loss=0.9362 recon=0.9339 kl=0.0023\n",
      "[Epoch 031] loss=0.9298 recon=0.9293 kl=0.0005\n",
      "[Epoch 032] loss=0.9361 recon=0.9360 kl=0.0000\n",
      "[Epoch 033] loss=0.9305 recon=0.9305 kl=0.0000\n",
      "[Epoch 034] loss=0.9329 recon=0.9329 kl=0.0000\n",
      "[Epoch 035] loss=0.9244 recon=0.9234 kl=0.0010\n",
      "[Epoch 036] loss=0.9393 recon=0.9390 kl=0.0003\n",
      "[Epoch 037] loss=0.9270 recon=0.9268 kl=0.0003\n",
      "[Epoch 038] loss=0.9486 recon=0.9484 kl=0.0002\n",
      "[Epoch 039] loss=0.9334 recon=0.9322 kl=0.0012\n",
      "[Epoch 040] loss=0.9405 recon=0.9230 kl=0.0174\n",
      "[Epoch 041] loss=0.9280 recon=0.9257 kl=0.0023\n",
      "[Epoch 042] loss=0.9373 recon=0.9371 kl=0.0002\n",
      "[Epoch 043] loss=0.9388 recon=0.9388 kl=0.0000\n",
      "[Epoch 044] loss=0.9273 recon=0.9273 kl=0.0000\n",
      "[Epoch 045] loss=0.9253 recon=0.9253 kl=0.0000\n",
      "[Epoch 046] loss=0.9321 recon=0.9321 kl=0.0000\n",
      "[Epoch 047] loss=0.9430 recon=0.9430 kl=0.0000\n",
      "[Epoch 048] loss=0.9351 recon=0.9339 kl=0.0012\n",
      "[Epoch 049] loss=0.9374 recon=0.9335 kl=0.0039\n",
      "[Epoch 050] loss=0.9354 recon=0.9332 kl=0.0021\n",
      "[Epoch 051] loss=0.9378 recon=0.9373 kl=0.0006\n",
      "[Epoch 052] loss=0.9599 recon=0.9599 kl=0.0001\n",
      "[Epoch 053] loss=0.9304 recon=0.9304 kl=0.0000\n",
      "[Epoch 054] loss=0.9387 recon=0.9387 kl=0.0000\n",
      "[Epoch 055] loss=0.9280 recon=0.9277 kl=0.0003\n",
      "[Epoch 056] loss=0.9380 recon=0.9376 kl=0.0004\n",
      "[Epoch 057] loss=0.9447 recon=0.9442 kl=0.0005\n",
      "[Epoch 058] loss=0.9638 recon=0.9637 kl=0.0001\n",
      "[Epoch 059] loss=0.9273 recon=0.9265 kl=0.0008\n",
      "[Epoch 060] loss=0.9434 recon=0.9429 kl=0.0005\n",
      "[Epoch 061] loss=0.9362 recon=0.9358 kl=0.0004\n",
      "[Epoch 062] loss=0.9341 recon=0.9338 kl=0.0003\n",
      "[Epoch 063] loss=0.9293 recon=0.9290 kl=0.0003\n",
      "[Epoch 064] loss=0.9325 recon=0.9319 kl=0.0006\n",
      "[Epoch 065] loss=0.9295 recon=0.9293 kl=0.0002\n",
      "[Epoch 066] loss=0.9283 recon=0.9275 kl=0.0007\n",
      "[Epoch 067] loss=0.9282 recon=0.9280 kl=0.0002\n",
      "[Epoch 068] loss=0.9362 recon=0.9355 kl=0.0007\n",
      "[Epoch 069] loss=0.9336 recon=0.9291 kl=0.0045\n",
      "[Epoch 070] loss=0.9418 recon=0.9394 kl=0.0025\n",
      "[Epoch 071] loss=0.9377 recon=0.9374 kl=0.0003\n",
      "[Epoch 072] loss=0.9221 recon=0.9220 kl=0.0000\n",
      "[Epoch 073] loss=0.9329 recon=0.9329 kl=0.0000\n",
      "[Epoch 074] loss=0.9196 recon=0.9196 kl=0.0000\n",
      "[Epoch 075] loss=0.9355 recon=0.9354 kl=0.0001\n",
      "[Epoch 076] loss=0.9285 recon=0.9279 kl=0.0006\n",
      "[Epoch 077] loss=0.9337 recon=0.9334 kl=0.0003\n",
      "[Epoch 078] loss=0.9384 recon=0.9380 kl=0.0003\n",
      "[Epoch 079] loss=0.9191 recon=0.9185 kl=0.0005\n",
      "[Epoch 080] loss=0.9231 recon=0.9229 kl=0.0002\n",
      "[Epoch 081] loss=0.9444 recon=0.9441 kl=0.0003\n",
      "[Epoch 082] loss=0.9340 recon=0.9332 kl=0.0008\n",
      "[Epoch 083] loss=0.9252 recon=0.9250 kl=0.0002\n",
      "[Epoch 084] loss=0.9249 recon=0.9245 kl=0.0004\n",
      "[Epoch 085] loss=0.9231 recon=0.9226 kl=0.0006\n",
      "[Epoch 086] loss=0.9234 recon=0.9233 kl=0.0001\n",
      "[Epoch 087] loss=0.9211 recon=0.9205 kl=0.0007\n",
      "[Epoch 088] loss=0.9303 recon=0.9263 kl=0.0040\n",
      "[Epoch 089] loss=0.9302 recon=0.9271 kl=0.0031\n",
      "[Epoch 090] loss=0.9260 recon=0.9239 kl=0.0021\n",
      "38\n",
      "[Epoch 001] loss=1.1368 recon=0.9263 kl=0.2105\n",
      "[Epoch 002] loss=0.9252 recon=0.9233 kl=0.0018\n",
      "[Epoch 003] loss=0.9305 recon=0.9303 kl=0.0002\n",
      "[Epoch 004] loss=0.9335 recon=0.9333 kl=0.0001\n",
      "[Epoch 005] loss=0.9238 recon=0.9236 kl=0.0002\n",
      "[Epoch 006] loss=0.9294 recon=0.9292 kl=0.0001\n",
      "[Epoch 007] loss=0.9547 recon=0.9545 kl=0.0002\n",
      "[Epoch 008] loss=0.9555 recon=0.9555 kl=0.0001\n",
      "[Epoch 009] loss=0.9306 recon=0.9303 kl=0.0003\n",
      "[Epoch 010] loss=0.9309 recon=0.9306 kl=0.0004\n",
      "[Epoch 011] loss=0.9246 recon=0.9246 kl=0.0001\n",
      "[Epoch 012] loss=0.9281 recon=0.9274 kl=0.0008\n",
      "[Epoch 013] loss=0.9362 recon=0.9358 kl=0.0004\n",
      "[Epoch 014] loss=0.9199 recon=0.9196 kl=0.0003\n",
      "[Epoch 015] loss=0.9527 recon=0.9527 kl=0.0001\n",
      "[Epoch 016] loss=0.9288 recon=0.9282 kl=0.0006\n",
      "[Epoch 017] loss=0.9304 recon=0.9301 kl=0.0003\n",
      "[Epoch 018] loss=0.9334 recon=0.9333 kl=0.0001\n",
      "[Epoch 019] loss=0.9347 recon=0.9342 kl=0.0005\n",
      "[Epoch 020] loss=0.9662 recon=0.9659 kl=0.0003\n",
      "[Epoch 021] loss=0.9280 recon=0.9275 kl=0.0005\n",
      "[Epoch 022] loss=0.9222 recon=0.9217 kl=0.0005\n",
      "[Epoch 023] loss=0.9421 recon=0.9413 kl=0.0008\n",
      "[Epoch 024] loss=0.9334 recon=0.9332 kl=0.0002\n",
      "[Epoch 025] loss=0.9293 recon=0.9288 kl=0.0005\n",
      "[Epoch 026] loss=0.9263 recon=0.9261 kl=0.0003\n",
      "[Epoch 027] loss=0.9473 recon=0.9470 kl=0.0003\n",
      "[Epoch 028] loss=0.9363 recon=0.9355 kl=0.0007\n",
      "[Epoch 029] loss=0.9269 recon=0.9266 kl=0.0003\n",
      "[Epoch 030] loss=0.9371 recon=0.9366 kl=0.0005\n",
      "[Epoch 031] loss=0.9263 recon=0.9260 kl=0.0003\n",
      "[Epoch 032] loss=0.9232 recon=0.9225 kl=0.0007\n",
      "[Epoch 033] loss=0.9363 recon=0.9362 kl=0.0001\n",
      "[Epoch 034] loss=0.9383 recon=0.9374 kl=0.0009\n",
      "[Epoch 035] loss=0.9358 recon=0.9355 kl=0.0003\n",
      "[Epoch 036] loss=0.9232 recon=0.9226 kl=0.0006\n",
      "[Epoch 037] loss=0.9465 recon=0.9429 kl=0.0036\n",
      "[Epoch 038] loss=0.9243 recon=0.9239 kl=0.0004\n",
      "[Epoch 039] loss=0.9358 recon=0.9358 kl=0.0001\n",
      "[Epoch 040] loss=0.9329 recon=0.9329 kl=0.0000\n",
      "[Epoch 041] loss=0.9412 recon=0.9407 kl=0.0005\n",
      "[Epoch 042] loss=0.9189 recon=0.9186 kl=0.0003\n",
      "[Epoch 043] loss=0.9375 recon=0.9368 kl=0.0007\n",
      "[Epoch 044] loss=0.9312 recon=0.9307 kl=0.0006\n",
      "[Epoch 045] loss=0.9316 recon=0.9314 kl=0.0001\n",
      "[Epoch 046] loss=0.9229 recon=0.9221 kl=0.0008\n",
      "[Epoch 047] loss=0.9757 recon=0.9720 kl=0.0037\n",
      "[Epoch 048] loss=0.9287 recon=0.9269 kl=0.0018\n",
      "[Epoch 049] loss=0.9212 recon=0.9210 kl=0.0002\n",
      "[Epoch 050] loss=0.9294 recon=0.9294 kl=0.0000\n",
      "[Epoch 051] loss=0.9354 recon=0.9352 kl=0.0002\n",
      "[Epoch 052] loss=0.9442 recon=0.9439 kl=0.0003\n",
      "[Epoch 053] loss=0.9508 recon=0.9500 kl=0.0008\n",
      "[Epoch 054] loss=0.9251 recon=0.9245 kl=0.0006\n",
      "[Epoch 055] loss=0.9301 recon=0.9300 kl=0.0001\n",
      "[Epoch 056] loss=0.9397 recon=0.9392 kl=0.0005\n",
      "[Epoch 057] loss=0.9269 recon=0.9264 kl=0.0006\n",
      "[Epoch 058] loss=0.9388 recon=0.9386 kl=0.0002\n",
      "[Epoch 059] loss=0.9262 recon=0.9255 kl=0.0007\n",
      "[Epoch 060] loss=0.9245 recon=0.9241 kl=0.0004\n",
      "[Epoch 061] loss=0.9336 recon=0.9330 kl=0.0006\n",
      "[Epoch 062] loss=0.9290 recon=0.9289 kl=0.0001\n",
      "[Epoch 063] loss=0.9439 recon=0.9423 kl=0.0016\n",
      "[Epoch 064] loss=0.9380 recon=0.9376 kl=0.0005\n",
      "[Epoch 065] loss=0.9210 recon=0.9210 kl=0.0001\n",
      "[Epoch 066] loss=0.9358 recon=0.9337 kl=0.0021\n",
      "[Epoch 067] loss=0.9311 recon=0.9273 kl=0.0038\n",
      "[Epoch 068] loss=0.9320 recon=0.9299 kl=0.0021\n",
      "[Epoch 069] loss=0.9235 recon=0.9231 kl=0.0004\n",
      "[Epoch 070] loss=0.9274 recon=0.9273 kl=0.0000\n",
      "[Epoch 071] loss=0.9536 recon=0.9536 kl=0.0000\n",
      "[Epoch 072] loss=0.9318 recon=0.9318 kl=0.0000\n",
      "[Epoch 073] loss=0.9210 recon=0.9209 kl=0.0000\n",
      "[Epoch 074] loss=0.9228 recon=0.9221 kl=0.0006\n",
      "[Epoch 075] loss=0.9639 recon=0.9629 kl=0.0010\n",
      "[Epoch 076] loss=0.9345 recon=0.9344 kl=0.0001\n",
      "[Epoch 077] loss=0.9281 recon=0.9281 kl=0.0000\n",
      "[Epoch 078] loss=0.9329 recon=0.9318 kl=0.0011\n",
      "[Epoch 079] loss=0.9403 recon=0.9398 kl=0.0005\n",
      "[Epoch 080] loss=0.9206 recon=0.9203 kl=0.0004\n",
      "[Epoch 081] loss=0.9255 recon=0.9255 kl=0.0000\n",
      "[Epoch 082] loss=0.9469 recon=0.9464 kl=0.0005\n",
      "[Epoch 083] loss=0.9421 recon=0.9415 kl=0.0006\n",
      "[Epoch 084] loss=0.9285 recon=0.9283 kl=0.0003\n",
      "[Epoch 085] loss=0.9337 recon=0.9332 kl=0.0006\n",
      "[Epoch 086] loss=0.9473 recon=0.9465 kl=0.0007\n",
      "[Epoch 087] loss=0.9369 recon=0.9366 kl=0.0003\n",
      "[Epoch 088] loss=0.9228 recon=0.9223 kl=0.0005\n",
      "[Epoch 089] loss=0.9336 recon=0.9333 kl=0.0003\n",
      "[Epoch 090] loss=0.9503 recon=0.9497 kl=0.0006\n",
      "39\n",
      "[Epoch 001] loss=1.3244 recon=0.9286 kl=0.3959\n",
      "[Epoch 002] loss=0.9540 recon=0.9512 kl=0.0028\n",
      "[Epoch 003] loss=0.9299 recon=0.9296 kl=0.0003\n",
      "[Epoch 004] loss=0.9283 recon=0.9283 kl=0.0000\n",
      "[Epoch 005] loss=0.9260 recon=0.9259 kl=0.0001\n",
      "[Epoch 006] loss=0.9306 recon=0.9305 kl=0.0001\n",
      "[Epoch 007] loss=0.9394 recon=0.9391 kl=0.0004\n",
      "[Epoch 008] loss=0.9284 recon=0.9282 kl=0.0001\n",
      "[Epoch 009] loss=0.9330 recon=0.9329 kl=0.0001\n",
      "[Epoch 010] loss=0.9537 recon=0.9535 kl=0.0003\n",
      "[Epoch 011] loss=0.9327 recon=0.9323 kl=0.0004\n",
      "[Epoch 012] loss=0.9284 recon=0.9281 kl=0.0003\n",
      "[Epoch 013] loss=0.9226 recon=0.9224 kl=0.0002\n",
      "[Epoch 014] loss=0.9434 recon=0.9430 kl=0.0003\n",
      "[Epoch 015] loss=0.9320 recon=0.9316 kl=0.0004\n",
      "[Epoch 016] loss=0.9373 recon=0.9367 kl=0.0006\n",
      "[Epoch 017] loss=0.9471 recon=0.9470 kl=0.0001\n",
      "[Epoch 018] loss=0.9291 recon=0.9285 kl=0.0005\n",
      "[Epoch 019] loss=0.9377 recon=0.9372 kl=0.0005\n",
      "[Epoch 020] loss=0.9327 recon=0.9324 kl=0.0004\n",
      "[Epoch 021] loss=0.9179 recon=0.9172 kl=0.0008\n",
      "[Epoch 022] loss=0.9389 recon=0.9385 kl=0.0004\n",
      "[Epoch 023] loss=0.9383 recon=0.9375 kl=0.0007\n",
      "[Epoch 024] loss=0.9390 recon=0.9389 kl=0.0001\n",
      "[Epoch 025] loss=0.9299 recon=0.9293 kl=0.0006\n",
      "[Epoch 026] loss=0.9602 recon=0.9598 kl=0.0004\n",
      "[Epoch 027] loss=0.9297 recon=0.9289 kl=0.0008\n",
      "[Epoch 028] loss=0.9277 recon=0.9268 kl=0.0008\n",
      "[Epoch 029] loss=0.9440 recon=0.9439 kl=0.0001\n",
      "[Epoch 030] loss=0.9354 recon=0.9350 kl=0.0004\n",
      "[Epoch 031] loss=0.9238 recon=0.9196 kl=0.0043\n",
      "[Epoch 032] loss=0.9377 recon=0.9354 kl=0.0024\n",
      "[Epoch 033] loss=0.9326 recon=0.9317 kl=0.0009\n",
      "[Epoch 034] loss=0.9396 recon=0.9396 kl=0.0001\n",
      "[Epoch 035] loss=0.9202 recon=0.9202 kl=0.0000\n",
      "[Epoch 036] loss=0.9222 recon=0.9222 kl=0.0000\n",
      "[Epoch 037] loss=0.9323 recon=0.9317 kl=0.0006\n",
      "[Epoch 038] loss=0.9394 recon=0.9393 kl=0.0001\n",
      "[Epoch 039] loss=0.9177 recon=0.9165 kl=0.0012\n",
      "[Epoch 040] loss=0.9348 recon=0.9322 kl=0.0026\n",
      "[Epoch 041] loss=0.9373 recon=0.9370 kl=0.0003\n",
      "[Epoch 042] loss=0.9438 recon=0.9438 kl=0.0000\n",
      "[Epoch 043] loss=0.9310 recon=0.9307 kl=0.0002\n",
      "[Epoch 044] loss=0.9338 recon=0.9330 kl=0.0008\n",
      "[Epoch 045] loss=0.9367 recon=0.9364 kl=0.0003\n",
      "[Epoch 046] loss=0.9242 recon=0.9237 kl=0.0005\n",
      "[Epoch 047] loss=0.9219 recon=0.9214 kl=0.0005\n",
      "[Epoch 048] loss=0.9358 recon=0.9354 kl=0.0004\n",
      "[Epoch 049] loss=0.9330 recon=0.9327 kl=0.0004\n",
      "[Epoch 050] loss=0.9415 recon=0.9408 kl=0.0007\n",
      "[Epoch 051] loss=0.9345 recon=0.9317 kl=0.0028\n",
      "[Epoch 052] loss=0.9262 recon=0.9256 kl=0.0006\n",
      "[Epoch 053] loss=0.9341 recon=0.9341 kl=0.0001\n",
      "[Epoch 054] loss=0.9233 recon=0.9233 kl=0.0000\n",
      "[Epoch 055] loss=0.9451 recon=0.9446 kl=0.0004\n",
      "[Epoch 056] loss=0.9245 recon=0.9237 kl=0.0008\n",
      "[Epoch 057] loss=0.9408 recon=0.9404 kl=0.0004\n",
      "[Epoch 058] loss=0.9538 recon=0.9534 kl=0.0004\n",
      "[Epoch 059] loss=0.9257 recon=0.9246 kl=0.0011\n",
      "[Epoch 060] loss=0.9242 recon=0.9238 kl=0.0003\n",
      "[Epoch 061] loss=0.9292 recon=0.9287 kl=0.0005\n",
      "[Epoch 062] loss=0.9439 recon=0.9432 kl=0.0007\n",
      "[Epoch 063] loss=0.9275 recon=0.9272 kl=0.0003\n",
      "[Epoch 064] loss=0.9314 recon=0.9311 kl=0.0003\n",
      "[Epoch 065] loss=0.9338 recon=0.9332 kl=0.0006\n",
      "[Epoch 066] loss=0.9257 recon=0.9250 kl=0.0007\n",
      "[Epoch 067] loss=0.9439 recon=0.9434 kl=0.0006\n",
      "[Epoch 068] loss=0.9346 recon=0.9345 kl=0.0001\n",
      "[Epoch 069] loss=0.9303 recon=0.9297 kl=0.0006\n",
      "[Epoch 070] loss=0.9397 recon=0.9390 kl=0.0007\n",
      "[Epoch 071] loss=0.9298 recon=0.9293 kl=0.0005\n",
      "[Epoch 072] loss=0.9310 recon=0.9305 kl=0.0004\n",
      "[Epoch 073] loss=0.9353 recon=0.9348 kl=0.0005\n",
      "[Epoch 074] loss=0.9262 recon=0.9259 kl=0.0003\n",
      "[Epoch 075] loss=0.9520 recon=0.9515 kl=0.0004\n",
      "[Epoch 076] loss=0.9264 recon=0.9257 kl=0.0007\n",
      "[Epoch 077] loss=0.9396 recon=0.9392 kl=0.0004\n",
      "[Epoch 078] loss=0.9386 recon=0.9383 kl=0.0003\n",
      "[Epoch 079] loss=0.9284 recon=0.9279 kl=0.0005\n",
      "[Epoch 080] loss=0.9291 recon=0.9287 kl=0.0004\n",
      "[Epoch 081] loss=0.9246 recon=0.9240 kl=0.0005\n",
      "[Epoch 082] loss=0.9454 recon=0.9451 kl=0.0002\n",
      "[Epoch 083] loss=0.9233 recon=0.9227 kl=0.0006\n",
      "[Epoch 084] loss=0.9240 recon=0.9235 kl=0.0005\n",
      "[Epoch 085] loss=0.9256 recon=0.9252 kl=0.0005\n",
      "[Epoch 086] loss=0.9266 recon=0.9262 kl=0.0004\n",
      "[Epoch 087] loss=0.9260 recon=0.9255 kl=0.0005\n",
      "[Epoch 088] loss=0.9400 recon=0.9396 kl=0.0004\n",
      "[Epoch 089] loss=0.9387 recon=0.9377 kl=0.0010\n",
      "[Epoch 090] loss=0.9278 recon=0.9272 kl=0.0006\n",
      "40\n",
      "[Epoch 001] loss=1.5601 recon=0.9387 kl=0.6215\n",
      "[Epoch 002] loss=0.9475 recon=0.9441 kl=0.0034\n",
      "[Epoch 003] loss=0.9378 recon=0.9376 kl=0.0003\n",
      "[Epoch 004] loss=0.9309 recon=0.9309 kl=0.0001\n",
      "[Epoch 005] loss=0.9448 recon=0.9446 kl=0.0002\n",
      "[Epoch 006] loss=0.9397 recon=0.9396 kl=0.0001\n",
      "[Epoch 007] loss=0.9309 recon=0.9306 kl=0.0003\n",
      "[Epoch 008] loss=0.9255 recon=0.9254 kl=0.0001\n",
      "[Epoch 009] loss=0.9273 recon=0.9268 kl=0.0005\n",
      "[Epoch 010] loss=0.9336 recon=0.9334 kl=0.0001\n",
      "[Epoch 011] loss=0.9307 recon=0.9305 kl=0.0002\n",
      "[Epoch 012] loss=0.9269 recon=0.9265 kl=0.0004\n",
      "[Epoch 013] loss=0.9273 recon=0.9271 kl=0.0002\n",
      "[Epoch 014] loss=0.9237 recon=0.9233 kl=0.0004\n",
      "[Epoch 015] loss=0.9370 recon=0.9366 kl=0.0004\n",
      "[Epoch 016] loss=0.9276 recon=0.9272 kl=0.0004\n",
      "[Epoch 017] loss=0.9339 recon=0.9336 kl=0.0003\n",
      "[Epoch 018] loss=0.9287 recon=0.9281 kl=0.0006\n",
      "[Epoch 019] loss=0.9380 recon=0.9371 kl=0.0008\n",
      "[Epoch 020] loss=0.9493 recon=0.9472 kl=0.0021\n",
      "[Epoch 021] loss=0.9431 recon=0.9428 kl=0.0003\n",
      "[Epoch 022] loss=0.9371 recon=0.9371 kl=0.0000\n",
      "[Epoch 023] loss=0.9266 recon=0.9262 kl=0.0004\n",
      "[Epoch 024] loss=0.9229 recon=0.9226 kl=0.0003\n",
      "[Epoch 025] loss=0.9322 recon=0.9315 kl=0.0007\n",
      "[Epoch 026] loss=0.9441 recon=0.9437 kl=0.0004\n",
      "[Epoch 027] loss=0.9311 recon=0.9299 kl=0.0012\n",
      "[Epoch 028] loss=0.9404 recon=0.9398 kl=0.0006\n",
      "[Epoch 029] loss=0.9329 recon=0.9329 kl=0.0001\n",
      "[Epoch 030] loss=0.9343 recon=0.9336 kl=0.0007\n",
      "[Epoch 031] loss=0.9348 recon=0.9345 kl=0.0003\n",
      "[Epoch 032] loss=0.9418 recon=0.9408 kl=0.0010\n",
      "[Epoch 033] loss=0.9354 recon=0.9351 kl=0.0003\n",
      "[Epoch 034] loss=0.9498 recon=0.9494 kl=0.0004\n",
      "[Epoch 035] loss=0.9392 recon=0.9383 kl=0.0009\n",
      "[Epoch 036] loss=0.9299 recon=0.9290 kl=0.0009\n",
      "[Epoch 037] loss=0.9305 recon=0.9304 kl=0.0001\n",
      "[Epoch 038] loss=0.9304 recon=0.9297 kl=0.0006\n",
      "[Epoch 039] loss=0.9272 recon=0.9269 kl=0.0003\n",
      "[Epoch 040] loss=0.9396 recon=0.9353 kl=0.0044\n",
      "[Epoch 041] loss=0.9557 recon=0.9526 kl=0.0031\n",
      "[Epoch 042] loss=0.9394 recon=0.9388 kl=0.0007\n",
      "[Epoch 043] loss=0.9378 recon=0.9378 kl=0.0001\n",
      "[Epoch 044] loss=0.9311 recon=0.9311 kl=0.0000\n",
      "[Epoch 045] loss=0.9439 recon=0.9439 kl=0.0000\n",
      "[Epoch 046] loss=0.9470 recon=0.9465 kl=0.0005\n",
      "[Epoch 047] loss=0.9223 recon=0.9215 kl=0.0008\n",
      "[Epoch 048] loss=0.9346 recon=0.9344 kl=0.0001\n",
      "[Epoch 049] loss=0.9254 recon=0.9250 kl=0.0004\n",
      "[Epoch 050] loss=0.9324 recon=0.9316 kl=0.0008\n",
      "[Epoch 051] loss=0.9257 recon=0.9254 kl=0.0004\n",
      "[Epoch 052] loss=0.9312 recon=0.9306 kl=0.0005\n",
      "[Epoch 053] loss=0.9382 recon=0.9377 kl=0.0005\n",
      "[Epoch 054] loss=0.9309 recon=0.9274 kl=0.0034\n",
      "[Epoch 055] loss=0.9277 recon=0.9247 kl=0.0030\n",
      "[Epoch 056] loss=0.9241 recon=0.9220 kl=0.0022\n",
      "[Epoch 057] loss=0.9353 recon=0.9349 kl=0.0004\n",
      "[Epoch 058] loss=0.9348 recon=0.9348 kl=0.0000\n",
      "[Epoch 059] loss=0.9432 recon=0.9432 kl=0.0000\n",
      "[Epoch 060] loss=0.9268 recon=0.9268 kl=0.0000\n",
      "[Epoch 061] loss=0.9274 recon=0.9273 kl=0.0000\n",
      "[Epoch 062] loss=0.9313 recon=0.9284 kl=0.0028\n",
      "[Epoch 063] loss=0.9326 recon=0.9294 kl=0.0033\n",
      "[Epoch 064] loss=0.9609 recon=0.9596 kl=0.0013\n",
      "[Epoch 065] loss=0.9415 recon=0.9414 kl=0.0001\n",
      "[Epoch 066] loss=0.9457 recon=0.9457 kl=0.0000\n",
      "[Epoch 067] loss=0.9280 recon=0.9280 kl=0.0000\n",
      "[Epoch 068] loss=0.9436 recon=0.9436 kl=0.0000\n",
      "[Epoch 069] loss=0.9398 recon=0.9392 kl=0.0007\n",
      "[Epoch 070] loss=0.9583 recon=0.9579 kl=0.0004\n",
      "[Epoch 071] loss=0.9345 recon=0.9306 kl=0.0039\n",
      "[Epoch 072] loss=0.9376 recon=0.9351 kl=0.0024\n",
      "[Epoch 073] loss=0.9419 recon=0.9410 kl=0.0009\n",
      "[Epoch 074] loss=0.9350 recon=0.9349 kl=0.0001\n",
      "[Epoch 075] loss=0.9389 recon=0.9389 kl=0.0000\n",
      "[Epoch 076] loss=0.9232 recon=0.9232 kl=0.0000\n",
      "[Epoch 077] loss=0.9209 recon=0.9207 kl=0.0002\n",
      "[Epoch 078] loss=0.9363 recon=0.9356 kl=0.0006\n",
      "[Epoch 079] loss=0.9370 recon=0.9365 kl=0.0004\n",
      "[Epoch 080] loss=0.9237 recon=0.9235 kl=0.0002\n",
      "[Epoch 081] loss=0.9443 recon=0.9436 kl=0.0007\n",
      "[Epoch 082] loss=0.9295 recon=0.9291 kl=0.0003\n",
      "[Epoch 083] loss=0.9356 recon=0.9355 kl=0.0001\n",
      "[Epoch 084] loss=0.9304 recon=0.9297 kl=0.0007\n",
      "[Epoch 085] loss=0.9210 recon=0.9208 kl=0.0002\n",
      "[Epoch 086] loss=0.9268 recon=0.9263 kl=0.0005\n",
      "[Epoch 087] loss=0.9336 recon=0.9332 kl=0.0004\n",
      "[Epoch 088] loss=0.9207 recon=0.9200 kl=0.0007\n",
      "[Epoch 089] loss=0.9309 recon=0.9308 kl=0.0001\n",
      "[Epoch 090] loss=0.9482 recon=0.9477 kl=0.0005\n",
      "41\n",
      "[Epoch 001] loss=1.3676 recon=0.9352 kl=0.4324\n",
      "[Epoch 002] loss=0.9380 recon=0.9350 kl=0.0030\n",
      "[Epoch 003] loss=0.9394 recon=0.9391 kl=0.0003\n",
      "[Epoch 004] loss=0.9347 recon=0.9346 kl=0.0001\n",
      "[Epoch 005] loss=0.9436 recon=0.9434 kl=0.0002\n",
      "[Epoch 006] loss=0.9356 recon=0.9355 kl=0.0001\n",
      "[Epoch 007] loss=0.9527 recon=0.9524 kl=0.0003\n",
      "[Epoch 008] loss=0.9271 recon=0.9267 kl=0.0004\n",
      "[Epoch 009] loss=0.9281 recon=0.9279 kl=0.0002\n",
      "[Epoch 010] loss=0.9271 recon=0.9266 kl=0.0005\n",
      "[Epoch 011] loss=0.9266 recon=0.9265 kl=0.0001\n",
      "[Epoch 012] loss=0.9306 recon=0.9302 kl=0.0004\n",
      "[Epoch 013] loss=0.9359 recon=0.9356 kl=0.0003\n",
      "[Epoch 014] loss=0.9231 recon=0.9227 kl=0.0004\n",
      "[Epoch 015] loss=0.9332 recon=0.9327 kl=0.0005\n",
      "[Epoch 016] loss=0.9438 recon=0.9433 kl=0.0005\n",
      "[Epoch 017] loss=0.9329 recon=0.9326 kl=0.0002\n",
      "[Epoch 018] loss=0.9335 recon=0.9330 kl=0.0005\n",
      "[Epoch 019] loss=0.9294 recon=0.9289 kl=0.0005\n",
      "[Epoch 020] loss=0.9399 recon=0.9393 kl=0.0005\n",
      "[Epoch 021] loss=0.9542 recon=0.9535 kl=0.0006\n",
      "[Epoch 022] loss=0.9320 recon=0.9317 kl=0.0004\n",
      "[Epoch 023] loss=0.9419 recon=0.9414 kl=0.0006\n",
      "[Epoch 024] loss=0.9338 recon=0.9334 kl=0.0005\n",
      "[Epoch 025] loss=0.9363 recon=0.9355 kl=0.0008\n",
      "[Epoch 026] loss=0.9298 recon=0.9295 kl=0.0003\n",
      "[Epoch 027] loss=0.9335 recon=0.9329 kl=0.0006\n",
      "[Epoch 028] loss=0.9255 recon=0.9249 kl=0.0006\n",
      "[Epoch 029] loss=0.9483 recon=0.9474 kl=0.0008\n",
      "[Epoch 030] loss=0.9265 recon=0.9260 kl=0.0005\n",
      "[Epoch 031] loss=0.9360 recon=0.9356 kl=0.0004\n",
      "[Epoch 032] loss=0.9260 recon=0.9253 kl=0.0006\n",
      "[Epoch 033] loss=0.9336 recon=0.9328 kl=0.0008\n",
      "[Epoch 034] loss=0.9394 recon=0.9392 kl=0.0003\n",
      "[Epoch 035] loss=0.9338 recon=0.9328 kl=0.0010\n",
      "[Epoch 036] loss=0.9587 recon=0.9547 kl=0.0039\n",
      "[Epoch 037] loss=0.9394 recon=0.9372 kl=0.0022\n",
      "[Epoch 038] loss=0.9195 recon=0.9185 kl=0.0010\n",
      "[Epoch 039] loss=0.9268 recon=0.9267 kl=0.0001\n",
      "[Epoch 040] loss=0.9357 recon=0.9357 kl=0.0000\n",
      "[Epoch 041] loss=0.9180 recon=0.9180 kl=0.0000\n",
      "[Epoch 042] loss=0.9249 recon=0.9240 kl=0.0010\n",
      "[Epoch 043] loss=0.9307 recon=0.9304 kl=0.0003\n",
      "[Epoch 044] loss=0.9270 recon=0.9260 kl=0.0009\n",
      "[Epoch 045] loss=0.9351 recon=0.9347 kl=0.0005\n",
      "[Epoch 046] loss=0.9362 recon=0.9361 kl=0.0001\n",
      "[Epoch 047] loss=0.9415 recon=0.9408 kl=0.0007\n",
      "[Epoch 048] loss=0.9359 recon=0.9351 kl=0.0008\n",
      "[Epoch 049] loss=0.9345 recon=0.9343 kl=0.0002\n",
      "[Epoch 050] loss=0.9206 recon=0.9201 kl=0.0005\n",
      "[Epoch 051] loss=0.9572 recon=0.9562 kl=0.0010\n",
      "[Epoch 052] loss=0.9474 recon=0.9469 kl=0.0005\n",
      "[Epoch 053] loss=0.9344 recon=0.9337 kl=0.0007\n",
      "[Epoch 054] loss=0.9329 recon=0.9322 kl=0.0006\n",
      "[Epoch 055] loss=0.9322 recon=0.9318 kl=0.0004\n",
      "[Epoch 056] loss=0.9362 recon=0.9357 kl=0.0006\n",
      "[Epoch 057] loss=0.9261 recon=0.9255 kl=0.0006\n",
      "[Epoch 058] loss=0.9535 recon=0.9530 kl=0.0005\n",
      "[Epoch 059] loss=0.9296 recon=0.9284 kl=0.0012\n",
      "[Epoch 060] loss=0.9427 recon=0.9421 kl=0.0006\n",
      "[Epoch 061] loss=0.9343 recon=0.9313 kl=0.0030\n",
      "[Epoch 062] loss=0.9331 recon=0.9306 kl=0.0025\n",
      "[Epoch 063] loss=0.9381 recon=0.9370 kl=0.0011\n",
      "[Epoch 064] loss=0.9288 recon=0.9287 kl=0.0001\n",
      "[Epoch 065] loss=0.9339 recon=0.9339 kl=0.0000\n",
      "[Epoch 066] loss=0.9416 recon=0.9416 kl=0.0000\n",
      "[Epoch 067] loss=0.9411 recon=0.9405 kl=0.0006\n",
      "[Epoch 068] loss=0.9344 recon=0.9338 kl=0.0006\n",
      "[Epoch 069] loss=0.9170 recon=0.9167 kl=0.0003\n",
      "[Epoch 070] loss=0.9341 recon=0.9334 kl=0.0007\n",
      "[Epoch 071] loss=0.9333 recon=0.9329 kl=0.0004\n",
      "[Epoch 072] loss=0.9371 recon=0.9363 kl=0.0008\n",
      "[Epoch 073] loss=0.9265 recon=0.9264 kl=0.0001\n",
      "[Epoch 074] loss=0.9495 recon=0.9487 kl=0.0008\n",
      "[Epoch 075] loss=0.9275 recon=0.9272 kl=0.0004\n",
      "[Epoch 076] loss=0.9438 recon=0.9434 kl=0.0004\n",
      "[Epoch 077] loss=0.9300 recon=0.9293 kl=0.0007\n",
      "[Epoch 078] loss=0.9292 recon=0.9289 kl=0.0003\n",
      "[Epoch 079] loss=0.9247 recon=0.9239 kl=0.0008\n",
      "[Epoch 080] loss=0.9501 recon=0.9496 kl=0.0005\n",
      "[Epoch 081] loss=0.9374 recon=0.9354 kl=0.0020\n",
      "[Epoch 082] loss=0.9217 recon=0.9183 kl=0.0034\n",
      "[Epoch 083] loss=0.9326 recon=0.9298 kl=0.0028\n",
      "[Epoch 084] loss=0.9261 recon=0.9240 kl=0.0021\n",
      "[Epoch 085] loss=0.9383 recon=0.9374 kl=0.0009\n",
      "[Epoch 086] loss=0.9316 recon=0.9314 kl=0.0002\n",
      "[Epoch 087] loss=0.9297 recon=0.9296 kl=0.0000\n",
      "[Epoch 088] loss=0.9344 recon=0.9344 kl=0.0000\n",
      "[Epoch 089] loss=0.9251 recon=0.9251 kl=0.0000\n",
      "[Epoch 090] loss=0.9261 recon=0.9259 kl=0.0002\n",
      "42\n",
      "[Epoch 001] loss=1.1318 recon=0.9367 kl=0.1951\n",
      "[Epoch 002] loss=0.9403 recon=0.9383 kl=0.0020\n",
      "[Epoch 003] loss=0.9394 recon=0.9392 kl=0.0002\n",
      "[Epoch 004] loss=0.9301 recon=0.9298 kl=0.0003\n",
      "[Epoch 005] loss=0.9242 recon=0.9242 kl=0.0001\n",
      "[Epoch 006] loss=0.9297 recon=0.9295 kl=0.0001\n",
      "[Epoch 007] loss=0.9395 recon=0.9393 kl=0.0002\n",
      "[Epoch 008] loss=0.9472 recon=0.9469 kl=0.0003\n",
      "[Epoch 009] loss=0.9490 recon=0.9486 kl=0.0004\n",
      "[Epoch 010] loss=0.9341 recon=0.9340 kl=0.0001\n",
      "[Epoch 011] loss=0.9263 recon=0.9259 kl=0.0003\n",
      "[Epoch 012] loss=0.9343 recon=0.9339 kl=0.0005\n",
      "[Epoch 013] loss=0.9343 recon=0.9341 kl=0.0002\n",
      "[Epoch 014] loss=0.9458 recon=0.9451 kl=0.0007\n",
      "[Epoch 015] loss=0.9332 recon=0.9331 kl=0.0001\n",
      "[Epoch 016] loss=0.9441 recon=0.9435 kl=0.0006\n",
      "[Epoch 017] loss=0.9510 recon=0.9507 kl=0.0003\n",
      "[Epoch 018] loss=0.9197 recon=0.9192 kl=0.0005\n",
      "[Epoch 019] loss=0.9358 recon=0.9354 kl=0.0004\n",
      "[Epoch 020] loss=0.9427 recon=0.9409 kl=0.0019\n",
      "[Epoch 021] loss=0.9389 recon=0.9365 kl=0.0024\n",
      "[Epoch 022] loss=0.9229 recon=0.9221 kl=0.0007\n",
      "[Epoch 023] loss=0.9350 recon=0.9349 kl=0.0001\n",
      "[Epoch 024] loss=0.9358 recon=0.9358 kl=0.0000\n",
      "[Epoch 025] loss=0.9230 recon=0.9229 kl=0.0001\n",
      "[Epoch 026] loss=0.9239 recon=0.9232 kl=0.0006\n",
      "[Epoch 027] loss=0.9385 recon=0.9380 kl=0.0005\n",
      "[Epoch 028] loss=0.9320 recon=0.9311 kl=0.0010\n",
      "[Epoch 029] loss=0.9425 recon=0.9423 kl=0.0002\n",
      "[Epoch 030] loss=0.9418 recon=0.9395 kl=0.0022\n",
      "[Epoch 031] loss=0.9599 recon=0.9585 kl=0.0015\n",
      "[Epoch 032] loss=0.9259 recon=0.9258 kl=0.0001\n",
      "[Epoch 033] loss=0.9265 recon=0.9265 kl=0.0000\n",
      "[Epoch 034] loss=0.9315 recon=0.9250 kl=0.0065\n",
      "[Epoch 035] loss=0.9461 recon=0.9390 kl=0.0071\n",
      "[Epoch 036] loss=0.9314 recon=0.9301 kl=0.0013\n",
      "[Epoch 037] loss=0.9239 recon=0.9238 kl=0.0001\n",
      "[Epoch 038] loss=0.9349 recon=0.9349 kl=0.0000\n",
      "[Epoch 039] loss=0.9337 recon=0.9337 kl=0.0000\n",
      "[Epoch 040] loss=0.9472 recon=0.9472 kl=0.0000\n",
      "[Epoch 041] loss=0.9267 recon=0.9265 kl=0.0002\n",
      "[Epoch 042] loss=0.9294 recon=0.9291 kl=0.0003\n",
      "[Epoch 043] loss=0.9296 recon=0.9289 kl=0.0007\n",
      "[Epoch 044] loss=0.9243 recon=0.9232 kl=0.0011\n",
      "[Epoch 045] loss=0.9387 recon=0.9345 kl=0.0042\n",
      "[Epoch 046] loss=0.9392 recon=0.9386 kl=0.0006\n",
      "[Epoch 047] loss=0.9135 recon=0.9135 kl=0.0001\n",
      "[Epoch 048] loss=0.9293 recon=0.9293 kl=0.0000\n",
      "[Epoch 049] loss=0.9257 recon=0.9232 kl=0.0025\n",
      "[Epoch 050] loss=0.9246 recon=0.9215 kl=0.0031\n",
      "[Epoch 051] loss=0.9325 recon=0.9324 kl=0.0002\n",
      "[Epoch 052] loss=0.9305 recon=0.9305 kl=0.0000\n",
      "[Epoch 053] loss=0.9255 recon=0.9255 kl=0.0000\n",
      "[Epoch 054] loss=0.9259 recon=0.9256 kl=0.0003\n",
      "[Epoch 055] loss=0.9276 recon=0.9267 kl=0.0008\n",
      "[Epoch 056] loss=0.9243 recon=0.9240 kl=0.0004\n",
      "[Epoch 057] loss=0.9276 recon=0.9246 kl=0.0029\n",
      "[Epoch 058] loss=0.9325 recon=0.9295 kl=0.0030\n",
      "[Epoch 059] loss=0.9391 recon=0.9375 kl=0.0015\n",
      "[Epoch 060] loss=0.9490 recon=0.9488 kl=0.0001\n",
      "[Epoch 061] loss=0.9420 recon=0.9420 kl=0.0000\n",
      "[Epoch 062] loss=0.9503 recon=0.9503 kl=0.0000\n",
      "[Epoch 063] loss=0.9316 recon=0.9313 kl=0.0003\n",
      "[Epoch 064] loss=0.9292 recon=0.9278 kl=0.0014\n",
      "[Epoch 065] loss=0.9341 recon=0.9334 kl=0.0007\n",
      "[Epoch 066] loss=0.9213 recon=0.9212 kl=0.0001\n",
      "[Epoch 067] loss=0.9389 recon=0.9379 kl=0.0011\n",
      "[Epoch 068] loss=0.9328 recon=0.9303 kl=0.0025\n",
      "[Epoch 069] loss=0.9348 recon=0.9346 kl=0.0002\n",
      "[Epoch 070] loss=0.9239 recon=0.9239 kl=0.0000\n",
      "[Epoch 071] loss=0.9325 recon=0.9322 kl=0.0003\n",
      "[Epoch 072] loss=0.9186 recon=0.9180 kl=0.0006\n",
      "[Epoch 073] loss=0.9432 recon=0.9430 kl=0.0002\n",
      "[Epoch 074] loss=0.9355 recon=0.9351 kl=0.0004\n",
      "[Epoch 075] loss=0.9287 recon=0.9283 kl=0.0004\n",
      "[Epoch 076] loss=0.9356 recon=0.9350 kl=0.0006\n",
      "[Epoch 077] loss=0.9476 recon=0.9475 kl=0.0001\n",
      "[Epoch 078] loss=0.9277 recon=0.9274 kl=0.0003\n",
      "[Epoch 079] loss=0.9277 recon=0.9272 kl=0.0005\n",
      "[Epoch 080] loss=0.9279 recon=0.9274 kl=0.0005\n",
      "[Epoch 081] loss=0.9316 recon=0.9312 kl=0.0004\n",
      "[Epoch 082] loss=0.9432 recon=0.9428 kl=0.0005\n",
      "[Epoch 083] loss=0.9388 recon=0.9387 kl=0.0001\n",
      "[Epoch 084] loss=0.9278 recon=0.9271 kl=0.0007\n",
      "[Epoch 085] loss=0.9438 recon=0.9436 kl=0.0002\n",
      "[Epoch 086] loss=0.9493 recon=0.9483 kl=0.0009\n",
      "[Epoch 087] loss=0.9231 recon=0.9225 kl=0.0006\n",
      "[Epoch 088] loss=0.9398 recon=0.9397 kl=0.0001\n",
      "[Epoch 089] loss=0.9183 recon=0.9177 kl=0.0006\n",
      "[Epoch 090] loss=0.9328 recon=0.9321 kl=0.0006\n",
      "43\n",
      "[Epoch 001] loss=1.1734 recon=0.9340 kl=0.2394\n",
      "[Epoch 002] loss=0.9405 recon=0.9384 kl=0.0021\n",
      "[Epoch 003] loss=0.9368 recon=0.9367 kl=0.0002\n",
      "[Epoch 004] loss=0.9403 recon=0.9402 kl=0.0001\n",
      "[Epoch 005] loss=0.9442 recon=0.9441 kl=0.0001\n",
      "[Epoch 006] loss=0.9333 recon=0.9332 kl=0.0001\n",
      "[Epoch 007] loss=0.9257 recon=0.9256 kl=0.0001\n",
      "[Epoch 008] loss=0.9382 recon=0.9380 kl=0.0002\n",
      "[Epoch 009] loss=0.9410 recon=0.9408 kl=0.0003\n",
      "[Epoch 010] loss=0.9241 recon=0.9238 kl=0.0003\n",
      "[Epoch 011] loss=0.9416 recon=0.9415 kl=0.0001\n",
      "[Epoch 012] loss=0.9472 recon=0.9469 kl=0.0003\n",
      "[Epoch 013] loss=0.9301 recon=0.9299 kl=0.0002\n",
      "[Epoch 014] loss=0.9279 recon=0.9274 kl=0.0004\n",
      "[Epoch 015] loss=0.9411 recon=0.9409 kl=0.0002\n",
      "[Epoch 016] loss=0.9358 recon=0.9354 kl=0.0004\n",
      "[Epoch 017] loss=0.9452 recon=0.9448 kl=0.0004\n",
      "[Epoch 018] loss=0.9309 recon=0.9306 kl=0.0003\n",
      "[Epoch 019] loss=0.9333 recon=0.9329 kl=0.0004\n",
      "[Epoch 020] loss=0.9370 recon=0.9365 kl=0.0005\n",
      "[Epoch 021] loss=0.9335 recon=0.9331 kl=0.0004\n",
      "[Epoch 022] loss=0.9210 recon=0.9205 kl=0.0005\n",
      "[Epoch 023] loss=0.9281 recon=0.9273 kl=0.0008\n",
      "[Epoch 024] loss=0.9382 recon=0.9381 kl=0.0001\n",
      "[Epoch 025] loss=0.9335 recon=0.9329 kl=0.0006\n",
      "[Epoch 026] loss=0.9245 recon=0.9240 kl=0.0005\n",
      "[Epoch 027] loss=0.9373 recon=0.9368 kl=0.0005\n",
      "[Epoch 028] loss=0.9435 recon=0.9432 kl=0.0003\n",
      "[Epoch 029] loss=0.9341 recon=0.9332 kl=0.0009\n",
      "[Epoch 030] loss=0.9289 recon=0.9288 kl=0.0001\n",
      "[Epoch 031] loss=0.9561 recon=0.9555 kl=0.0006\n",
      "[Epoch 032] loss=0.9533 recon=0.9531 kl=0.0002\n",
      "[Epoch 033] loss=0.9346 recon=0.9313 kl=0.0033\n",
      "[Epoch 034] loss=0.9418 recon=0.9380 kl=0.0038\n",
      "[Epoch 035] loss=0.9325 recon=0.9319 kl=0.0006\n",
      "[Epoch 036] loss=0.9331 recon=0.9330 kl=0.0001\n",
      "[Epoch 037] loss=0.9367 recon=0.9367 kl=0.0000\n",
      "[Epoch 038] loss=0.9303 recon=0.9303 kl=0.0000\n",
      "[Epoch 039] loss=0.9218 recon=0.9217 kl=0.0001\n",
      "[Epoch 040] loss=0.9252 recon=0.9237 kl=0.0014\n",
      "[Epoch 041] loss=0.9337 recon=0.9304 kl=0.0033\n",
      "[Epoch 042] loss=0.9209 recon=0.9197 kl=0.0012\n",
      "[Epoch 043] loss=0.9378 recon=0.9377 kl=0.0001\n",
      "[Epoch 044] loss=0.9596 recon=0.9596 kl=0.0000\n",
      "[Epoch 045] loss=0.9312 recon=0.9311 kl=0.0001\n",
      "[Epoch 046] loss=0.9357 recon=0.9345 kl=0.0012\n",
      "[Epoch 047] loss=0.9323 recon=0.9321 kl=0.0002\n",
      "[Epoch 048] loss=0.9384 recon=0.9380 kl=0.0004\n",
      "[Epoch 049] loss=0.9272 recon=0.9271 kl=0.0001\n",
      "[Epoch 050] loss=0.9319 recon=0.9315 kl=0.0005\n",
      "[Epoch 051] loss=0.9308 recon=0.9302 kl=0.0007\n",
      "[Epoch 052] loss=0.9362 recon=0.9345 kl=0.0017\n",
      "[Epoch 053] loss=0.9307 recon=0.9273 kl=0.0034\n",
      "[Epoch 054] loss=0.9393 recon=0.9378 kl=0.0015\n",
      "[Epoch 055] loss=0.9412 recon=0.9411 kl=0.0002\n",
      "[Epoch 056] loss=0.9264 recon=0.9264 kl=0.0000\n",
      "[Epoch 057] loss=0.9292 recon=0.9292 kl=0.0000\n",
      "[Epoch 058] loss=0.9216 recon=0.9216 kl=0.0000\n",
      "[Epoch 059] loss=0.9277 recon=0.9270 kl=0.0006\n",
      "[Epoch 060] loss=0.9423 recon=0.9420 kl=0.0003\n",
      "[Epoch 061] loss=0.9465 recon=0.9461 kl=0.0004\n",
      "[Epoch 062] loss=0.9321 recon=0.9314 kl=0.0007\n",
      "[Epoch 063] loss=0.9304 recon=0.9302 kl=0.0002\n",
      "[Epoch 064] loss=0.9237 recon=0.9234 kl=0.0003\n",
      "[Epoch 065] loss=0.9397 recon=0.9392 kl=0.0005\n",
      "[Epoch 066] loss=0.9319 recon=0.9310 kl=0.0009\n",
      "[Epoch 067] loss=0.9237 recon=0.9236 kl=0.0001\n",
      "[Epoch 068] loss=0.9210 recon=0.9209 kl=0.0001\n",
      "[Epoch 069] loss=0.9261 recon=0.9249 kl=0.0013\n",
      "[Epoch 070] loss=0.9293 recon=0.9287 kl=0.0006\n",
      "[Epoch 071] loss=0.9391 recon=0.9388 kl=0.0003\n",
      "[Epoch 072] loss=0.9305 recon=0.9301 kl=0.0003\n",
      "[Epoch 073] loss=0.9242 recon=0.9236 kl=0.0006\n",
      "[Epoch 074] loss=0.9455 recon=0.9454 kl=0.0001\n",
      "[Epoch 075] loss=0.9287 recon=0.9279 kl=0.0008\n",
      "[Epoch 076] loss=0.9480 recon=0.9478 kl=0.0002\n",
      "[Epoch 077] loss=0.9476 recon=0.9469 kl=0.0007\n",
      "[Epoch 078] loss=0.9239 recon=0.9237 kl=0.0002\n",
      "[Epoch 079] loss=0.9360 recon=0.9355 kl=0.0005\n",
      "[Epoch 080] loss=0.9438 recon=0.9436 kl=0.0002\n",
      "[Epoch 081] loss=0.9262 recon=0.9256 kl=0.0006\n",
      "[Epoch 082] loss=0.9431 recon=0.9426 kl=0.0005\n",
      "[Epoch 083] loss=0.9266 recon=0.9261 kl=0.0005\n",
      "[Epoch 084] loss=0.9345 recon=0.9341 kl=0.0004\n",
      "[Epoch 085] loss=0.9300 recon=0.9290 kl=0.0011\n",
      "[Epoch 086] loss=0.9336 recon=0.9331 kl=0.0004\n",
      "[Epoch 087] loss=0.9348 recon=0.9347 kl=0.0001\n",
      "[Epoch 088] loss=0.9604 recon=0.9566 kl=0.0038\n",
      "[Epoch 089] loss=0.9510 recon=0.9483 kl=0.0027\n",
      "[Epoch 090] loss=0.9552 recon=0.9545 kl=0.0007\n",
      "44\n",
      "[Epoch 001] loss=1.1969 recon=0.9275 kl=0.2694\n",
      "[Epoch 002] loss=0.9566 recon=0.9547 kl=0.0019\n",
      "[Epoch 003] loss=0.9317 recon=0.9315 kl=0.0002\n",
      "[Epoch 004] loss=0.9337 recon=0.9336 kl=0.0000\n",
      "[Epoch 005] loss=0.9311 recon=0.9310 kl=0.0001\n",
      "[Epoch 006] loss=0.9352 recon=0.9351 kl=0.0001\n",
      "[Epoch 007] loss=0.9294 recon=0.9290 kl=0.0004\n",
      "[Epoch 008] loss=0.9503 recon=0.9502 kl=0.0001\n",
      "[Epoch 009] loss=0.9555 recon=0.9555 kl=0.0000\n",
      "[Epoch 010] loss=0.9256 recon=0.9253 kl=0.0003\n",
      "[Epoch 011] loss=0.9476 recon=0.9474 kl=0.0002\n",
      "[Epoch 012] loss=0.9254 recon=0.9251 kl=0.0004\n",
      "[Epoch 013] loss=0.9249 recon=0.9247 kl=0.0002\n",
      "[Epoch 014] loss=0.9209 recon=0.9206 kl=0.0003\n",
      "[Epoch 015] loss=0.9393 recon=0.9388 kl=0.0005\n",
      "[Epoch 016] loss=0.9269 recon=0.9268 kl=0.0001\n",
      "[Epoch 017] loss=0.9274 recon=0.9264 kl=0.0010\n",
      "[Epoch 018] loss=0.9427 recon=0.9425 kl=0.0002\n",
      "[Epoch 019] loss=0.9245 recon=0.9239 kl=0.0006\n",
      "[Epoch 020] loss=0.9605 recon=0.9604 kl=0.0001\n",
      "[Epoch 021] loss=0.9410 recon=0.9402 kl=0.0007\n",
      "[Epoch 022] loss=0.9282 recon=0.9276 kl=0.0006\n",
      "[Epoch 023] loss=0.9409 recon=0.9406 kl=0.0003\n",
      "[Epoch 024] loss=0.9338 recon=0.9333 kl=0.0005\n",
      "[Epoch 025] loss=0.9400 recon=0.9396 kl=0.0005\n",
      "[Epoch 026] loss=0.9368 recon=0.9363 kl=0.0005\n",
      "[Epoch 027] loss=0.9353 recon=0.9351 kl=0.0002\n",
      "[Epoch 028] loss=0.9307 recon=0.9298 kl=0.0009\n",
      "[Epoch 029] loss=0.9342 recon=0.9338 kl=0.0004\n",
      "[Epoch 030] loss=0.9245 recon=0.9243 kl=0.0002\n",
      "[Epoch 031] loss=0.9364 recon=0.9336 kl=0.0028\n",
      "[Epoch 032] loss=0.9347 recon=0.9329 kl=0.0018\n",
      "[Epoch 033] loss=0.9269 recon=0.9268 kl=0.0001\n",
      "[Epoch 034] loss=0.9402 recon=0.9402 kl=0.0000\n",
      "[Epoch 035] loss=0.9615 recon=0.9609 kl=0.0005\n",
      "[Epoch 036] loss=0.9290 recon=0.9286 kl=0.0004\n",
      "[Epoch 037] loss=0.9306 recon=0.9304 kl=0.0002\n",
      "[Epoch 038] loss=0.9277 recon=0.9271 kl=0.0006\n",
      "[Epoch 039] loss=0.9463 recon=0.9456 kl=0.0007\n",
      "[Epoch 040] loss=0.9507 recon=0.9498 kl=0.0009\n",
      "[Epoch 041] loss=0.9727 recon=0.9725 kl=0.0002\n",
      "[Epoch 042] loss=0.9282 recon=0.9270 kl=0.0012\n",
      "[Epoch 043] loss=0.9422 recon=0.9419 kl=0.0004\n",
      "[Epoch 044] loss=0.9320 recon=0.9277 kl=0.0043\n",
      "[Epoch 045] loss=0.9408 recon=0.9366 kl=0.0042\n",
      "[Epoch 046] loss=0.9460 recon=0.9457 kl=0.0003\n",
      "[Epoch 047] loss=0.9323 recon=0.9322 kl=0.0000\n",
      "[Epoch 048] loss=0.9614 recon=0.9611 kl=0.0003\n",
      "[Epoch 049] loss=0.9337 recon=0.9330 kl=0.0007\n",
      "[Epoch 050] loss=0.9222 recon=0.9221 kl=0.0002\n",
      "[Epoch 051] loss=0.9245 recon=0.9241 kl=0.0003\n",
      "[Epoch 052] loss=0.9423 recon=0.9399 kl=0.0024\n",
      "[Epoch 053] loss=0.9448 recon=0.9437 kl=0.0011\n",
      "[Epoch 054] loss=0.9385 recon=0.9384 kl=0.0001\n",
      "[Epoch 055] loss=0.9330 recon=0.9330 kl=0.0000\n",
      "[Epoch 056] loss=0.9319 recon=0.9311 kl=0.0008\n",
      "[Epoch 057] loss=0.9405 recon=0.9393 kl=0.0012\n",
      "[Epoch 058] loss=0.9350 recon=0.9348 kl=0.0003\n",
      "[Epoch 059] loss=0.9399 recon=0.9396 kl=0.0003\n",
      "[Epoch 060] loss=0.9364 recon=0.9357 kl=0.0007\n",
      "[Epoch 061] loss=0.9355 recon=0.9351 kl=0.0004\n",
      "[Epoch 062] loss=0.9448 recon=0.9445 kl=0.0003\n",
      "[Epoch 063] loss=0.9266 recon=0.9261 kl=0.0006\n",
      "[Epoch 064] loss=0.9265 recon=0.9260 kl=0.0005\n",
      "[Epoch 065] loss=0.9359 recon=0.9357 kl=0.0002\n",
      "[Epoch 066] loss=0.9254 recon=0.9249 kl=0.0005\n",
      "[Epoch 067] loss=0.9231 recon=0.9229 kl=0.0003\n",
      "[Epoch 068] loss=0.9330 recon=0.9315 kl=0.0015\n",
      "[Epoch 069] loss=0.9344 recon=0.9310 kl=0.0034\n",
      "[Epoch 070] loss=0.9393 recon=0.9386 kl=0.0007\n",
      "[Epoch 071] loss=0.9334 recon=0.9333 kl=0.0001\n",
      "[Epoch 072] loss=0.9394 recon=0.9393 kl=0.0000\n",
      "[Epoch 073] loss=0.9556 recon=0.9556 kl=0.0000\n",
      "[Epoch 074] loss=0.9351 recon=0.9344 kl=0.0007\n",
      "[Epoch 075] loss=0.9356 recon=0.9350 kl=0.0006\n",
      "[Epoch 076] loss=0.9582 recon=0.9581 kl=0.0001\n",
      "[Epoch 077] loss=0.9339 recon=0.9334 kl=0.0005\n",
      "[Epoch 078] loss=0.9298 recon=0.9296 kl=0.0002\n",
      "[Epoch 079] loss=0.9277 recon=0.9269 kl=0.0008\n",
      "[Epoch 080] loss=0.9302 recon=0.9299 kl=0.0003\n",
      "[Epoch 081] loss=0.9239 recon=0.9234 kl=0.0005\n",
      "[Epoch 082] loss=0.9298 recon=0.9295 kl=0.0003\n",
      "[Epoch 083] loss=0.9344 recon=0.9339 kl=0.0006\n",
      "[Epoch 084] loss=0.9208 recon=0.9202 kl=0.0006\n",
      "[Epoch 085] loss=0.9251 recon=0.9250 kl=0.0001\n",
      "[Epoch 086] loss=0.9268 recon=0.9231 kl=0.0037\n",
      "[Epoch 087] loss=0.9539 recon=0.9530 kl=0.0009\n",
      "[Epoch 088] loss=0.9263 recon=0.9262 kl=0.0001\n",
      "[Epoch 089] loss=0.9481 recon=0.9481 kl=0.0000\n",
      "[Epoch 090] loss=0.9212 recon=0.9212 kl=0.0001\n",
      "45\n",
      "[Epoch 001] loss=1.4959 recon=0.9472 kl=0.5487\n",
      "[Epoch 002] loss=0.9441 recon=0.9402 kl=0.0038\n",
      "[Epoch 003] loss=0.9498 recon=0.9493 kl=0.0005\n",
      "[Epoch 004] loss=0.9526 recon=0.9524 kl=0.0002\n",
      "[Epoch 005] loss=0.9320 recon=0.9318 kl=0.0002\n",
      "[Epoch 006] loss=0.9306 recon=0.9305 kl=0.0002\n",
      "[Epoch 007] loss=0.9372 recon=0.9368 kl=0.0004\n",
      "[Epoch 008] loss=0.9353 recon=0.9352 kl=0.0001\n",
      "[Epoch 009] loss=0.9350 recon=0.9346 kl=0.0004\n",
      "[Epoch 010] loss=0.9293 recon=0.9289 kl=0.0004\n",
      "[Epoch 011] loss=0.9523 recon=0.9522 kl=0.0001\n",
      "[Epoch 012] loss=0.9339 recon=0.9334 kl=0.0005\n",
      "[Epoch 013] loss=0.9312 recon=0.9308 kl=0.0004\n",
      "[Epoch 014] loss=0.9278 recon=0.9274 kl=0.0004\n",
      "[Epoch 015] loss=0.9366 recon=0.9364 kl=0.0003\n",
      "[Epoch 016] loss=0.9301 recon=0.9296 kl=0.0004\n",
      "[Epoch 017] loss=0.9342 recon=0.9338 kl=0.0004\n",
      "[Epoch 018] loss=0.9434 recon=0.9428 kl=0.0005\n",
      "[Epoch 019] loss=0.9414 recon=0.9409 kl=0.0005\n",
      "[Epoch 020] loss=0.9241 recon=0.9238 kl=0.0003\n",
      "[Epoch 021] loss=0.9374 recon=0.9369 kl=0.0005\n",
      "[Epoch 022] loss=0.9323 recon=0.9317 kl=0.0006\n",
      "[Epoch 023] loss=0.9224 recon=0.9222 kl=0.0003\n",
      "[Epoch 024] loss=0.9514 recon=0.9507 kl=0.0006\n",
      "[Epoch 025] loss=0.9312 recon=0.9307 kl=0.0005\n",
      "[Epoch 026] loss=0.9453 recon=0.9431 kl=0.0021\n",
      "[Epoch 027] loss=0.9424 recon=0.9395 kl=0.0029\n",
      "[Epoch 028] loss=0.9275 recon=0.9259 kl=0.0017\n",
      "[Epoch 029] loss=0.9289 recon=0.9286 kl=0.0003\n",
      "[Epoch 030] loss=0.9352 recon=0.9352 kl=0.0000\n",
      "[Epoch 031] loss=0.9306 recon=0.9306 kl=0.0000\n",
      "[Epoch 032] loss=0.9254 recon=0.9247 kl=0.0007\n",
      "[Epoch 033] loss=0.9353 recon=0.9350 kl=0.0003\n",
      "[Epoch 034] loss=0.9363 recon=0.9359 kl=0.0004\n",
      "[Epoch 035] loss=0.9294 recon=0.9289 kl=0.0005\n",
      "[Epoch 036] loss=0.9367 recon=0.9363 kl=0.0005\n",
      "[Epoch 037] loss=0.9357 recon=0.9331 kl=0.0026\n",
      "[Epoch 038] loss=0.9397 recon=0.9368 kl=0.0029\n",
      "[Epoch 039] loss=0.9375 recon=0.9370 kl=0.0005\n",
      "[Epoch 040] loss=0.9658 recon=0.9658 kl=0.0000\n",
      "[Epoch 041] loss=0.9261 recon=0.9259 kl=0.0002\n",
      "[Epoch 042] loss=0.9272 recon=0.9268 kl=0.0004\n",
      "[Epoch 043] loss=0.9451 recon=0.9446 kl=0.0006\n",
      "[Epoch 044] loss=0.9322 recon=0.9318 kl=0.0003\n",
      "[Epoch 045] loss=0.9231 recon=0.9223 kl=0.0008\n",
      "[Epoch 046] loss=0.9400 recon=0.9396 kl=0.0003\n",
      "[Epoch 047] loss=0.9393 recon=0.9389 kl=0.0004\n",
      "[Epoch 048] loss=0.9322 recon=0.9316 kl=0.0005\n",
      "[Epoch 049] loss=0.9401 recon=0.9394 kl=0.0007\n",
      "[Epoch 050] loss=0.9516 recon=0.9512 kl=0.0004\n",
      "[Epoch 051] loss=0.9359 recon=0.9354 kl=0.0005\n",
      "[Epoch 052] loss=0.9419 recon=0.9412 kl=0.0007\n",
      "[Epoch 053] loss=0.9458 recon=0.9454 kl=0.0004\n",
      "[Epoch 054] loss=0.9447 recon=0.9440 kl=0.0006\n",
      "[Epoch 055] loss=0.9371 recon=0.9366 kl=0.0005\n",
      "[Epoch 056] loss=0.9345 recon=0.9340 kl=0.0005\n",
      "[Epoch 057] loss=0.9408 recon=0.9404 kl=0.0005\n",
      "[Epoch 058] loss=0.9408 recon=0.9402 kl=0.0007\n",
      "[Epoch 059] loss=0.9194 recon=0.9191 kl=0.0002\n",
      "[Epoch 060] loss=0.9298 recon=0.9291 kl=0.0007\n",
      "[Epoch 061] loss=0.9394 recon=0.9385 kl=0.0008\n",
      "[Epoch 062] loss=0.9362 recon=0.9361 kl=0.0002\n",
      "[Epoch 063] loss=0.9423 recon=0.9417 kl=0.0006\n",
      "[Epoch 064] loss=0.9218 recon=0.9212 kl=0.0006\n",
      "[Epoch 065] loss=0.9260 recon=0.9258 kl=0.0002\n",
      "[Epoch 066] loss=0.9377 recon=0.9371 kl=0.0005\n",
      "[Epoch 067] loss=0.9308 recon=0.9301 kl=0.0007\n",
      "[Epoch 068] loss=0.9489 recon=0.9486 kl=0.0003\n",
      "[Epoch 069] loss=0.9230 recon=0.9223 kl=0.0007\n",
      "[Epoch 070] loss=0.9789 recon=0.9784 kl=0.0005\n",
      "[Epoch 071] loss=0.9295 recon=0.9290 kl=0.0006\n",
      "[Epoch 072] loss=0.9269 recon=0.9264 kl=0.0006\n",
      "[Epoch 073] loss=0.9417 recon=0.9413 kl=0.0004\n",
      "[Epoch 074] loss=0.9411 recon=0.9405 kl=0.0006\n",
      "[Epoch 075] loss=0.9316 recon=0.9312 kl=0.0004\n",
      "[Epoch 076] loss=0.9347 recon=0.9342 kl=0.0005\n",
      "[Epoch 077] loss=0.9252 recon=0.9245 kl=0.0006\n",
      "[Epoch 078] loss=0.9264 recon=0.9260 kl=0.0004\n",
      "[Epoch 079] loss=0.9333 recon=0.9329 kl=0.0004\n",
      "[Epoch 080] loss=0.9396 recon=0.9391 kl=0.0005\n",
      "[Epoch 081] loss=0.9247 recon=0.9239 kl=0.0008\n",
      "[Epoch 082] loss=0.9380 recon=0.9375 kl=0.0005\n",
      "[Epoch 083] loss=0.9443 recon=0.9440 kl=0.0004\n",
      "[Epoch 084] loss=0.9250 recon=0.9244 kl=0.0006\n",
      "[Epoch 085] loss=0.9385 recon=0.9379 kl=0.0005\n",
      "[Epoch 086] loss=0.9283 recon=0.9281 kl=0.0003\n",
      "[Epoch 087] loss=0.9285 recon=0.9273 kl=0.0012\n",
      "[Epoch 088] loss=0.9268 recon=0.9241 kl=0.0027\n",
      "[Epoch 089] loss=0.9569 recon=0.9560 kl=0.0009\n",
      "[Epoch 090] loss=0.9277 recon=0.9276 kl=0.0001\n",
      "46\n",
      "[Epoch 001] loss=1.4315 recon=0.9478 kl=0.4837\n",
      "[Epoch 002] loss=0.9399 recon=0.9356 kl=0.0043\n",
      "[Epoch 003] loss=0.9503 recon=0.9499 kl=0.0004\n",
      "[Epoch 004] loss=0.9328 recon=0.9327 kl=0.0001\n",
      "[Epoch 005] loss=0.9344 recon=0.9343 kl=0.0001\n",
      "[Epoch 006] loss=0.9283 recon=0.9281 kl=0.0003\n",
      "[Epoch 007] loss=0.9399 recon=0.9396 kl=0.0002\n",
      "[Epoch 008] loss=0.9450 recon=0.9449 kl=0.0001\n",
      "[Epoch 009] loss=0.9398 recon=0.9391 kl=0.0006\n",
      "[Epoch 010] loss=0.9315 recon=0.9313 kl=0.0001\n",
      "[Epoch 011] loss=0.9383 recon=0.9379 kl=0.0004\n",
      "[Epoch 012] loss=0.9423 recon=0.9419 kl=0.0004\n",
      "[Epoch 013] loss=0.9255 recon=0.9250 kl=0.0005\n",
      "[Epoch 014] loss=0.9296 recon=0.9292 kl=0.0004\n",
      "[Epoch 015] loss=0.9419 recon=0.9413 kl=0.0006\n",
      "[Epoch 016] loss=0.9318 recon=0.9313 kl=0.0005\n",
      "[Epoch 017] loss=0.9442 recon=0.9425 kl=0.0017\n",
      "[Epoch 018] loss=0.9337 recon=0.9313 kl=0.0024\n",
      "[Epoch 019] loss=0.9362 recon=0.9357 kl=0.0005\n",
      "[Epoch 020] loss=0.9360 recon=0.9359 kl=0.0001\n",
      "[Epoch 021] loss=0.9326 recon=0.9323 kl=0.0003\n",
      "[Epoch 022] loss=0.9337 recon=0.9305 kl=0.0032\n",
      "[Epoch 023] loss=0.9390 recon=0.9372 kl=0.0018\n",
      "[Epoch 024] loss=0.9272 recon=0.9269 kl=0.0002\n",
      "[Epoch 025] loss=0.9341 recon=0.9340 kl=0.0000\n",
      "[Epoch 026] loss=0.9462 recon=0.9462 kl=0.0000\n",
      "[Epoch 027] loss=0.9322 recon=0.9300 kl=0.0022\n",
      "[Epoch 028] loss=0.9377 recon=0.9351 kl=0.0026\n",
      "[Epoch 029] loss=0.9579 recon=0.9563 kl=0.0016\n",
      "[Epoch 030] loss=0.9304 recon=0.9301 kl=0.0002\n",
      "[Epoch 031] loss=0.9248 recon=0.9248 kl=0.0000\n",
      "[Epoch 032] loss=0.9400 recon=0.9400 kl=0.0000\n",
      "[Epoch 033] loss=0.9523 recon=0.9515 kl=0.0008\n",
      "[Epoch 034] loss=0.9274 recon=0.9265 kl=0.0009\n",
      "[Epoch 035] loss=0.9432 recon=0.9430 kl=0.0001\n",
      "[Epoch 036] loss=0.9437 recon=0.9429 kl=0.0008\n",
      "[Epoch 037] loss=0.9359 recon=0.9355 kl=0.0003\n",
      "[Epoch 038] loss=0.9444 recon=0.9438 kl=0.0006\n",
      "[Epoch 039] loss=0.9393 recon=0.9390 kl=0.0003\n",
      "[Epoch 040] loss=0.9415 recon=0.9409 kl=0.0007\n",
      "[Epoch 041] loss=0.9226 recon=0.9216 kl=0.0010\n",
      "[Epoch 042] loss=0.9355 recon=0.9350 kl=0.0005\n",
      "[Epoch 043] loss=0.9411 recon=0.9405 kl=0.0006\n",
      "[Epoch 044] loss=0.9359 recon=0.9355 kl=0.0004\n",
      "[Epoch 045] loss=0.9285 recon=0.9279 kl=0.0006\n",
      "[Epoch 046] loss=0.9424 recon=0.9416 kl=0.0008\n",
      "[Epoch 047] loss=0.9246 recon=0.9244 kl=0.0002\n",
      "[Epoch 048] loss=0.9337 recon=0.9330 kl=0.0007\n",
      "[Epoch 049] loss=0.9413 recon=0.9406 kl=0.0006\n",
      "[Epoch 050] loss=0.9306 recon=0.9302 kl=0.0004\n",
      "[Epoch 051] loss=0.9283 recon=0.9279 kl=0.0004\n",
      "[Epoch 052] loss=0.9460 recon=0.9455 kl=0.0005\n",
      "[Epoch 053] loss=0.9287 recon=0.9277 kl=0.0010\n",
      "[Epoch 054] loss=0.9327 recon=0.9325 kl=0.0002\n",
      "[Epoch 055] loss=0.9442 recon=0.9436 kl=0.0006\n",
      "[Epoch 056] loss=0.9423 recon=0.9416 kl=0.0007\n",
      "[Epoch 057] loss=0.9392 recon=0.9359 kl=0.0033\n",
      "[Epoch 058] loss=0.9423 recon=0.9397 kl=0.0027\n",
      "[Epoch 059] loss=0.9298 recon=0.9286 kl=0.0011\n",
      "[Epoch 060] loss=0.9336 recon=0.9336 kl=0.0001\n",
      "[Epoch 061] loss=0.9394 recon=0.9394 kl=0.0000\n",
      "[Epoch 062] loss=0.9389 recon=0.9389 kl=0.0000\n",
      "[Epoch 063] loss=0.9341 recon=0.9334 kl=0.0007\n",
      "[Epoch 064] loss=0.9225 recon=0.9221 kl=0.0004\n",
      "[Epoch 065] loss=0.9341 recon=0.9335 kl=0.0006\n",
      "[Epoch 066] loss=0.9377 recon=0.9371 kl=0.0005\n",
      "[Epoch 067] loss=0.9380 recon=0.9375 kl=0.0004\n",
      "[Epoch 068] loss=0.9341 recon=0.9333 kl=0.0008\n",
      "[Epoch 069] loss=0.9239 recon=0.9228 kl=0.0011\n",
      "[Epoch 070] loss=0.9479 recon=0.9449 kl=0.0030\n",
      "[Epoch 071] loss=0.9366 recon=0.9343 kl=0.0023\n",
      "[Epoch 072] loss=0.9210 recon=0.9203 kl=0.0006\n",
      "[Epoch 073] loss=0.9392 recon=0.9392 kl=0.0001\n",
      "[Epoch 074] loss=0.9386 recon=0.9386 kl=0.0000\n",
      "[Epoch 075] loss=0.9580 recon=0.9575 kl=0.0005\n",
      "[Epoch 076] loss=0.9312 recon=0.9286 kl=0.0027\n",
      "[Epoch 077] loss=0.9369 recon=0.9317 kl=0.0052\n",
      "[Epoch 078] loss=0.9323 recon=0.9309 kl=0.0014\n",
      "[Epoch 079] loss=0.9316 recon=0.9314 kl=0.0001\n",
      "[Epoch 080] loss=0.9304 recon=0.9304 kl=0.0000\n",
      "[Epoch 081] loss=0.9294 recon=0.9294 kl=0.0000\n",
      "[Epoch 082] loss=0.9444 recon=0.9444 kl=0.0000\n",
      "[Epoch 083] loss=0.9267 recon=0.9263 kl=0.0003\n",
      "[Epoch 084] loss=0.9417 recon=0.9413 kl=0.0005\n",
      "[Epoch 085] loss=0.9315 recon=0.9311 kl=0.0004\n",
      "[Epoch 086] loss=0.9422 recon=0.9418 kl=0.0005\n",
      "[Epoch 087] loss=0.9242 recon=0.9234 kl=0.0008\n",
      "[Epoch 088] loss=0.9380 recon=0.9378 kl=0.0002\n",
      "[Epoch 089] loss=0.9475 recon=0.9470 kl=0.0005\n",
      "[Epoch 090] loss=0.9213 recon=0.9207 kl=0.0006\n",
      "47\n",
      "[Epoch 001] loss=1.0977 recon=0.9282 kl=0.1695\n",
      "[Epoch 002] loss=0.9328 recon=0.9310 kl=0.0018\n",
      "[Epoch 003] loss=0.9475 recon=0.9473 kl=0.0002\n",
      "[Epoch 004] loss=0.9346 recon=0.9344 kl=0.0002\n",
      "[Epoch 005] loss=0.9442 recon=0.9440 kl=0.0002\n",
      "[Epoch 006] loss=0.9356 recon=0.9356 kl=0.0001\n",
      "[Epoch 007] loss=0.9421 recon=0.9417 kl=0.0004\n",
      "[Epoch 008] loss=0.9253 recon=0.9251 kl=0.0002\n",
      "[Epoch 009] loss=0.9323 recon=0.9319 kl=0.0004\n",
      "[Epoch 010] loss=0.9290 recon=0.9288 kl=0.0002\n",
      "[Epoch 011] loss=0.9352 recon=0.9350 kl=0.0002\n",
      "[Epoch 012] loss=0.9339 recon=0.9336 kl=0.0004\n",
      "[Epoch 013] loss=0.9368 recon=0.9365 kl=0.0003\n",
      "[Epoch 014] loss=0.9369 recon=0.9364 kl=0.0005\n",
      "[Epoch 015] loss=0.9236 recon=0.9235 kl=0.0002\n",
      "[Epoch 016] loss=0.9367 recon=0.9362 kl=0.0005\n",
      "[Epoch 017] loss=0.9350 recon=0.9345 kl=0.0005\n",
      "[Epoch 018] loss=0.9239 recon=0.9237 kl=0.0002\n",
      "[Epoch 019] loss=0.9237 recon=0.9229 kl=0.0008\n",
      "[Epoch 020] loss=0.9355 recon=0.9349 kl=0.0005\n",
      "[Epoch 021] loss=0.9358 recon=0.9355 kl=0.0003\n",
      "[Epoch 022] loss=0.9343 recon=0.9337 kl=0.0006\n",
      "[Epoch 023] loss=0.9308 recon=0.9302 kl=0.0006\n",
      "[Epoch 024] loss=0.9316 recon=0.9313 kl=0.0003\n",
      "[Epoch 025] loss=0.9357 recon=0.9348 kl=0.0009\n",
      "[Epoch 026] loss=0.9423 recon=0.9420 kl=0.0003\n",
      "[Epoch 027] loss=0.9301 recon=0.9292 kl=0.0009\n",
      "[Epoch 028] loss=0.9423 recon=0.9420 kl=0.0002\n",
      "[Epoch 029] loss=0.9342 recon=0.9336 kl=0.0006\n",
      "[Epoch 030] loss=0.9484 recon=0.9479 kl=0.0006\n",
      "[Epoch 031] loss=0.9282 recon=0.9277 kl=0.0005\n",
      "[Epoch 032] loss=0.9330 recon=0.9291 kl=0.0038\n",
      "[Epoch 033] loss=0.9452 recon=0.9434 kl=0.0018\n",
      "[Epoch 034] loss=0.9463 recon=0.9460 kl=0.0003\n",
      "[Epoch 035] loss=0.9297 recon=0.9296 kl=0.0000\n",
      "[Epoch 036] loss=0.9330 recon=0.9330 kl=0.0000\n",
      "[Epoch 037] loss=0.9338 recon=0.9332 kl=0.0006\n",
      "[Epoch 038] loss=0.9350 recon=0.9345 kl=0.0005\n",
      "[Epoch 039] loss=0.9390 recon=0.9383 kl=0.0007\n",
      "[Epoch 040] loss=0.9270 recon=0.9264 kl=0.0006\n",
      "[Epoch 041] loss=0.9298 recon=0.9296 kl=0.0002\n",
      "[Epoch 042] loss=0.9336 recon=0.9328 kl=0.0008\n",
      "[Epoch 043] loss=0.9360 recon=0.9352 kl=0.0008\n",
      "[Epoch 044] loss=0.9418 recon=0.9413 kl=0.0005\n",
      "[Epoch 045] loss=0.9410 recon=0.9405 kl=0.0005\n",
      "[Epoch 046] loss=0.9340 recon=0.9330 kl=0.0009\n",
      "[Epoch 047] loss=0.9305 recon=0.9302 kl=0.0003\n",
      "[Epoch 048] loss=0.9298 recon=0.9292 kl=0.0006\n",
      "[Epoch 049] loss=0.9322 recon=0.9316 kl=0.0006\n",
      "[Epoch 050] loss=0.9420 recon=0.9416 kl=0.0004\n",
      "[Epoch 051] loss=0.9321 recon=0.9313 kl=0.0007\n",
      "[Epoch 052] loss=0.9285 recon=0.9279 kl=0.0006\n",
      "[Epoch 053] loss=0.9271 recon=0.9262 kl=0.0008\n",
      "[Epoch 054] loss=0.9379 recon=0.9373 kl=0.0006\n",
      "[Epoch 055] loss=0.9209 recon=0.9207 kl=0.0002\n",
      "[Epoch 056] loss=0.9297 recon=0.9296 kl=0.0002\n",
      "[Epoch 057] loss=0.9385 recon=0.9377 kl=0.0008\n",
      "[Epoch 058] loss=0.9383 recon=0.9377 kl=0.0006\n",
      "[Epoch 059] loss=0.9332 recon=0.9327 kl=0.0005\n",
      "[Epoch 060] loss=0.9476 recon=0.9470 kl=0.0006\n",
      "[Epoch 061] loss=0.9343 recon=0.9260 kl=0.0083\n",
      "[Epoch 062] loss=0.9431 recon=0.9353 kl=0.0078\n",
      "[Epoch 063] loss=0.9401 recon=0.9395 kl=0.0006\n",
      "[Epoch 064] loss=0.9323 recon=0.9322 kl=0.0001\n",
      "[Epoch 065] loss=0.9250 recon=0.9250 kl=0.0000\n",
      "[Epoch 066] loss=0.9415 recon=0.9415 kl=0.0000\n",
      "[Epoch 067] loss=0.9402 recon=0.9400 kl=0.0002\n",
      "[Epoch 068] loss=0.9424 recon=0.9419 kl=0.0005\n",
      "[Epoch 069] loss=0.9332 recon=0.9325 kl=0.0006\n",
      "[Epoch 070] loss=0.9371 recon=0.9365 kl=0.0006\n",
      "[Epoch 071] loss=0.9265 recon=0.9258 kl=0.0007\n",
      "[Epoch 072] loss=0.9289 recon=0.9286 kl=0.0004\n",
      "[Epoch 073] loss=0.9381 recon=0.9288 kl=0.0093\n",
      "[Epoch 074] loss=0.9258 recon=0.9235 kl=0.0023\n",
      "[Epoch 075] loss=0.9225 recon=0.9222 kl=0.0003\n",
      "[Epoch 076] loss=0.9377 recon=0.9377 kl=0.0000\n",
      "[Epoch 077] loss=0.9380 recon=0.9380 kl=0.0000\n",
      "[Epoch 078] loss=0.9247 recon=0.9247 kl=0.0000\n",
      "[Epoch 079] loss=0.9601 recon=0.9600 kl=0.0001\n",
      "[Epoch 080] loss=0.9309 recon=0.9303 kl=0.0006\n",
      "[Epoch 081] loss=0.9320 recon=0.9315 kl=0.0005\n",
      "[Epoch 082] loss=0.9234 recon=0.9231 kl=0.0003\n",
      "[Epoch 083] loss=0.9399 recon=0.9394 kl=0.0005\n",
      "[Epoch 084] loss=0.9524 recon=0.9498 kl=0.0026\n",
      "[Epoch 085] loss=0.9297 recon=0.9281 kl=0.0015\n",
      "[Epoch 086] loss=0.9292 recon=0.9289 kl=0.0002\n",
      "[Epoch 087] loss=0.9273 recon=0.9273 kl=0.0000\n",
      "[Epoch 088] loss=0.9329 recon=0.9329 kl=0.0001\n",
      "[Epoch 089] loss=0.9234 recon=0.9226 kl=0.0008\n",
      "[Epoch 090] loss=0.9207 recon=0.9205 kl=0.0002\n",
      "48\n",
      "[Epoch 001] loss=1.3161 recon=0.9391 kl=0.3770\n",
      "[Epoch 002] loss=0.9323 recon=0.9295 kl=0.0028\n",
      "[Epoch 003] loss=0.9355 recon=0.9352 kl=0.0003\n",
      "[Epoch 004] loss=0.9398 recon=0.9397 kl=0.0001\n",
      "[Epoch 005] loss=0.9319 recon=0.9319 kl=0.0000\n",
      "[Epoch 006] loss=0.9315 recon=0.9313 kl=0.0001\n",
      "[Epoch 007] loss=0.9498 recon=0.9495 kl=0.0002\n",
      "[Epoch 008] loss=0.9281 recon=0.9279 kl=0.0002\n",
      "[Epoch 009] loss=0.9220 recon=0.9219 kl=0.0001\n",
      "[Epoch 010] loss=0.9350 recon=0.9348 kl=0.0003\n",
      "[Epoch 011] loss=0.9316 recon=0.9312 kl=0.0004\n",
      "[Epoch 012] loss=0.9288 recon=0.9284 kl=0.0004\n",
      "[Epoch 013] loss=0.9351 recon=0.9350 kl=0.0001\n",
      "[Epoch 014] loss=0.9385 recon=0.9381 kl=0.0003\n",
      "[Epoch 015] loss=0.9228 recon=0.9226 kl=0.0002\n",
      "[Epoch 016] loss=0.9264 recon=0.9259 kl=0.0005\n",
      "[Epoch 017] loss=0.9298 recon=0.9295 kl=0.0003\n",
      "[Epoch 018] loss=0.9265 recon=0.9257 kl=0.0008\n",
      "[Epoch 019] loss=0.9402 recon=0.9401 kl=0.0001\n",
      "[Epoch 020] loss=0.9285 recon=0.9279 kl=0.0006\n",
      "[Epoch 021] loss=0.9407 recon=0.9401 kl=0.0006\n",
      "[Epoch 022] loss=0.9338 recon=0.9320 kl=0.0019\n",
      "[Epoch 023] loss=0.9389 recon=0.9387 kl=0.0002\n",
      "[Epoch 024] loss=0.9239 recon=0.9239 kl=0.0000\n",
      "[Epoch 025] loss=0.9305 recon=0.9286 kl=0.0019\n",
      "[Epoch 026] loss=0.9310 recon=0.9282 kl=0.0028\n",
      "[Epoch 027] loss=0.9408 recon=0.9405 kl=0.0003\n",
      "[Epoch 028] loss=0.9380 recon=0.9379 kl=0.0001\n",
      "[Epoch 029] loss=0.9202 recon=0.9202 kl=0.0000\n",
      "[Epoch 030] loss=0.9490 recon=0.9484 kl=0.0006\n",
      "[Epoch 031] loss=0.9582 recon=0.9580 kl=0.0003\n",
      "[Epoch 032] loss=0.9280 recon=0.9272 kl=0.0007\n",
      "[Epoch 033] loss=0.9257 recon=0.9255 kl=0.0002\n",
      "[Epoch 034] loss=0.9421 recon=0.9415 kl=0.0005\n",
      "[Epoch 035] loss=0.9398 recon=0.9393 kl=0.0005\n",
      "[Epoch 036] loss=0.9234 recon=0.9231 kl=0.0003\n",
      "[Epoch 037] loss=0.9270 recon=0.9262 kl=0.0007\n",
      "[Epoch 038] loss=0.9284 recon=0.9280 kl=0.0003\n",
      "[Epoch 039] loss=0.9495 recon=0.9485 kl=0.0010\n",
      "[Epoch 040] loss=0.9238 recon=0.9236 kl=0.0002\n",
      "[Epoch 041] loss=0.9267 recon=0.9261 kl=0.0005\n",
      "[Epoch 042] loss=0.9378 recon=0.9376 kl=0.0003\n",
      "[Epoch 043] loss=0.9349 recon=0.9343 kl=0.0006\n",
      "[Epoch 044] loss=0.9398 recon=0.9393 kl=0.0005\n",
      "[Epoch 045] loss=0.9494 recon=0.9486 kl=0.0008\n",
      "[Epoch 046] loss=0.9255 recon=0.9253 kl=0.0002\n",
      "[Epoch 047] loss=0.9202 recon=0.9198 kl=0.0005\n",
      "[Epoch 048] loss=0.9340 recon=0.9333 kl=0.0007\n",
      "[Epoch 049] loss=0.9440 recon=0.9436 kl=0.0003\n",
      "[Epoch 050] loss=0.9357 recon=0.9350 kl=0.0007\n",
      "[Epoch 051] loss=0.9296 recon=0.9293 kl=0.0004\n",
      "[Epoch 052] loss=0.9252 recon=0.9248 kl=0.0004\n",
      "[Epoch 053] loss=0.9320 recon=0.9313 kl=0.0007\n",
      "[Epoch 054] loss=0.9316 recon=0.9311 kl=0.0005\n",
      "[Epoch 055] loss=0.9297 recon=0.9295 kl=0.0003\n",
      "[Epoch 056] loss=0.9566 recon=0.9532 kl=0.0034\n",
      "[Epoch 057] loss=0.9379 recon=0.9362 kl=0.0017\n",
      "[Epoch 058] loss=0.9356 recon=0.9353 kl=0.0003\n",
      "[Epoch 059] loss=0.9216 recon=0.9216 kl=0.0000\n",
      "[Epoch 060] loss=0.9416 recon=0.9416 kl=0.0000\n",
      "[Epoch 061] loss=0.9338 recon=0.9226 kl=0.0112\n",
      "[Epoch 062] loss=0.9349 recon=0.9284 kl=0.0064\n",
      "[Epoch 063] loss=0.9458 recon=0.9452 kl=0.0006\n",
      "[Epoch 064] loss=0.9371 recon=0.9370 kl=0.0000\n",
      "[Epoch 065] loss=0.9486 recon=0.9486 kl=0.0000\n",
      "[Epoch 066] loss=0.9319 recon=0.9319 kl=0.0000\n",
      "[Epoch 067] loss=0.9200 recon=0.9200 kl=0.0000\n",
      "[Epoch 068] loss=0.9409 recon=0.9408 kl=0.0000\n",
      "[Epoch 069] loss=0.9334 recon=0.9331 kl=0.0003\n",
      "[Epoch 070] loss=0.9250 recon=0.9245 kl=0.0005\n",
      "[Epoch 071] loss=0.9372 recon=0.9369 kl=0.0003\n",
      "[Epoch 072] loss=0.9380 recon=0.9374 kl=0.0005\n",
      "[Epoch 073] loss=0.9351 recon=0.9345 kl=0.0006\n",
      "[Epoch 074] loss=0.9328 recon=0.9325 kl=0.0003\n",
      "[Epoch 075] loss=0.9317 recon=0.9315 kl=0.0003\n",
      "[Epoch 076] loss=0.9274 recon=0.9254 kl=0.0020\n",
      "[Epoch 077] loss=0.9318 recon=0.9307 kl=0.0011\n",
      "[Epoch 078] loss=0.9344 recon=0.9342 kl=0.0002\n",
      "[Epoch 079] loss=0.9356 recon=0.9356 kl=0.0000\n",
      "[Epoch 080] loss=0.9319 recon=0.9314 kl=0.0005\n",
      "[Epoch 081] loss=0.9307 recon=0.9300 kl=0.0007\n",
      "[Epoch 082] loss=0.9413 recon=0.9411 kl=0.0001\n",
      "[Epoch 083] loss=0.9371 recon=0.9368 kl=0.0004\n",
      "[Epoch 084] loss=0.9327 recon=0.9319 kl=0.0008\n",
      "[Epoch 085] loss=0.9280 recon=0.9277 kl=0.0004\n",
      "[Epoch 086] loss=0.9363 recon=0.9357 kl=0.0006\n",
      "[Epoch 087] loss=0.9429 recon=0.9425 kl=0.0003\n",
      "[Epoch 088] loss=0.9218 recon=0.9214 kl=0.0004\n",
      "[Epoch 089] loss=0.9429 recon=0.9425 kl=0.0005\n",
      "[Epoch 090] loss=0.9219 recon=0.9204 kl=0.0015\n",
      "49\n",
      "[Epoch 001] loss=1.1124 recon=0.9282 kl=0.1842\n",
      "[Epoch 002] loss=0.9312 recon=0.9287 kl=0.0025\n",
      "[Epoch 003] loss=0.9495 recon=0.9493 kl=0.0002\n",
      "[Epoch 004] loss=0.9234 recon=0.9233 kl=0.0001\n",
      "[Epoch 005] loss=0.9297 recon=0.9296 kl=0.0001\n",
      "[Epoch 006] loss=0.9300 recon=0.9299 kl=0.0002\n",
      "[Epoch 007] loss=0.9603 recon=0.9601 kl=0.0002\n",
      "[Epoch 008] loss=0.9279 recon=0.9276 kl=0.0003\n",
      "[Epoch 009] loss=0.9391 recon=0.9390 kl=0.0001\n",
      "[Epoch 010] loss=0.9438 recon=0.9434 kl=0.0004\n",
      "[Epoch 011] loss=0.9255 recon=0.9253 kl=0.0002\n",
      "[Epoch 012] loss=0.9429 recon=0.9424 kl=0.0004\n",
      "[Epoch 013] loss=0.9608 recon=0.9607 kl=0.0001\n",
      "[Epoch 014] loss=0.9315 recon=0.9309 kl=0.0006\n",
      "[Epoch 015] loss=0.9462 recon=0.9460 kl=0.0001\n",
      "[Epoch 016] loss=0.9352 recon=0.9347 kl=0.0004\n",
      "[Epoch 017] loss=0.9415 recon=0.9411 kl=0.0004\n",
      "[Epoch 018] loss=0.9408 recon=0.9403 kl=0.0005\n",
      "[Epoch 019] loss=0.9313 recon=0.9310 kl=0.0002\n",
      "[Epoch 020] loss=0.9212 recon=0.9206 kl=0.0006\n",
      "[Epoch 021] loss=0.9538 recon=0.9536 kl=0.0002\n",
      "[Epoch 022] loss=0.9369 recon=0.9365 kl=0.0004\n",
      "[Epoch 023] loss=0.9257 recon=0.9253 kl=0.0004\n",
      "[Epoch 024] loss=0.9480 recon=0.9474 kl=0.0007\n",
      "[Epoch 025] loss=0.9275 recon=0.9273 kl=0.0002\n",
      "[Epoch 026] loss=0.9392 recon=0.9385 kl=0.0007\n",
      "[Epoch 027] loss=0.9262 recon=0.9258 kl=0.0004\n",
      "[Epoch 028] loss=0.9466 recon=0.9462 kl=0.0004\n",
      "[Epoch 029] loss=0.9261 recon=0.9252 kl=0.0009\n",
      "[Epoch 030] loss=0.9255 recon=0.9250 kl=0.0005\n",
      "[Epoch 031] loss=0.9339 recon=0.9334 kl=0.0005\n",
      "[Epoch 032] loss=0.9254 recon=0.9251 kl=0.0002\n",
      "[Epoch 033] loss=0.9405 recon=0.9398 kl=0.0007\n",
      "[Epoch 034] loss=0.9227 recon=0.9221 kl=0.0006\n",
      "[Epoch 035] loss=0.9357 recon=0.9353 kl=0.0004\n",
      "[Epoch 036] loss=0.9288 recon=0.9280 kl=0.0008\n",
      "[Epoch 037] loss=0.9339 recon=0.9337 kl=0.0002\n",
      "[Epoch 038] loss=0.9263 recon=0.9257 kl=0.0006\n",
      "[Epoch 039] loss=0.9290 recon=0.9282 kl=0.0008\n",
      "[Epoch 040] loss=0.9370 recon=0.9369 kl=0.0002\n",
      "[Epoch 041] loss=0.9436 recon=0.9429 kl=0.0007\n",
      "[Epoch 042] loss=0.9314 recon=0.9309 kl=0.0005\n",
      "[Epoch 043] loss=0.9318 recon=0.9312 kl=0.0006\n",
      "[Epoch 044] loss=0.9449 recon=0.9444 kl=0.0006\n",
      "[Epoch 045] loss=0.9429 recon=0.9423 kl=0.0005\n",
      "[Epoch 046] loss=0.9370 recon=0.9348 kl=0.0022\n",
      "[Epoch 047] loss=0.9308 recon=0.9251 kl=0.0057\n",
      "[Epoch 048] loss=0.9327 recon=0.9319 kl=0.0007\n",
      "[Epoch 049] loss=0.9386 recon=0.9386 kl=0.0001\n",
      "[Epoch 050] loss=0.9299 recon=0.9298 kl=0.0000\n",
      "[Epoch 051] loss=0.9397 recon=0.9397 kl=0.0000\n",
      "[Epoch 052] loss=0.9382 recon=0.9375 kl=0.0007\n",
      "[Epoch 053] loss=0.9256 recon=0.9249 kl=0.0007\n",
      "[Epoch 054] loss=0.9394 recon=0.9392 kl=0.0002\n",
      "[Epoch 055] loss=0.9336 recon=0.9330 kl=0.0007\n",
      "[Epoch 056] loss=0.9299 recon=0.9297 kl=0.0002\n",
      "[Epoch 057] loss=0.9293 recon=0.9287 kl=0.0007\n",
      "[Epoch 058] loss=0.9464 recon=0.9459 kl=0.0005\n",
      "[Epoch 059] loss=0.9356 recon=0.9352 kl=0.0004\n",
      "[Epoch 060] loss=0.9235 recon=0.9227 kl=0.0008\n",
      "[Epoch 061] loss=0.9357 recon=0.9353 kl=0.0004\n",
      "[Epoch 062] loss=0.9494 recon=0.9491 kl=0.0004\n",
      "[Epoch 063] loss=0.9367 recon=0.9360 kl=0.0007\n",
      "[Epoch 064] loss=0.9297 recon=0.9292 kl=0.0005\n",
      "[Epoch 065] loss=0.9339 recon=0.9334 kl=0.0005\n",
      "[Epoch 066] loss=0.9286 recon=0.9280 kl=0.0006\n",
      "[Epoch 067] loss=0.9384 recon=0.9379 kl=0.0005\n",
      "[Epoch 068] loss=0.9380 recon=0.9369 kl=0.0011\n",
      "[Epoch 069] loss=0.9265 recon=0.9262 kl=0.0003\n",
      "[Epoch 070] loss=0.9380 recon=0.9376 kl=0.0004\n",
      "[Epoch 071] loss=0.9296 recon=0.9291 kl=0.0004\n",
      "[Epoch 072] loss=0.9320 recon=0.9314 kl=0.0006\n",
      "[Epoch 073] loss=0.9253 recon=0.9247 kl=0.0006\n",
      "[Epoch 074] loss=0.9382 recon=0.9380 kl=0.0002\n",
      "[Epoch 075] loss=0.9376 recon=0.9370 kl=0.0006\n",
      "[Epoch 076] loss=0.9364 recon=0.9329 kl=0.0035\n",
      "[Epoch 077] loss=0.9367 recon=0.9338 kl=0.0028\n",
      "[Epoch 078] loss=0.9609 recon=0.9587 kl=0.0021\n",
      "[Epoch 079] loss=0.9353 recon=0.9350 kl=0.0004\n",
      "[Epoch 080] loss=0.9312 recon=0.9312 kl=0.0000\n",
      "[Epoch 081] loss=0.9264 recon=0.9264 kl=0.0000\n",
      "[Epoch 082] loss=0.9336 recon=0.9335 kl=0.0001\n",
      "[Epoch 083] loss=0.9318 recon=0.9297 kl=0.0021\n",
      "[Epoch 084] loss=0.9308 recon=0.9272 kl=0.0037\n",
      "[Epoch 085] loss=0.9291 recon=0.9259 kl=0.0032\n",
      "[Epoch 086] loss=0.9521 recon=0.9499 kl=0.0022\n",
      "[Epoch 087] loss=0.9242 recon=0.9235 kl=0.0007\n",
      "[Epoch 088] loss=0.9416 recon=0.9415 kl=0.0001\n",
      "[Epoch 089] loss=0.9709 recon=0.9709 kl=0.0000\n",
      "[Epoch 090] loss=0.9298 recon=0.9297 kl=0.0000\n",
      "50\n",
      "[Epoch 001] loss=1.5370 recon=0.9397 kl=0.5974\n",
      "[Epoch 002] loss=0.9256 recon=0.9219 kl=0.0037\n",
      "[Epoch 003] loss=0.9301 recon=0.9298 kl=0.0003\n",
      "[Epoch 004] loss=0.9295 recon=0.9294 kl=0.0001\n",
      "[Epoch 005] loss=0.9389 recon=0.9386 kl=0.0004\n",
      "[Epoch 006] loss=0.9285 recon=0.9285 kl=0.0001\n",
      "[Epoch 007] loss=0.9239 recon=0.9238 kl=0.0001\n",
      "[Epoch 008] loss=0.9665 recon=0.9662 kl=0.0004\n",
      "[Epoch 009] loss=0.9331 recon=0.9327 kl=0.0004\n",
      "[Epoch 010] loss=0.9393 recon=0.9391 kl=0.0002\n",
      "[Epoch 011] loss=0.9364 recon=0.9359 kl=0.0005\n",
      "[Epoch 012] loss=0.9365 recon=0.9363 kl=0.0002\n",
      "[Epoch 013] loss=0.9426 recon=0.9419 kl=0.0007\n",
      "[Epoch 014] loss=0.9355 recon=0.9354 kl=0.0002\n",
      "[Epoch 015] loss=0.9194 recon=0.9191 kl=0.0002\n",
      "[Epoch 016] loss=0.9511 recon=0.9503 kl=0.0008\n",
      "[Epoch 017] loss=0.9343 recon=0.9341 kl=0.0002\n",
      "[Epoch 018] loss=0.9317 recon=0.9311 kl=0.0006\n",
      "[Epoch 019] loss=0.9354 recon=0.9352 kl=0.0002\n",
      "[Epoch 020] loss=0.9232 recon=0.9221 kl=0.0011\n",
      "[Epoch 021] loss=0.9366 recon=0.9361 kl=0.0006\n",
      "[Epoch 022] loss=0.9511 recon=0.9508 kl=0.0004\n",
      "[Epoch 023] loss=0.9489 recon=0.9483 kl=0.0006\n",
      "[Epoch 024] loss=0.9296 recon=0.9289 kl=0.0006\n",
      "[Epoch 025] loss=0.9376 recon=0.9371 kl=0.0005\n",
      "[Epoch 026] loss=0.9408 recon=0.9400 kl=0.0008\n",
      "[Epoch 027] loss=0.9403 recon=0.9368 kl=0.0035\n",
      "[Epoch 028] loss=0.9486 recon=0.9467 kl=0.0019\n",
      "[Epoch 029] loss=0.9374 recon=0.9371 kl=0.0003\n",
      "[Epoch 030] loss=0.9293 recon=0.9292 kl=0.0000\n",
      "[Epoch 031] loss=0.9271 recon=0.9270 kl=0.0001\n",
      "[Epoch 032] loss=0.9466 recon=0.9460 kl=0.0006\n",
      "[Epoch 033] loss=0.9389 recon=0.9384 kl=0.0005\n",
      "[Epoch 034] loss=0.9282 recon=0.9274 kl=0.0008\n",
      "[Epoch 035] loss=0.9288 recon=0.9284 kl=0.0004\n",
      "[Epoch 036] loss=0.9354 recon=0.9350 kl=0.0005\n",
      "[Epoch 037] loss=0.9582 recon=0.9496 kl=0.0086\n",
      "[Epoch 038] loss=0.9614 recon=0.9574 kl=0.0039\n",
      "[Epoch 039] loss=0.9419 recon=0.9417 kl=0.0003\n",
      "[Epoch 040] loss=0.9242 recon=0.9242 kl=0.0000\n",
      "[Epoch 041] loss=0.9441 recon=0.9441 kl=0.0000\n",
      "[Epoch 042] loss=0.9384 recon=0.9376 kl=0.0007\n",
      "[Epoch 043] loss=0.9392 recon=0.9390 kl=0.0001\n",
      "[Epoch 044] loss=0.9228 recon=0.9221 kl=0.0007\n",
      "[Epoch 045] loss=0.9236 recon=0.9233 kl=0.0003\n",
      "[Epoch 046] loss=0.9310 recon=0.9300 kl=0.0010\n",
      "[Epoch 047] loss=0.9346 recon=0.9344 kl=0.0002\n",
      "[Epoch 048] loss=0.9357 recon=0.9349 kl=0.0008\n",
      "[Epoch 049] loss=0.9357 recon=0.9350 kl=0.0007\n",
      "[Epoch 050] loss=0.9426 recon=0.9414 kl=0.0012\n",
      "[Epoch 051] loss=0.9335 recon=0.9334 kl=0.0002\n",
      "[Epoch 052] loss=0.9338 recon=0.9332 kl=0.0006\n",
      "[Epoch 053] loss=0.9392 recon=0.9354 kl=0.0037\n",
      "[Epoch 054] loss=0.9293 recon=0.9264 kl=0.0029\n",
      "[Epoch 055] loss=0.9262 recon=0.9241 kl=0.0021\n",
      "[Epoch 056] loss=0.9293 recon=0.9287 kl=0.0007\n",
      "[Epoch 057] loss=0.9504 recon=0.9503 kl=0.0001\n",
      "[Epoch 058] loss=0.9362 recon=0.9362 kl=0.0000\n",
      "[Epoch 059] loss=0.9340 recon=0.9340 kl=0.0000\n",
      "[Epoch 060] loss=0.9273 recon=0.9271 kl=0.0001\n",
      "[Epoch 061] loss=0.9286 recon=0.9280 kl=0.0006\n",
      "[Epoch 062] loss=0.9261 recon=0.9259 kl=0.0003\n",
      "[Epoch 063] loss=0.9352 recon=0.9347 kl=0.0005\n",
      "[Epoch 064] loss=0.9362 recon=0.9329 kl=0.0033\n",
      "[Epoch 065] loss=0.9329 recon=0.9314 kl=0.0015\n",
      "[Epoch 066] loss=0.9341 recon=0.9339 kl=0.0001\n",
      "[Epoch 067] loss=0.9326 recon=0.9326 kl=0.0000\n",
      "[Epoch 068] loss=0.9438 recon=0.9434 kl=0.0005\n",
      "[Epoch 069] loss=0.9248 recon=0.9240 kl=0.0008\n",
      "[Epoch 070] loss=0.9252 recon=0.9247 kl=0.0006\n",
      "[Epoch 071] loss=0.9348 recon=0.9343 kl=0.0004\n",
      "[Epoch 072] loss=0.9444 recon=0.9438 kl=0.0006\n",
      "[Epoch 073] loss=0.9291 recon=0.9287 kl=0.0004\n",
      "[Epoch 074] loss=0.9380 recon=0.9377 kl=0.0003\n",
      "[Epoch 075] loss=0.9413 recon=0.9407 kl=0.0006\n",
      "[Epoch 076] loss=0.9412 recon=0.9406 kl=0.0007\n",
      "[Epoch 077] loss=0.9226 recon=0.9225 kl=0.0001\n",
      "[Epoch 078] loss=0.9326 recon=0.9321 kl=0.0005\n",
      "[Epoch 079] loss=0.9308 recon=0.9303 kl=0.0005\n",
      "[Epoch 080] loss=0.9393 recon=0.9390 kl=0.0003\n",
      "[Epoch 081] loss=0.9284 recon=0.9278 kl=0.0006\n",
      "[Epoch 082] loss=0.9539 recon=0.9535 kl=0.0004\n",
      "[Epoch 083] loss=0.9368 recon=0.9362 kl=0.0006\n",
      "[Epoch 084] loss=0.9199 recon=0.9194 kl=0.0005\n",
      "[Epoch 085] loss=0.9537 recon=0.9535 kl=0.0002\n",
      "[Epoch 086] loss=0.9257 recon=0.9251 kl=0.0005\n",
      "[Epoch 087] loss=0.9469 recon=0.9462 kl=0.0007\n",
      "[Epoch 088] loss=0.9501 recon=0.9495 kl=0.0006\n",
      "[Epoch 089] loss=0.9319 recon=0.9315 kl=0.0004\n",
      "[Epoch 090] loss=0.9302 recon=0.9300 kl=0.0003\n",
      "51\n",
      "[Epoch 001] loss=1.4335 recon=0.9301 kl=0.5033\n",
      "[Epoch 002] loss=0.9387 recon=0.9351 kl=0.0036\n",
      "[Epoch 003] loss=0.9507 recon=0.9504 kl=0.0003\n",
      "[Epoch 004] loss=0.9327 recon=0.9327 kl=0.0000\n",
      "[Epoch 005] loss=0.9348 recon=0.9347 kl=0.0001\n",
      "[Epoch 006] loss=0.9452 recon=0.9451 kl=0.0000\n",
      "[Epoch 007] loss=0.9376 recon=0.9374 kl=0.0001\n",
      "[Epoch 008] loss=0.9534 recon=0.9533 kl=0.0001\n",
      "[Epoch 009] loss=0.9332 recon=0.9331 kl=0.0001\n",
      "[Epoch 010] loss=0.9527 recon=0.9526 kl=0.0001\n",
      "[Epoch 011] loss=0.9381 recon=0.9379 kl=0.0002\n",
      "[Epoch 012] loss=0.9246 recon=0.9244 kl=0.0002\n",
      "[Epoch 013] loss=0.9367 recon=0.9366 kl=0.0001\n",
      "[Epoch 014] loss=0.9254 recon=0.9249 kl=0.0005\n",
      "[Epoch 015] loss=0.9307 recon=0.9306 kl=0.0001\n",
      "[Epoch 016] loss=0.9420 recon=0.9416 kl=0.0004\n",
      "[Epoch 017] loss=0.9404 recon=0.9402 kl=0.0002\n",
      "[Epoch 018] loss=0.9351 recon=0.9350 kl=0.0001\n",
      "[Epoch 019] loss=0.9356 recon=0.9344 kl=0.0012\n",
      "[Epoch 020] loss=0.9421 recon=0.9418 kl=0.0004\n",
      "[Epoch 021] loss=0.9378 recon=0.9377 kl=0.0000\n",
      "[Epoch 022] loss=0.9300 recon=0.9294 kl=0.0006\n",
      "[Epoch 023] loss=0.9323 recon=0.9321 kl=0.0002\n",
      "[Epoch 024] loss=0.9265 recon=0.9259 kl=0.0005\n",
      "[Epoch 025] loss=0.9362 recon=0.9358 kl=0.0005\n",
      "[Epoch 026] loss=0.9262 recon=0.9258 kl=0.0004\n",
      "[Epoch 027] loss=0.9261 recon=0.9232 kl=0.0029\n",
      "[Epoch 028] loss=0.9294 recon=0.9290 kl=0.0004\n",
      "[Epoch 029] loss=0.9306 recon=0.9305 kl=0.0000\n",
      "[Epoch 030] loss=0.9295 recon=0.9295 kl=0.0000\n",
      "[Epoch 031] loss=0.9422 recon=0.9421 kl=0.0001\n",
      "[Epoch 032] loss=0.9302 recon=0.9298 kl=0.0005\n",
      "[Epoch 033] loss=0.9355 recon=0.9350 kl=0.0005\n",
      "[Epoch 034] loss=0.9301 recon=0.9297 kl=0.0003\n",
      "[Epoch 035] loss=0.9274 recon=0.9265 kl=0.0008\n",
      "[Epoch 036] loss=0.9574 recon=0.9573 kl=0.0001\n",
      "[Epoch 037] loss=0.9441 recon=0.9432 kl=0.0009\n",
      "[Epoch 038] loss=0.9293 recon=0.9291 kl=0.0002\n",
      "[Epoch 039] loss=0.9555 recon=0.9553 kl=0.0003\n",
      "[Epoch 040] loss=0.9445 recon=0.9432 kl=0.0013\n",
      "[Epoch 041] loss=0.9327 recon=0.9325 kl=0.0002\n",
      "[Epoch 042] loss=0.9301 recon=0.9297 kl=0.0004\n",
      "[Epoch 043] loss=0.9267 recon=0.9264 kl=0.0003\n",
      "[Epoch 044] loss=0.9327 recon=0.9324 kl=0.0004\n",
      "[Epoch 045] loss=0.9336 recon=0.9328 kl=0.0007\n",
      "[Epoch 046] loss=0.9605 recon=0.9603 kl=0.0002\n",
      "[Epoch 047] loss=0.9249 recon=0.9242 kl=0.0007\n",
      "[Epoch 048] loss=0.9467 recon=0.9464 kl=0.0002\n",
      "[Epoch 049] loss=0.9358 recon=0.9350 kl=0.0008\n",
      "[Epoch 050] loss=0.9332 recon=0.9331 kl=0.0001\n",
      "[Epoch 051] loss=0.9410 recon=0.9399 kl=0.0011\n",
      "[Epoch 052] loss=0.9347 recon=0.9345 kl=0.0001\n",
      "[Epoch 053] loss=0.9335 recon=0.9331 kl=0.0005\n",
      "[Epoch 054] loss=0.9603 recon=0.9549 kl=0.0054\n",
      "[Epoch 055] loss=0.9286 recon=0.9273 kl=0.0014\n",
      "[Epoch 056] loss=0.9302 recon=0.9301 kl=0.0001\n",
      "[Epoch 057] loss=0.9318 recon=0.9318 kl=0.0000\n",
      "[Epoch 058] loss=0.9305 recon=0.9305 kl=0.0000\n",
      "[Epoch 059] loss=0.9484 recon=0.9481 kl=0.0003\n",
      "[Epoch 060] loss=0.9350 recon=0.9346 kl=0.0005\n",
      "[Epoch 061] loss=0.9334 recon=0.9329 kl=0.0005\n",
      "[Epoch 062] loss=0.9518 recon=0.9512 kl=0.0006\n",
      "[Epoch 063] loss=0.9367 recon=0.9364 kl=0.0003\n",
      "[Epoch 064] loss=0.9372 recon=0.9371 kl=0.0001\n",
      "[Epoch 065] loss=0.9374 recon=0.9363 kl=0.0011\n",
      "[Epoch 066] loss=0.9297 recon=0.9294 kl=0.0003\n",
      "[Epoch 067] loss=0.9388 recon=0.9385 kl=0.0003\n",
      "[Epoch 068] loss=0.9316 recon=0.9308 kl=0.0007\n",
      "[Epoch 069] loss=0.9367 recon=0.9365 kl=0.0002\n",
      "[Epoch 070] loss=0.9260 recon=0.9255 kl=0.0005\n",
      "[Epoch 071] loss=0.9434 recon=0.9428 kl=0.0006\n",
      "[Epoch 072] loss=0.9501 recon=0.9495 kl=0.0006\n",
      "[Epoch 073] loss=0.9242 recon=0.9236 kl=0.0006\n",
      "[Epoch 074] loss=0.9353 recon=0.9350 kl=0.0004\n",
      "[Epoch 075] loss=0.9255 recon=0.9254 kl=0.0002\n",
      "[Epoch 076] loss=0.9381 recon=0.9375 kl=0.0006\n",
      "[Epoch 077] loss=0.9339 recon=0.9336 kl=0.0003\n",
      "[Epoch 078] loss=0.9345 recon=0.9339 kl=0.0006\n",
      "[Epoch 079] loss=0.9348 recon=0.9345 kl=0.0003\n",
      "[Epoch 080] loss=0.9287 recon=0.9283 kl=0.0005\n",
      "[Epoch 081] loss=0.9340 recon=0.9336 kl=0.0004\n",
      "[Epoch 082] loss=0.9292 recon=0.9286 kl=0.0005\n",
      "[Epoch 083] loss=0.9427 recon=0.9421 kl=0.0005\n",
      "[Epoch 084] loss=0.9299 recon=0.9297 kl=0.0002\n",
      "[Epoch 085] loss=0.9343 recon=0.9333 kl=0.0010\n",
      "[Epoch 086] loss=0.9359 recon=0.9357 kl=0.0002\n",
      "[Epoch 087] loss=0.9264 recon=0.9259 kl=0.0005\n",
      "[Epoch 088] loss=0.9452 recon=0.9447 kl=0.0005\n",
      "[Epoch 089] loss=0.9578 recon=0.9577 kl=0.0001\n",
      "[Epoch 090] loss=0.9220 recon=0.9213 kl=0.0007\n",
      "52\n",
      "[Epoch 001] loss=1.2109 recon=0.9379 kl=0.2729\n",
      "[Epoch 002] loss=0.9430 recon=0.9410 kl=0.0020\n",
      "[Epoch 003] loss=0.9496 recon=0.9494 kl=0.0002\n",
      "[Epoch 004] loss=0.9394 recon=0.9393 kl=0.0001\n",
      "[Epoch 005] loss=0.9423 recon=0.9420 kl=0.0003\n",
      "[Epoch 006] loss=0.9330 recon=0.9328 kl=0.0002\n",
      "[Epoch 007] loss=0.9412 recon=0.9412 kl=0.0000\n",
      "[Epoch 008] loss=0.9332 recon=0.9330 kl=0.0002\n",
      "[Epoch 009] loss=0.9409 recon=0.9408 kl=0.0001\n",
      "[Epoch 010] loss=0.9436 recon=0.9433 kl=0.0003\n",
      "[Epoch 011] loss=0.9266 recon=0.9263 kl=0.0003\n",
      "[Epoch 012] loss=0.9388 recon=0.9386 kl=0.0002\n",
      "[Epoch 013] loss=0.9266 recon=0.9262 kl=0.0004\n",
      "[Epoch 014] loss=0.9409 recon=0.9407 kl=0.0002\n",
      "[Epoch 015] loss=0.9308 recon=0.9303 kl=0.0005\n",
      "[Epoch 016] loss=0.9352 recon=0.9349 kl=0.0003\n",
      "[Epoch 017] loss=0.9333 recon=0.9330 kl=0.0004\n",
      "[Epoch 018] loss=0.9568 recon=0.9564 kl=0.0005\n",
      "[Epoch 019] loss=0.9397 recon=0.9394 kl=0.0004\n",
      "[Epoch 020] loss=0.9415 recon=0.9414 kl=0.0001\n",
      "[Epoch 021] loss=0.9442 recon=0.9429 kl=0.0013\n",
      "[Epoch 022] loss=0.9278 recon=0.9276 kl=0.0002\n",
      "[Epoch 023] loss=0.9274 recon=0.9273 kl=0.0001\n",
      "[Epoch 024] loss=0.9389 recon=0.9378 kl=0.0011\n",
      "[Epoch 025] loss=0.9354 recon=0.9350 kl=0.0004\n",
      "[Epoch 026] loss=0.9270 recon=0.9270 kl=0.0001\n",
      "[Epoch 027] loss=0.9331 recon=0.9324 kl=0.0007\n",
      "[Epoch 028] loss=0.9500 recon=0.9494 kl=0.0006\n",
      "[Epoch 029] loss=0.9295 recon=0.9293 kl=0.0002\n",
      "[Epoch 030] loss=0.9301 recon=0.9259 kl=0.0042\n",
      "[Epoch 031] loss=0.9297 recon=0.9289 kl=0.0008\n",
      "[Epoch 032] loss=0.9270 recon=0.9270 kl=0.0001\n",
      "[Epoch 033] loss=0.9387 recon=0.9386 kl=0.0000\n",
      "[Epoch 034] loss=0.9258 recon=0.9257 kl=0.0001\n",
      "[Epoch 035] loss=0.9431 recon=0.9424 kl=0.0007\n",
      "[Epoch 036] loss=0.9366 recon=0.9363 kl=0.0003\n",
      "[Epoch 037] loss=0.9335 recon=0.9330 kl=0.0005\n",
      "[Epoch 038] loss=0.9237 recon=0.9227 kl=0.0010\n",
      "[Epoch 039] loss=0.9307 recon=0.9270 kl=0.0037\n",
      "[Epoch 040] loss=0.9295 recon=0.9289 kl=0.0006\n",
      "[Epoch 041] loss=0.9501 recon=0.9501 kl=0.0001\n",
      "[Epoch 042] loss=0.9339 recon=0.9338 kl=0.0000\n",
      "[Epoch 043] loss=0.9364 recon=0.9364 kl=0.0000\n",
      "[Epoch 044] loss=0.9273 recon=0.9269 kl=0.0005\n",
      "[Epoch 045] loss=0.9215 recon=0.9211 kl=0.0004\n",
      "[Epoch 046] loss=0.9273 recon=0.9268 kl=0.0005\n",
      "[Epoch 047] loss=0.9288 recon=0.9283 kl=0.0005\n",
      "[Epoch 048] loss=0.9377 recon=0.9373 kl=0.0004\n",
      "[Epoch 049] loss=0.9301 recon=0.9294 kl=0.0007\n",
      "[Epoch 050] loss=0.9271 recon=0.9255 kl=0.0017\n",
      "[Epoch 051] loss=0.9263 recon=0.9231 kl=0.0032\n",
      "[Epoch 052] loss=0.9317 recon=0.9314 kl=0.0003\n",
      "[Epoch 053] loss=0.9331 recon=0.9330 kl=0.0000\n",
      "[Epoch 054] loss=0.9210 recon=0.9210 kl=0.0000\n",
      "[Epoch 055] loss=0.9340 recon=0.9324 kl=0.0016\n",
      "[Epoch 056] loss=0.9507 recon=0.9382 kl=0.0126\n",
      "[Epoch 057] loss=0.9340 recon=0.9333 kl=0.0007\n",
      "[Epoch 058] loss=0.9210 recon=0.9210 kl=0.0001\n",
      "[Epoch 059] loss=0.9327 recon=0.9327 kl=0.0000\n",
      "[Epoch 060] loss=0.9292 recon=0.9292 kl=0.0000\n",
      "[Epoch 061] loss=0.9588 recon=0.9588 kl=0.0000\n",
      "[Epoch 062] loss=0.9284 recon=0.9284 kl=0.0000\n",
      "[Epoch 063] loss=0.9437 recon=0.9434 kl=0.0003\n",
      "[Epoch 064] loss=0.9293 recon=0.9285 kl=0.0008\n",
      "[Epoch 065] loss=0.9263 recon=0.9259 kl=0.0004\n",
      "[Epoch 066] loss=0.9336 recon=0.9330 kl=0.0006\n",
      "[Epoch 067] loss=0.9345 recon=0.9344 kl=0.0001\n",
      "[Epoch 068] loss=0.9401 recon=0.9388 kl=0.0013\n",
      "[Epoch 069] loss=0.9376 recon=0.9373 kl=0.0003\n",
      "[Epoch 070] loss=0.9433 recon=0.9428 kl=0.0005\n",
      "[Epoch 071] loss=0.9224 recon=0.9218 kl=0.0006\n",
      "[Epoch 072] loss=0.9366 recon=0.9364 kl=0.0003\n",
      "[Epoch 073] loss=0.9498 recon=0.9492 kl=0.0006\n",
      "[Epoch 074] loss=0.9384 recon=0.9383 kl=0.0001\n",
      "[Epoch 075] loss=0.9273 recon=0.9265 kl=0.0008\n",
      "[Epoch 076] loss=0.9320 recon=0.9313 kl=0.0007\n",
      "[Epoch 077] loss=0.9326 recon=0.9322 kl=0.0004\n",
      "[Epoch 078] loss=0.9294 recon=0.9292 kl=0.0002\n",
      "[Epoch 079] loss=0.9414 recon=0.9409 kl=0.0005\n",
      "[Epoch 080] loss=0.9400 recon=0.9392 kl=0.0008\n",
      "[Epoch 081] loss=0.9236 recon=0.9234 kl=0.0002\n",
      "[Epoch 082] loss=0.9572 recon=0.9568 kl=0.0003\n",
      "[Epoch 083] loss=0.9409 recon=0.9398 kl=0.0011\n",
      "[Epoch 084] loss=0.9234 recon=0.9232 kl=0.0002\n",
      "[Epoch 085] loss=0.9360 recon=0.9360 kl=0.0000\n",
      "[Epoch 086] loss=0.9364 recon=0.9342 kl=0.0022\n",
      "[Epoch 087] loss=0.9346 recon=0.9317 kl=0.0028\n",
      "[Epoch 088] loss=0.9359 recon=0.9331 kl=0.0027\n",
      "[Epoch 089] loss=0.9400 recon=0.9387 kl=0.0013\n",
      "[Epoch 090] loss=0.9357 recon=0.9355 kl=0.0002\n",
      "53\n",
      "[Epoch 001] loss=1.2373 recon=0.9504 kl=0.2869\n",
      "[Epoch 002] loss=0.9398 recon=0.9372 kl=0.0026\n",
      "[Epoch 003] loss=0.9365 recon=0.9362 kl=0.0003\n",
      "[Epoch 004] loss=0.9414 recon=0.9412 kl=0.0002\n",
      "[Epoch 005] loss=0.9273 recon=0.9272 kl=0.0001\n",
      "[Epoch 006] loss=0.9428 recon=0.9427 kl=0.0001\n",
      "[Epoch 007] loss=0.9225 recon=0.9221 kl=0.0004\n",
      "[Epoch 008] loss=0.9445 recon=0.9443 kl=0.0001\n",
      "[Epoch 009] loss=0.9229 recon=0.9224 kl=0.0005\n",
      "[Epoch 010] loss=0.9488 recon=0.9486 kl=0.0003\n",
      "[Epoch 011] loss=0.9294 recon=0.9290 kl=0.0004\n",
      "[Epoch 012] loss=0.9417 recon=0.9412 kl=0.0005\n",
      "[Epoch 013] loss=0.9286 recon=0.9277 kl=0.0009\n",
      "[Epoch 014] loss=0.9401 recon=0.9400 kl=0.0001\n",
      "[Epoch 015] loss=0.9178 recon=0.9173 kl=0.0005\n",
      "[Epoch 016] loss=0.9315 recon=0.9312 kl=0.0003\n",
      "[Epoch 017] loss=0.9286 recon=0.9281 kl=0.0004\n",
      "[Epoch 018] loss=0.9376 recon=0.9374 kl=0.0002\n",
      "[Epoch 019] loss=0.9429 recon=0.9423 kl=0.0006\n",
      "[Epoch 020] loss=0.9377 recon=0.9371 kl=0.0006\n",
      "[Epoch 021] loss=0.9260 recon=0.9258 kl=0.0002\n",
      "[Epoch 022] loss=0.9221 recon=0.9214 kl=0.0007\n",
      "[Epoch 023] loss=0.9265 recon=0.9263 kl=0.0002\n",
      "[Epoch 024] loss=0.9282 recon=0.9245 kl=0.0037\n",
      "[Epoch 025] loss=0.9483 recon=0.9412 kl=0.0071\n",
      "[Epoch 026] loss=0.9291 recon=0.9286 kl=0.0005\n",
      "[Epoch 027] loss=0.9283 recon=0.9283 kl=0.0000\n",
      "[Epoch 028] loss=0.9507 recon=0.9506 kl=0.0001\n",
      "[Epoch 029] loss=0.9589 recon=0.9585 kl=0.0005\n",
      "[Epoch 030] loss=0.9200 recon=0.9195 kl=0.0005\n",
      "[Epoch 031] loss=0.9395 recon=0.9391 kl=0.0004\n",
      "[Epoch 032] loss=0.9324 recon=0.9322 kl=0.0002\n",
      "[Epoch 033] loss=0.9370 recon=0.9330 kl=0.0040\n",
      "[Epoch 034] loss=0.9277 recon=0.9259 kl=0.0018\n",
      "[Epoch 035] loss=0.9322 recon=0.9320 kl=0.0002\n",
      "[Epoch 036] loss=0.9305 recon=0.9305 kl=0.0000\n",
      "[Epoch 037] loss=0.9304 recon=0.9303 kl=0.0000\n",
      "[Epoch 038] loss=0.9271 recon=0.9266 kl=0.0005\n",
      "[Epoch 039] loss=0.9319 recon=0.9315 kl=0.0004\n",
      "[Epoch 040] loss=0.9492 recon=0.9480 kl=0.0012\n",
      "[Epoch 041] loss=0.9412 recon=0.9406 kl=0.0006\n",
      "[Epoch 042] loss=0.9411 recon=0.9407 kl=0.0004\n",
      "[Epoch 043] loss=0.9371 recon=0.9367 kl=0.0004\n",
      "[Epoch 044] loss=0.9308 recon=0.9303 kl=0.0005\n",
      "[Epoch 045] loss=0.9301 recon=0.9298 kl=0.0003\n",
      "[Epoch 046] loss=0.9473 recon=0.9466 kl=0.0007\n",
      "[Epoch 047] loss=0.9273 recon=0.9271 kl=0.0002\n",
      "[Epoch 048] loss=0.9421 recon=0.9412 kl=0.0010\n",
      "[Epoch 049] loss=0.9354 recon=0.9324 kl=0.0029\n",
      "[Epoch 050] loss=0.9291 recon=0.9275 kl=0.0016\n",
      "[Epoch 051] loss=0.9419 recon=0.9417 kl=0.0001\n",
      "[Epoch 052] loss=0.9254 recon=0.9254 kl=0.0000\n",
      "[Epoch 053] loss=0.9248 recon=0.9245 kl=0.0003\n",
      "[Epoch 054] loss=0.9245 recon=0.9238 kl=0.0006\n",
      "[Epoch 055] loss=0.9324 recon=0.9319 kl=0.0005\n",
      "[Epoch 056] loss=0.9477 recon=0.9476 kl=0.0001\n",
      "[Epoch 057] loss=0.9385 recon=0.9356 kl=0.0028\n",
      "[Epoch 058] loss=0.9295 recon=0.9291 kl=0.0004\n",
      "[Epoch 059] loss=0.9308 recon=0.9307 kl=0.0000\n",
      "[Epoch 060] loss=0.9297 recon=0.9293 kl=0.0004\n",
      "[Epoch 061] loss=0.9272 recon=0.9264 kl=0.0008\n",
      "[Epoch 062] loss=0.9273 recon=0.9272 kl=0.0002\n",
      "[Epoch 063] loss=0.9330 recon=0.9326 kl=0.0003\n",
      "[Epoch 064] loss=0.9278 recon=0.9271 kl=0.0006\n",
      "[Epoch 065] loss=0.9272 recon=0.9270 kl=0.0002\n",
      "[Epoch 066] loss=0.9278 recon=0.9271 kl=0.0007\n",
      "[Epoch 067] loss=0.9335 recon=0.9330 kl=0.0005\n",
      "[Epoch 068] loss=0.9289 recon=0.9285 kl=0.0004\n",
      "[Epoch 069] loss=0.9366 recon=0.9362 kl=0.0004\n",
      "[Epoch 070] loss=0.9639 recon=0.9636 kl=0.0003\n",
      "[Epoch 071] loss=0.9255 recon=0.9220 kl=0.0035\n",
      "[Epoch 072] loss=0.9262 recon=0.9246 kl=0.0016\n",
      "[Epoch 073] loss=0.9310 recon=0.9309 kl=0.0001\n",
      "[Epoch 074] loss=0.9316 recon=0.9316 kl=0.0000\n",
      "[Epoch 075] loss=0.9502 recon=0.9501 kl=0.0001\n",
      "[Epoch 076] loss=0.9480 recon=0.9474 kl=0.0006\n",
      "[Epoch 077] loss=0.9309 recon=0.9307 kl=0.0002\n",
      "[Epoch 078] loss=0.9320 recon=0.9314 kl=0.0006\n",
      "[Epoch 079] loss=0.9447 recon=0.9444 kl=0.0004\n",
      "[Epoch 080] loss=0.9344 recon=0.9338 kl=0.0005\n",
      "[Epoch 081] loss=0.9311 recon=0.9307 kl=0.0003\n",
      "[Epoch 082] loss=0.9507 recon=0.9501 kl=0.0006\n",
      "[Epoch 083] loss=0.9353 recon=0.9351 kl=0.0002\n",
      "[Epoch 084] loss=0.9393 recon=0.9386 kl=0.0007\n",
      "[Epoch 085] loss=0.9280 recon=0.9275 kl=0.0005\n",
      "[Epoch 086] loss=0.9221 recon=0.9219 kl=0.0002\n",
      "[Epoch 087] loss=0.9624 recon=0.9619 kl=0.0005\n",
      "[Epoch 088] loss=0.9361 recon=0.9355 kl=0.0005\n",
      "[Epoch 089] loss=0.9509 recon=0.9507 kl=0.0002\n",
      "[Epoch 090] loss=0.9237 recon=0.9232 kl=0.0005\n",
      "54\n",
      "[Epoch 001] loss=1.3601 recon=0.9413 kl=0.4188\n",
      "[Epoch 002] loss=0.9390 recon=0.9362 kl=0.0028\n",
      "[Epoch 003] loss=0.9540 recon=0.9538 kl=0.0002\n",
      "[Epoch 004] loss=0.9340 recon=0.9338 kl=0.0001\n",
      "[Epoch 005] loss=0.9403 recon=0.9402 kl=0.0001\n",
      "[Epoch 006] loss=0.9278 recon=0.9275 kl=0.0003\n",
      "[Epoch 007] loss=0.9219 recon=0.9217 kl=0.0002\n",
      "[Epoch 008] loss=0.9362 recon=0.9360 kl=0.0002\n",
      "[Epoch 009] loss=0.9394 recon=0.9391 kl=0.0003\n",
      "[Epoch 010] loss=0.9506 recon=0.9503 kl=0.0002\n",
      "[Epoch 011] loss=0.9385 recon=0.9382 kl=0.0003\n",
      "[Epoch 012] loss=0.9336 recon=0.9333 kl=0.0003\n",
      "[Epoch 013] loss=0.9221 recon=0.9216 kl=0.0005\n",
      "[Epoch 014] loss=0.9352 recon=0.9349 kl=0.0003\n",
      "[Epoch 015] loss=0.9497 recon=0.9494 kl=0.0003\n",
      "[Epoch 016] loss=0.9381 recon=0.9376 kl=0.0005\n",
      "[Epoch 017] loss=0.9258 recon=0.9255 kl=0.0003\n",
      "[Epoch 018] loss=0.9287 recon=0.9284 kl=0.0003\n",
      "[Epoch 019] loss=0.9347 recon=0.9339 kl=0.0008\n",
      "[Epoch 020] loss=0.9373 recon=0.9372 kl=0.0001\n",
      "[Epoch 021] loss=0.9500 recon=0.9492 kl=0.0008\n",
      "[Epoch 022] loss=0.9264 recon=0.9260 kl=0.0004\n",
      "[Epoch 023] loss=0.9536 recon=0.9533 kl=0.0003\n",
      "[Epoch 024] loss=0.9321 recon=0.9315 kl=0.0006\n",
      "[Epoch 025] loss=0.9516 recon=0.9509 kl=0.0007\n",
      "[Epoch 026] loss=0.9317 recon=0.9312 kl=0.0005\n",
      "[Epoch 027] loss=0.9367 recon=0.9359 kl=0.0007\n",
      "[Epoch 028] loss=0.9464 recon=0.9445 kl=0.0019\n",
      "[Epoch 029] loss=0.9589 recon=0.9554 kl=0.0035\n",
      "[Epoch 030] loss=0.9342 recon=0.9335 kl=0.0007\n",
      "[Epoch 031] loss=0.9355 recon=0.9354 kl=0.0001\n",
      "[Epoch 032] loss=0.9276 recon=0.9276 kl=0.0000\n",
      "[Epoch 033] loss=0.9370 recon=0.9365 kl=0.0005\n",
      "[Epoch 034] loss=0.9271 recon=0.9264 kl=0.0006\n",
      "[Epoch 035] loss=0.9482 recon=0.9480 kl=0.0001\n",
      "[Epoch 036] loss=0.9434 recon=0.9424 kl=0.0010\n",
      "[Epoch 037] loss=0.9534 recon=0.9428 kl=0.0106\n",
      "[Epoch 038] loss=0.9309 recon=0.9287 kl=0.0022\n",
      "[Epoch 039] loss=0.9272 recon=0.9270 kl=0.0002\n",
      "[Epoch 040] loss=0.9380 recon=0.9380 kl=0.0000\n",
      "[Epoch 041] loss=0.9369 recon=0.9369 kl=0.0000\n",
      "[Epoch 042] loss=0.9461 recon=0.9457 kl=0.0005\n",
      "[Epoch 043] loss=0.9493 recon=0.9487 kl=0.0006\n",
      "[Epoch 044] loss=0.9464 recon=0.9459 kl=0.0005\n",
      "[Epoch 045] loss=0.9369 recon=0.9363 kl=0.0006\n",
      "[Epoch 046] loss=0.9373 recon=0.9362 kl=0.0011\n",
      "[Epoch 047] loss=0.9349 recon=0.9347 kl=0.0002\n",
      "[Epoch 048] loss=0.9296 recon=0.9266 kl=0.0030\n",
      "[Epoch 049] loss=0.9512 recon=0.9484 kl=0.0028\n",
      "[Epoch 050] loss=0.9325 recon=0.9318 kl=0.0008\n",
      "[Epoch 051] loss=0.9408 recon=0.9407 kl=0.0001\n",
      "[Epoch 052] loss=0.9396 recon=0.9394 kl=0.0003\n",
      "[Epoch 053] loss=0.9303 recon=0.9297 kl=0.0005\n",
      "[Epoch 054] loss=0.9470 recon=0.9466 kl=0.0004\n",
      "[Epoch 055] loss=0.9360 recon=0.9354 kl=0.0005\n",
      "[Epoch 056] loss=0.9375 recon=0.9346 kl=0.0029\n",
      "[Epoch 057] loss=0.9324 recon=0.9305 kl=0.0019\n",
      "[Epoch 058] loss=0.9541 recon=0.9539 kl=0.0002\n",
      "[Epoch 059] loss=0.9354 recon=0.9353 kl=0.0000\n",
      "[Epoch 060] loss=0.9314 recon=0.9312 kl=0.0003\n",
      "[Epoch 061] loss=0.9423 recon=0.9419 kl=0.0005\n",
      "[Epoch 062] loss=0.9480 recon=0.9474 kl=0.0006\n",
      "[Epoch 063] loss=0.9369 recon=0.9362 kl=0.0006\n",
      "[Epoch 064] loss=0.9317 recon=0.9310 kl=0.0007\n",
      "[Epoch 065] loss=0.9330 recon=0.9324 kl=0.0007\n",
      "[Epoch 066] loss=0.9284 recon=0.9281 kl=0.0003\n",
      "[Epoch 067] loss=0.9313 recon=0.9307 kl=0.0006\n",
      "[Epoch 068] loss=0.9235 recon=0.9233 kl=0.0002\n",
      "[Epoch 069] loss=0.9359 recon=0.9319 kl=0.0040\n",
      "[Epoch 070] loss=0.9375 recon=0.9359 kl=0.0017\n",
      "[Epoch 071] loss=0.9314 recon=0.9312 kl=0.0002\n",
      "[Epoch 072] loss=0.9387 recon=0.9387 kl=0.0000\n",
      "[Epoch 073] loss=0.9298 recon=0.9297 kl=0.0001\n",
      "[Epoch 074] loss=0.9383 recon=0.9348 kl=0.0035\n",
      "[Epoch 075] loss=0.9366 recon=0.9332 kl=0.0034\n",
      "[Epoch 076] loss=0.9411 recon=0.9388 kl=0.0023\n",
      "[Epoch 077] loss=0.9623 recon=0.9608 kl=0.0015\n",
      "[Epoch 078] loss=0.9419 recon=0.9417 kl=0.0003\n",
      "[Epoch 079] loss=0.9419 recon=0.9419 kl=0.0000\n",
      "[Epoch 080] loss=0.9384 recon=0.9384 kl=0.0000\n",
      "[Epoch 081] loss=0.9313 recon=0.9313 kl=0.0000\n",
      "[Epoch 082] loss=0.9506 recon=0.9506 kl=0.0000\n",
      "[Epoch 083] loss=0.9275 recon=0.9270 kl=0.0005\n",
      "[Epoch 084] loss=0.9853 recon=0.9849 kl=0.0004\n",
      "[Epoch 085] loss=0.9299 recon=0.9291 kl=0.0008\n",
      "[Epoch 086] loss=0.9401 recon=0.9396 kl=0.0005\n",
      "[Epoch 087] loss=0.9284 recon=0.9277 kl=0.0007\n",
      "[Epoch 088] loss=0.9403 recon=0.9400 kl=0.0003\n",
      "[Epoch 089] loss=0.9247 recon=0.9244 kl=0.0003\n",
      "[Epoch 090] loss=0.9522 recon=0.9516 kl=0.0006\n",
      "55\n",
      "[Epoch 001] loss=1.5214 recon=0.9383 kl=0.5831\n",
      "[Epoch 002] loss=0.9473 recon=0.9434 kl=0.0039\n",
      "[Epoch 003] loss=0.9371 recon=0.9368 kl=0.0003\n",
      "[Epoch 004] loss=0.9475 recon=0.9474 kl=0.0001\n",
      "[Epoch 005] loss=0.9269 recon=0.9268 kl=0.0001\n",
      "[Epoch 006] loss=0.9362 recon=0.9358 kl=0.0004\n",
      "[Epoch 007] loss=0.9268 recon=0.9267 kl=0.0002\n",
      "[Epoch 008] loss=0.9381 recon=0.9380 kl=0.0002\n",
      "[Epoch 009] loss=0.9272 recon=0.9270 kl=0.0002\n",
      "[Epoch 010] loss=0.9329 recon=0.9326 kl=0.0003\n",
      "[Epoch 011] loss=0.9248 recon=0.9245 kl=0.0003\n",
      "[Epoch 012] loss=0.9325 recon=0.9321 kl=0.0004\n",
      "[Epoch 013] loss=0.9320 recon=0.9317 kl=0.0003\n",
      "[Epoch 014] loss=0.9328 recon=0.9326 kl=0.0002\n",
      "[Epoch 015] loss=0.9324 recon=0.9320 kl=0.0004\n",
      "[Epoch 016] loss=0.9389 recon=0.9387 kl=0.0002\n",
      "[Epoch 017] loss=0.9301 recon=0.9294 kl=0.0007\n",
      "[Epoch 018] loss=0.9420 recon=0.9417 kl=0.0003\n",
      "[Epoch 019] loss=0.9318 recon=0.9312 kl=0.0007\n",
      "[Epoch 020] loss=0.9296 recon=0.9294 kl=0.0002\n",
      "[Epoch 021] loss=0.9504 recon=0.9477 kl=0.0027\n",
      "[Epoch 022] loss=0.9431 recon=0.9403 kl=0.0028\n",
      "[Epoch 023] loss=0.9402 recon=0.9394 kl=0.0009\n",
      "[Epoch 024] loss=0.9298 recon=0.9297 kl=0.0001\n",
      "[Epoch 025] loss=0.9313 recon=0.9313 kl=0.0000\n",
      "[Epoch 026] loss=0.9237 recon=0.9237 kl=0.0000\n",
      "[Epoch 027] loss=0.9333 recon=0.9327 kl=0.0006\n",
      "[Epoch 028] loss=0.9391 recon=0.9385 kl=0.0006\n",
      "[Epoch 029] loss=0.9302 recon=0.9298 kl=0.0004\n",
      "[Epoch 030] loss=0.9412 recon=0.9411 kl=0.0001\n",
      "[Epoch 031] loss=0.9328 recon=0.9316 kl=0.0011\n",
      "[Epoch 032] loss=0.9671 recon=0.9668 kl=0.0003\n",
      "[Epoch 033] loss=0.9283 recon=0.9278 kl=0.0005\n",
      "[Epoch 034] loss=0.9405 recon=0.9397 kl=0.0008\n",
      "[Epoch 035] loss=0.9468 recon=0.9465 kl=0.0003\n",
      "[Epoch 036] loss=0.9260 recon=0.9254 kl=0.0006\n",
      "[Epoch 037] loss=0.9334 recon=0.9315 kl=0.0019\n",
      "[Epoch 038] loss=0.9428 recon=0.9400 kl=0.0028\n",
      "[Epoch 039] loss=0.9327 recon=0.9312 kl=0.0015\n",
      "[Epoch 040] loss=0.9236 recon=0.9234 kl=0.0002\n",
      "[Epoch 041] loss=0.9436 recon=0.9435 kl=0.0000\n",
      "[Epoch 042] loss=0.9299 recon=0.9295 kl=0.0003\n",
      "[Epoch 043] loss=0.9436 recon=0.9389 kl=0.0048\n",
      "[Epoch 044] loss=0.9438 recon=0.9414 kl=0.0023\n",
      "[Epoch 045] loss=0.9285 recon=0.9265 kl=0.0020\n",
      "[Epoch 046] loss=0.9346 recon=0.9340 kl=0.0006\n",
      "[Epoch 047] loss=0.9336 recon=0.9335 kl=0.0001\n",
      "[Epoch 048] loss=0.9385 recon=0.9385 kl=0.0000\n",
      "[Epoch 049] loss=0.9400 recon=0.9400 kl=0.0000\n",
      "[Epoch 050] loss=0.9425 recon=0.9417 kl=0.0008\n",
      "[Epoch 051] loss=0.9258 recon=0.9253 kl=0.0004\n",
      "[Epoch 052] loss=0.9369 recon=0.9364 kl=0.0005\n",
      "[Epoch 053] loss=0.9315 recon=0.9311 kl=0.0005\n",
      "[Epoch 054] loss=0.9324 recon=0.9321 kl=0.0003\n",
      "[Epoch 055] loss=0.9403 recon=0.9398 kl=0.0005\n",
      "[Epoch 056] loss=0.9272 recon=0.9267 kl=0.0005\n",
      "[Epoch 057] loss=0.9245 recon=0.9240 kl=0.0005\n",
      "[Epoch 058] loss=0.9491 recon=0.9486 kl=0.0005\n",
      "[Epoch 059] loss=0.9470 recon=0.9461 kl=0.0009\n",
      "[Epoch 060] loss=0.9505 recon=0.9503 kl=0.0002\n",
      "[Epoch 061] loss=0.9389 recon=0.9375 kl=0.0014\n",
      "[Epoch 062] loss=0.9233 recon=0.9225 kl=0.0008\n",
      "[Epoch 063] loss=0.9434 recon=0.9433 kl=0.0001\n",
      "[Epoch 064] loss=0.9338 recon=0.9298 kl=0.0039\n",
      "[Epoch 065] loss=0.9415 recon=0.9403 kl=0.0012\n",
      "[Epoch 066] loss=0.9341 recon=0.9340 kl=0.0001\n",
      "[Epoch 067] loss=0.9381 recon=0.9381 kl=0.0000\n",
      "[Epoch 068] loss=0.9405 recon=0.9400 kl=0.0005\n",
      "[Epoch 069] loss=0.9370 recon=0.9365 kl=0.0005\n",
      "[Epoch 070] loss=0.9191 recon=0.9186 kl=0.0005\n",
      "[Epoch 071] loss=0.9426 recon=0.9423 kl=0.0004\n",
      "[Epoch 072] loss=0.9291 recon=0.9284 kl=0.0006\n",
      "[Epoch 073] loss=0.9348 recon=0.9343 kl=0.0005\n",
      "[Epoch 074] loss=0.9323 recon=0.9318 kl=0.0005\n",
      "[Epoch 075] loss=0.9345 recon=0.9339 kl=0.0006\n",
      "[Epoch 076] loss=0.9341 recon=0.9337 kl=0.0004\n",
      "[Epoch 077] loss=0.9326 recon=0.9321 kl=0.0005\n",
      "[Epoch 078] loss=0.9305 recon=0.9299 kl=0.0006\n",
      "[Epoch 079] loss=0.9252 recon=0.9249 kl=0.0002\n",
      "[Epoch 080] loss=0.9518 recon=0.9511 kl=0.0007\n",
      "[Epoch 081] loss=0.9318 recon=0.9314 kl=0.0004\n",
      "[Epoch 082] loss=0.9476 recon=0.9472 kl=0.0004\n",
      "[Epoch 083] loss=0.9455 recon=0.9449 kl=0.0005\n",
      "[Epoch 084] loss=0.9294 recon=0.9284 kl=0.0010\n",
      "[Epoch 085] loss=0.9360 recon=0.9331 kl=0.0029\n",
      "[Epoch 086] loss=0.9309 recon=0.9301 kl=0.0009\n",
      "[Epoch 087] loss=0.9228 recon=0.9227 kl=0.0001\n",
      "[Epoch 088] loss=0.9386 recon=0.9386 kl=0.0000\n",
      "[Epoch 089] loss=0.9348 recon=0.9346 kl=0.0002\n",
      "[Epoch 090] loss=0.9318 recon=0.9310 kl=0.0008\n",
      "56\n",
      "[Epoch 001] loss=1.2224 recon=0.9292 kl=0.2931\n",
      "[Epoch 002] loss=0.9441 recon=0.9407 kl=0.0034\n",
      "[Epoch 003] loss=0.9368 recon=0.9365 kl=0.0003\n",
      "[Epoch 004] loss=0.9399 recon=0.9397 kl=0.0002\n",
      "[Epoch 005] loss=0.9392 recon=0.9389 kl=0.0002\n",
      "[Epoch 006] loss=0.9637 recon=0.9632 kl=0.0005\n",
      "[Epoch 007] loss=0.9416 recon=0.9415 kl=0.0001\n",
      "[Epoch 008] loss=0.9290 recon=0.9287 kl=0.0003\n",
      "[Epoch 009] loss=0.9241 recon=0.9237 kl=0.0004\n",
      "[Epoch 010] loss=0.9574 recon=0.9568 kl=0.0005\n",
      "[Epoch 011] loss=0.9336 recon=0.9334 kl=0.0001\n",
      "[Epoch 012] loss=0.9635 recon=0.9628 kl=0.0007\n",
      "[Epoch 013] loss=0.9583 recon=0.9574 kl=0.0009\n",
      "[Epoch 014] loss=0.9303 recon=0.9302 kl=0.0001\n",
      "[Epoch 015] loss=0.9459 recon=0.9454 kl=0.0005\n",
      "[Epoch 016] loss=0.9423 recon=0.9417 kl=0.0005\n",
      "[Epoch 017] loss=0.9313 recon=0.9310 kl=0.0003\n",
      "[Epoch 018] loss=0.9369 recon=0.9336 kl=0.0033\n",
      "[Epoch 019] loss=0.9652 recon=0.9643 kl=0.0009\n",
      "[Epoch 020] loss=0.9360 recon=0.9359 kl=0.0001\n",
      "[Epoch 021] loss=0.9393 recon=0.9391 kl=0.0002\n",
      "[Epoch 022] loss=0.9279 recon=0.9272 kl=0.0007\n",
      "[Epoch 023] loss=0.9441 recon=0.9440 kl=0.0001\n",
      "[Epoch 024] loss=0.9454 recon=0.9424 kl=0.0031\n",
      "[Epoch 025] loss=0.9437 recon=0.9423 kl=0.0014\n",
      "[Epoch 026] loss=0.9437 recon=0.9436 kl=0.0001\n",
      "[Epoch 027] loss=0.9542 recon=0.9542 kl=0.0000\n",
      "[Epoch 028] loss=0.9439 recon=0.9415 kl=0.0025\n",
      "[Epoch 029] loss=0.9357 recon=0.9328 kl=0.0029\n",
      "[Epoch 030] loss=0.9385 recon=0.9369 kl=0.0016\n",
      "[Epoch 031] loss=0.9413 recon=0.9411 kl=0.0002\n",
      "[Epoch 032] loss=0.9394 recon=0.9394 kl=0.0000\n",
      "[Epoch 033] loss=0.9259 recon=0.9259 kl=0.0000\n",
      "[Epoch 034] loss=0.9404 recon=0.9398 kl=0.0006\n",
      "[Epoch 035] loss=0.9282 recon=0.9280 kl=0.0003\n",
      "[Epoch 036] loss=0.9344 recon=0.9337 kl=0.0007\n",
      "[Epoch 037] loss=0.9315 recon=0.9311 kl=0.0003\n",
      "[Epoch 038] loss=0.9349 recon=0.9344 kl=0.0005\n",
      "[Epoch 039] loss=0.9382 recon=0.9375 kl=0.0007\n",
      "[Epoch 040] loss=0.9370 recon=0.9344 kl=0.0027\n",
      "[Epoch 041] loss=0.9273 recon=0.9269 kl=0.0004\n",
      "[Epoch 042] loss=0.9322 recon=0.9321 kl=0.0001\n",
      "[Epoch 043] loss=0.9355 recon=0.9350 kl=0.0006\n",
      "[Epoch 044] loss=0.9350 recon=0.9346 kl=0.0005\n",
      "[Epoch 045] loss=0.9305 recon=0.9300 kl=0.0005\n",
      "[Epoch 046] loss=0.9499 recon=0.9488 kl=0.0011\n",
      "[Epoch 047] loss=0.9290 recon=0.9287 kl=0.0004\n",
      "[Epoch 048] loss=0.9372 recon=0.9357 kl=0.0015\n",
      "[Epoch 049] loss=0.9278 recon=0.9259 kl=0.0019\n",
      "[Epoch 050] loss=0.9356 recon=0.9353 kl=0.0003\n",
      "[Epoch 051] loss=0.9371 recon=0.9370 kl=0.0000\n",
      "[Epoch 052] loss=0.9581 recon=0.9569 kl=0.0012\n",
      "[Epoch 053] loss=0.9348 recon=0.9336 kl=0.0012\n",
      "[Epoch 054] loss=0.9412 recon=0.9410 kl=0.0002\n",
      "[Epoch 055] loss=0.9344 recon=0.9339 kl=0.0004\n",
      "[Epoch 056] loss=0.9495 recon=0.9490 kl=0.0005\n",
      "[Epoch 057] loss=0.9353 recon=0.9344 kl=0.0009\n",
      "[Epoch 058] loss=0.9515 recon=0.9508 kl=0.0007\n",
      "[Epoch 059] loss=0.9422 recon=0.9419 kl=0.0004\n",
      "[Epoch 060] loss=0.9352 recon=0.9347 kl=0.0005\n",
      "[Epoch 061] loss=0.9427 recon=0.9419 kl=0.0008\n",
      "[Epoch 062] loss=0.9375 recon=0.9370 kl=0.0005\n",
      "[Epoch 063] loss=0.9268 recon=0.9267 kl=0.0002\n",
      "[Epoch 064] loss=0.9312 recon=0.9306 kl=0.0007\n",
      "[Epoch 065] loss=0.9542 recon=0.9537 kl=0.0006\n",
      "[Epoch 066] loss=0.9376 recon=0.9374 kl=0.0002\n",
      "[Epoch 067] loss=0.9310 recon=0.9305 kl=0.0005\n",
      "[Epoch 068] loss=0.9522 recon=0.9514 kl=0.0008\n",
      "[Epoch 069] loss=0.9401 recon=0.9399 kl=0.0001\n",
      "[Epoch 070] loss=0.9302 recon=0.9295 kl=0.0006\n",
      "[Epoch 071] loss=0.9358 recon=0.9355 kl=0.0003\n",
      "[Epoch 072] loss=0.9454 recon=0.9449 kl=0.0005\n",
      "[Epoch 073] loss=0.9402 recon=0.9393 kl=0.0008\n",
      "[Epoch 074] loss=0.9317 recon=0.9315 kl=0.0002\n",
      "[Epoch 075] loss=0.9332 recon=0.9299 kl=0.0034\n",
      "[Epoch 076] loss=0.9465 recon=0.9437 kl=0.0028\n",
      "[Epoch 077] loss=0.9293 recon=0.9264 kl=0.0029\n",
      "[Epoch 078] loss=0.9502 recon=0.9480 kl=0.0022\n",
      "[Epoch 079] loss=0.9351 recon=0.9336 kl=0.0015\n",
      "[Epoch 080] loss=0.9307 recon=0.9304 kl=0.0002\n",
      "[Epoch 081] loss=0.9388 recon=0.9388 kl=0.0000\n",
      "[Epoch 082] loss=0.9265 recon=0.9265 kl=0.0000\n",
      "[Epoch 083] loss=0.9358 recon=0.9358 kl=0.0000\n",
      "[Epoch 084] loss=0.9465 recon=0.9465 kl=0.0000\n",
      "[Epoch 085] loss=0.9435 recon=0.9435 kl=0.0000\n",
      "[Epoch 086] loss=0.9310 recon=0.9307 kl=0.0003\n",
      "[Epoch 087] loss=0.9278 recon=0.9270 kl=0.0008\n",
      "[Epoch 088] loss=0.9306 recon=0.9305 kl=0.0001\n",
      "[Epoch 089] loss=0.9538 recon=0.9536 kl=0.0002\n",
      "[Epoch 090] loss=0.9401 recon=0.9392 kl=0.0009\n",
      "57\n",
      "[Epoch 001] loss=1.8332 recon=0.9311 kl=0.9021\n",
      "[Epoch 002] loss=0.9489 recon=0.9435 kl=0.0054\n",
      "[Epoch 003] loss=0.9268 recon=0.9264 kl=0.0004\n",
      "[Epoch 004] loss=0.9324 recon=0.9323 kl=0.0001\n",
      "[Epoch 005] loss=0.9442 recon=0.9442 kl=0.0001\n",
      "[Epoch 006] loss=0.9352 recon=0.9351 kl=0.0001\n",
      "[Epoch 007] loss=0.9369 recon=0.9366 kl=0.0002\n",
      "[Epoch 008] loss=0.9346 recon=0.9344 kl=0.0002\n",
      "[Epoch 009] loss=0.9270 recon=0.9268 kl=0.0002\n",
      "[Epoch 010] loss=0.9480 recon=0.9479 kl=0.0001\n",
      "[Epoch 011] loss=0.9408 recon=0.9403 kl=0.0006\n",
      "[Epoch 012] loss=0.9450 recon=0.9448 kl=0.0002\n",
      "[Epoch 013] loss=0.9440 recon=0.9439 kl=0.0001\n",
      "[Epoch 014] loss=0.9378 recon=0.9371 kl=0.0007\n",
      "[Epoch 015] loss=0.9372 recon=0.9371 kl=0.0001\n",
      "[Epoch 016] loss=0.9376 recon=0.9371 kl=0.0004\n",
      "[Epoch 017] loss=0.9537 recon=0.9534 kl=0.0003\n",
      "[Epoch 018] loss=0.9539 recon=0.9532 kl=0.0007\n",
      "[Epoch 019] loss=0.9444 recon=0.9438 kl=0.0006\n",
      "[Epoch 020] loss=0.9386 recon=0.9386 kl=0.0001\n",
      "[Epoch 021] loss=0.9386 recon=0.9382 kl=0.0004\n",
      "[Epoch 022] loss=0.9406 recon=0.9403 kl=0.0003\n",
      "[Epoch 023] loss=0.9320 recon=0.9311 kl=0.0009\n",
      "[Epoch 024] loss=0.9514 recon=0.9512 kl=0.0002\n",
      "[Epoch 025] loss=0.9266 recon=0.9263 kl=0.0004\n",
      "[Epoch 026] loss=0.9322 recon=0.9317 kl=0.0005\n",
      "[Epoch 027] loss=0.9367 recon=0.9364 kl=0.0003\n",
      "[Epoch 028] loss=0.9318 recon=0.9314 kl=0.0004\n",
      "[Epoch 029] loss=0.9374 recon=0.9367 kl=0.0007\n",
      "[Epoch 030] loss=0.9417 recon=0.9416 kl=0.0001\n",
      "[Epoch 031] loss=0.9400 recon=0.9388 kl=0.0012\n",
      "[Epoch 032] loss=0.9406 recon=0.9404 kl=0.0002\n",
      "[Epoch 033] loss=0.9320 recon=0.9314 kl=0.0005\n",
      "[Epoch 034] loss=0.9353 recon=0.9352 kl=0.0002\n",
      "[Epoch 035] loss=0.9508 recon=0.9472 kl=0.0036\n",
      "[Epoch 036] loss=0.9433 recon=0.9413 kl=0.0020\n",
      "[Epoch 037] loss=0.9420 recon=0.9418 kl=0.0002\n",
      "[Epoch 038] loss=0.9442 recon=0.9442 kl=0.0000\n",
      "[Epoch 039] loss=0.9266 recon=0.9266 kl=0.0000\n",
      "[Epoch 040] loss=0.9270 recon=0.9265 kl=0.0005\n",
      "[Epoch 041] loss=0.9504 recon=0.9503 kl=0.0002\n",
      "[Epoch 042] loss=0.9571 recon=0.9567 kl=0.0004\n",
      "[Epoch 043] loss=0.9390 recon=0.9384 kl=0.0006\n",
      "[Epoch 044] loss=0.9450 recon=0.9446 kl=0.0004\n",
      "[Epoch 045] loss=0.9332 recon=0.9329 kl=0.0003\n",
      "[Epoch 046] loss=0.9471 recon=0.9466 kl=0.0006\n",
      "[Epoch 047] loss=0.9393 recon=0.9391 kl=0.0002\n",
      "[Epoch 048] loss=0.9459 recon=0.9451 kl=0.0009\n",
      "[Epoch 049] loss=0.9471 recon=0.9469 kl=0.0002\n",
      "[Epoch 050] loss=0.9536 recon=0.9531 kl=0.0005\n",
      "[Epoch 051] loss=0.9354 recon=0.9346 kl=0.0008\n",
      "[Epoch 052] loss=0.9452 recon=0.9451 kl=0.0001\n",
      "[Epoch 053] loss=0.9324 recon=0.9316 kl=0.0008\n",
      "[Epoch 054] loss=0.9195 recon=0.9192 kl=0.0003\n",
      "[Epoch 055] loss=0.9332 recon=0.9329 kl=0.0003\n",
      "[Epoch 056] loss=0.9285 recon=0.9279 kl=0.0006\n",
      "[Epoch 057] loss=0.9334 recon=0.9330 kl=0.0004\n",
      "[Epoch 058] loss=0.9303 recon=0.9300 kl=0.0003\n",
      "[Epoch 059] loss=0.9363 recon=0.9354 kl=0.0009\n",
      "[Epoch 060] loss=0.9422 recon=0.9419 kl=0.0003\n",
      "[Epoch 061] loss=0.9372 recon=0.9367 kl=0.0005\n",
      "[Epoch 062] loss=0.9284 recon=0.9279 kl=0.0004\n",
      "[Epoch 063] loss=0.9406 recon=0.9346 kl=0.0060\n",
      "[Epoch 064] loss=0.9338 recon=0.9320 kl=0.0017\n",
      "[Epoch 065] loss=0.9368 recon=0.9367 kl=0.0002\n",
      "[Epoch 066] loss=0.9488 recon=0.9487 kl=0.0000\n",
      "[Epoch 067] loss=0.9367 recon=0.9367 kl=0.0000\n",
      "[Epoch 068] loss=0.9456 recon=0.9456 kl=0.0000\n",
      "[Epoch 069] loss=0.9337 recon=0.9334 kl=0.0003\n",
      "[Epoch 070] loss=0.9663 recon=0.9616 kl=0.0047\n",
      "[Epoch 071] loss=0.9350 recon=0.9315 kl=0.0035\n",
      "[Epoch 072] loss=0.9361 recon=0.9354 kl=0.0007\n",
      "[Epoch 073] loss=0.9369 recon=0.9369 kl=0.0001\n",
      "[Epoch 074] loss=0.9354 recon=0.9354 kl=0.0000\n",
      "[Epoch 075] loss=0.9459 recon=0.9459 kl=0.0000\n",
      "[Epoch 076] loss=0.9465 recon=0.9465 kl=0.0000\n",
      "[Epoch 077] loss=0.9386 recon=0.9383 kl=0.0003\n",
      "[Epoch 078] loss=0.9231 recon=0.9223 kl=0.0008\n",
      "[Epoch 079] loss=0.9432 recon=0.9431 kl=0.0001\n",
      "[Epoch 080] loss=0.9301 recon=0.9292 kl=0.0009\n",
      "[Epoch 081] loss=0.9313 recon=0.9305 kl=0.0008\n",
      "[Epoch 082] loss=0.9326 recon=0.9325 kl=0.0001\n",
      "[Epoch 083] loss=0.9362 recon=0.9337 kl=0.0025\n",
      "[Epoch 084] loss=0.9319 recon=0.9311 kl=0.0009\n",
      "[Epoch 085] loss=0.9305 recon=0.9304 kl=0.0001\n",
      "[Epoch 086] loss=0.9350 recon=0.9349 kl=0.0000\n",
      "[Epoch 087] loss=0.9324 recon=0.9318 kl=0.0006\n",
      "[Epoch 088] loss=0.9622 recon=0.9613 kl=0.0009\n",
      "[Epoch 089] loss=0.9280 recon=0.9278 kl=0.0002\n",
      "[Epoch 090] loss=0.9356 recon=0.9353 kl=0.0003\n",
      "58\n",
      "[Epoch 001] loss=1.1676 recon=0.9368 kl=0.2309\n",
      "[Epoch 002] loss=0.9490 recon=0.9469 kl=0.0021\n",
      "[Epoch 003] loss=0.9303 recon=0.9301 kl=0.0002\n",
      "[Epoch 004] loss=0.9448 recon=0.9446 kl=0.0002\n",
      "[Epoch 005] loss=0.9324 recon=0.9322 kl=0.0002\n",
      "[Epoch 006] loss=0.9267 recon=0.9265 kl=0.0002\n",
      "[Epoch 007] loss=0.9346 recon=0.9343 kl=0.0003\n",
      "[Epoch 008] loss=0.9403 recon=0.9402 kl=0.0001\n",
      "[Epoch 009] loss=0.9300 recon=0.9298 kl=0.0002\n",
      "[Epoch 010] loss=0.9459 recon=0.9457 kl=0.0002\n",
      "[Epoch 011] loss=0.9448 recon=0.9446 kl=0.0002\n",
      "[Epoch 012] loss=0.9257 recon=0.9251 kl=0.0006\n",
      "[Epoch 013] loss=0.9638 recon=0.9637 kl=0.0001\n",
      "[Epoch 014] loss=0.9461 recon=0.9458 kl=0.0003\n",
      "[Epoch 015] loss=0.9386 recon=0.9382 kl=0.0004\n",
      "[Epoch 016] loss=0.9266 recon=0.9262 kl=0.0003\n",
      "[Epoch 017] loss=0.9445 recon=0.9442 kl=0.0003\n",
      "[Epoch 018] loss=0.9428 recon=0.9424 kl=0.0004\n",
      "[Epoch 019] loss=0.9479 recon=0.9473 kl=0.0005\n",
      "[Epoch 020] loss=0.9336 recon=0.9332 kl=0.0004\n",
      "[Epoch 021] loss=0.9440 recon=0.9437 kl=0.0003\n",
      "[Epoch 022] loss=0.9305 recon=0.9299 kl=0.0006\n",
      "[Epoch 023] loss=0.9435 recon=0.9425 kl=0.0009\n",
      "[Epoch 024] loss=0.9336 recon=0.9334 kl=0.0002\n",
      "[Epoch 025] loss=0.9341 recon=0.9334 kl=0.0007\n",
      "[Epoch 026] loss=0.9390 recon=0.9387 kl=0.0003\n",
      "[Epoch 027] loss=0.9373 recon=0.9362 kl=0.0010\n",
      "[Epoch 028] loss=0.9280 recon=0.9278 kl=0.0003\n",
      "[Epoch 029] loss=0.9291 recon=0.9286 kl=0.0004\n",
      "[Epoch 030] loss=0.9363 recon=0.9355 kl=0.0008\n",
      "[Epoch 031] loss=0.9262 recon=0.9258 kl=0.0004\n",
      "[Epoch 032] loss=0.9276 recon=0.9271 kl=0.0005\n",
      "[Epoch 033] loss=0.9286 recon=0.9279 kl=0.0007\n",
      "[Epoch 034] loss=0.9364 recon=0.9361 kl=0.0003\n",
      "[Epoch 035] loss=0.9245 recon=0.9233 kl=0.0012\n",
      "[Epoch 036] loss=0.9232 recon=0.9208 kl=0.0024\n",
      "[Epoch 037] loss=0.9408 recon=0.9403 kl=0.0005\n",
      "[Epoch 038] loss=0.9705 recon=0.9704 kl=0.0001\n",
      "[Epoch 039] loss=0.9396 recon=0.9392 kl=0.0004\n",
      "[Epoch 040] loss=0.9322 recon=0.9316 kl=0.0005\n",
      "[Epoch 041] loss=0.9324 recon=0.9319 kl=0.0005\n",
      "[Epoch 042] loss=0.9338 recon=0.9330 kl=0.0008\n",
      "[Epoch 043] loss=0.9510 recon=0.9504 kl=0.0005\n",
      "[Epoch 044] loss=0.9495 recon=0.9451 kl=0.0044\n",
      "[Epoch 045] loss=0.9269 recon=0.9257 kl=0.0013\n",
      "[Epoch 046] loss=0.9412 recon=0.9411 kl=0.0001\n",
      "[Epoch 047] loss=0.9526 recon=0.9526 kl=0.0000\n",
      "[Epoch 048] loss=0.9290 recon=0.9289 kl=0.0000\n",
      "[Epoch 049] loss=0.9429 recon=0.9420 kl=0.0009\n",
      "[Epoch 050] loss=0.9347 recon=0.9341 kl=0.0006\n",
      "[Epoch 051] loss=0.9429 recon=0.9425 kl=0.0004\n",
      "[Epoch 052] loss=0.9313 recon=0.9307 kl=0.0007\n",
      "[Epoch 053] loss=0.9285 recon=0.9279 kl=0.0005\n",
      "[Epoch 054] loss=0.9366 recon=0.9298 kl=0.0068\n",
      "[Epoch 055] loss=0.9361 recon=0.9325 kl=0.0037\n",
      "[Epoch 056] loss=0.9327 recon=0.9323 kl=0.0003\n",
      "[Epoch 057] loss=0.9322 recon=0.9321 kl=0.0000\n",
      "[Epoch 058] loss=0.9405 recon=0.9405 kl=0.0000\n",
      "[Epoch 059] loss=0.9362 recon=0.9353 kl=0.0009\n",
      "[Epoch 060] loss=0.9676 recon=0.9633 kl=0.0043\n",
      "[Epoch 061] loss=0.9288 recon=0.9279 kl=0.0008\n",
      "[Epoch 062] loss=0.9450 recon=0.9449 kl=0.0001\n",
      "[Epoch 063] loss=0.9531 recon=0.9530 kl=0.0000\n",
      "[Epoch 064] loss=0.9270 recon=0.9269 kl=0.0000\n",
      "[Epoch 065] loss=0.9325 recon=0.9320 kl=0.0005\n",
      "[Epoch 066] loss=0.9518 recon=0.9514 kl=0.0004\n",
      "[Epoch 067] loss=0.9293 recon=0.9285 kl=0.0008\n",
      "[Epoch 068] loss=0.9338 recon=0.9336 kl=0.0002\n",
      "[Epoch 069] loss=0.9730 recon=0.9724 kl=0.0006\n",
      "[Epoch 070] loss=0.9575 recon=0.9568 kl=0.0007\n",
      "[Epoch 071] loss=0.9465 recon=0.9463 kl=0.0002\n",
      "[Epoch 072] loss=0.9485 recon=0.9477 kl=0.0007\n",
      "[Epoch 073] loss=0.9406 recon=0.9389 kl=0.0016\n",
      "[Epoch 074] loss=0.9355 recon=0.9320 kl=0.0036\n",
      "[Epoch 075] loss=0.9394 recon=0.9366 kl=0.0028\n",
      "[Epoch 076] loss=0.9522 recon=0.9503 kl=0.0019\n",
      "[Epoch 077] loss=0.9436 recon=0.9434 kl=0.0002\n",
      "[Epoch 078] loss=0.9249 recon=0.9249 kl=0.0000\n",
      "[Epoch 079] loss=0.9505 recon=0.9505 kl=0.0000\n",
      "[Epoch 080] loss=0.9426 recon=0.9426 kl=0.0000\n",
      "[Epoch 081] loss=0.9286 recon=0.9280 kl=0.0007\n",
      "[Epoch 082] loss=0.9445 recon=0.9438 kl=0.0007\n",
      "[Epoch 083] loss=0.9428 recon=0.9426 kl=0.0002\n",
      "[Epoch 084] loss=0.9358 recon=0.9355 kl=0.0003\n",
      "[Epoch 085] loss=0.9330 recon=0.9324 kl=0.0006\n",
      "[Epoch 086] loss=0.9304 recon=0.9299 kl=0.0005\n",
      "[Epoch 087] loss=0.9336 recon=0.9334 kl=0.0002\n",
      "[Epoch 088] loss=0.9366 recon=0.9360 kl=0.0006\n",
      "[Epoch 089] loss=0.9411 recon=0.9405 kl=0.0005\n",
      "[Epoch 090] loss=0.9383 recon=0.9380 kl=0.0003\n",
      "59\n",
      "[Epoch 001] loss=1.3777 recon=0.9485 kl=0.4292\n",
      "[Epoch 002] loss=0.9307 recon=0.9279 kl=0.0028\n",
      "[Epoch 003] loss=0.9358 recon=0.9356 kl=0.0002\n",
      "[Epoch 004] loss=0.9701 recon=0.9700 kl=0.0001\n",
      "[Epoch 005] loss=0.9473 recon=0.9472 kl=0.0001\n",
      "[Epoch 006] loss=0.9262 recon=0.9260 kl=0.0002\n",
      "[Epoch 007] loss=0.9548 recon=0.9546 kl=0.0002\n",
      "[Epoch 008] loss=0.9442 recon=0.9440 kl=0.0002\n",
      "[Epoch 009] loss=0.9284 recon=0.9282 kl=0.0002\n",
      "[Epoch 010] loss=0.9492 recon=0.9489 kl=0.0003\n",
      "[Epoch 011] loss=0.9420 recon=0.9412 kl=0.0008\n",
      "[Epoch 012] loss=0.9448 recon=0.9444 kl=0.0004\n",
      "[Epoch 013] loss=0.9318 recon=0.9317 kl=0.0001\n",
      "[Epoch 014] loss=0.9589 recon=0.9583 kl=0.0005\n",
      "[Epoch 015] loss=0.9325 recon=0.9321 kl=0.0004\n",
      "[Epoch 016] loss=0.9307 recon=0.9303 kl=0.0004\n",
      "[Epoch 017] loss=0.9303 recon=0.9297 kl=0.0006\n",
      "[Epoch 018] loss=0.9385 recon=0.9380 kl=0.0005\n",
      "[Epoch 019] loss=0.9221 recon=0.9220 kl=0.0001\n",
      "[Epoch 020] loss=0.9603 recon=0.9598 kl=0.0005\n",
      "[Epoch 021] loss=0.9356 recon=0.9354 kl=0.0002\n",
      "[Epoch 022] loss=0.9330 recon=0.9323 kl=0.0007\n",
      "[Epoch 023] loss=0.9302 recon=0.9299 kl=0.0003\n",
      "[Epoch 024] loss=0.9434 recon=0.9427 kl=0.0007\n",
      "[Epoch 025] loss=0.9427 recon=0.9424 kl=0.0003\n",
      "[Epoch 026] loss=0.9576 recon=0.9533 kl=0.0043\n",
      "[Epoch 027] loss=0.9287 recon=0.9268 kl=0.0020\n",
      "[Epoch 028] loss=0.9375 recon=0.9372 kl=0.0003\n",
      "[Epoch 029] loss=0.9366 recon=0.9366 kl=0.0000\n",
      "[Epoch 030] loss=0.9292 recon=0.9289 kl=0.0003\n",
      "[Epoch 031] loss=0.9342 recon=0.9337 kl=0.0005\n",
      "[Epoch 032] loss=0.9358 recon=0.9355 kl=0.0003\n",
      "[Epoch 033] loss=0.9553 recon=0.9548 kl=0.0006\n",
      "[Epoch 034] loss=0.9376 recon=0.9374 kl=0.0002\n",
      "[Epoch 035] loss=0.9303 recon=0.9298 kl=0.0006\n",
      "[Epoch 036] loss=0.9335 recon=0.9329 kl=0.0006\n",
      "[Epoch 037] loss=0.9274 recon=0.9260 kl=0.0015\n",
      "[Epoch 038] loss=0.9358 recon=0.9353 kl=0.0005\n",
      "[Epoch 039] loss=0.9502 recon=0.9499 kl=0.0003\n",
      "[Epoch 040] loss=0.9431 recon=0.9426 kl=0.0005\n",
      "[Epoch 041] loss=0.9459 recon=0.9423 kl=0.0037\n",
      "[Epoch 042] loss=0.9334 recon=0.9304 kl=0.0031\n",
      "[Epoch 043] loss=0.9483 recon=0.9465 kl=0.0018\n",
      "[Epoch 044] loss=0.9334 recon=0.9331 kl=0.0003\n",
      "[Epoch 045] loss=0.9380 recon=0.9380 kl=0.0000\n",
      "[Epoch 046] loss=0.9431 recon=0.9431 kl=0.0000\n",
      "[Epoch 047] loss=0.9458 recon=0.9458 kl=0.0000\n",
      "[Epoch 048] loss=0.9541 recon=0.9535 kl=0.0006\n",
      "[Epoch 049] loss=0.9367 recon=0.9335 kl=0.0031\n",
      "[Epoch 050] loss=0.9433 recon=0.9406 kl=0.0027\n",
      "[Epoch 051] loss=0.9308 recon=0.9289 kl=0.0019\n",
      "[Epoch 052] loss=0.9253 recon=0.9248 kl=0.0005\n",
      "[Epoch 053] loss=0.9371 recon=0.9370 kl=0.0001\n",
      "[Epoch 054] loss=0.9340 recon=0.9340 kl=0.0000\n",
      "[Epoch 055] loss=0.9398 recon=0.9398 kl=0.0000\n",
      "[Epoch 056] loss=0.9373 recon=0.9373 kl=0.0000\n",
      "[Epoch 057] loss=0.9291 recon=0.9287 kl=0.0005\n",
      "[Epoch 058] loss=0.9296 recon=0.9294 kl=0.0001\n",
      "[Epoch 059] loss=0.9512 recon=0.9506 kl=0.0006\n",
      "[Epoch 060] loss=0.9278 recon=0.9273 kl=0.0004\n",
      "[Epoch 061] loss=0.9311 recon=0.9305 kl=0.0006\n",
      "[Epoch 062] loss=0.9505 recon=0.9503 kl=0.0002\n",
      "[Epoch 063] loss=0.9395 recon=0.9389 kl=0.0006\n",
      "[Epoch 064] loss=0.9519 recon=0.9451 kl=0.0068\n",
      "[Epoch 065] loss=0.9297 recon=0.9278 kl=0.0019\n",
      "[Epoch 066] loss=0.9510 recon=0.9508 kl=0.0002\n",
      "[Epoch 067] loss=0.9308 recon=0.9308 kl=0.0000\n",
      "[Epoch 068] loss=0.9354 recon=0.9353 kl=0.0000\n",
      "[Epoch 069] loss=0.9321 recon=0.9321 kl=0.0000\n",
      "[Epoch 070] loss=0.9336 recon=0.9329 kl=0.0007\n",
      "[Epoch 071] loss=0.9349 recon=0.9341 kl=0.0008\n",
      "[Epoch 072] loss=0.9319 recon=0.9315 kl=0.0004\n",
      "[Epoch 073] loss=0.9352 recon=0.9351 kl=0.0001\n",
      "[Epoch 074] loss=0.9326 recon=0.9319 kl=0.0007\n",
      "[Epoch 075] loss=0.9357 recon=0.9356 kl=0.0001\n",
      "[Epoch 076] loss=0.9308 recon=0.9303 kl=0.0005\n",
      "[Epoch 077] loss=0.9319 recon=0.9313 kl=0.0007\n",
      "[Epoch 078] loss=0.9335 recon=0.9332 kl=0.0003\n",
      "[Epoch 079] loss=0.9452 recon=0.9445 kl=0.0007\n",
      "[Epoch 080] loss=0.9599 recon=0.9597 kl=0.0002\n",
      "[Epoch 081] loss=0.9408 recon=0.9403 kl=0.0005\n",
      "[Epoch 082] loss=0.9311 recon=0.9281 kl=0.0031\n",
      "[Epoch 083] loss=0.9340 recon=0.9316 kl=0.0024\n",
      "[Epoch 084] loss=0.9393 recon=0.9384 kl=0.0009\n",
      "[Epoch 085] loss=0.9406 recon=0.9406 kl=0.0001\n",
      "[Epoch 086] loss=0.9364 recon=0.9364 kl=0.0000\n",
      "[Epoch 087] loss=0.9382 recon=0.9382 kl=0.0000\n",
      "[Epoch 088] loss=0.9553 recon=0.9551 kl=0.0002\n",
      "[Epoch 089] loss=0.9458 recon=0.9347 kl=0.0111\n",
      "[Epoch 090] loss=0.9311 recon=0.9247 kl=0.0064\n",
      "60\n",
      "[Epoch 001] loss=1.3085 recon=0.9307 kl=0.3778\n",
      "[Epoch 002] loss=0.9483 recon=0.9460 kl=0.0023\n",
      "[Epoch 003] loss=0.9373 recon=0.9370 kl=0.0002\n",
      "[Epoch 004] loss=0.9382 recon=0.9381 kl=0.0001\n",
      "[Epoch 005] loss=0.9332 recon=0.9331 kl=0.0001\n",
      "[Epoch 006] loss=0.9500 recon=0.9497 kl=0.0004\n",
      "[Epoch 007] loss=0.9414 recon=0.9413 kl=0.0001\n",
      "[Epoch 008] loss=0.9404 recon=0.9398 kl=0.0006\n",
      "[Epoch 009] loss=0.9320 recon=0.9317 kl=0.0003\n",
      "[Epoch 010] loss=0.9449 recon=0.9447 kl=0.0002\n",
      "[Epoch 011] loss=0.9309 recon=0.9304 kl=0.0005\n",
      "[Epoch 012] loss=0.9310 recon=0.9307 kl=0.0003\n",
      "[Epoch 013] loss=0.9397 recon=0.9392 kl=0.0005\n",
      "[Epoch 014] loss=0.9359 recon=0.9336 kl=0.0023\n",
      "[Epoch 015] loss=0.9588 recon=0.9571 kl=0.0016\n",
      "[Epoch 016] loss=0.9491 recon=0.9489 kl=0.0002\n",
      "[Epoch 017] loss=0.9408 recon=0.9408 kl=0.0000\n",
      "[Epoch 018] loss=0.9522 recon=0.9520 kl=0.0002\n",
      "[Epoch 019] loss=0.9516 recon=0.9510 kl=0.0006\n",
      "[Epoch 020] loss=0.9362 recon=0.9357 kl=0.0005\n",
      "[Epoch 021] loss=0.9408 recon=0.9404 kl=0.0003\n",
      "[Epoch 022] loss=0.9419 recon=0.9412 kl=0.0007\n",
      "[Epoch 023] loss=0.9316 recon=0.9313 kl=0.0003\n",
      "[Epoch 024] loss=0.9243 recon=0.9232 kl=0.0011\n",
      "[Epoch 025] loss=0.9465 recon=0.9463 kl=0.0001\n",
      "[Epoch 026] loss=0.9608 recon=0.9602 kl=0.0006\n",
      "[Epoch 027] loss=0.9285 recon=0.9282 kl=0.0003\n",
      "[Epoch 028] loss=0.9284 recon=0.9278 kl=0.0006\n",
      "[Epoch 029] loss=0.9312 recon=0.9303 kl=0.0010\n",
      "[Epoch 030] loss=0.9335 recon=0.9332 kl=0.0003\n",
      "[Epoch 031] loss=0.9380 recon=0.9379 kl=0.0001\n",
      "[Epoch 032] loss=0.9488 recon=0.9478 kl=0.0010\n",
      "[Epoch 033] loss=0.9400 recon=0.9395 kl=0.0005\n",
      "[Epoch 034] loss=0.9423 recon=0.9420 kl=0.0003\n",
      "[Epoch 035] loss=0.9289 recon=0.9283 kl=0.0006\n",
      "[Epoch 036] loss=0.9312 recon=0.9308 kl=0.0004\n",
      "[Epoch 037] loss=0.9358 recon=0.9351 kl=0.0007\n",
      "[Epoch 038] loss=0.9279 recon=0.9273 kl=0.0006\n",
      "[Epoch 039] loss=0.9332 recon=0.9329 kl=0.0003\n",
      "[Epoch 040] loss=0.9575 recon=0.9569 kl=0.0006\n",
      "[Epoch 041] loss=0.9260 recon=0.9231 kl=0.0029\n",
      "[Epoch 042] loss=0.9339 recon=0.9327 kl=0.0012\n",
      "[Epoch 043] loss=0.9351 recon=0.9350 kl=0.0001\n",
      "[Epoch 044] loss=0.9381 recon=0.9380 kl=0.0000\n",
      "[Epoch 045] loss=0.9421 recon=0.9417 kl=0.0004\n",
      "[Epoch 046] loss=0.9421 recon=0.9412 kl=0.0008\n",
      "[Epoch 047] loss=0.9338 recon=0.9337 kl=0.0001\n",
      "[Epoch 048] loss=0.9287 recon=0.9279 kl=0.0008\n",
      "[Epoch 049] loss=0.9271 recon=0.9267 kl=0.0004\n",
      "[Epoch 050] loss=0.9336 recon=0.9329 kl=0.0007\n",
      "[Epoch 051] loss=0.9277 recon=0.9272 kl=0.0005\n",
      "[Epoch 052] loss=0.9379 recon=0.9373 kl=0.0006\n",
      "[Epoch 053] loss=0.9390 recon=0.9350 kl=0.0039\n",
      "[Epoch 054] loss=0.9397 recon=0.9369 kl=0.0027\n",
      "[Epoch 055] loss=0.9336 recon=0.9320 kl=0.0016\n",
      "[Epoch 056] loss=0.9325 recon=0.9323 kl=0.0003\n",
      "[Epoch 057] loss=0.9425 recon=0.9424 kl=0.0000\n",
      "[Epoch 058] loss=0.9257 recon=0.9257 kl=0.0000\n",
      "[Epoch 059] loss=0.9447 recon=0.9446 kl=0.0001\n",
      "[Epoch 060] loss=0.9514 recon=0.9511 kl=0.0003\n",
      "[Epoch 061] loss=0.9319 recon=0.9311 kl=0.0008\n",
      "[Epoch 062] loss=0.9280 recon=0.9272 kl=0.0009\n",
      "[Epoch 063] loss=0.9324 recon=0.9323 kl=0.0001\n",
      "[Epoch 064] loss=0.9300 recon=0.9294 kl=0.0005\n",
      "[Epoch 065] loss=0.9297 recon=0.9291 kl=0.0006\n",
      "[Epoch 066] loss=0.9452 recon=0.9449 kl=0.0003\n",
      "[Epoch 067] loss=0.9429 recon=0.9423 kl=0.0005\n",
      "[Epoch 068] loss=0.9389 recon=0.9383 kl=0.0006\n",
      "[Epoch 069] loss=0.9437 recon=0.9433 kl=0.0004\n",
      "[Epoch 070] loss=0.9424 recon=0.9418 kl=0.0006\n",
      "[Epoch 071] loss=0.9388 recon=0.9383 kl=0.0005\n",
      "[Epoch 072] loss=0.9427 recon=0.9419 kl=0.0008\n",
      "[Epoch 073] loss=0.9403 recon=0.9393 kl=0.0009\n",
      "[Epoch 074] loss=0.9514 recon=0.9513 kl=0.0001\n",
      "[Epoch 075] loss=0.9353 recon=0.9349 kl=0.0003\n",
      "[Epoch 076] loss=0.9355 recon=0.9348 kl=0.0006\n",
      "[Epoch 077] loss=0.9441 recon=0.9436 kl=0.0005\n",
      "[Epoch 078] loss=0.9499 recon=0.9497 kl=0.0002\n",
      "[Epoch 079] loss=0.9328 recon=0.9321 kl=0.0007\n",
      "[Epoch 080] loss=0.9297 recon=0.9290 kl=0.0007\n",
      "[Epoch 081] loss=0.9338 recon=0.9337 kl=0.0002\n",
      "[Epoch 082] loss=0.9209 recon=0.9204 kl=0.0004\n",
      "[Epoch 083] loss=0.9441 recon=0.9435 kl=0.0006\n",
      "[Epoch 084] loss=0.9416 recon=0.9412 kl=0.0004\n",
      "[Epoch 085] loss=0.9326 recon=0.9322 kl=0.0005\n",
      "[Epoch 086] loss=0.9466 recon=0.9460 kl=0.0005\n",
      "[Epoch 087] loss=0.9409 recon=0.9402 kl=0.0007\n",
      "[Epoch 088] loss=0.9363 recon=0.9360 kl=0.0003\n",
      "[Epoch 089] loss=0.9547 recon=0.9544 kl=0.0003\n",
      "[Epoch 090] loss=0.9309 recon=0.9304 kl=0.0005\n",
      "61\n",
      "[Epoch 001] loss=1.3996 recon=0.9446 kl=0.4549\n",
      "[Epoch 002] loss=0.9405 recon=0.9376 kl=0.0029\n",
      "[Epoch 003] loss=0.9429 recon=0.9426 kl=0.0003\n",
      "[Epoch 004] loss=0.9376 recon=0.9375 kl=0.0001\n",
      "[Epoch 005] loss=0.9289 recon=0.9287 kl=0.0002\n",
      "[Epoch 006] loss=0.9571 recon=0.9570 kl=0.0001\n",
      "[Epoch 007] loss=0.9341 recon=0.9338 kl=0.0002\n",
      "[Epoch 008] loss=0.9342 recon=0.9332 kl=0.0010\n",
      "[Epoch 009] loss=0.9342 recon=0.9341 kl=0.0001\n",
      "[Epoch 010] loss=0.9346 recon=0.9343 kl=0.0003\n",
      "[Epoch 011] loss=0.9327 recon=0.9326 kl=0.0001\n",
      "[Epoch 012] loss=0.9450 recon=0.9447 kl=0.0003\n",
      "[Epoch 013] loss=0.9372 recon=0.9369 kl=0.0004\n",
      "[Epoch 014] loss=0.9323 recon=0.9322 kl=0.0001\n",
      "[Epoch 015] loss=0.9344 recon=0.9337 kl=0.0007\n",
      "[Epoch 016] loss=0.9334 recon=0.9330 kl=0.0003\n",
      "[Epoch 017] loss=0.9267 recon=0.9265 kl=0.0002\n",
      "[Epoch 018] loss=0.9414 recon=0.9411 kl=0.0003\n",
      "[Epoch 019] loss=0.9357 recon=0.9351 kl=0.0006\n",
      "[Epoch 020] loss=0.9570 recon=0.9568 kl=0.0002\n",
      "[Epoch 021] loss=0.9342 recon=0.9335 kl=0.0007\n",
      "[Epoch 022] loss=0.9512 recon=0.9510 kl=0.0003\n",
      "[Epoch 023] loss=0.9380 recon=0.9376 kl=0.0003\n",
      "[Epoch 024] loss=0.9329 recon=0.9323 kl=0.0006\n",
      "[Epoch 025] loss=0.9519 recon=0.9517 kl=0.0002\n",
      "[Epoch 026] loss=0.9377 recon=0.9372 kl=0.0005\n",
      "[Epoch 027] loss=0.9385 recon=0.9345 kl=0.0040\n",
      "[Epoch 028] loss=0.9412 recon=0.9396 kl=0.0016\n",
      "[Epoch 029] loss=0.9243 recon=0.9241 kl=0.0002\n",
      "[Epoch 030] loss=0.9382 recon=0.9382 kl=0.0000\n",
      "[Epoch 031] loss=0.9406 recon=0.9405 kl=0.0001\n",
      "[Epoch 032] loss=0.9381 recon=0.9375 kl=0.0007\n",
      "[Epoch 033] loss=0.9302 recon=0.9300 kl=0.0002\n",
      "[Epoch 034] loss=0.9348 recon=0.9334 kl=0.0014\n",
      "[Epoch 035] loss=0.9461 recon=0.9427 kl=0.0034\n",
      "[Epoch 036] loss=0.9399 recon=0.9394 kl=0.0005\n",
      "[Epoch 037] loss=0.9402 recon=0.9401 kl=0.0001\n",
      "[Epoch 038] loss=0.9375 recon=0.9367 kl=0.0008\n",
      "[Epoch 039] loss=0.9460 recon=0.9458 kl=0.0002\n",
      "[Epoch 040] loss=0.9306 recon=0.9274 kl=0.0032\n",
      "[Epoch 041] loss=0.9280 recon=0.9253 kl=0.0027\n",
      "[Epoch 042] loss=0.9422 recon=0.9418 kl=0.0004\n",
      "[Epoch 043] loss=0.9345 recon=0.9345 kl=0.0000\n",
      "[Epoch 044] loss=0.9251 recon=0.9251 kl=0.0000\n",
      "[Epoch 045] loss=0.9323 recon=0.9323 kl=0.0000\n",
      "[Epoch 046] loss=0.9303 recon=0.9297 kl=0.0006\n",
      "[Epoch 047] loss=0.9345 recon=0.9343 kl=0.0002\n",
      "[Epoch 048] loss=0.9484 recon=0.9481 kl=0.0003\n",
      "[Epoch 049] loss=0.9378 recon=0.9352 kl=0.0026\n",
      "[Epoch 050] loss=0.9524 recon=0.9521 kl=0.0003\n",
      "[Epoch 051] loss=0.9308 recon=0.9307 kl=0.0000\n",
      "[Epoch 052] loss=0.9362 recon=0.9355 kl=0.0007\n",
      "[Epoch 053] loss=0.9596 recon=0.9593 kl=0.0003\n",
      "[Epoch 054] loss=0.9450 recon=0.9443 kl=0.0007\n",
      "[Epoch 055] loss=0.9385 recon=0.9382 kl=0.0003\n",
      "[Epoch 056] loss=0.9388 recon=0.9384 kl=0.0004\n",
      "[Epoch 057] loss=0.9280 recon=0.9278 kl=0.0002\n",
      "[Epoch 058] loss=0.9418 recon=0.9411 kl=0.0007\n",
      "[Epoch 059] loss=0.9295 recon=0.9292 kl=0.0003\n",
      "[Epoch 060] loss=0.9344 recon=0.9338 kl=0.0006\n",
      "[Epoch 061] loss=0.9449 recon=0.9441 kl=0.0007\n",
      "[Epoch 062] loss=0.9376 recon=0.9372 kl=0.0004\n",
      "[Epoch 063] loss=0.9362 recon=0.9360 kl=0.0002\n",
      "[Epoch 064] loss=0.9374 recon=0.9341 kl=0.0033\n",
      "[Epoch 065] loss=0.9492 recon=0.9474 kl=0.0018\n",
      "[Epoch 066] loss=0.9358 recon=0.9355 kl=0.0003\n",
      "[Epoch 067] loss=0.9373 recon=0.9373 kl=0.0000\n",
      "[Epoch 068] loss=0.9361 recon=0.9361 kl=0.0000\n",
      "[Epoch 069] loss=0.9363 recon=0.9357 kl=0.0006\n",
      "[Epoch 070] loss=0.9388 recon=0.9385 kl=0.0003\n",
      "[Epoch 071] loss=0.9278 recon=0.9274 kl=0.0004\n",
      "[Epoch 072] loss=0.9390 recon=0.9385 kl=0.0006\n",
      "[Epoch 073] loss=0.9462 recon=0.9461 kl=0.0002\n",
      "[Epoch 074] loss=0.9336 recon=0.9300 kl=0.0035\n",
      "[Epoch 075] loss=0.9542 recon=0.9515 kl=0.0027\n",
      "[Epoch 076] loss=0.9337 recon=0.9334 kl=0.0003\n",
      "[Epoch 077] loss=0.9341 recon=0.9341 kl=0.0000\n",
      "[Epoch 078] loss=0.9382 recon=0.9382 kl=0.0000\n",
      "[Epoch 079] loss=0.9337 recon=0.9334 kl=0.0003\n",
      "[Epoch 080] loss=0.9327 recon=0.9322 kl=0.0005\n",
      "[Epoch 081] loss=0.9434 recon=0.9431 kl=0.0003\n",
      "[Epoch 082] loss=0.9341 recon=0.9336 kl=0.0005\n",
      "[Epoch 083] loss=0.9310 recon=0.9306 kl=0.0004\n",
      "[Epoch 084] loss=0.9381 recon=0.9377 kl=0.0005\n",
      "[Epoch 085] loss=0.9252 recon=0.9249 kl=0.0002\n",
      "[Epoch 086] loss=0.9361 recon=0.9351 kl=0.0009\n",
      "[Epoch 087] loss=0.9512 recon=0.9508 kl=0.0004\n",
      "[Epoch 088] loss=0.9389 recon=0.9385 kl=0.0004\n",
      "[Epoch 089] loss=0.9345 recon=0.9340 kl=0.0005\n",
      "[Epoch 090] loss=0.9329 recon=0.9323 kl=0.0006\n",
      "62\n",
      "[Epoch 001] loss=1.3269 recon=0.9482 kl=0.3787\n",
      "[Epoch 002] loss=0.9520 recon=0.9490 kl=0.0030\n",
      "[Epoch 003] loss=0.9354 recon=0.9351 kl=0.0002\n",
      "[Epoch 004] loss=0.9340 recon=0.9340 kl=0.0001\n",
      "[Epoch 005] loss=0.9522 recon=0.9519 kl=0.0003\n",
      "[Epoch 006] loss=0.9431 recon=0.9430 kl=0.0001\n",
      "[Epoch 007] loss=0.9402 recon=0.9401 kl=0.0002\n",
      "[Epoch 008] loss=0.9492 recon=0.9489 kl=0.0003\n",
      "[Epoch 009] loss=0.9548 recon=0.9546 kl=0.0003\n",
      "[Epoch 010] loss=0.9660 recon=0.9657 kl=0.0002\n",
      "[Epoch 011] loss=0.9364 recon=0.9362 kl=0.0002\n",
      "[Epoch 012] loss=0.9425 recon=0.9421 kl=0.0004\n",
      "[Epoch 013] loss=0.9448 recon=0.9445 kl=0.0003\n",
      "[Epoch 014] loss=0.9462 recon=0.9457 kl=0.0005\n",
      "[Epoch 015] loss=0.9314 recon=0.9312 kl=0.0001\n",
      "[Epoch 016] loss=0.9287 recon=0.9282 kl=0.0006\n",
      "[Epoch 017] loss=0.9432 recon=0.9426 kl=0.0006\n",
      "[Epoch 018] loss=0.9304 recon=0.9302 kl=0.0002\n",
      "[Epoch 019] loss=0.9299 recon=0.9295 kl=0.0004\n",
      "[Epoch 020] loss=0.9449 recon=0.9444 kl=0.0005\n",
      "[Epoch 021] loss=0.9326 recon=0.9322 kl=0.0004\n",
      "[Epoch 022] loss=0.9355 recon=0.9348 kl=0.0007\n",
      "[Epoch 023] loss=0.9334 recon=0.9333 kl=0.0001\n",
      "[Epoch 024] loss=0.9277 recon=0.9264 kl=0.0013\n",
      "[Epoch 025] loss=0.9404 recon=0.9401 kl=0.0003\n",
      "[Epoch 026] loss=0.9340 recon=0.9338 kl=0.0002\n",
      "[Epoch 027] loss=0.9449 recon=0.9443 kl=0.0005\n",
      "[Epoch 028] loss=0.9563 recon=0.9557 kl=0.0006\n",
      "[Epoch 029] loss=0.9269 recon=0.9263 kl=0.0006\n",
      "[Epoch 030] loss=0.9357 recon=0.9353 kl=0.0004\n",
      "[Epoch 031] loss=0.9396 recon=0.9393 kl=0.0003\n",
      "[Epoch 032] loss=0.9359 recon=0.9351 kl=0.0009\n",
      "[Epoch 033] loss=0.9380 recon=0.9378 kl=0.0001\n",
      "[Epoch 034] loss=0.9321 recon=0.9312 kl=0.0008\n",
      "[Epoch 035] loss=0.9309 recon=0.9295 kl=0.0014\n",
      "[Epoch 036] loss=0.9417 recon=0.9413 kl=0.0003\n",
      "[Epoch 037] loss=0.9413 recon=0.9411 kl=0.0002\n",
      "[Epoch 038] loss=0.9345 recon=0.9337 kl=0.0009\n",
      "[Epoch 039] loss=0.9367 recon=0.9359 kl=0.0008\n",
      "[Epoch 040] loss=0.9328 recon=0.9324 kl=0.0004\n",
      "[Epoch 041] loss=0.9300 recon=0.9293 kl=0.0007\n",
      "[Epoch 042] loss=0.9389 recon=0.9387 kl=0.0002\n",
      "[Epoch 043] loss=0.9314 recon=0.9308 kl=0.0006\n",
      "[Epoch 044] loss=0.9348 recon=0.9306 kl=0.0042\n",
      "[Epoch 045] loss=0.9439 recon=0.9414 kl=0.0025\n",
      "[Epoch 046] loss=0.9272 recon=0.9266 kl=0.0006\n",
      "[Epoch 047] loss=0.9489 recon=0.9489 kl=0.0001\n",
      "[Epoch 048] loss=0.9295 recon=0.9295 kl=0.0000\n",
      "[Epoch 049] loss=0.9689 recon=0.9688 kl=0.0000\n",
      "[Epoch 050] loss=0.9399 recon=0.9399 kl=0.0000\n",
      "[Epoch 051] loss=0.9495 recon=0.9488 kl=0.0006\n",
      "[Epoch 052] loss=0.9403 recon=0.9399 kl=0.0005\n",
      "[Epoch 053] loss=0.9374 recon=0.9370 kl=0.0004\n",
      "[Epoch 054] loss=0.9370 recon=0.9363 kl=0.0007\n",
      "[Epoch 055] loss=0.9462 recon=0.9461 kl=0.0001\n",
      "[Epoch 056] loss=0.9281 recon=0.9253 kl=0.0029\n",
      "[Epoch 057] loss=0.9290 recon=0.9252 kl=0.0038\n",
      "[Epoch 058] loss=0.9297 recon=0.9271 kl=0.0026\n",
      "[Epoch 059] loss=0.9229 recon=0.9209 kl=0.0020\n",
      "[Epoch 060] loss=0.9465 recon=0.9458 kl=0.0006\n",
      "[Epoch 061] loss=0.9320 recon=0.9319 kl=0.0001\n",
      "[Epoch 062] loss=0.9432 recon=0.9432 kl=0.0000\n",
      "[Epoch 063] loss=0.9393 recon=0.9393 kl=0.0000\n",
      "[Epoch 064] loss=0.9258 recon=0.9258 kl=0.0000\n",
      "[Epoch 065] loss=0.9308 recon=0.9272 kl=0.0035\n",
      "[Epoch 066] loss=0.9369 recon=0.9332 kl=0.0037\n",
      "[Epoch 067] loss=0.9323 recon=0.9311 kl=0.0012\n",
      "[Epoch 068] loss=0.9415 recon=0.9414 kl=0.0001\n",
      "[Epoch 069] loss=0.9337 recon=0.9337 kl=0.0000\n",
      "[Epoch 070] loss=0.9369 recon=0.9368 kl=0.0000\n",
      "[Epoch 071] loss=0.9331 recon=0.9331 kl=0.0000\n",
      "[Epoch 072] loss=0.9448 recon=0.9448 kl=0.0000\n",
      "[Epoch 073] loss=0.9399 recon=0.9396 kl=0.0003\n",
      "[Epoch 074] loss=0.9377 recon=0.9371 kl=0.0006\n",
      "[Epoch 075] loss=0.9519 recon=0.9515 kl=0.0004\n",
      "[Epoch 076] loss=0.9393 recon=0.9392 kl=0.0001\n",
      "[Epoch 077] loss=0.9271 recon=0.9265 kl=0.0007\n",
      "[Epoch 078] loss=0.9288 recon=0.9284 kl=0.0004\n",
      "[Epoch 079] loss=0.9468 recon=0.9463 kl=0.0005\n",
      "[Epoch 080] loss=0.9352 recon=0.9349 kl=0.0002\n",
      "[Epoch 081] loss=0.9462 recon=0.9456 kl=0.0006\n",
      "[Epoch 082] loss=0.9266 recon=0.9265 kl=0.0001\n",
      "[Epoch 083] loss=0.9315 recon=0.9307 kl=0.0008\n",
      "[Epoch 084] loss=0.9284 recon=0.9282 kl=0.0002\n",
      "[Epoch 085] loss=0.9310 recon=0.9306 kl=0.0003\n",
      "[Epoch 086] loss=0.9268 recon=0.9263 kl=0.0005\n",
      "[Epoch 087] loss=0.9418 recon=0.9411 kl=0.0007\n",
      "[Epoch 088] loss=0.9251 recon=0.9249 kl=0.0002\n",
      "[Epoch 089] loss=0.9386 recon=0.9378 kl=0.0008\n",
      "[Epoch 090] loss=0.9432 recon=0.9431 kl=0.0001\n",
      "63\n",
      "[Epoch 001] loss=1.3524 recon=0.9509 kl=0.4015\n",
      "[Epoch 002] loss=0.9457 recon=0.9430 kl=0.0027\n",
      "[Epoch 003] loss=0.9322 recon=0.9320 kl=0.0002\n",
      "[Epoch 004] loss=0.9310 recon=0.9309 kl=0.0001\n",
      "[Epoch 005] loss=0.9327 recon=0.9326 kl=0.0001\n",
      "[Epoch 006] loss=0.9440 recon=0.9439 kl=0.0001\n",
      "[Epoch 007] loss=0.9390 recon=0.9387 kl=0.0003\n",
      "[Epoch 008] loss=0.9338 recon=0.9336 kl=0.0003\n",
      "[Epoch 009] loss=0.9408 recon=0.9404 kl=0.0003\n",
      "[Epoch 010] loss=0.9350 recon=0.9348 kl=0.0003\n",
      "[Epoch 011] loss=0.9340 recon=0.9336 kl=0.0004\n",
      "[Epoch 012] loss=0.9629 recon=0.9626 kl=0.0003\n",
      "[Epoch 013] loss=0.9422 recon=0.9417 kl=0.0005\n",
      "[Epoch 014] loss=0.9372 recon=0.9370 kl=0.0002\n",
      "[Epoch 015] loss=0.9393 recon=0.9388 kl=0.0005\n",
      "[Epoch 016] loss=0.9390 recon=0.9386 kl=0.0004\n",
      "[Epoch 017] loss=0.9385 recon=0.9380 kl=0.0005\n",
      "[Epoch 018] loss=0.9353 recon=0.9348 kl=0.0005\n",
      "[Epoch 019] loss=0.9276 recon=0.9272 kl=0.0003\n",
      "[Epoch 020] loss=0.9281 recon=0.9276 kl=0.0005\n",
      "[Epoch 021] loss=0.9258 recon=0.9254 kl=0.0005\n",
      "[Epoch 022] loss=0.9361 recon=0.9357 kl=0.0004\n",
      "[Epoch 023] loss=0.9272 recon=0.9265 kl=0.0007\n",
      "[Epoch 024] loss=0.9352 recon=0.9347 kl=0.0005\n",
      "[Epoch 025] loss=0.9583 recon=0.9576 kl=0.0006\n",
      "[Epoch 026] loss=0.9319 recon=0.9318 kl=0.0002\n",
      "[Epoch 027] loss=0.9316 recon=0.9291 kl=0.0026\n",
      "[Epoch 028] loss=0.9412 recon=0.9399 kl=0.0014\n",
      "[Epoch 029] loss=0.9359 recon=0.9358 kl=0.0001\n",
      "[Epoch 030] loss=0.9341 recon=0.9338 kl=0.0003\n",
      "[Epoch 031] loss=0.9540 recon=0.9530 kl=0.0010\n",
      "[Epoch 032] loss=0.9378 recon=0.9375 kl=0.0003\n",
      "[Epoch 033] loss=0.9380 recon=0.9374 kl=0.0006\n",
      "[Epoch 034] loss=0.9346 recon=0.9341 kl=0.0005\n",
      "[Epoch 035] loss=0.9466 recon=0.9461 kl=0.0005\n",
      "[Epoch 036] loss=0.9392 recon=0.9384 kl=0.0008\n",
      "[Epoch 037] loss=0.9450 recon=0.9442 kl=0.0008\n",
      "[Epoch 038] loss=0.9501 recon=0.9499 kl=0.0002\n",
      "[Epoch 039] loss=0.9384 recon=0.9378 kl=0.0006\n",
      "[Epoch 040] loss=0.9464 recon=0.9456 kl=0.0008\n",
      "[Epoch 041] loss=0.9688 recon=0.9682 kl=0.0006\n",
      "[Epoch 042] loss=0.9234 recon=0.9230 kl=0.0004\n",
      "[Epoch 043] loss=0.9327 recon=0.9323 kl=0.0003\n",
      "[Epoch 044] loss=0.9278 recon=0.9269 kl=0.0010\n",
      "[Epoch 045] loss=0.9505 recon=0.9501 kl=0.0004\n",
      "[Epoch 046] loss=0.9374 recon=0.9366 kl=0.0008\n",
      "[Epoch 047] loss=0.9351 recon=0.9347 kl=0.0004\n",
      "[Epoch 048] loss=0.9389 recon=0.9385 kl=0.0004\n",
      "[Epoch 049] loss=0.9517 recon=0.9505 kl=0.0012\n",
      "[Epoch 050] loss=0.9441 recon=0.9369 kl=0.0072\n",
      "[Epoch 051] loss=0.9355 recon=0.9328 kl=0.0027\n",
      "[Epoch 052] loss=0.9379 recon=0.9376 kl=0.0003\n",
      "[Epoch 053] loss=0.9337 recon=0.9337 kl=0.0000\n",
      "[Epoch 054] loss=0.9242 recon=0.9242 kl=0.0000\n",
      "[Epoch 055] loss=0.9320 recon=0.9320 kl=0.0000\n",
      "[Epoch 056] loss=0.9519 recon=0.9487 kl=0.0031\n",
      "[Epoch 057] loss=0.9396 recon=0.9368 kl=0.0028\n",
      "[Epoch 058] loss=0.9312 recon=0.9305 kl=0.0006\n",
      "[Epoch 059] loss=0.9311 recon=0.9310 kl=0.0001\n",
      "[Epoch 060] loss=0.9376 recon=0.9375 kl=0.0000\n",
      "[Epoch 061] loss=0.9287 recon=0.9287 kl=0.0000\n",
      "[Epoch 062] loss=0.9472 recon=0.9466 kl=0.0006\n",
      "[Epoch 063] loss=0.9424 recon=0.9423 kl=0.0001\n",
      "[Epoch 064] loss=0.9332 recon=0.9326 kl=0.0006\n",
      "[Epoch 065] loss=0.9286 recon=0.9281 kl=0.0005\n",
      "[Epoch 066] loss=0.9497 recon=0.9491 kl=0.0006\n",
      "[Epoch 067] loss=0.9235 recon=0.9226 kl=0.0010\n",
      "[Epoch 068] loss=0.9405 recon=0.9402 kl=0.0003\n",
      "[Epoch 069] loss=0.9359 recon=0.9358 kl=0.0001\n",
      "[Epoch 070] loss=0.9390 recon=0.9384 kl=0.0006\n",
      "[Epoch 071] loss=0.9279 recon=0.9273 kl=0.0006\n",
      "[Epoch 072] loss=0.9403 recon=0.9400 kl=0.0003\n",
      "[Epoch 073] loss=0.9539 recon=0.9497 kl=0.0042\n",
      "[Epoch 074] loss=0.9316 recon=0.9288 kl=0.0028\n",
      "[Epoch 075] loss=0.9373 recon=0.9366 kl=0.0007\n",
      "[Epoch 076] loss=0.9514 recon=0.9514 kl=0.0001\n",
      "[Epoch 077] loss=0.9418 recon=0.9418 kl=0.0000\n",
      "[Epoch 078] loss=0.9316 recon=0.9316 kl=0.0000\n",
      "[Epoch 079] loss=0.9400 recon=0.9394 kl=0.0006\n",
      "[Epoch 080] loss=0.9292 recon=0.9285 kl=0.0006\n",
      "[Epoch 081] loss=0.9274 recon=0.9272 kl=0.0002\n",
      "[Epoch 082] loss=0.9469 recon=0.9464 kl=0.0005\n",
      "[Epoch 083] loss=0.9331 recon=0.9305 kl=0.0026\n",
      "[Epoch 084] loss=0.9443 recon=0.9415 kl=0.0028\n",
      "[Epoch 085] loss=0.9288 recon=0.9282 kl=0.0006\n",
      "[Epoch 086] loss=0.9329 recon=0.9328 kl=0.0001\n",
      "[Epoch 087] loss=0.9308 recon=0.9308 kl=0.0000\n",
      "[Epoch 088] loss=0.9365 recon=0.9362 kl=0.0003\n",
      "[Epoch 089] loss=0.9460 recon=0.9455 kl=0.0005\n",
      "[Epoch 090] loss=0.9302 recon=0.9297 kl=0.0004\n",
      "64\n",
      "[Epoch 001] loss=1.1994 recon=0.9353 kl=0.2641\n",
      "[Epoch 002] loss=0.9425 recon=0.9403 kl=0.0022\n",
      "[Epoch 003] loss=0.9465 recon=0.9464 kl=0.0002\n",
      "[Epoch 004] loss=0.9408 recon=0.9408 kl=0.0001\n",
      "[Epoch 005] loss=0.9337 recon=0.9335 kl=0.0002\n",
      "[Epoch 006] loss=0.9489 recon=0.9488 kl=0.0001\n",
      "[Epoch 007] loss=0.9416 recon=0.9413 kl=0.0003\n",
      "[Epoch 008] loss=0.9350 recon=0.9349 kl=0.0001\n",
      "[Epoch 009] loss=0.9296 recon=0.9293 kl=0.0003\n",
      "[Epoch 010] loss=0.9413 recon=0.9411 kl=0.0002\n",
      "[Epoch 011] loss=0.9324 recon=0.9320 kl=0.0005\n",
      "[Epoch 012] loss=0.9396 recon=0.9394 kl=0.0002\n",
      "[Epoch 013] loss=0.9664 recon=0.9660 kl=0.0005\n",
      "[Epoch 014] loss=0.9370 recon=0.9368 kl=0.0003\n",
      "[Epoch 015] loss=0.9295 recon=0.9291 kl=0.0003\n",
      "[Epoch 016] loss=0.9352 recon=0.9348 kl=0.0004\n",
      "[Epoch 017] loss=0.9430 recon=0.9429 kl=0.0002\n",
      "[Epoch 018] loss=0.9249 recon=0.9241 kl=0.0008\n",
      "[Epoch 019] loss=0.9344 recon=0.9342 kl=0.0002\n",
      "[Epoch 020] loss=0.9563 recon=0.9552 kl=0.0011\n",
      "[Epoch 021] loss=0.9423 recon=0.9421 kl=0.0002\n",
      "[Epoch 022] loss=0.9661 recon=0.9660 kl=0.0000\n",
      "[Epoch 023] loss=0.9393 recon=0.9384 kl=0.0009\n",
      "[Epoch 024] loss=0.9385 recon=0.9383 kl=0.0002\n",
      "[Epoch 025] loss=0.9357 recon=0.9351 kl=0.0006\n",
      "[Epoch 026] loss=0.9289 recon=0.9284 kl=0.0004\n",
      "[Epoch 027] loss=0.9582 recon=0.9540 kl=0.0041\n",
      "[Epoch 028] loss=0.9384 recon=0.9371 kl=0.0013\n",
      "[Epoch 029] loss=0.9319 recon=0.9317 kl=0.0002\n",
      "[Epoch 030] loss=0.9463 recon=0.9463 kl=0.0000\n",
      "[Epoch 031] loss=0.9383 recon=0.9380 kl=0.0003\n",
      "[Epoch 032] loss=0.9293 recon=0.9291 kl=0.0002\n",
      "[Epoch 033] loss=0.9411 recon=0.9405 kl=0.0006\n",
      "[Epoch 034] loss=0.9278 recon=0.9275 kl=0.0004\n",
      "[Epoch 035] loss=0.9338 recon=0.9331 kl=0.0007\n",
      "[Epoch 036] loss=0.9420 recon=0.9417 kl=0.0002\n",
      "[Epoch 037] loss=0.9451 recon=0.9442 kl=0.0009\n",
      "[Epoch 038] loss=0.9328 recon=0.9324 kl=0.0004\n",
      "[Epoch 039] loss=0.9276 recon=0.9268 kl=0.0008\n",
      "[Epoch 040] loss=0.9493 recon=0.9487 kl=0.0006\n",
      "[Epoch 041] loss=0.9404 recon=0.9401 kl=0.0004\n",
      "[Epoch 042] loss=0.9403 recon=0.9393 kl=0.0010\n",
      "[Epoch 043] loss=0.9215 recon=0.9212 kl=0.0003\n",
      "[Epoch 044] loss=0.9264 recon=0.9258 kl=0.0006\n",
      "[Epoch 045] loss=0.9515 recon=0.9482 kl=0.0032\n",
      "[Epoch 046] loss=0.9398 recon=0.9374 kl=0.0024\n",
      "[Epoch 047] loss=0.9354 recon=0.9352 kl=0.0003\n",
      "[Epoch 048] loss=0.9436 recon=0.9435 kl=0.0000\n",
      "[Epoch 049] loss=0.9293 recon=0.9293 kl=0.0001\n",
      "[Epoch 050] loss=0.9402 recon=0.9391 kl=0.0011\n",
      "[Epoch 051] loss=0.9316 recon=0.9309 kl=0.0008\n",
      "[Epoch 052] loss=0.9244 recon=0.9241 kl=0.0003\n",
      "[Epoch 053] loss=0.9507 recon=0.9494 kl=0.0013\n",
      "[Epoch 054] loss=0.9528 recon=0.9522 kl=0.0006\n",
      "[Epoch 055] loss=0.9324 recon=0.9319 kl=0.0004\n",
      "[Epoch 056] loss=0.9256 recon=0.9225 kl=0.0031\n",
      "[Epoch 057] loss=0.9358 recon=0.9354 kl=0.0004\n",
      "[Epoch 058] loss=0.9371 recon=0.9370 kl=0.0000\n",
      "[Epoch 059] loss=0.9291 recon=0.9286 kl=0.0005\n",
      "[Epoch 060] loss=0.9392 recon=0.9385 kl=0.0007\n",
      "[Epoch 061] loss=0.9255 recon=0.9247 kl=0.0009\n",
      "[Epoch 062] loss=0.9316 recon=0.9310 kl=0.0006\n",
      "[Epoch 063] loss=0.9387 recon=0.9380 kl=0.0007\n",
      "[Epoch 064] loss=0.9492 recon=0.9479 kl=0.0013\n",
      "[Epoch 065] loss=0.9459 recon=0.9456 kl=0.0003\n",
      "[Epoch 066] loss=0.9266 recon=0.9266 kl=0.0000\n",
      "[Epoch 067] loss=0.9402 recon=0.9381 kl=0.0021\n",
      "[Epoch 068] loss=0.9392 recon=0.9356 kl=0.0036\n",
      "[Epoch 069] loss=0.9307 recon=0.9284 kl=0.0022\n",
      "[Epoch 070] loss=0.9504 recon=0.9502 kl=0.0003\n",
      "[Epoch 071] loss=0.9341 recon=0.9341 kl=0.0000\n",
      "[Epoch 072] loss=0.9425 recon=0.9425 kl=0.0000\n",
      "[Epoch 073] loss=0.9343 recon=0.9343 kl=0.0000\n",
      "[Epoch 074] loss=0.9671 recon=0.9609 kl=0.0062\n",
      "[Epoch 075] loss=0.9303 recon=0.9282 kl=0.0021\n",
      "[Epoch 076] loss=0.9323 recon=0.9321 kl=0.0002\n",
      "[Epoch 077] loss=0.9385 recon=0.9384 kl=0.0000\n",
      "[Epoch 078] loss=0.9411 recon=0.9411 kl=0.0000\n",
      "[Epoch 079] loss=0.9366 recon=0.9362 kl=0.0004\n",
      "[Epoch 080] loss=0.9482 recon=0.9472 kl=0.0010\n",
      "[Epoch 081] loss=0.9300 recon=0.9297 kl=0.0002\n",
      "[Epoch 082] loss=0.9436 recon=0.9435 kl=0.0000\n",
      "[Epoch 083] loss=0.9348 recon=0.9340 kl=0.0008\n",
      "[Epoch 084] loss=0.9349 recon=0.9342 kl=0.0007\n",
      "[Epoch 085] loss=0.9348 recon=0.9314 kl=0.0034\n",
      "[Epoch 086] loss=0.9234 recon=0.9212 kl=0.0021\n",
      "[Epoch 087] loss=0.9398 recon=0.9386 kl=0.0012\n",
      "[Epoch 088] loss=0.9318 recon=0.9316 kl=0.0001\n",
      "[Epoch 089] loss=0.9339 recon=0.9339 kl=0.0000\n",
      "[Epoch 090] loss=0.9563 recon=0.9563 kl=0.0000\n",
      "65\n",
      "[Epoch 001] loss=1.1243 recon=0.9411 kl=0.1832\n",
      "[Epoch 002] loss=0.9405 recon=0.9390 kl=0.0015\n",
      "[Epoch 003] loss=0.9397 recon=0.9395 kl=0.0002\n",
      "[Epoch 004] loss=0.9366 recon=0.9365 kl=0.0001\n",
      "[Epoch 005] loss=0.9452 recon=0.9451 kl=0.0001\n",
      "[Epoch 006] loss=0.9400 recon=0.9398 kl=0.0001\n",
      "[Epoch 007] loss=0.9308 recon=0.9306 kl=0.0001\n",
      "[Epoch 008] loss=0.9320 recon=0.9318 kl=0.0002\n",
      "[Epoch 009] loss=0.9374 recon=0.9371 kl=0.0003\n",
      "[Epoch 010] loss=0.9357 recon=0.9356 kl=0.0001\n",
      "[Epoch 011] loss=0.9250 recon=0.9247 kl=0.0003\n",
      "[Epoch 012] loss=0.9408 recon=0.9406 kl=0.0003\n",
      "[Epoch 013] loss=0.9391 recon=0.9385 kl=0.0006\n",
      "[Epoch 014] loss=0.9470 recon=0.9468 kl=0.0001\n",
      "[Epoch 015] loss=0.9514 recon=0.9509 kl=0.0005\n",
      "[Epoch 016] loss=0.9551 recon=0.9546 kl=0.0005\n",
      "[Epoch 017] loss=0.9465 recon=0.9463 kl=0.0002\n",
      "[Epoch 018] loss=0.9414 recon=0.9408 kl=0.0006\n",
      "[Epoch 019] loss=0.9391 recon=0.9389 kl=0.0002\n",
      "[Epoch 020] loss=0.9402 recon=0.9396 kl=0.0006\n",
      "[Epoch 021] loss=0.9362 recon=0.9359 kl=0.0003\n",
      "[Epoch 022] loss=0.9379 recon=0.9371 kl=0.0008\n",
      "[Epoch 023] loss=0.9377 recon=0.9376 kl=0.0001\n",
      "[Epoch 024] loss=0.9424 recon=0.9419 kl=0.0006\n",
      "[Epoch 025] loss=0.9413 recon=0.9411 kl=0.0002\n",
      "[Epoch 026] loss=0.9442 recon=0.9436 kl=0.0006\n",
      "[Epoch 027] loss=0.9462 recon=0.9457 kl=0.0005\n",
      "[Epoch 028] loss=0.9316 recon=0.9312 kl=0.0004\n",
      "[Epoch 029] loss=0.9292 recon=0.9287 kl=0.0005\n",
      "[Epoch 030] loss=0.9302 recon=0.9298 kl=0.0004\n",
      "[Epoch 031] loss=0.9288 recon=0.9281 kl=0.0007\n",
      "[Epoch 032] loss=0.9246 recon=0.9244 kl=0.0002\n",
      "[Epoch 033] loss=0.9426 recon=0.9422 kl=0.0003\n",
      "[Epoch 034] loss=0.9347 recon=0.9335 kl=0.0013\n",
      "[Epoch 035] loss=0.9572 recon=0.9570 kl=0.0003\n",
      "[Epoch 036] loss=0.9485 recon=0.9481 kl=0.0004\n",
      "[Epoch 037] loss=0.9378 recon=0.9373 kl=0.0005\n",
      "[Epoch 038] loss=0.9514 recon=0.9509 kl=0.0005\n",
      "[Epoch 039] loss=0.9313 recon=0.9310 kl=0.0003\n",
      "[Epoch 040] loss=0.9398 recon=0.9393 kl=0.0006\n",
      "[Epoch 041] loss=0.9297 recon=0.9291 kl=0.0006\n",
      "[Epoch 042] loss=0.9350 recon=0.9348 kl=0.0003\n",
      "[Epoch 043] loss=0.9387 recon=0.9336 kl=0.0052\n",
      "[Epoch 044] loss=0.9234 recon=0.9217 kl=0.0017\n",
      "[Epoch 045] loss=0.9295 recon=0.9293 kl=0.0002\n",
      "[Epoch 046] loss=0.9407 recon=0.9407 kl=0.0000\n",
      "[Epoch 047] loss=0.9708 recon=0.9708 kl=0.0000\n",
      "[Epoch 048] loss=0.9271 recon=0.9268 kl=0.0003\n",
      "[Epoch 049] loss=0.9313 recon=0.9308 kl=0.0005\n",
      "[Epoch 050] loss=0.9337 recon=0.9334 kl=0.0004\n",
      "[Epoch 051] loss=0.9408 recon=0.9404 kl=0.0004\n",
      "[Epoch 052] loss=0.9414 recon=0.9408 kl=0.0006\n",
      "[Epoch 053] loss=0.9562 recon=0.9561 kl=0.0001\n",
      "[Epoch 054] loss=0.9289 recon=0.9282 kl=0.0008\n",
      "[Epoch 055] loss=0.9348 recon=0.9345 kl=0.0003\n",
      "[Epoch 056] loss=0.9476 recon=0.9469 kl=0.0007\n",
      "[Epoch 057] loss=0.9367 recon=0.9358 kl=0.0009\n",
      "[Epoch 058] loss=0.9294 recon=0.9288 kl=0.0006\n",
      "[Epoch 059] loss=0.9255 recon=0.9254 kl=0.0001\n",
      "[Epoch 060] loss=0.9476 recon=0.9472 kl=0.0004\n",
      "[Epoch 061] loss=0.9286 recon=0.9285 kl=0.0002\n",
      "[Epoch 062] loss=0.9284 recon=0.9279 kl=0.0005\n",
      "[Epoch 063] loss=0.9322 recon=0.9315 kl=0.0006\n",
      "[Epoch 064] loss=0.9339 recon=0.9334 kl=0.0005\n",
      "[Epoch 065] loss=0.9457 recon=0.9454 kl=0.0003\n",
      "[Epoch 066] loss=0.9368 recon=0.9364 kl=0.0005\n",
      "[Epoch 067] loss=0.9392 recon=0.9350 kl=0.0042\n",
      "[Epoch 068] loss=0.9319 recon=0.9290 kl=0.0029\n",
      "[Epoch 069] loss=0.9309 recon=0.9287 kl=0.0021\n",
      "[Epoch 070] loss=0.9284 recon=0.9277 kl=0.0007\n",
      "[Epoch 071] loss=0.9350 recon=0.9350 kl=0.0001\n",
      "[Epoch 072] loss=0.9452 recon=0.9452 kl=0.0000\n",
      "[Epoch 073] loss=0.9535 recon=0.9535 kl=0.0000\n",
      "[Epoch 074] loss=0.9616 recon=0.9616 kl=0.0000\n",
      "[Epoch 075] loss=0.9361 recon=0.9359 kl=0.0002\n",
      "[Epoch 076] loss=0.9614 recon=0.9610 kl=0.0004\n",
      "[Epoch 077] loss=0.9404 recon=0.9403 kl=0.0001\n",
      "[Epoch 078] loss=0.9575 recon=0.9568 kl=0.0007\n",
      "[Epoch 079] loss=0.9273 recon=0.9271 kl=0.0002\n",
      "[Epoch 080] loss=0.9256 recon=0.9250 kl=0.0006\n",
      "[Epoch 081] loss=0.9362 recon=0.9349 kl=0.0013\n",
      "[Epoch 082] loss=0.9427 recon=0.9423 kl=0.0004\n",
      "[Epoch 083] loss=0.9265 recon=0.9265 kl=0.0000\n",
      "[Epoch 084] loss=0.9252 recon=0.9251 kl=0.0001\n",
      "[Epoch 085] loss=0.9289 recon=0.9283 kl=0.0006\n",
      "[Epoch 086] loss=0.9461 recon=0.9459 kl=0.0002\n",
      "[Epoch 087] loss=0.9453 recon=0.9442 kl=0.0011\n",
      "[Epoch 088] loss=0.9227 recon=0.9222 kl=0.0005\n",
      "[Epoch 089] loss=0.9431 recon=0.9430 kl=0.0000\n",
      "[Epoch 090] loss=0.9267 recon=0.9260 kl=0.0007\n",
      "66\n",
      "[Epoch 001] loss=1.5168 recon=0.9293 kl=0.5876\n",
      "[Epoch 002] loss=0.9416 recon=0.9372 kl=0.0045\n",
      "[Epoch 003] loss=0.9438 recon=0.9434 kl=0.0004\n",
      "[Epoch 004] loss=0.9348 recon=0.9348 kl=0.0001\n",
      "[Epoch 005] loss=0.9333 recon=0.9329 kl=0.0003\n",
      "[Epoch 006] loss=0.9419 recon=0.9418 kl=0.0001\n",
      "[Epoch 007] loss=0.9365 recon=0.9363 kl=0.0002\n",
      "[Epoch 008] loss=0.9432 recon=0.9429 kl=0.0003\n",
      "[Epoch 009] loss=0.9385 recon=0.9383 kl=0.0002\n",
      "[Epoch 010] loss=0.9428 recon=0.9424 kl=0.0004\n",
      "[Epoch 011] loss=0.9300 recon=0.9296 kl=0.0004\n",
      "[Epoch 012] loss=0.9463 recon=0.9459 kl=0.0004\n",
      "[Epoch 013] loss=0.9558 recon=0.9554 kl=0.0004\n",
      "[Epoch 014] loss=0.9323 recon=0.9318 kl=0.0005\n",
      "[Epoch 015] loss=0.9394 recon=0.9389 kl=0.0005\n",
      "[Epoch 016] loss=0.9316 recon=0.9313 kl=0.0003\n",
      "[Epoch 017] loss=0.9404 recon=0.9400 kl=0.0004\n",
      "[Epoch 018] loss=0.9420 recon=0.9417 kl=0.0003\n",
      "[Epoch 019] loss=0.9334 recon=0.9328 kl=0.0006\n",
      "[Epoch 020] loss=0.9317 recon=0.9311 kl=0.0006\n",
      "[Epoch 021] loss=0.9313 recon=0.9309 kl=0.0004\n",
      "[Epoch 022] loss=0.9317 recon=0.9312 kl=0.0005\n",
      "[Epoch 023] loss=0.9463 recon=0.9460 kl=0.0003\n",
      "[Epoch 024] loss=0.9335 recon=0.9323 kl=0.0012\n",
      "[Epoch 025] loss=0.9273 recon=0.9268 kl=0.0005\n",
      "[Epoch 026] loss=0.9375 recon=0.9375 kl=0.0001\n",
      "[Epoch 027] loss=0.9289 recon=0.9278 kl=0.0011\n",
      "[Epoch 028] loss=0.9624 recon=0.9620 kl=0.0004\n",
      "[Epoch 029] loss=0.9244 recon=0.9242 kl=0.0002\n",
      "[Epoch 030] loss=0.9476 recon=0.9467 kl=0.0008\n",
      "[Epoch 031] loss=0.9299 recon=0.9295 kl=0.0004\n",
      "[Epoch 032] loss=0.9271 recon=0.9262 kl=0.0009\n",
      "[Epoch 033] loss=0.9311 recon=0.9309 kl=0.0001\n",
      "[Epoch 034] loss=0.9431 recon=0.9422 kl=0.0009\n",
      "[Epoch 035] loss=0.9340 recon=0.9333 kl=0.0008\n",
      "[Epoch 036] loss=0.9328 recon=0.9327 kl=0.0002\n",
      "[Epoch 037] loss=0.9290 recon=0.9282 kl=0.0008\n",
      "[Epoch 038] loss=0.9380 recon=0.9375 kl=0.0004\n",
      "[Epoch 039] loss=0.9327 recon=0.9321 kl=0.0006\n",
      "[Epoch 040] loss=0.9358 recon=0.9353 kl=0.0005\n",
      "[Epoch 041] loss=0.9369 recon=0.9364 kl=0.0005\n",
      "[Epoch 042] loss=0.9416 recon=0.9409 kl=0.0006\n",
      "[Epoch 043] loss=0.9250 recon=0.9248 kl=0.0002\n",
      "[Epoch 044] loss=0.9471 recon=0.9422 kl=0.0049\n",
      "[Epoch 045] loss=0.9347 recon=0.9315 kl=0.0031\n",
      "[Epoch 046] loss=0.9331 recon=0.9309 kl=0.0023\n",
      "[Epoch 047] loss=0.9351 recon=0.9335 kl=0.0015\n",
      "[Epoch 048] loss=0.9234 recon=0.9226 kl=0.0009\n",
      "[Epoch 049] loss=0.9398 recon=0.9397 kl=0.0001\n",
      "[Epoch 050] loss=0.9456 recon=0.9456 kl=0.0000\n",
      "[Epoch 051] loss=0.9366 recon=0.9366 kl=0.0000\n",
      "[Epoch 052] loss=0.9379 recon=0.9368 kl=0.0011\n",
      "[Epoch 053] loss=0.9468 recon=0.9400 kl=0.0068\n",
      "[Epoch 054] loss=0.9468 recon=0.9435 kl=0.0033\n",
      "[Epoch 055] loss=0.9559 recon=0.9555 kl=0.0004\n",
      "[Epoch 056] loss=0.9340 recon=0.9339 kl=0.0000\n",
      "[Epoch 057] loss=0.9498 recon=0.9498 kl=0.0000\n",
      "[Epoch 058] loss=0.9516 recon=0.9516 kl=0.0000\n",
      "[Epoch 059] loss=0.9550 recon=0.9549 kl=0.0001\n",
      "[Epoch 060] loss=0.9533 recon=0.9526 kl=0.0006\n",
      "[Epoch 061] loss=0.9350 recon=0.9347 kl=0.0003\n",
      "[Epoch 062] loss=0.9391 recon=0.9390 kl=0.0002\n",
      "[Epoch 063] loss=0.9312 recon=0.9302 kl=0.0010\n",
      "[Epoch 064] loss=0.9384 recon=0.9380 kl=0.0004\n",
      "[Epoch 065] loss=0.9312 recon=0.9309 kl=0.0003\n",
      "[Epoch 066] loss=0.9393 recon=0.9387 kl=0.0006\n",
      "[Epoch 067] loss=0.9325 recon=0.9320 kl=0.0005\n",
      "[Epoch 068] loss=0.9368 recon=0.9361 kl=0.0006\n",
      "[Epoch 069] loss=0.9322 recon=0.9320 kl=0.0002\n",
      "[Epoch 070] loss=0.9309 recon=0.9301 kl=0.0008\n",
      "[Epoch 071] loss=0.9435 recon=0.9424 kl=0.0011\n",
      "[Epoch 072] loss=0.9420 recon=0.9418 kl=0.0002\n",
      "[Epoch 073] loss=0.9283 recon=0.9279 kl=0.0004\n",
      "[Epoch 074] loss=0.9419 recon=0.9413 kl=0.0006\n",
      "[Epoch 075] loss=0.9388 recon=0.9383 kl=0.0005\n",
      "[Epoch 076] loss=0.9405 recon=0.9398 kl=0.0007\n",
      "[Epoch 077] loss=0.9305 recon=0.9304 kl=0.0001\n",
      "[Epoch 078] loss=0.9365 recon=0.9354 kl=0.0011\n",
      "[Epoch 079] loss=0.9271 recon=0.9266 kl=0.0005\n",
      "[Epoch 080] loss=0.9305 recon=0.9303 kl=0.0002\n",
      "[Epoch 081] loss=0.9339 recon=0.9333 kl=0.0005\n",
      "[Epoch 082] loss=0.9445 recon=0.9439 kl=0.0006\n",
      "[Epoch 083] loss=0.9518 recon=0.9513 kl=0.0005\n",
      "[Epoch 084] loss=0.9363 recon=0.9360 kl=0.0003\n",
      "[Epoch 085] loss=0.9534 recon=0.9527 kl=0.0007\n",
      "[Epoch 086] loss=0.9364 recon=0.9358 kl=0.0006\n",
      "[Epoch 087] loss=0.9351 recon=0.9351 kl=0.0001\n",
      "[Epoch 088] loss=0.9383 recon=0.9370 kl=0.0013\n",
      "[Epoch 089] loss=0.9329 recon=0.9321 kl=0.0008\n",
      "[Epoch 090] loss=0.9295 recon=0.9293 kl=0.0002\n",
      "67\n",
      "[Epoch 001] loss=1.3486 recon=0.9343 kl=0.4143\n",
      "[Epoch 002] loss=0.9579 recon=0.9554 kl=0.0025\n",
      "[Epoch 003] loss=0.9432 recon=0.9430 kl=0.0003\n",
      "[Epoch 004] loss=0.9344 recon=0.9343 kl=0.0001\n",
      "[Epoch 005] loss=0.9406 recon=0.9404 kl=0.0002\n",
      "[Epoch 006] loss=0.9411 recon=0.9410 kl=0.0001\n",
      "[Epoch 007] loss=0.9310 recon=0.9306 kl=0.0004\n",
      "[Epoch 008] loss=0.9273 recon=0.9271 kl=0.0002\n",
      "[Epoch 009] loss=0.9385 recon=0.9382 kl=0.0003\n",
      "[Epoch 010] loss=0.9473 recon=0.9470 kl=0.0002\n",
      "[Epoch 011] loss=0.9347 recon=0.9343 kl=0.0004\n",
      "[Epoch 012] loss=0.9394 recon=0.9392 kl=0.0002\n",
      "[Epoch 013] loss=0.9549 recon=0.9546 kl=0.0004\n",
      "[Epoch 014] loss=0.9314 recon=0.9310 kl=0.0004\n",
      "[Epoch 015] loss=0.9366 recon=0.9364 kl=0.0002\n",
      "[Epoch 016] loss=0.9516 recon=0.9511 kl=0.0005\n",
      "[Epoch 017] loss=0.9394 recon=0.9389 kl=0.0004\n",
      "[Epoch 018] loss=0.9295 recon=0.9289 kl=0.0006\n",
      "[Epoch 019] loss=0.9339 recon=0.9337 kl=0.0002\n",
      "[Epoch 020] loss=0.9328 recon=0.9323 kl=0.0005\n",
      "[Epoch 021] loss=0.9398 recon=0.9392 kl=0.0006\n",
      "[Epoch 022] loss=0.9402 recon=0.9396 kl=0.0006\n",
      "[Epoch 023] loss=0.9462 recon=0.9459 kl=0.0003\n",
      "[Epoch 024] loss=0.9314 recon=0.9308 kl=0.0006\n",
      "[Epoch 025] loss=0.9682 recon=0.9677 kl=0.0005\n",
      "[Epoch 026] loss=0.9231 recon=0.9224 kl=0.0007\n",
      "[Epoch 027] loss=0.9522 recon=0.9508 kl=0.0014\n",
      "[Epoch 028] loss=0.9396 recon=0.9364 kl=0.0032\n",
      "[Epoch 029] loss=0.9448 recon=0.9428 kl=0.0020\n",
      "[Epoch 030] loss=0.9489 recon=0.9484 kl=0.0004\n",
      "[Epoch 031] loss=0.9390 recon=0.9389 kl=0.0000\n",
      "[Epoch 032] loss=0.9490 recon=0.9489 kl=0.0000\n",
      "[Epoch 033] loss=0.9342 recon=0.9337 kl=0.0005\n",
      "[Epoch 034] loss=0.9481 recon=0.9477 kl=0.0004\n",
      "[Epoch 035] loss=0.9303 recon=0.9296 kl=0.0007\n",
      "[Epoch 036] loss=0.9295 recon=0.9294 kl=0.0001\n",
      "[Epoch 037] loss=0.9364 recon=0.9356 kl=0.0008\n",
      "[Epoch 038] loss=0.9294 recon=0.9290 kl=0.0004\n",
      "[Epoch 039] loss=0.9388 recon=0.9383 kl=0.0005\n",
      "[Epoch 040] loss=0.9312 recon=0.9305 kl=0.0007\n",
      "[Epoch 041] loss=0.9309 recon=0.9306 kl=0.0003\n",
      "[Epoch 042] loss=0.9310 recon=0.9303 kl=0.0007\n",
      "[Epoch 043] loss=0.9315 recon=0.9310 kl=0.0005\n",
      "[Epoch 044] loss=0.9427 recon=0.9423 kl=0.0004\n",
      "[Epoch 045] loss=0.9407 recon=0.9400 kl=0.0007\n",
      "[Epoch 046] loss=0.9382 recon=0.9377 kl=0.0005\n",
      "[Epoch 047] loss=0.9306 recon=0.9298 kl=0.0008\n",
      "[Epoch 048] loss=0.9537 recon=0.9460 kl=0.0077\n",
      "[Epoch 049] loss=0.9479 recon=0.9462 kl=0.0017\n",
      "[Epoch 050] loss=0.9493 recon=0.9490 kl=0.0003\n",
      "[Epoch 051] loss=0.9334 recon=0.9333 kl=0.0000\n",
      "[Epoch 052] loss=0.9366 recon=0.9365 kl=0.0000\n",
      "[Epoch 053] loss=0.9384 recon=0.9380 kl=0.0004\n",
      "[Epoch 054] loss=0.9599 recon=0.9591 kl=0.0008\n",
      "[Epoch 055] loss=0.9305 recon=0.9299 kl=0.0006\n",
      "[Epoch 056] loss=0.9352 recon=0.9347 kl=0.0005\n",
      "[Epoch 057] loss=0.9486 recon=0.9484 kl=0.0002\n",
      "[Epoch 058] loss=0.9339 recon=0.9334 kl=0.0005\n",
      "[Epoch 059] loss=0.9418 recon=0.9413 kl=0.0005\n",
      "[Epoch 060] loss=0.9337 recon=0.9332 kl=0.0005\n",
      "[Epoch 061] loss=0.9372 recon=0.9365 kl=0.0007\n",
      "[Epoch 062] loss=0.9435 recon=0.9430 kl=0.0005\n",
      "[Epoch 063] loss=0.9375 recon=0.9371 kl=0.0004\n",
      "[Epoch 064] loss=0.9388 recon=0.9383 kl=0.0005\n",
      "[Epoch 065] loss=0.9581 recon=0.9576 kl=0.0005\n",
      "[Epoch 066] loss=0.9281 recon=0.9276 kl=0.0005\n",
      "[Epoch 067] loss=0.9313 recon=0.9305 kl=0.0007\n",
      "[Epoch 068] loss=0.9286 recon=0.9282 kl=0.0004\n",
      "[Epoch 069] loss=0.9421 recon=0.9419 kl=0.0002\n",
      "[Epoch 070] loss=0.9368 recon=0.9359 kl=0.0009\n",
      "[Epoch 071] loss=0.9435 recon=0.9428 kl=0.0006\n",
      "[Epoch 072] loss=0.9425 recon=0.9418 kl=0.0007\n",
      "[Epoch 073] loss=0.9628 recon=0.9623 kl=0.0004\n",
      "[Epoch 074] loss=0.9234 recon=0.9231 kl=0.0003\n",
      "[Epoch 075] loss=0.9391 recon=0.9387 kl=0.0004\n",
      "[Epoch 076] loss=0.9326 recon=0.9318 kl=0.0007\n",
      "[Epoch 077] loss=0.9283 recon=0.9282 kl=0.0001\n",
      "[Epoch 078] loss=0.9265 recon=0.9259 kl=0.0006\n",
      "[Epoch 079] loss=0.9490 recon=0.9479 kl=0.0011\n",
      "[Epoch 080] loss=0.9618 recon=0.9613 kl=0.0005\n",
      "[Epoch 081] loss=0.9414 recon=0.9413 kl=0.0001\n",
      "[Epoch 082] loss=0.9280 recon=0.9276 kl=0.0004\n",
      "[Epoch 083] loss=0.9365 recon=0.9357 kl=0.0008\n",
      "[Epoch 084] loss=0.9383 recon=0.9378 kl=0.0005\n",
      "[Epoch 085] loss=0.9439 recon=0.9438 kl=0.0001\n",
      "[Epoch 086] loss=0.9610 recon=0.9589 kl=0.0021\n",
      "[Epoch 087] loss=0.9509 recon=0.9427 kl=0.0083\n",
      "[Epoch 088] loss=0.9560 recon=0.9537 kl=0.0024\n",
      "[Epoch 089] loss=0.9415 recon=0.9398 kl=0.0017\n",
      "[Epoch 090] loss=0.9283 recon=0.9278 kl=0.0004\n",
      "68\n",
      "[Epoch 001] loss=1.2766 recon=0.9434 kl=0.3332\n",
      "[Epoch 002] loss=0.9375 recon=0.9351 kl=0.0024\n",
      "[Epoch 003] loss=0.9336 recon=0.9334 kl=0.0002\n",
      "[Epoch 004] loss=0.9344 recon=0.9341 kl=0.0003\n",
      "[Epoch 005] loss=0.9273 recon=0.9273 kl=0.0001\n",
      "[Epoch 006] loss=0.9356 recon=0.9353 kl=0.0003\n",
      "[Epoch 007] loss=0.9439 recon=0.9438 kl=0.0001\n",
      "[Epoch 008] loss=0.9449 recon=0.9447 kl=0.0002\n",
      "[Epoch 009] loss=0.9325 recon=0.9322 kl=0.0003\n",
      "[Epoch 010] loss=0.9363 recon=0.9362 kl=0.0002\n",
      "[Epoch 011] loss=0.9306 recon=0.9302 kl=0.0004\n",
      "[Epoch 012] loss=0.9417 recon=0.9414 kl=0.0003\n",
      "[Epoch 013] loss=0.9569 recon=0.9565 kl=0.0004\n",
      "[Epoch 014] loss=0.9458 recon=0.9454 kl=0.0003\n",
      "[Epoch 015] loss=0.9307 recon=0.9300 kl=0.0007\n",
      "[Epoch 016] loss=0.9380 recon=0.9378 kl=0.0002\n",
      "[Epoch 017] loss=0.9362 recon=0.9357 kl=0.0005\n",
      "[Epoch 018] loss=0.9473 recon=0.9469 kl=0.0004\n",
      "[Epoch 019] loss=0.9540 recon=0.9537 kl=0.0003\n",
      "[Epoch 020] loss=0.9260 recon=0.9253 kl=0.0007\n",
      "[Epoch 021] loss=0.9511 recon=0.9508 kl=0.0004\n",
      "[Epoch 022] loss=0.9348 recon=0.9345 kl=0.0003\n",
      "[Epoch 023] loss=0.9382 recon=0.9377 kl=0.0005\n",
      "[Epoch 024] loss=0.9410 recon=0.9405 kl=0.0005\n",
      "[Epoch 025] loss=0.9413 recon=0.9403 kl=0.0010\n",
      "[Epoch 026] loss=0.9385 recon=0.9383 kl=0.0001\n",
      "[Epoch 027] loss=0.9310 recon=0.9299 kl=0.0012\n",
      "[Epoch 028] loss=0.9362 recon=0.9335 kl=0.0027\n",
      "[Epoch 029] loss=0.9285 recon=0.9281 kl=0.0004\n",
      "[Epoch 030] loss=0.9336 recon=0.9336 kl=0.0000\n",
      "[Epoch 031] loss=0.9446 recon=0.9446 kl=0.0001\n",
      "[Epoch 032] loss=0.9326 recon=0.9321 kl=0.0004\n",
      "[Epoch 033] loss=0.9527 recon=0.9490 kl=0.0037\n",
      "[Epoch 034] loss=0.9382 recon=0.9332 kl=0.0050\n",
      "[Epoch 035] loss=0.9281 recon=0.9268 kl=0.0012\n",
      "[Epoch 036] loss=0.9437 recon=0.9436 kl=0.0001\n",
      "[Epoch 037] loss=0.9391 recon=0.9390 kl=0.0000\n",
      "[Epoch 038] loss=0.9284 recon=0.9279 kl=0.0005\n",
      "[Epoch 039] loss=0.9310 recon=0.9307 kl=0.0004\n",
      "[Epoch 040] loss=0.9361 recon=0.9358 kl=0.0003\n",
      "[Epoch 041] loss=0.9422 recon=0.9417 kl=0.0005\n",
      "[Epoch 042] loss=0.9591 recon=0.9583 kl=0.0007\n",
      "[Epoch 043] loss=0.9278 recon=0.9274 kl=0.0004\n",
      "[Epoch 044] loss=0.9341 recon=0.9334 kl=0.0006\n",
      "[Epoch 045] loss=0.9279 recon=0.9276 kl=0.0003\n",
      "[Epoch 046] loss=0.9306 recon=0.9299 kl=0.0007\n",
      "[Epoch 047] loss=0.9502 recon=0.9501 kl=0.0001\n",
      "[Epoch 048] loss=0.9279 recon=0.9270 kl=0.0009\n",
      "[Epoch 049] loss=0.9310 recon=0.9305 kl=0.0005\n",
      "[Epoch 050] loss=0.9400 recon=0.9395 kl=0.0004\n",
      "[Epoch 051] loss=0.9326 recon=0.9321 kl=0.0005\n",
      "[Epoch 052] loss=0.9329 recon=0.9326 kl=0.0003\n",
      "[Epoch 053] loss=0.9267 recon=0.9261 kl=0.0006\n",
      "[Epoch 054] loss=0.9330 recon=0.9325 kl=0.0004\n",
      "[Epoch 055] loss=0.9368 recon=0.9360 kl=0.0008\n",
      "[Epoch 056] loss=0.9402 recon=0.9397 kl=0.0005\n",
      "[Epoch 057] loss=0.9385 recon=0.9380 kl=0.0005\n",
      "[Epoch 058] loss=0.9301 recon=0.9297 kl=0.0004\n",
      "[Epoch 059] loss=0.9444 recon=0.9441 kl=0.0002\n",
      "[Epoch 060] loss=0.9298 recon=0.9289 kl=0.0009\n",
      "[Epoch 061] loss=0.9365 recon=0.9361 kl=0.0005\n",
      "[Epoch 062] loss=0.9560 recon=0.9555 kl=0.0006\n",
      "[Epoch 063] loss=0.9411 recon=0.9410 kl=0.0001\n",
      "[Epoch 064] loss=0.9423 recon=0.9390 kl=0.0033\n",
      "[Epoch 065] loss=0.9395 recon=0.9359 kl=0.0036\n",
      "[Epoch 066] loss=0.9481 recon=0.9455 kl=0.0026\n",
      "[Epoch 067] loss=0.9353 recon=0.9334 kl=0.0019\n",
      "[Epoch 068] loss=0.9252 recon=0.9243 kl=0.0009\n",
      "[Epoch 069] loss=0.9494 recon=0.9493 kl=0.0001\n",
      "[Epoch 070] loss=0.9311 recon=0.9311 kl=0.0000\n",
      "[Epoch 071] loss=0.9230 recon=0.9229 kl=0.0000\n",
      "[Epoch 072] loss=0.9237 recon=0.9237 kl=0.0000\n",
      "[Epoch 073] loss=0.9384 recon=0.9384 kl=0.0000\n",
      "[Epoch 074] loss=0.9543 recon=0.9537 kl=0.0006\n",
      "[Epoch 075] loss=0.9304 recon=0.9301 kl=0.0003\n",
      "[Epoch 076] loss=0.9386 recon=0.9381 kl=0.0006\n",
      "[Epoch 077] loss=0.9294 recon=0.9291 kl=0.0003\n",
      "[Epoch 078] loss=0.9399 recon=0.9396 kl=0.0003\n",
      "[Epoch 079] loss=0.9301 recon=0.9295 kl=0.0006\n",
      "[Epoch 080] loss=0.9374 recon=0.9371 kl=0.0004\n",
      "[Epoch 081] loss=0.9399 recon=0.9393 kl=0.0006\n",
      "[Epoch 082] loss=0.9436 recon=0.9432 kl=0.0003\n",
      "[Epoch 083] loss=0.9431 recon=0.9424 kl=0.0006\n",
      "[Epoch 084] loss=0.9534 recon=0.9530 kl=0.0004\n",
      "[Epoch 085] loss=0.9267 recon=0.9265 kl=0.0001\n",
      "[Epoch 086] loss=0.9260 recon=0.9252 kl=0.0008\n",
      "[Epoch 087] loss=0.9373 recon=0.9371 kl=0.0002\n",
      "[Epoch 088] loss=0.9425 recon=0.9419 kl=0.0006\n",
      "[Epoch 089] loss=0.9423 recon=0.9420 kl=0.0003\n",
      "[Epoch 090] loss=0.9440 recon=0.9431 kl=0.0009\n",
      "69\n",
      "[Epoch 001] loss=1.3330 recon=0.9367 kl=0.3963\n",
      "[Epoch 002] loss=0.9349 recon=0.9323 kl=0.0026\n",
      "[Epoch 003] loss=0.9396 recon=0.9394 kl=0.0002\n",
      "[Epoch 004] loss=0.9566 recon=0.9565 kl=0.0001\n",
      "[Epoch 005] loss=0.9517 recon=0.9517 kl=0.0001\n",
      "[Epoch 006] loss=0.9316 recon=0.9314 kl=0.0002\n",
      "[Epoch 007] loss=0.9424 recon=0.9423 kl=0.0001\n",
      "[Epoch 008] loss=0.9437 recon=0.9434 kl=0.0004\n",
      "[Epoch 009] loss=0.9472 recon=0.9472 kl=0.0001\n",
      "[Epoch 010] loss=0.9383 recon=0.9380 kl=0.0003\n",
      "[Epoch 011] loss=0.9318 recon=0.9317 kl=0.0001\n",
      "[Epoch 012] loss=0.9350 recon=0.9345 kl=0.0005\n",
      "[Epoch 013] loss=0.9395 recon=0.9394 kl=0.0001\n",
      "[Epoch 014] loss=0.9469 recon=0.9466 kl=0.0003\n",
      "[Epoch 015] loss=0.9305 recon=0.9303 kl=0.0002\n",
      "[Epoch 016] loss=0.9334 recon=0.9329 kl=0.0005\n",
      "[Epoch 017] loss=0.9452 recon=0.9450 kl=0.0002\n",
      "[Epoch 018] loss=0.9397 recon=0.9390 kl=0.0007\n",
      "[Epoch 019] loss=0.9321 recon=0.9320 kl=0.0001\n",
      "[Epoch 020] loss=0.9262 recon=0.9257 kl=0.0005\n",
      "[Epoch 021] loss=0.9444 recon=0.9438 kl=0.0005\n",
      "[Epoch 022] loss=0.9381 recon=0.9379 kl=0.0001\n",
      "[Epoch 023] loss=0.9525 recon=0.9520 kl=0.0005\n",
      "[Epoch 024] loss=0.9552 recon=0.9549 kl=0.0003\n",
      "[Epoch 025] loss=0.9253 recon=0.9249 kl=0.0004\n",
      "[Epoch 026] loss=0.9343 recon=0.9338 kl=0.0006\n",
      "[Epoch 027] loss=0.9302 recon=0.9301 kl=0.0001\n",
      "[Epoch 028] loss=0.9287 recon=0.9279 kl=0.0008\n",
      "[Epoch 029] loss=0.9286 recon=0.9283 kl=0.0002\n",
      "[Epoch 030] loss=0.9594 recon=0.9553 kl=0.0040\n",
      "[Epoch 031] loss=0.9348 recon=0.9285 kl=0.0063\n",
      "[Epoch 032] loss=0.9515 recon=0.9511 kl=0.0005\n",
      "[Epoch 033] loss=0.9354 recon=0.9353 kl=0.0000\n",
      "[Epoch 034] loss=0.9306 recon=0.9306 kl=0.0000\n",
      "[Epoch 035] loss=0.9315 recon=0.9315 kl=0.0000\n",
      "[Epoch 036] loss=0.9454 recon=0.9452 kl=0.0002\n",
      "[Epoch 037] loss=0.9470 recon=0.9445 kl=0.0026\n",
      "[Epoch 038] loss=0.9402 recon=0.9370 kl=0.0032\n",
      "[Epoch 039] loss=0.9356 recon=0.9341 kl=0.0014\n",
      "[Epoch 040] loss=0.9357 recon=0.9356 kl=0.0002\n",
      "[Epoch 041] loss=0.9451 recon=0.9451 kl=0.0000\n",
      "[Epoch 042] loss=0.9357 recon=0.9356 kl=0.0000\n",
      "[Epoch 043] loss=0.9392 recon=0.9392 kl=0.0000\n",
      "[Epoch 044] loss=0.9453 recon=0.9445 kl=0.0007\n",
      "[Epoch 045] loss=0.9354 recon=0.9351 kl=0.0003\n",
      "[Epoch 046] loss=0.9389 recon=0.9388 kl=0.0001\n",
      "[Epoch 047] loss=0.9419 recon=0.9411 kl=0.0008\n",
      "[Epoch 048] loss=0.9375 recon=0.9373 kl=0.0003\n",
      "[Epoch 049] loss=0.9575 recon=0.9569 kl=0.0006\n",
      "[Epoch 050] loss=0.9495 recon=0.9491 kl=0.0004\n",
      "[Epoch 051] loss=0.9412 recon=0.9403 kl=0.0009\n",
      "[Epoch 052] loss=0.9719 recon=0.9717 kl=0.0002\n",
      "[Epoch 053] loss=0.9589 recon=0.9562 kl=0.0027\n",
      "[Epoch 054] loss=0.9393 recon=0.9363 kl=0.0030\n",
      "[Epoch 055] loss=0.9315 recon=0.9308 kl=0.0007\n",
      "[Epoch 056] loss=0.9461 recon=0.9461 kl=0.0001\n",
      "[Epoch 057] loss=0.9291 recon=0.9291 kl=0.0000\n",
      "[Epoch 058] loss=0.9343 recon=0.9342 kl=0.0000\n",
      "[Epoch 059] loss=0.9452 recon=0.9426 kl=0.0026\n",
      "[Epoch 060] loss=0.9257 recon=0.9247 kl=0.0010\n",
      "[Epoch 061] loss=0.9411 recon=0.9410 kl=0.0001\n",
      "[Epoch 062] loss=0.9301 recon=0.9301 kl=0.0000\n",
      "[Epoch 063] loss=0.9449 recon=0.9444 kl=0.0005\n",
      "[Epoch 064] loss=0.9437 recon=0.9394 kl=0.0043\n",
      "[Epoch 065] loss=0.9414 recon=0.9400 kl=0.0014\n",
      "[Epoch 066] loss=0.9274 recon=0.9272 kl=0.0002\n",
      "[Epoch 067] loss=0.9364 recon=0.9364 kl=0.0000\n",
      "[Epoch 068] loss=0.9296 recon=0.9296 kl=0.0000\n",
      "[Epoch 069] loss=0.9419 recon=0.9409 kl=0.0010\n",
      "[Epoch 070] loss=0.9578 recon=0.9573 kl=0.0005\n",
      "[Epoch 071] loss=0.9469 recon=0.9468 kl=0.0001\n",
      "[Epoch 072] loss=0.9324 recon=0.9323 kl=0.0002\n",
      "[Epoch 073] loss=0.9408 recon=0.9402 kl=0.0006\n",
      "[Epoch 074] loss=0.9281 recon=0.9278 kl=0.0003\n",
      "[Epoch 075] loss=0.9341 recon=0.9300 kl=0.0041\n",
      "[Epoch 076] loss=0.9517 recon=0.9511 kl=0.0007\n",
      "[Epoch 077] loss=0.9448 recon=0.9447 kl=0.0001\n",
      "[Epoch 078] loss=0.9255 recon=0.9254 kl=0.0000\n",
      "[Epoch 079] loss=0.9351 recon=0.9346 kl=0.0004\n",
      "[Epoch 080] loss=0.9364 recon=0.9357 kl=0.0007\n",
      "[Epoch 081] loss=0.9486 recon=0.9482 kl=0.0004\n",
      "[Epoch 082] loss=0.9285 recon=0.9280 kl=0.0005\n",
      "[Epoch 083] loss=0.9524 recon=0.9523 kl=0.0001\n",
      "[Epoch 084] loss=0.9446 recon=0.9368 kl=0.0078\n",
      "[Epoch 085] loss=0.9421 recon=0.9393 kl=0.0028\n",
      "[Epoch 086] loss=0.9379 recon=0.9376 kl=0.0002\n",
      "[Epoch 087] loss=0.9371 recon=0.9370 kl=0.0000\n",
      "[Epoch 088] loss=0.9299 recon=0.9299 kl=0.0000\n",
      "[Epoch 089] loss=0.9223 recon=0.9223 kl=0.0000\n",
      "[Epoch 090] loss=0.9471 recon=0.9440 kl=0.0031\n",
      "70\n",
      "[Epoch 001] loss=1.2571 recon=0.9346 kl=0.3226\n",
      "[Epoch 002] loss=0.9467 recon=0.9444 kl=0.0023\n",
      "[Epoch 003] loss=0.9527 recon=0.9525 kl=0.0002\n",
      "[Epoch 004] loss=0.9545 recon=0.9544 kl=0.0001\n",
      "[Epoch 005] loss=0.9338 recon=0.9336 kl=0.0002\n",
      "[Epoch 006] loss=0.9426 recon=0.9425 kl=0.0001\n",
      "[Epoch 007] loss=0.9433 recon=0.9430 kl=0.0003\n",
      "[Epoch 008] loss=0.9343 recon=0.9340 kl=0.0003\n",
      "[Epoch 009] loss=0.9454 recon=0.9453 kl=0.0001\n",
      "[Epoch 010] loss=0.9436 recon=0.9432 kl=0.0004\n",
      "[Epoch 011] loss=0.9528 recon=0.9526 kl=0.0002\n",
      "[Epoch 012] loss=0.9511 recon=0.9504 kl=0.0007\n",
      "[Epoch 013] loss=0.9362 recon=0.9361 kl=0.0001\n",
      "[Epoch 014] loss=0.9352 recon=0.9348 kl=0.0004\n",
      "[Epoch 015] loss=0.9434 recon=0.9431 kl=0.0003\n",
      "[Epoch 016] loss=0.9421 recon=0.9414 kl=0.0007\n",
      "[Epoch 017] loss=0.9310 recon=0.9307 kl=0.0002\n",
      "[Epoch 018] loss=0.9523 recon=0.9517 kl=0.0005\n",
      "[Epoch 019] loss=0.9492 recon=0.9487 kl=0.0005\n",
      "[Epoch 020] loss=0.9346 recon=0.9341 kl=0.0004\n",
      "[Epoch 021] loss=0.9513 recon=0.9509 kl=0.0004\n",
      "[Epoch 022] loss=0.9535 recon=0.9531 kl=0.0003\n",
      "[Epoch 023] loss=0.9418 recon=0.9411 kl=0.0008\n",
      "[Epoch 024] loss=0.9358 recon=0.9335 kl=0.0023\n",
      "[Epoch 025] loss=0.9313 recon=0.9309 kl=0.0004\n",
      "[Epoch 026] loss=0.9421 recon=0.9420 kl=0.0001\n",
      "[Epoch 027] loss=0.9306 recon=0.9301 kl=0.0005\n",
      "[Epoch 028] loss=0.9382 recon=0.9379 kl=0.0002\n",
      "[Epoch 029] loss=0.9361 recon=0.9343 kl=0.0018\n",
      "[Epoch 030] loss=0.9310 recon=0.9285 kl=0.0025\n",
      "[Epoch 031] loss=0.9358 recon=0.9355 kl=0.0003\n",
      "[Epoch 032] loss=0.9473 recon=0.9473 kl=0.0001\n",
      "[Epoch 033] loss=0.9308 recon=0.9302 kl=0.0006\n",
      "[Epoch 034] loss=0.9326 recon=0.9324 kl=0.0002\n",
      "[Epoch 035] loss=0.9606 recon=0.9601 kl=0.0006\n",
      "[Epoch 036] loss=0.9406 recon=0.9398 kl=0.0008\n",
      "[Epoch 037] loss=0.9399 recon=0.9397 kl=0.0002\n",
      "[Epoch 038] loss=0.9452 recon=0.9448 kl=0.0004\n",
      "[Epoch 039] loss=0.9458 recon=0.9416 kl=0.0042\n",
      "[Epoch 040] loss=0.9361 recon=0.9330 kl=0.0032\n",
      "[Epoch 041] loss=0.9397 recon=0.9374 kl=0.0023\n",
      "[Epoch 042] loss=0.9283 recon=0.9274 kl=0.0010\n",
      "[Epoch 043] loss=0.9243 recon=0.9242 kl=0.0001\n",
      "[Epoch 044] loss=0.9459 recon=0.9459 kl=0.0000\n",
      "[Epoch 045] loss=0.9341 recon=0.9341 kl=0.0000\n",
      "[Epoch 046] loss=0.9437 recon=0.9437 kl=0.0000\n",
      "[Epoch 047] loss=0.9517 recon=0.9512 kl=0.0005\n",
      "[Epoch 048] loss=0.9302 recon=0.9297 kl=0.0005\n",
      "[Epoch 049] loss=0.9349 recon=0.9346 kl=0.0003\n",
      "[Epoch 050] loss=0.9376 recon=0.9372 kl=0.0004\n",
      "[Epoch 051] loss=0.9279 recon=0.9274 kl=0.0006\n",
      "[Epoch 052] loss=0.9444 recon=0.9438 kl=0.0006\n",
      "[Epoch 053] loss=0.9394 recon=0.9390 kl=0.0004\n",
      "[Epoch 054] loss=0.9345 recon=0.9337 kl=0.0008\n",
      "[Epoch 055] loss=0.9339 recon=0.9332 kl=0.0007\n",
      "[Epoch 056] loss=0.9296 recon=0.9280 kl=0.0015\n",
      "[Epoch 057] loss=0.9267 recon=0.9242 kl=0.0026\n",
      "[Epoch 058] loss=0.9260 recon=0.9255 kl=0.0005\n",
      "[Epoch 059] loss=0.9373 recon=0.9372 kl=0.0001\n",
      "[Epoch 060] loss=0.9414 recon=0.9414 kl=0.0000\n",
      "[Epoch 061] loss=0.9258 recon=0.9251 kl=0.0007\n",
      "[Epoch 062] loss=0.9432 recon=0.9431 kl=0.0002\n",
      "[Epoch 063] loss=0.9351 recon=0.9345 kl=0.0006\n",
      "[Epoch 064] loss=0.9261 recon=0.9258 kl=0.0003\n",
      "[Epoch 065] loss=0.9319 recon=0.9316 kl=0.0003\n",
      "[Epoch 066] loss=0.9327 recon=0.9319 kl=0.0008\n",
      "[Epoch 067] loss=0.9361 recon=0.9356 kl=0.0005\n",
      "[Epoch 068] loss=0.9344 recon=0.9340 kl=0.0004\n",
      "[Epoch 069] loss=0.9563 recon=0.9555 kl=0.0007\n",
      "[Epoch 070] loss=0.9541 recon=0.9529 kl=0.0012\n",
      "[Epoch 071] loss=0.9289 recon=0.9285 kl=0.0004\n",
      "[Epoch 072] loss=0.9287 recon=0.9286 kl=0.0001\n",
      "[Epoch 073] loss=0.9356 recon=0.9349 kl=0.0007\n",
      "[Epoch 074] loss=0.9268 recon=0.9263 kl=0.0006\n",
      "[Epoch 075] loss=0.9376 recon=0.9369 kl=0.0007\n",
      "[Epoch 076] loss=0.9266 recon=0.9264 kl=0.0002\n",
      "[Epoch 077] loss=0.9390 recon=0.9361 kl=0.0029\n",
      "[Epoch 078] loss=0.9362 recon=0.9345 kl=0.0017\n",
      "[Epoch 079] loss=0.9398 recon=0.9396 kl=0.0002\n",
      "[Epoch 080] loss=0.9309 recon=0.9309 kl=0.0000\n",
      "[Epoch 081] loss=0.9612 recon=0.9612 kl=0.0000\n",
      "[Epoch 082] loss=0.9216 recon=0.9212 kl=0.0004\n",
      "[Epoch 083] loss=0.9276 recon=0.9239 kl=0.0037\n",
      "[Epoch 084] loss=0.9405 recon=0.9396 kl=0.0009\n",
      "[Epoch 085] loss=0.9469 recon=0.9468 kl=0.0001\n",
      "[Epoch 086] loss=0.9296 recon=0.9295 kl=0.0000\n",
      "[Epoch 087] loss=0.9505 recon=0.9499 kl=0.0006\n",
      "[Epoch 088] loss=0.9478 recon=0.9471 kl=0.0007\n",
      "[Epoch 089] loss=0.9304 recon=0.9303 kl=0.0001\n",
      "[Epoch 090] loss=0.9317 recon=0.9311 kl=0.0006\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T17:19:39.426743Z",
     "start_time": "2025-10-10T17:19:39.365289Z"
    }
   },
   "cell_type": "code",
   "source": "out_dir",
   "id": "23d6231718bf88a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comed_results'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "3ca0dee4-c216-4ab3-a0c6-602048f0dc4c",
   "metadata": {},
   "source": [
    "## DAYTON"
   ]
  },
  {
   "cell_type": "code",
   "id": "89b69783-5c4d-4ce5-9707-7b41ee140a4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T21:52:25.088328Z",
     "start_time": "2025-10-10T21:52:23.038971Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import model_summary as model_class\n",
    "import prophet_linear_adjust as prophet_based\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "301ff3fe-0ffc-46c8-bd19-98d31cd4be20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T21:52:25.164547Z",
     "start_time": "2025-10-10T21:52:25.098364Z"
    }
   },
   "source": [
    "df_dayton = pd.read_csv(\"DAYTON_hourly.csv\")\n",
    "df_dayton.rename(columns={'Datetime': 'ds', 'DAYTON_MW': 'y'}, inplace=True)\n",
    "df_dayton['ds'] = pd.to_datetime(df_dayton['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'Dayton_results'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "c2a43fda96025ca4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T01:17:23.200590Z",
     "start_time": "2025-10-04T01:08:44.684379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_demand_dayton = df_dayton.groupby(df_dayton['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_dayton, date_start, date_end, daily_demand_dayton, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv(out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "50bf8437d421c5e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:08:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:08:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:08:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:09:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:09:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:10:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:10:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:10:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:10:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:10:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:10:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:10:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:10:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:11:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:11:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:11:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:11:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:11:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:11:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:11:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:11:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:11:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:11:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:11:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:11:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:11:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:11:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:12:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:12:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:12:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:12:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:12:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:12:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:12:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:12:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:12:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:12:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:12:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:12:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:12:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:12:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:12:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:12:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:13:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:13:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:13:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:13:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:13:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:13:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:13:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:13:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:13:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:13:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:13:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:13:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:13:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:13:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:14:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:14:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:14:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:14:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:14:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:14:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:14:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:14:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:14:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:14:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:14:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:14:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:14:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:14:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:15:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:15:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:16:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:16:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:16:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:16:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:16:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:16:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:16:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:16:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:16:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:16:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:16:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:16:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:16:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:16:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:16:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:16:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:16:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:16:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:17:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:17:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:17:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:17:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:17:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:17:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:17:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with seasonality",
   "id": "87a4d70da45eb581"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T01:27:02.326238Z",
     "start_time": "2025-10-04T01:17:23.233210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_demand_dayton = df_dayton.groupby(df_dayton['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "results_prophet_w = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_dayton, date_start, date_end, daily_demand_dayton, manual = False, daily = True, weekly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_w.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_w = pd.concat(results_prophet_w, ignore_index=True)\n",
    "\n",
    "results_prophet_w.to_csv(out_dir + '/results_prophet_w.csv', index=False)"
   ],
   "id": "49a41aceef093834",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:17:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:17:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:17:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:17:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:17:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:17:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:17:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:18:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:18:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:18:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:18:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:18:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:18:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:18:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:18:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:18:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:18:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:18:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:18:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:18:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:18:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:18:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:18:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:19:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:19:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:19:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:19:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:19:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:19:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:19:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:19:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:19:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:19:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:19:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:19:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:19:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:19:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:19:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:19:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:20:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:20:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:20:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:20:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:20:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:20:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:20:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:20:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:20:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:20:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:20:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:20:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:20:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:20:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:21:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:21:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:21:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:21:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:21:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-10-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:21:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:21:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:21:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:21:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:21:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:21:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:21:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:22:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:22:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:22:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:22:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:22:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:22:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:22:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:22:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:22:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:22:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:22:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:22:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:22:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:22:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:23:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:23:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:23:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:23:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:23:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:23:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:23:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:23:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:23:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:23:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:23:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:23:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:25:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:26:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:26:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:26:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:26:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:26:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:26:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:26:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:26:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:26:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:26:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:26:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:26:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:26:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2016-12-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:26:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:27:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "15e06fbb-b00d-4517-b3e3-b7b87c857a2b",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "id": "9893c3dd-afac-42f1-97a0-c37c2a8f912c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T20:27:28.252558Z",
     "start_time": "2025-10-03T19:22:27.998113Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con.to_csv(out_dir + '/results_aep_self_con.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:853: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {epoch+1} loss:\", float(loss))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.939308226108551\n",
      "epoch 2 loss: 0.5631309151649475\n",
      "epoch 3 loss: 0.3834574520587921\n",
      "epoch 4 loss: 0.21174007654190063\n",
      "epoch 5 loss: 0.16203318536281586\n",
      "epoch 6 loss: 0.19071727991104126\n",
      "epoch 7 loss: 0.15068133175373077\n",
      "epoch 8 loss: 0.15765677392482758\n",
      "epoch 9 loss: 0.15446890890598297\n",
      "epoch 10 loss: 0.20670722424983978\n",
      "epoch 11 loss: 0.20862093567848206\n",
      "epoch 12 loss: 0.16015109419822693\n",
      "epoch 13 loss: 0.14782682061195374\n",
      "epoch 14 loss: 0.125766783952713\n",
      "epoch 15 loss: 0.1373230516910553\n",
      "epoch 16 loss: 0.16150914132595062\n",
      "epoch 17 loss: 0.1828644573688507\n",
      "epoch 18 loss: 0.1745288223028183\n",
      "epoch 19 loss: 0.16186682879924774\n",
      "epoch 20 loss: 0.08814308047294617\n",
      "epoch 21 loss: 0.15779729187488556\n",
      "epoch 22 loss: 0.14702589809894562\n",
      "epoch 23 loss: 0.12249288707971573\n",
      "epoch 24 loss: 0.12337148189544678\n",
      "epoch 25 loss: 0.11441438645124435\n",
      "epoch 26 loss: 0.1085873618721962\n",
      "epoch 27 loss: 0.121479831635952\n",
      "epoch 28 loss: 0.10990456491708755\n",
      "epoch 29 loss: 0.10412468016147614\n",
      "epoch 30 loss: 0.11771883815526962\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_74380/3267305768.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.891365647315979\n",
      "epoch 2 loss: 0.7614630460739136\n",
      "epoch 3 loss: 0.44481393694877625\n",
      "epoch 4 loss: 0.2191857248544693\n",
      "epoch 5 loss: 0.17499452829360962\n",
      "epoch 6 loss: 0.17133350670337677\n",
      "epoch 7 loss: 0.1735900193452835\n",
      "epoch 8 loss: 0.14612078666687012\n",
      "epoch 9 loss: 0.17285114526748657\n",
      "epoch 10 loss: 0.1769193559885025\n",
      "epoch 11 loss: 0.19641399383544922\n",
      "epoch 12 loss: 0.13468602299690247\n",
      "epoch 13 loss: 0.18551984429359436\n",
      "epoch 14 loss: 0.16620787978172302\n",
      "epoch 15 loss: 0.18450814485549927\n",
      "epoch 16 loss: 0.15606112778186798\n",
      "epoch 17 loss: 0.1650710552930832\n",
      "epoch 18 loss: 0.19153423607349396\n",
      "epoch 19 loss: 0.1653517186641693\n",
      "epoch 20 loss: 0.13315559923648834\n",
      "epoch 21 loss: 0.158402681350708\n",
      "epoch 22 loss: 0.14619988203048706\n",
      "epoch 23 loss: 0.1790519654750824\n",
      "epoch 24 loss: 0.15698984265327454\n",
      "epoch 25 loss: 0.15835532546043396\n",
      "epoch 26 loss: 0.08529486507177353\n",
      "epoch 27 loss: 0.12556567788124084\n",
      "epoch 28 loss: 0.16067562997341156\n",
      "epoch 29 loss: 0.12115822732448578\n",
      "epoch 30 loss: 0.18769758939743042\n",
      "3\n",
      "epoch 1 loss: 0.7694404125213623\n",
      "epoch 2 loss: 0.7803052067756653\n",
      "epoch 3 loss: 0.4218980669975281\n",
      "epoch 4 loss: 0.2072935402393341\n",
      "epoch 5 loss: 0.17543137073516846\n",
      "epoch 6 loss: 0.1606646329164505\n",
      "epoch 7 loss: 0.1453038603067398\n",
      "epoch 8 loss: 0.16252106428146362\n",
      "epoch 9 loss: 0.19194287061691284\n",
      "epoch 10 loss: 0.1626177728176117\n",
      "epoch 11 loss: 0.1704738289117813\n",
      "epoch 12 loss: 0.14907006919384003\n",
      "epoch 13 loss: 0.185868039727211\n",
      "epoch 14 loss: 0.15760892629623413\n",
      "epoch 15 loss: 0.17271485924720764\n",
      "epoch 16 loss: 0.13271932303905487\n",
      "epoch 17 loss: 0.17065918445587158\n",
      "epoch 18 loss: 0.16084232926368713\n",
      "epoch 19 loss: 0.16216477751731873\n",
      "epoch 20 loss: 0.19560734927654266\n",
      "epoch 21 loss: 0.1247749850153923\n",
      "epoch 22 loss: 0.1614016592502594\n",
      "epoch 23 loss: 0.11424586921930313\n",
      "epoch 24 loss: 0.11433368921279907\n",
      "epoch 25 loss: 0.10028564184904099\n",
      "epoch 26 loss: 0.10857603698968887\n",
      "epoch 27 loss: 0.12176504731178284\n",
      "epoch 28 loss: 0.1456039547920227\n",
      "epoch 29 loss: 0.08265703171491623\n",
      "epoch 30 loss: 0.10790035873651505\n",
      "4\n",
      "epoch 1 loss: 0.8033936023712158\n",
      "epoch 2 loss: 0.5256070494651794\n",
      "epoch 3 loss: 0.4790855646133423\n",
      "epoch 4 loss: 0.2169284075498581\n",
      "epoch 5 loss: 0.17616315186023712\n",
      "epoch 6 loss: 0.18491318821907043\n",
      "epoch 7 loss: 0.16630958020687103\n",
      "epoch 8 loss: 0.1720001995563507\n",
      "epoch 9 loss: 0.1678982824087143\n",
      "epoch 10 loss: 0.13146266341209412\n",
      "epoch 11 loss: 0.17452380061149597\n",
      "epoch 12 loss: 0.17646512389183044\n",
      "epoch 13 loss: 0.15757901966571808\n",
      "epoch 14 loss: 0.18228577077388763\n",
      "epoch 15 loss: 0.19708110392093658\n",
      "epoch 16 loss: 0.18125590682029724\n",
      "epoch 17 loss: 0.15873563289642334\n",
      "epoch 18 loss: 0.155061274766922\n",
      "epoch 19 loss: 0.13881129026412964\n",
      "epoch 20 loss: 0.1532941609621048\n",
      "epoch 21 loss: 0.12748219072818756\n",
      "epoch 22 loss: 0.1293047070503235\n",
      "epoch 23 loss: 0.1348126381635666\n",
      "epoch 24 loss: 0.13301901519298553\n",
      "epoch 25 loss: 0.140402689576149\n",
      "epoch 26 loss: 0.11611626297235489\n",
      "epoch 27 loss: 0.09246204793453217\n",
      "epoch 28 loss: 0.0918295606970787\n",
      "epoch 29 loss: 0.11748111993074417\n",
      "epoch 30 loss: 0.0906875729560852\n",
      "5\n",
      "epoch 1 loss: 0.908493161201477\n",
      "epoch 2 loss: 0.6849066019058228\n",
      "epoch 3 loss: 0.5117539167404175\n",
      "epoch 4 loss: 0.2744506299495697\n",
      "epoch 5 loss: 0.20113781094551086\n",
      "epoch 6 loss: 0.18169809877872467\n",
      "epoch 7 loss: 0.15378426015377045\n",
      "epoch 8 loss: 0.18267403542995453\n",
      "epoch 9 loss: 0.2109765261411667\n",
      "epoch 10 loss: 0.18463332951068878\n",
      "epoch 11 loss: 0.12533017992973328\n",
      "epoch 12 loss: 0.15924648940563202\n",
      "epoch 13 loss: 0.13960400223731995\n",
      "epoch 14 loss: 0.17006173729896545\n",
      "epoch 15 loss: 0.15291307866573334\n",
      "epoch 16 loss: 0.17252323031425476\n",
      "epoch 17 loss: 0.16095133125782013\n",
      "epoch 18 loss: 0.139504075050354\n",
      "epoch 19 loss: 0.14961004257202148\n",
      "epoch 20 loss: 0.13329161703586578\n",
      "epoch 21 loss: 0.15898959338665009\n",
      "epoch 22 loss: 0.13931144773960114\n",
      "epoch 23 loss: 0.15416134893894196\n",
      "epoch 24 loss: 0.1503029316663742\n",
      "epoch 25 loss: 0.16034989058971405\n",
      "epoch 26 loss: 0.15899449586868286\n",
      "epoch 27 loss: 0.1552165299654007\n",
      "epoch 28 loss: 0.12396767735481262\n",
      "epoch 29 loss: 0.11114007234573364\n",
      "epoch 30 loss: 0.08370450139045715\n",
      "6\n",
      "epoch 1 loss: 0.916776716709137\n",
      "epoch 2 loss: 0.6348850727081299\n",
      "epoch 3 loss: 0.4674436151981354\n",
      "epoch 4 loss: 0.2506343126296997\n",
      "epoch 5 loss: 0.19529323279857635\n",
      "epoch 6 loss: 0.18635648488998413\n",
      "epoch 7 loss: 0.15426412224769592\n",
      "epoch 8 loss: 0.1795506775379181\n",
      "epoch 9 loss: 0.19332799315452576\n",
      "epoch 10 loss: 0.15655513107776642\n",
      "epoch 11 loss: 0.20590032637119293\n",
      "epoch 12 loss: 0.17455823719501495\n",
      "epoch 13 loss: 0.15872201323509216\n",
      "epoch 14 loss: 0.19653122127056122\n",
      "epoch 15 loss: 0.10384929925203323\n",
      "epoch 16 loss: 0.18312963843345642\n",
      "epoch 17 loss: 0.14410023391246796\n",
      "epoch 18 loss: 0.14288710057735443\n",
      "epoch 19 loss: 0.16518136858940125\n",
      "epoch 20 loss: 0.15393897891044617\n",
      "epoch 21 loss: 0.15038146078586578\n",
      "epoch 22 loss: 0.1211184486746788\n",
      "epoch 23 loss: 0.21270640194416046\n",
      "epoch 24 loss: 0.1252553015947342\n",
      "epoch 25 loss: 0.11033093929290771\n",
      "epoch 26 loss: 0.11227105557918549\n",
      "epoch 27 loss: 0.1337873786687851\n",
      "epoch 28 loss: 0.13697493076324463\n",
      "epoch 29 loss: 0.10663505643606186\n",
      "epoch 30 loss: 0.11628855019807816\n",
      "7\n",
      "epoch 1 loss: 0.8522947430610657\n",
      "epoch 2 loss: 0.5842806696891785\n",
      "epoch 3 loss: 0.36776068806648254\n",
      "epoch 4 loss: 0.19079215824604034\n",
      "epoch 5 loss: 0.17782604694366455\n",
      "epoch 6 loss: 0.1804494857788086\n",
      "epoch 7 loss: 0.18437471985816956\n",
      "epoch 8 loss: 0.17345120012760162\n",
      "epoch 9 loss: 0.16297264397144318\n",
      "epoch 10 loss: 0.1566222459077835\n",
      "epoch 11 loss: 0.19917583465576172\n",
      "epoch 12 loss: 0.1699889451265335\n",
      "epoch 13 loss: 0.14072582125663757\n",
      "epoch 14 loss: 0.15252047777175903\n",
      "epoch 15 loss: 0.17004019021987915\n",
      "epoch 16 loss: 0.17446504533290863\n",
      "epoch 17 loss: 0.17220522463321686\n",
      "epoch 18 loss: 0.16427995264530182\n",
      "epoch 19 loss: 0.16428202390670776\n",
      "epoch 20 loss: 0.13879714906215668\n",
      "epoch 21 loss: 0.1746358871459961\n",
      "epoch 22 loss: 0.13996151089668274\n",
      "epoch 23 loss: 0.1177544891834259\n",
      "epoch 24 loss: 0.17435964941978455\n",
      "epoch 25 loss: 0.16574840247631073\n",
      "epoch 26 loss: 0.1268322616815567\n",
      "epoch 27 loss: 0.15080758929252625\n",
      "epoch 28 loss: 0.12377188354730606\n",
      "epoch 29 loss: 0.11212360113859177\n",
      "epoch 30 loss: 0.10778357833623886\n",
      "8\n",
      "epoch 1 loss: 0.9190835952758789\n",
      "epoch 2 loss: 0.6867715120315552\n",
      "epoch 3 loss: 0.35628119111061096\n",
      "epoch 4 loss: 0.2274075150489807\n",
      "epoch 5 loss: 0.20675863325595856\n",
      "epoch 6 loss: 0.15925383567810059\n",
      "epoch 7 loss: 0.21412013471126556\n",
      "epoch 8 loss: 0.19989053905010223\n",
      "epoch 9 loss: 0.21625229716300964\n",
      "epoch 10 loss: 0.17939653992652893\n",
      "epoch 11 loss: 0.19450949132442474\n",
      "epoch 12 loss: 0.16948489844799042\n",
      "epoch 13 loss: 0.17258766293525696\n",
      "epoch 14 loss: 0.18705876171588898\n",
      "epoch 15 loss: 0.17863094806671143\n",
      "epoch 16 loss: 0.16684465110301971\n",
      "epoch 17 loss: 0.1713653951883316\n",
      "epoch 18 loss: 0.1847737431526184\n",
      "epoch 19 loss: 0.1639537513256073\n",
      "epoch 20 loss: 0.18144500255584717\n",
      "epoch 21 loss: 0.15566377341747284\n",
      "epoch 22 loss: 0.14231573045253754\n",
      "epoch 23 loss: 0.1323823183774948\n",
      "epoch 24 loss: 0.158946692943573\n",
      "epoch 25 loss: 0.16019515693187714\n",
      "epoch 26 loss: 0.16217711567878723\n",
      "epoch 27 loss: 0.19778232276439667\n",
      "epoch 28 loss: 0.1202009990811348\n",
      "epoch 29 loss: 0.17800408601760864\n",
      "epoch 30 loss: 0.1911119520664215\n",
      "9\n",
      "epoch 1 loss: 0.8681080341339111\n",
      "epoch 2 loss: 0.8392645716667175\n",
      "epoch 3 loss: 0.5063039660453796\n",
      "epoch 4 loss: 0.2608579993247986\n",
      "epoch 5 loss: 0.1529494822025299\n",
      "epoch 6 loss: 0.14854083955287933\n",
      "epoch 7 loss: 0.18139322102069855\n",
      "epoch 8 loss: 0.17848096787929535\n",
      "epoch 9 loss: 0.19745171070098877\n",
      "epoch 10 loss: 0.14078544080257416\n",
      "epoch 11 loss: 0.16061922907829285\n",
      "epoch 12 loss: 0.15890829265117645\n",
      "epoch 13 loss: 0.14570412039756775\n",
      "epoch 14 loss: 0.1356946974992752\n",
      "epoch 15 loss: 0.16883082687854767\n",
      "epoch 16 loss: 0.15933220088481903\n",
      "epoch 17 loss: 0.11508557945489883\n",
      "epoch 18 loss: 0.16146530210971832\n",
      "epoch 19 loss: 0.16696709394454956\n",
      "epoch 20 loss: 0.15644629299640656\n",
      "epoch 21 loss: 0.1478172391653061\n",
      "epoch 22 loss: 0.14242224395275116\n",
      "epoch 23 loss: 0.16386820375919342\n",
      "epoch 24 loss: 0.11467038840055466\n",
      "epoch 25 loss: 0.15104302763938904\n",
      "epoch 26 loss: 0.13326984643936157\n",
      "epoch 27 loss: 0.10631363838911057\n",
      "epoch 28 loss: 0.13187745213508606\n",
      "epoch 29 loss: 0.09757891297340393\n",
      "epoch 30 loss: 0.1287582963705063\n",
      "10\n",
      "epoch 1 loss: 0.800279438495636\n",
      "epoch 2 loss: 0.5470395088195801\n",
      "epoch 3 loss: 0.44162747263908386\n",
      "epoch 4 loss: 0.2680608034133911\n",
      "epoch 5 loss: 0.1990651786327362\n",
      "epoch 6 loss: 0.2206130027770996\n",
      "epoch 7 loss: 0.14221173524856567\n",
      "epoch 8 loss: 0.1292470246553421\n",
      "epoch 9 loss: 0.14224790036678314\n",
      "epoch 10 loss: 0.14151792228221893\n",
      "epoch 11 loss: 0.1966799795627594\n",
      "epoch 12 loss: 0.14154165983200073\n",
      "epoch 13 loss: 0.138510599732399\n",
      "epoch 14 loss: 0.11536365002393723\n",
      "epoch 15 loss: 0.15500161051750183\n",
      "epoch 16 loss: 0.1383383423089981\n",
      "epoch 17 loss: 0.1738121211528778\n",
      "epoch 18 loss: 0.18668314814567566\n",
      "epoch 19 loss: 0.13758555054664612\n",
      "epoch 20 loss: 0.15160295367240906\n",
      "epoch 21 loss: 0.11235170811414719\n",
      "epoch 22 loss: 0.12211307883262634\n",
      "epoch 23 loss: 0.10291369259357452\n",
      "epoch 24 loss: 0.13139276206493378\n",
      "epoch 25 loss: 0.12518860399723053\n",
      "epoch 26 loss: 0.10700342059135437\n",
      "epoch 27 loss: 0.09810951352119446\n",
      "epoch 28 loss: 0.11272300779819489\n",
      "epoch 29 loss: 0.0985238254070282\n",
      "epoch 30 loss: 0.1141519695520401\n",
      "11\n",
      "epoch 1 loss: 0.7695782780647278\n",
      "epoch 2 loss: 0.7712103724479675\n",
      "epoch 3 loss: 0.36719053983688354\n",
      "epoch 4 loss: 0.20139499008655548\n",
      "epoch 5 loss: 0.20091085135936737\n",
      "epoch 6 loss: 0.18414871394634247\n",
      "epoch 7 loss: 0.1580781638622284\n",
      "epoch 8 loss: 0.1857411414384842\n",
      "epoch 9 loss: 0.15832005441188812\n",
      "epoch 10 loss: 0.156731978058815\n",
      "epoch 11 loss: 0.15952689945697784\n",
      "epoch 12 loss: 0.15684233605861664\n",
      "epoch 13 loss: 0.1668444275856018\n",
      "epoch 14 loss: 0.1685221940279007\n",
      "epoch 15 loss: 0.1630304455757141\n",
      "epoch 16 loss: 0.1631484180688858\n",
      "epoch 17 loss: 0.17796574532985687\n",
      "epoch 18 loss: 0.15424805879592896\n",
      "epoch 19 loss: 0.12626667320728302\n",
      "epoch 20 loss: 0.16161474585533142\n",
      "epoch 21 loss: 0.12397592514753342\n",
      "epoch 22 loss: 0.13325010240077972\n",
      "epoch 23 loss: 0.15422940254211426\n",
      "epoch 24 loss: 0.15448693931102753\n",
      "epoch 25 loss: 0.1556394398212433\n",
      "epoch 26 loss: 0.12876081466674805\n",
      "epoch 27 loss: 0.13139815628528595\n",
      "epoch 28 loss: 0.11482274532318115\n",
      "epoch 29 loss: 0.14233583211898804\n",
      "epoch 30 loss: 0.1355225145816803\n",
      "12\n",
      "epoch 1 loss: 0.7553819417953491\n",
      "epoch 2 loss: 0.4807251989841461\n",
      "epoch 3 loss: 0.23902779817581177\n",
      "epoch 4 loss: 0.16135385632514954\n",
      "epoch 5 loss: 0.17018061876296997\n",
      "epoch 6 loss: 0.17943592369556427\n",
      "epoch 7 loss: 0.16004899144172668\n",
      "epoch 8 loss: 0.17534387111663818\n",
      "epoch 9 loss: 0.15706086158752441\n",
      "epoch 10 loss: 0.23251274228096008\n",
      "epoch 11 loss: 0.1639859676361084\n",
      "epoch 12 loss: 0.19848021864891052\n",
      "epoch 13 loss: 0.1561110019683838\n",
      "epoch 14 loss: 0.1716921180486679\n",
      "epoch 15 loss: 0.16379989683628082\n",
      "epoch 16 loss: 0.18124382197856903\n",
      "epoch 17 loss: 0.15590506792068481\n",
      "epoch 18 loss: 0.16371288895606995\n",
      "epoch 19 loss: 0.1509784311056137\n",
      "epoch 20 loss: 0.15332071483135223\n",
      "epoch 21 loss: 0.12680557370185852\n",
      "epoch 22 loss: 0.12540264427661896\n",
      "epoch 23 loss: 0.1197085976600647\n",
      "epoch 24 loss: 0.1090870127081871\n",
      "epoch 25 loss: 0.16065600514411926\n",
      "epoch 26 loss: 0.16009719669818878\n",
      "epoch 27 loss: 0.1336064636707306\n",
      "epoch 28 loss: 0.16027866303920746\n",
      "epoch 29 loss: 0.12726929783821106\n",
      "epoch 30 loss: 0.134710893034935\n",
      "13\n",
      "epoch 1 loss: 0.7715232372283936\n",
      "epoch 2 loss: 0.5201154947280884\n",
      "epoch 3 loss: 0.27533158659935\n",
      "epoch 4 loss: 0.2086956799030304\n",
      "epoch 5 loss: 0.15235592424869537\n",
      "epoch 6 loss: 0.18762165307998657\n",
      "epoch 7 loss: 0.155145063996315\n",
      "epoch 8 loss: 0.15112517774105072\n",
      "epoch 9 loss: 0.15971091389656067\n",
      "epoch 10 loss: 0.16290096938610077\n",
      "epoch 11 loss: 0.16618824005126953\n",
      "epoch 12 loss: 0.12411177903413773\n",
      "epoch 13 loss: 0.1760312169790268\n",
      "epoch 14 loss: 0.19828936457633972\n",
      "epoch 15 loss: 0.18338309228420258\n",
      "epoch 16 loss: 0.12767119705677032\n",
      "epoch 17 loss: 0.1474262923002243\n",
      "epoch 18 loss: 0.1668160855770111\n",
      "epoch 19 loss: 0.13411688804626465\n",
      "epoch 20 loss: 0.13572344183921814\n",
      "epoch 21 loss: 0.1370425522327423\n",
      "epoch 22 loss: 0.1425485461950302\n",
      "epoch 23 loss: 0.10325607657432556\n",
      "epoch 24 loss: 0.16454541683197021\n",
      "epoch 25 loss: 0.09172695130109787\n",
      "epoch 26 loss: 0.10361245274543762\n",
      "epoch 27 loss: 0.18273188173770905\n",
      "epoch 28 loss: 0.1574944108724594\n",
      "epoch 29 loss: 0.09532646089792252\n",
      "epoch 30 loss: 0.11337989568710327\n",
      "14\n",
      "epoch 1 loss: 0.7803798317909241\n",
      "epoch 2 loss: 0.5719341039657593\n",
      "epoch 3 loss: 0.30767181515693665\n",
      "epoch 4 loss: 0.1791699230670929\n",
      "epoch 5 loss: 0.1690552532672882\n",
      "epoch 6 loss: 0.18412643671035767\n",
      "epoch 7 loss: 0.17240573465824127\n",
      "epoch 8 loss: 0.14287370443344116\n",
      "epoch 9 loss: 0.18736174702644348\n",
      "epoch 10 loss: 0.15660515427589417\n",
      "epoch 11 loss: 0.19481278955936432\n",
      "epoch 12 loss: 0.164199560880661\n",
      "epoch 13 loss: 0.14266882836818695\n",
      "epoch 14 loss: 0.18474137783050537\n",
      "epoch 15 loss: 0.1611209511756897\n",
      "epoch 16 loss: 0.09685803204774857\n",
      "epoch 17 loss: 0.18692050874233246\n",
      "epoch 18 loss: 0.16224965453147888\n",
      "epoch 19 loss: 0.18590466678142548\n",
      "epoch 20 loss: 0.1362435668706894\n",
      "epoch 21 loss: 0.1648959517478943\n",
      "epoch 22 loss: 0.17371611297130585\n",
      "epoch 23 loss: 0.1334475427865982\n",
      "epoch 24 loss: 0.1829206496477127\n",
      "epoch 25 loss: 0.19573836028575897\n",
      "epoch 26 loss: 0.1532452255487442\n",
      "epoch 27 loss: 0.1736329346895218\n",
      "epoch 28 loss: 0.165603369474411\n",
      "epoch 29 loss: 0.1597750335931778\n",
      "epoch 30 loss: 0.14828449487686157\n",
      "15\n",
      "epoch 1 loss: 0.8868751525878906\n",
      "epoch 2 loss: 0.5782037973403931\n",
      "epoch 3 loss: 0.3138447701931\n",
      "epoch 4 loss: 0.20308361947536469\n",
      "epoch 5 loss: 0.19893087446689606\n",
      "epoch 6 loss: 0.18819300830364227\n",
      "epoch 7 loss: 0.17497672140598297\n",
      "epoch 8 loss: 0.1362808793783188\n",
      "epoch 9 loss: 0.1863957941532135\n",
      "epoch 10 loss: 0.13297933340072632\n",
      "epoch 11 loss: 0.1583501398563385\n",
      "epoch 12 loss: 0.16794946789741516\n",
      "epoch 13 loss: 0.19592943787574768\n",
      "epoch 14 loss: 0.14795123040676117\n",
      "epoch 15 loss: 0.16708499193191528\n",
      "epoch 16 loss: 0.17015479505062103\n",
      "epoch 17 loss: 0.1612691879272461\n",
      "epoch 18 loss: 0.14510171115398407\n",
      "epoch 19 loss: 0.19129428267478943\n",
      "epoch 20 loss: 0.14070530235767365\n",
      "epoch 21 loss: 0.1331600397825241\n",
      "epoch 22 loss: 0.116303950548172\n",
      "epoch 23 loss: 0.0969325602054596\n",
      "epoch 24 loss: 0.14509309828281403\n",
      "epoch 25 loss: 0.11796985566616058\n",
      "epoch 26 loss: 0.1066453754901886\n",
      "epoch 27 loss: 0.12121984362602234\n",
      "epoch 28 loss: 0.12169747054576874\n",
      "epoch 29 loss: 0.119328573346138\n",
      "epoch 30 loss: 0.11027801781892776\n",
      "16\n",
      "epoch 1 loss: 0.7409563660621643\n",
      "epoch 2 loss: 0.5967462062835693\n",
      "epoch 3 loss: 0.47112590074539185\n",
      "epoch 4 loss: 0.24979586899280548\n",
      "epoch 5 loss: 0.19303958117961884\n",
      "epoch 6 loss: 0.17838139832019806\n",
      "epoch 7 loss: 0.15232737362384796\n",
      "epoch 8 loss: 0.14701969921588898\n",
      "epoch 9 loss: 0.1415652334690094\n",
      "epoch 10 loss: 0.14309468865394592\n",
      "epoch 11 loss: 0.1715100109577179\n",
      "epoch 12 loss: 0.1522539258003235\n",
      "epoch 13 loss: 0.13636745512485504\n",
      "epoch 14 loss: 0.18442302942276\n",
      "epoch 15 loss: 0.1433313488960266\n",
      "epoch 16 loss: 0.18567030131816864\n",
      "epoch 17 loss: 0.17828629910945892\n",
      "epoch 18 loss: 0.18863041698932648\n",
      "epoch 19 loss: 0.19323837757110596\n",
      "epoch 20 loss: 0.1445620208978653\n",
      "epoch 21 loss: 0.17374897003173828\n",
      "epoch 22 loss: 0.13031944632530212\n",
      "epoch 23 loss: 0.17116795480251312\n",
      "epoch 24 loss: 0.1569327563047409\n",
      "epoch 25 loss: 0.11664395779371262\n",
      "epoch 26 loss: 0.11369730532169342\n",
      "epoch 27 loss: 0.11939795315265656\n",
      "epoch 28 loss: 0.13787415623664856\n",
      "epoch 29 loss: 0.14454151690006256\n",
      "epoch 30 loss: 0.18432465195655823\n",
      "17\n",
      "epoch 1 loss: 0.8222165107727051\n",
      "epoch 2 loss: 0.7096566557884216\n",
      "epoch 3 loss: 0.380013644695282\n",
      "epoch 4 loss: 0.20725926756858826\n",
      "epoch 5 loss: 0.15068954229354858\n",
      "epoch 6 loss: 0.1483997404575348\n",
      "epoch 7 loss: 0.16944004595279694\n",
      "epoch 8 loss: 0.15994614362716675\n",
      "epoch 9 loss: 0.1668717861175537\n",
      "epoch 10 loss: 0.1473883092403412\n",
      "epoch 11 loss: 0.16682492196559906\n",
      "epoch 12 loss: 0.17378893494606018\n",
      "epoch 13 loss: 0.1779855191707611\n",
      "epoch 14 loss: 0.20257893204689026\n",
      "epoch 15 loss: 0.1480550467967987\n",
      "epoch 16 loss: 0.1587250530719757\n",
      "epoch 17 loss: 0.14888770878314972\n",
      "epoch 18 loss: 0.15775565803050995\n",
      "epoch 19 loss: 0.16208265721797943\n",
      "epoch 20 loss: 0.15252439677715302\n",
      "epoch 21 loss: 0.10485928505659103\n",
      "epoch 22 loss: 0.14518620073795319\n",
      "epoch 23 loss: 0.11707808077335358\n",
      "epoch 24 loss: 0.1049928143620491\n",
      "epoch 25 loss: 0.08179064840078354\n",
      "epoch 26 loss: 0.14490734040737152\n",
      "epoch 27 loss: 0.11430758237838745\n",
      "epoch 28 loss: 0.107143834233284\n",
      "epoch 29 loss: 0.11487127095460892\n",
      "epoch 30 loss: 0.09856075048446655\n",
      "18\n",
      "epoch 1 loss: 0.8384494185447693\n",
      "epoch 2 loss: 0.5120307207107544\n",
      "epoch 3 loss: 0.7704430818557739\n",
      "epoch 4 loss: 0.4482850730419159\n",
      "epoch 5 loss: 0.3348054587841034\n",
      "epoch 6 loss: 0.1790952980518341\n",
      "epoch 7 loss: 0.16500207781791687\n",
      "epoch 8 loss: 0.1698421686887741\n",
      "epoch 9 loss: 0.18146714568138123\n",
      "epoch 10 loss: 0.16914422810077667\n",
      "epoch 11 loss: 0.17578193545341492\n",
      "epoch 12 loss: 0.17966720461845398\n",
      "epoch 13 loss: 0.17050445079803467\n",
      "epoch 14 loss: 0.15239158272743225\n",
      "epoch 15 loss: 0.13135075569152832\n",
      "epoch 16 loss: 0.12462716549634933\n",
      "epoch 17 loss: 0.1261168271303177\n",
      "epoch 18 loss: 0.14979992806911469\n",
      "epoch 19 loss: 0.11535532772541046\n",
      "epoch 20 loss: 0.1397756189107895\n",
      "epoch 21 loss: 0.14100797474384308\n",
      "epoch 22 loss: 0.10708581656217575\n",
      "epoch 23 loss: 0.1563955396413803\n",
      "epoch 24 loss: 0.12655439972877502\n",
      "epoch 25 loss: 0.12921512126922607\n",
      "epoch 26 loss: 0.16132000088691711\n",
      "epoch 27 loss: 0.12509125471115112\n",
      "epoch 28 loss: 0.10913711041212082\n",
      "epoch 29 loss: 0.08931205421686172\n",
      "epoch 30 loss: 0.11353764683008194\n",
      "19\n",
      "epoch 1 loss: 0.6782172322273254\n",
      "epoch 2 loss: 0.7710530161857605\n",
      "epoch 3 loss: 0.4771405756473541\n",
      "epoch 4 loss: 0.17440281808376312\n",
      "epoch 5 loss: 0.18789108097553253\n",
      "epoch 6 loss: 0.18056228756904602\n",
      "epoch 7 loss: 0.14993396401405334\n",
      "epoch 8 loss: 0.16561256349086761\n",
      "epoch 9 loss: 0.18168257176876068\n",
      "epoch 10 loss: 0.17218142747879028\n",
      "epoch 11 loss: 0.17614686489105225\n",
      "epoch 12 loss: 0.17950975894927979\n",
      "epoch 13 loss: 0.17724628746509552\n",
      "epoch 14 loss: 0.14907169342041016\n",
      "epoch 15 loss: 0.18189199268817902\n",
      "epoch 16 loss: 0.1574711948633194\n",
      "epoch 17 loss: 0.1317290961742401\n",
      "epoch 18 loss: 0.15280909836292267\n",
      "epoch 19 loss: 0.19754818081855774\n",
      "epoch 20 loss: 0.12105170637369156\n",
      "epoch 21 loss: 0.11228539049625397\n",
      "epoch 22 loss: 0.11927710473537445\n",
      "epoch 23 loss: 0.10884696245193481\n",
      "epoch 24 loss: 0.13859613239765167\n",
      "epoch 25 loss: 0.12353254109621048\n",
      "epoch 26 loss: 0.12296188622713089\n",
      "epoch 27 loss: 0.11701897531747818\n",
      "epoch 28 loss: 0.09295809268951416\n",
      "epoch 29 loss: 0.09808571636676788\n",
      "epoch 30 loss: 0.11784981191158295\n",
      "20\n",
      "epoch 1 loss: 0.9048236608505249\n",
      "epoch 2 loss: 0.6136882305145264\n",
      "epoch 3 loss: 0.2859179377555847\n",
      "epoch 4 loss: 0.18911974132061005\n",
      "epoch 5 loss: 0.18688160181045532\n",
      "epoch 6 loss: 0.18266327679157257\n",
      "epoch 7 loss: 0.17183850705623627\n",
      "epoch 8 loss: 0.1484818309545517\n",
      "epoch 9 loss: 0.19479873776435852\n",
      "epoch 10 loss: 0.19043445587158203\n",
      "epoch 11 loss: 0.1454370617866516\n",
      "epoch 12 loss: 0.1707601547241211\n",
      "epoch 13 loss: 0.1566036343574524\n",
      "epoch 14 loss: 0.17332497239112854\n",
      "epoch 15 loss: 0.17163319885730743\n",
      "epoch 16 loss: 0.18541860580444336\n",
      "epoch 17 loss: 0.14312933385372162\n",
      "epoch 18 loss: 0.16042718291282654\n",
      "epoch 19 loss: 0.15840837359428406\n",
      "epoch 20 loss: 0.1936625987291336\n",
      "epoch 21 loss: 0.16601069271564484\n",
      "epoch 22 loss: 0.13418424129486084\n",
      "epoch 23 loss: 0.1409730315208435\n",
      "epoch 24 loss: 0.16126593947410583\n",
      "epoch 25 loss: 0.16621287167072296\n",
      "epoch 26 loss: 0.18507760763168335\n",
      "epoch 27 loss: 0.15162333846092224\n",
      "epoch 28 loss: 0.11535344272851944\n",
      "epoch 29 loss: 0.13815435767173767\n",
      "epoch 30 loss: 0.1404169499874115\n",
      "21\n",
      "epoch 1 loss: 0.8666452765464783\n",
      "epoch 2 loss: 0.6694235801696777\n",
      "epoch 3 loss: 0.6635546088218689\n",
      "epoch 4 loss: 0.48797544836997986\n",
      "epoch 5 loss: 0.23063021898269653\n",
      "epoch 6 loss: 0.17696784436702728\n",
      "epoch 7 loss: 0.19514672458171844\n",
      "epoch 8 loss: 0.1715105175971985\n",
      "epoch 9 loss: 0.17099589109420776\n",
      "epoch 10 loss: 0.18271172046661377\n",
      "epoch 11 loss: 0.18228045105934143\n",
      "epoch 12 loss: 0.17243421077728271\n",
      "epoch 13 loss: 0.17243526875972748\n",
      "epoch 14 loss: 0.15674425661563873\n",
      "epoch 15 loss: 0.14342288672924042\n",
      "epoch 16 loss: 0.14917728304862976\n",
      "epoch 17 loss: 0.15952655673027039\n",
      "epoch 18 loss: 0.15314672887325287\n",
      "epoch 19 loss: 0.12588031589984894\n",
      "epoch 20 loss: 0.14274263381958008\n",
      "epoch 21 loss: 0.14711175858974457\n",
      "epoch 22 loss: 0.14859120547771454\n",
      "epoch 23 loss: 0.18095919489860535\n",
      "epoch 24 loss: 0.1378304362297058\n",
      "epoch 25 loss: 0.21364682912826538\n",
      "epoch 26 loss: 0.13681672513484955\n",
      "epoch 27 loss: 0.1452033668756485\n",
      "epoch 28 loss: 0.10371717810630798\n",
      "epoch 29 loss: 0.12917521595954895\n",
      "epoch 30 loss: 0.11174977570772171\n",
      "22\n",
      "epoch 1 loss: 0.8036849498748779\n",
      "epoch 2 loss: 0.6743524074554443\n",
      "epoch 3 loss: 0.4438163936138153\n",
      "epoch 4 loss: 0.18216857314109802\n",
      "epoch 5 loss: 0.1746702343225479\n",
      "epoch 6 loss: 0.1848139762878418\n",
      "epoch 7 loss: 0.1825980544090271\n",
      "epoch 8 loss: 0.1717737466096878\n",
      "epoch 9 loss: 0.17202499508857727\n",
      "epoch 10 loss: 0.1637444794178009\n",
      "epoch 11 loss: 0.15853358805179596\n",
      "epoch 12 loss: 0.14901985228061676\n",
      "epoch 13 loss: 0.15472449362277985\n",
      "epoch 14 loss: 0.17164400219917297\n",
      "epoch 15 loss: 0.1778053492307663\n",
      "epoch 16 loss: 0.18016497790813446\n",
      "epoch 17 loss: 0.16988037526607513\n",
      "epoch 18 loss: 0.1958690881729126\n",
      "epoch 19 loss: 0.14829684793949127\n",
      "epoch 20 loss: 0.1685677319765091\n",
      "epoch 21 loss: 0.15490122139453888\n",
      "epoch 22 loss: 0.12723611295223236\n",
      "epoch 23 loss: 0.1639997512102127\n",
      "epoch 24 loss: 0.1800403892993927\n",
      "epoch 25 loss: 0.1518407016992569\n",
      "epoch 26 loss: 0.12726455926895142\n",
      "epoch 27 loss: 0.15008077025413513\n",
      "epoch 28 loss: 0.14249663054943085\n",
      "epoch 29 loss: 0.11729182302951813\n",
      "epoch 30 loss: 0.09019657224416733\n",
      "23\n",
      "epoch 1 loss: 0.9849020838737488\n",
      "epoch 2 loss: 0.3447604179382324\n",
      "epoch 3 loss: 0.17146115005016327\n",
      "epoch 4 loss: 0.16101253032684326\n",
      "epoch 5 loss: 0.1793036162853241\n",
      "epoch 6 loss: 0.17840896546840668\n",
      "epoch 7 loss: 0.20528580248355865\n",
      "epoch 8 loss: 0.18207266926765442\n",
      "epoch 9 loss: 0.1641848385334015\n",
      "epoch 10 loss: 0.19815365970134735\n",
      "epoch 11 loss: 0.1799158751964569\n",
      "epoch 12 loss: 0.1727563887834549\n",
      "epoch 13 loss: 0.14992451667785645\n",
      "epoch 14 loss: 0.1572042852640152\n",
      "epoch 15 loss: 0.16768653690814972\n",
      "epoch 16 loss: 0.1554560363292694\n",
      "epoch 17 loss: 0.18010488152503967\n",
      "epoch 18 loss: 0.16185033321380615\n",
      "epoch 19 loss: 0.1606740802526474\n",
      "epoch 20 loss: 0.1647774875164032\n",
      "epoch 21 loss: 0.1613115519285202\n",
      "epoch 22 loss: 0.20435570180416107\n",
      "epoch 23 loss: 0.17167019844055176\n",
      "epoch 24 loss: 0.14891718327999115\n",
      "epoch 25 loss: 0.17262783646583557\n",
      "epoch 26 loss: 0.16418233513832092\n",
      "epoch 27 loss: 0.16538918018341064\n",
      "epoch 28 loss: 0.12218789756298065\n",
      "epoch 29 loss: 0.16573700308799744\n",
      "epoch 30 loss: 0.1302831470966339\n",
      "24\n",
      "epoch 1 loss: 0.7985819578170776\n",
      "epoch 2 loss: 0.7282931804656982\n",
      "epoch 3 loss: 0.7173274755477905\n",
      "epoch 4 loss: 0.4264131784439087\n",
      "epoch 5 loss: 0.1877232789993286\n",
      "epoch 6 loss: 0.18700407445430756\n",
      "epoch 7 loss: 0.16378091275691986\n",
      "epoch 8 loss: 0.1410806030035019\n",
      "epoch 9 loss: 0.1743064671754837\n",
      "epoch 10 loss: 0.12849049270153046\n",
      "epoch 11 loss: 0.19981501996517181\n",
      "epoch 12 loss: 0.14428205788135529\n",
      "epoch 13 loss: 0.19269390404224396\n",
      "epoch 14 loss: 0.12904243171215057\n",
      "epoch 15 loss: 0.15042129158973694\n",
      "epoch 16 loss: 0.1748388409614563\n",
      "epoch 17 loss: 0.17486821115016937\n",
      "epoch 18 loss: 0.14938345551490784\n",
      "epoch 19 loss: 0.15957356989383698\n",
      "epoch 20 loss: 0.17052344977855682\n",
      "epoch 21 loss: 0.1671488881111145\n",
      "epoch 22 loss: 0.17843544483184814\n",
      "epoch 23 loss: 0.16342346370220184\n",
      "epoch 24 loss: 0.161600261926651\n",
      "epoch 25 loss: 0.11781446635723114\n",
      "epoch 26 loss: 0.2056834101676941\n",
      "epoch 27 loss: 0.13380341231822968\n",
      "epoch 28 loss: 0.13338470458984375\n",
      "epoch 29 loss: 0.15166470408439636\n",
      "epoch 30 loss: 0.14403162896633148\n",
      "25\n",
      "epoch 1 loss: 0.7746712565422058\n",
      "epoch 2 loss: 0.5997697710990906\n",
      "epoch 3 loss: 0.33781933784484863\n",
      "epoch 4 loss: 0.2550922632217407\n",
      "epoch 5 loss: 0.1754755675792694\n",
      "epoch 6 loss: 0.1974681168794632\n",
      "epoch 7 loss: 0.2024623602628708\n",
      "epoch 8 loss: 0.18607135117053986\n",
      "epoch 9 loss: 0.16531260311603546\n",
      "epoch 10 loss: 0.1577174961566925\n",
      "epoch 11 loss: 0.16419874131679535\n",
      "epoch 12 loss: 0.19971135258674622\n",
      "epoch 13 loss: 0.14088517427444458\n",
      "epoch 14 loss: 0.1655615270137787\n",
      "epoch 15 loss: 0.18355387449264526\n",
      "epoch 16 loss: 0.1880323737859726\n",
      "epoch 17 loss: 0.17953981459140778\n",
      "epoch 18 loss: 0.18672725558280945\n",
      "epoch 19 loss: 0.16363407671451569\n",
      "epoch 20 loss: 0.15373766422271729\n",
      "epoch 21 loss: 0.15260887145996094\n",
      "epoch 22 loss: 0.15189971029758453\n",
      "epoch 23 loss: 0.1588468849658966\n",
      "epoch 24 loss: 0.16406936943531036\n",
      "epoch 25 loss: 0.15817436575889587\n",
      "epoch 26 loss: 0.1664913445711136\n",
      "epoch 27 loss: 0.14568527042865753\n",
      "epoch 28 loss: 0.11966691166162491\n",
      "epoch 29 loss: 0.12984289228916168\n",
      "epoch 30 loss: 0.1470099240541458\n",
      "26\n",
      "epoch 1 loss: 0.8020297288894653\n",
      "epoch 2 loss: 0.6423853039741516\n",
      "epoch 3 loss: 0.7139730453491211\n",
      "epoch 4 loss: 0.3295871615409851\n",
      "epoch 5 loss: 0.23282918334007263\n",
      "epoch 6 loss: 0.17359738051891327\n",
      "epoch 7 loss: 0.16529786586761475\n",
      "epoch 8 loss: 0.1722099483013153\n",
      "epoch 9 loss: 0.15984897315502167\n",
      "epoch 10 loss: 0.171433225274086\n",
      "epoch 11 loss: 0.18416336178779602\n",
      "epoch 12 loss: 0.17482542991638184\n",
      "epoch 13 loss: 0.18728677928447723\n",
      "epoch 14 loss: 0.188343346118927\n",
      "epoch 15 loss: 0.17676310241222382\n",
      "epoch 16 loss: 0.19643978774547577\n",
      "epoch 17 loss: 0.1501159816980362\n",
      "epoch 18 loss: 0.1411779224872589\n",
      "epoch 19 loss: 0.192233145236969\n",
      "epoch 20 loss: 0.15613284707069397\n",
      "epoch 21 loss: 0.12052673101425171\n",
      "epoch 22 loss: 0.1501534879207611\n",
      "epoch 23 loss: 0.09467080980539322\n",
      "epoch 24 loss: 0.11696694791316986\n",
      "epoch 25 loss: 0.16621246933937073\n",
      "epoch 26 loss: 0.12645435333251953\n",
      "epoch 27 loss: 0.07691984623670578\n",
      "epoch 28 loss: 0.10020192712545395\n",
      "epoch 29 loss: 0.10913915187120438\n",
      "epoch 30 loss: 0.08522885292768478\n",
      "27\n",
      "epoch 1 loss: 0.8147985339164734\n",
      "epoch 2 loss: 0.6320968270301819\n",
      "epoch 3 loss: 0.2781382203102112\n",
      "epoch 4 loss: 0.2077258974313736\n",
      "epoch 5 loss: 0.19755573570728302\n",
      "epoch 6 loss: 0.17679086327552795\n",
      "epoch 7 loss: 0.1724744290113449\n",
      "epoch 8 loss: 0.18062952160835266\n",
      "epoch 9 loss: 0.14994874596595764\n",
      "epoch 10 loss: 0.15064235031604767\n",
      "epoch 11 loss: 0.17423389852046967\n",
      "epoch 12 loss: 0.13317550718784332\n",
      "epoch 13 loss: 0.16343501210212708\n",
      "epoch 14 loss: 0.17686371505260468\n",
      "epoch 15 loss: 0.1597047597169876\n",
      "epoch 16 loss: 0.17474226653575897\n",
      "epoch 17 loss: 0.1613253355026245\n",
      "epoch 18 loss: 0.14012371003627777\n",
      "epoch 19 loss: 0.1709945648908615\n",
      "epoch 20 loss: 0.15806180238723755\n",
      "epoch 21 loss: 0.15827859938144684\n",
      "epoch 22 loss: 0.1723795384168625\n",
      "epoch 23 loss: 0.16379569470882416\n",
      "epoch 24 loss: 0.14754275977611542\n",
      "epoch 25 loss: 0.12126149982213974\n",
      "epoch 26 loss: 0.10851968079805374\n",
      "epoch 27 loss: 0.10734748095273972\n",
      "epoch 28 loss: 0.13620439171791077\n",
      "epoch 29 loss: 0.09062791615724564\n",
      "epoch 30 loss: 0.10888727009296417\n",
      "28\n",
      "epoch 1 loss: 0.8140518665313721\n",
      "epoch 2 loss: 0.7248266935348511\n",
      "epoch 3 loss: 0.6669425964355469\n",
      "epoch 4 loss: 0.28090953826904297\n",
      "epoch 5 loss: 0.21538691222667694\n",
      "epoch 6 loss: 0.22811561822891235\n",
      "epoch 7 loss: 0.16063649952411652\n",
      "epoch 8 loss: 0.19456598162651062\n",
      "epoch 9 loss: 0.1512199342250824\n",
      "epoch 10 loss: 0.1494142860174179\n",
      "epoch 11 loss: 0.18212179839611053\n",
      "epoch 12 loss: 0.1911877691745758\n",
      "epoch 13 loss: 0.15258833765983582\n",
      "epoch 14 loss: 0.136230930685997\n",
      "epoch 15 loss: 0.16751374304294586\n",
      "epoch 16 loss: 0.14073003828525543\n",
      "epoch 17 loss: 0.175535649061203\n",
      "epoch 18 loss: 0.15299363434314728\n",
      "epoch 19 loss: 0.16146154701709747\n",
      "epoch 20 loss: 0.12174294888973236\n",
      "epoch 21 loss: 0.14170292019844055\n",
      "epoch 22 loss: 0.15990616381168365\n",
      "epoch 23 loss: 0.14698323607444763\n",
      "epoch 24 loss: 0.1313110589981079\n",
      "epoch 25 loss: 0.13963519036769867\n",
      "epoch 26 loss: 0.1306394636631012\n",
      "epoch 27 loss: 0.09542489796876907\n",
      "epoch 28 loss: 0.10291615128517151\n",
      "epoch 29 loss: 0.1023833379149437\n",
      "epoch 30 loss: 0.13865984976291656\n",
      "29\n",
      "epoch 1 loss: 0.7508904337882996\n",
      "epoch 2 loss: 0.8847267627716064\n",
      "epoch 3 loss: 0.8880404233932495\n",
      "epoch 4 loss: 0.47592052817344666\n",
      "epoch 5 loss: 0.2827073037624359\n",
      "epoch 6 loss: 0.22246284782886505\n",
      "epoch 7 loss: 0.20015178620815277\n",
      "epoch 8 loss: 0.16606251895427704\n",
      "epoch 9 loss: 0.1410684585571289\n",
      "epoch 10 loss: 0.19088837504386902\n",
      "epoch 11 loss: 0.19360557198524475\n",
      "epoch 12 loss: 0.136418879032135\n",
      "epoch 13 loss: 0.15602660179138184\n",
      "epoch 14 loss: 0.20190362632274628\n",
      "epoch 15 loss: 0.17061534523963928\n",
      "epoch 16 loss: 0.1340664029121399\n",
      "epoch 17 loss: 0.22007083892822266\n",
      "epoch 18 loss: 0.15566572546958923\n",
      "epoch 19 loss: 0.14255718886852264\n",
      "epoch 20 loss: 0.1697266548871994\n",
      "epoch 21 loss: 0.14832079410552979\n",
      "epoch 22 loss: 0.16534413397312164\n",
      "epoch 23 loss: 0.13960036635398865\n",
      "epoch 24 loss: 0.1711866408586502\n",
      "epoch 25 loss: 0.14990299940109253\n",
      "epoch 26 loss: 0.12513361871242523\n",
      "epoch 27 loss: 0.14901427924633026\n",
      "epoch 28 loss: 0.14485254883766174\n",
      "epoch 29 loss: 0.12341684848070145\n",
      "epoch 30 loss: 0.1544807106256485\n",
      "30\n",
      "epoch 1 loss: 0.7173986434936523\n",
      "epoch 2 loss: 0.6476197242736816\n",
      "epoch 3 loss: 0.43996572494506836\n",
      "epoch 4 loss: 0.23774917423725128\n",
      "epoch 5 loss: 0.19155141711235046\n",
      "epoch 6 loss: 0.16535000503063202\n",
      "epoch 7 loss: 0.13872000575065613\n",
      "epoch 8 loss: 0.20431426167488098\n",
      "epoch 9 loss: 0.1951611340045929\n",
      "epoch 10 loss: 0.1556178480386734\n",
      "epoch 11 loss: 0.20270489156246185\n",
      "epoch 12 loss: 0.18310758471488953\n",
      "epoch 13 loss: 0.144579216837883\n",
      "epoch 14 loss: 0.16685456037521362\n",
      "epoch 15 loss: 0.15027335286140442\n",
      "epoch 16 loss: 0.16677072644233704\n",
      "epoch 17 loss: 0.1652647852897644\n",
      "epoch 18 loss: 0.1565532237291336\n",
      "epoch 19 loss: 0.16056646406650543\n",
      "epoch 20 loss: 0.1623714119195938\n",
      "epoch 21 loss: 0.11820495128631592\n",
      "epoch 22 loss: 0.1354960948228836\n",
      "epoch 23 loss: 0.1272255927324295\n",
      "epoch 24 loss: 0.15988503396511078\n",
      "epoch 25 loss: 0.16170431673526764\n",
      "epoch 26 loss: 0.13688667118549347\n",
      "epoch 27 loss: 0.15287275612354279\n",
      "epoch 28 loss: 0.15144772827625275\n",
      "epoch 29 loss: 0.11366491764783859\n",
      "epoch 30 loss: 0.10573449730873108\n",
      "31\n",
      "epoch 1 loss: 0.9219810366630554\n",
      "epoch 2 loss: 0.7801429033279419\n",
      "epoch 3 loss: 0.33072543144226074\n",
      "epoch 4 loss: 0.2310681790113449\n",
      "epoch 5 loss: 0.1335747241973877\n",
      "epoch 6 loss: 0.23133185505867004\n",
      "epoch 7 loss: 0.2097664624452591\n",
      "epoch 8 loss: 0.1474931538105011\n",
      "epoch 9 loss: 0.1907145380973816\n",
      "epoch 10 loss: 0.15926223993301392\n",
      "epoch 11 loss: 0.12912043929100037\n",
      "epoch 12 loss: 0.16991032660007477\n",
      "epoch 13 loss: 0.1427282989025116\n",
      "epoch 14 loss: 0.1564028114080429\n",
      "epoch 15 loss: 0.14365363121032715\n",
      "epoch 16 loss: 0.17097729444503784\n",
      "epoch 17 loss: 0.16581474244594574\n",
      "epoch 18 loss: 0.19000376760959625\n",
      "epoch 19 loss: 0.1326615959405899\n",
      "epoch 20 loss: 0.16311435401439667\n",
      "epoch 21 loss: 0.1214958131313324\n",
      "epoch 22 loss: 0.18047161400318146\n",
      "epoch 23 loss: 0.1032484844326973\n",
      "epoch 24 loss: 0.14979925751686096\n",
      "epoch 25 loss: 0.12479354441165924\n",
      "epoch 26 loss: 0.14652477204799652\n",
      "epoch 27 loss: 0.15851421654224396\n",
      "epoch 28 loss: 0.12881216406822205\n",
      "epoch 29 loss: 0.09621158987283707\n",
      "epoch 30 loss: 0.12086348235607147\n",
      "32\n",
      "epoch 1 loss: 0.8607719540596008\n",
      "epoch 2 loss: 0.8244777321815491\n",
      "epoch 3 loss: 0.2767375707626343\n",
      "epoch 4 loss: 0.23597662150859833\n",
      "epoch 5 loss: 0.2201947122812271\n",
      "epoch 6 loss: 0.22069412469863892\n",
      "epoch 7 loss: 0.19920937716960907\n",
      "epoch 8 loss: 0.20275235176086426\n",
      "epoch 9 loss: 0.16927392780780792\n",
      "epoch 10 loss: 0.1838245838880539\n",
      "epoch 11 loss: 0.16910050809383392\n",
      "epoch 12 loss: 0.1522412747144699\n",
      "epoch 13 loss: 0.1271558403968811\n",
      "epoch 14 loss: 0.14409004151821136\n",
      "epoch 15 loss: 0.19654828310012817\n",
      "epoch 16 loss: 0.17820462584495544\n",
      "epoch 17 loss: 0.15164582431316376\n",
      "epoch 18 loss: 0.22252146899700165\n",
      "epoch 19 loss: 0.1140647754073143\n",
      "epoch 20 loss: 0.15385568141937256\n",
      "epoch 21 loss: 0.17397858202457428\n",
      "epoch 22 loss: 0.13074785470962524\n",
      "epoch 23 loss: 0.12810011208057404\n",
      "epoch 24 loss: 0.18463587760925293\n",
      "epoch 25 loss: 0.16421692073345184\n",
      "epoch 26 loss: 0.13631509244441986\n",
      "epoch 27 loss: 0.16565284132957458\n",
      "epoch 28 loss: 0.16932938992977142\n",
      "epoch 29 loss: 0.12222805619239807\n",
      "epoch 30 loss: 0.17340733110904694\n",
      "33\n",
      "epoch 1 loss: 0.8966304659843445\n",
      "epoch 2 loss: 0.6966692209243774\n",
      "epoch 3 loss: 0.4987601339817047\n",
      "epoch 4 loss: 0.2730386555194855\n",
      "epoch 5 loss: 0.22272692620754242\n",
      "epoch 6 loss: 0.1505650132894516\n",
      "epoch 7 loss: 0.15258489549160004\n",
      "epoch 8 loss: 0.17551913857460022\n",
      "epoch 9 loss: 0.1668880730867386\n",
      "epoch 10 loss: 0.14427854120731354\n",
      "epoch 11 loss: 0.15222841501235962\n",
      "epoch 12 loss: 0.1677006036043167\n",
      "epoch 13 loss: 0.15271754562854767\n",
      "epoch 14 loss: 0.16426678001880646\n",
      "epoch 15 loss: 0.1659797579050064\n",
      "epoch 16 loss: 0.1403632014989853\n",
      "epoch 17 loss: 0.1624506264925003\n",
      "epoch 18 loss: 0.16661478579044342\n",
      "epoch 19 loss: 0.14651285111904144\n",
      "epoch 20 loss: 0.13921041786670685\n",
      "epoch 21 loss: 0.12124244123697281\n",
      "epoch 22 loss: 0.13192297518253326\n",
      "epoch 23 loss: 0.1272008717060089\n",
      "epoch 24 loss: 0.1423109769821167\n",
      "epoch 25 loss: 0.1696987897157669\n",
      "epoch 26 loss: 0.14703702926635742\n",
      "epoch 27 loss: 0.17398102581501007\n",
      "epoch 28 loss: 0.11594926565885544\n",
      "epoch 29 loss: 0.10981990396976471\n",
      "epoch 30 loss: 0.10222049802541733\n",
      "34\n",
      "epoch 1 loss: 0.73848557472229\n",
      "epoch 2 loss: 0.5252305865287781\n",
      "epoch 3 loss: 0.3183607757091522\n",
      "epoch 4 loss: 0.1976465880870819\n",
      "epoch 5 loss: 0.1686866581439972\n",
      "epoch 6 loss: 0.16172721982002258\n",
      "epoch 7 loss: 0.12648192048072815\n",
      "epoch 8 loss: 0.16326169669628143\n",
      "epoch 9 loss: 0.18358339369297028\n",
      "epoch 10 loss: 0.1393585354089737\n",
      "epoch 11 loss: 0.1668890416622162\n",
      "epoch 12 loss: 0.1586221605539322\n",
      "epoch 13 loss: 0.17896999418735504\n",
      "epoch 14 loss: 0.164883553981781\n",
      "epoch 15 loss: 0.15349653363227844\n",
      "epoch 16 loss: 0.1504250019788742\n",
      "epoch 17 loss: 0.18389803171157837\n",
      "epoch 18 loss: 0.17832639813423157\n",
      "epoch 19 loss: 0.15125945210456848\n",
      "epoch 20 loss: 0.17338167130947113\n",
      "epoch 21 loss: 0.13719214498996735\n",
      "epoch 22 loss: 0.19225101172924042\n",
      "epoch 23 loss: 0.18663954734802246\n",
      "epoch 24 loss: 0.14650484919548035\n",
      "epoch 25 loss: 0.1454675793647766\n",
      "epoch 26 loss: 0.1380881667137146\n",
      "epoch 27 loss: 0.1310533881187439\n",
      "epoch 28 loss: 0.18650755286216736\n",
      "epoch 29 loss: 0.1082938089966774\n",
      "epoch 30 loss: 0.12979921698570251\n",
      "35\n",
      "epoch 1 loss: 0.8567633628845215\n",
      "epoch 2 loss: 0.8239174485206604\n",
      "epoch 3 loss: 0.38949254155158997\n",
      "epoch 4 loss: 0.23291142284870148\n",
      "epoch 5 loss: 0.20621700584888458\n",
      "epoch 6 loss: 0.1664033681154251\n",
      "epoch 7 loss: 0.16065379977226257\n",
      "epoch 8 loss: 0.1851857304573059\n",
      "epoch 9 loss: 0.1988806128501892\n",
      "epoch 10 loss: 0.13901355862617493\n",
      "epoch 11 loss: 0.14939115941524506\n",
      "epoch 12 loss: 0.09908021986484528\n",
      "epoch 13 loss: 0.12610864639282227\n",
      "epoch 14 loss: 0.1788541078567505\n",
      "epoch 15 loss: 0.14823566377162933\n",
      "epoch 16 loss: 0.19602549076080322\n",
      "epoch 17 loss: 0.10735700279474258\n",
      "epoch 18 loss: 0.1634032279253006\n",
      "epoch 19 loss: 0.16805800795555115\n",
      "epoch 20 loss: 0.10658036917448044\n",
      "epoch 21 loss: 0.11419552564620972\n",
      "epoch 22 loss: 0.1581776887178421\n",
      "epoch 23 loss: 0.12857721745967865\n",
      "epoch 24 loss: 0.1296258270740509\n",
      "epoch 25 loss: 0.13243643939495087\n",
      "epoch 26 loss: 0.12709112465381622\n",
      "epoch 27 loss: 0.1162148267030716\n",
      "epoch 28 loss: 0.13812918961048126\n",
      "epoch 29 loss: 0.11123021692037582\n",
      "epoch 30 loss: 0.11847588419914246\n",
      "36\n",
      "epoch 1 loss: 0.8324987292289734\n",
      "epoch 2 loss: 0.43473920226097107\n",
      "epoch 3 loss: 0.2573220133781433\n",
      "epoch 4 loss: 0.18000170588493347\n",
      "epoch 5 loss: 0.13121724128723145\n",
      "epoch 6 loss: 0.17648661136627197\n",
      "epoch 7 loss: 0.13242146372795105\n",
      "epoch 8 loss: 0.16331639885902405\n",
      "epoch 9 loss: 0.19216342270374298\n",
      "epoch 10 loss: 0.1488381028175354\n",
      "epoch 11 loss: 0.11941414326429367\n",
      "epoch 12 loss: 0.13457456231117249\n",
      "epoch 13 loss: 0.15262262523174286\n",
      "epoch 14 loss: 0.15456779301166534\n",
      "epoch 15 loss: 0.20857179164886475\n",
      "epoch 16 loss: 0.16766276955604553\n",
      "epoch 17 loss: 0.15924501419067383\n",
      "epoch 18 loss: 0.19444617629051208\n",
      "epoch 19 loss: 0.12896864116191864\n",
      "epoch 20 loss: 0.16913196444511414\n",
      "epoch 21 loss: 0.14993412792682648\n",
      "epoch 22 loss: 0.14719843864440918\n",
      "epoch 23 loss: 0.13298793137073517\n",
      "epoch 24 loss: 0.12283684313297272\n",
      "epoch 25 loss: 0.09966814517974854\n",
      "epoch 26 loss: 0.1700204312801361\n",
      "epoch 27 loss: 0.14435333013534546\n",
      "epoch 28 loss: 0.14569084346294403\n",
      "epoch 29 loss: 0.12561798095703125\n",
      "epoch 30 loss: 0.10308480262756348\n",
      "37\n",
      "epoch 1 loss: 0.9166095852851868\n",
      "epoch 2 loss: 0.9658768177032471\n",
      "epoch 3 loss: 0.798241138458252\n",
      "epoch 4 loss: 0.41578197479248047\n",
      "epoch 5 loss: 0.2127283364534378\n",
      "epoch 6 loss: 0.1674535870552063\n",
      "epoch 7 loss: 0.17518453299999237\n",
      "epoch 8 loss: 0.17822887003421783\n",
      "epoch 9 loss: 0.15038268268108368\n",
      "epoch 10 loss: 0.15353533625602722\n",
      "epoch 11 loss: 0.1500624716281891\n",
      "epoch 12 loss: 0.16552786529064178\n",
      "epoch 13 loss: 0.13693533837795258\n",
      "epoch 14 loss: 0.17807871103286743\n",
      "epoch 15 loss: 0.14826302230358124\n",
      "epoch 16 loss: 0.16866685450077057\n",
      "epoch 17 loss: 0.15509489178657532\n",
      "epoch 18 loss: 0.16635984182357788\n",
      "epoch 19 loss: 0.1335470974445343\n",
      "epoch 20 loss: 0.16226771473884583\n",
      "epoch 21 loss: 0.16098716855049133\n",
      "epoch 22 loss: 0.16952049732208252\n",
      "epoch 23 loss: 0.15983852744102478\n",
      "epoch 24 loss: 0.1720975637435913\n",
      "epoch 25 loss: 0.12782599031925201\n",
      "epoch 26 loss: 0.18196585774421692\n",
      "epoch 27 loss: 0.13138608634471893\n",
      "epoch 28 loss: 0.13656507432460785\n",
      "epoch 29 loss: 0.13233856856822968\n",
      "epoch 30 loss: 0.11511580646038055\n",
      "38\n",
      "epoch 1 loss: 0.9464468359947205\n",
      "epoch 2 loss: 0.5941346287727356\n",
      "epoch 3 loss: 0.4004741609096527\n",
      "epoch 4 loss: 0.25888800621032715\n",
      "epoch 5 loss: 0.21444693207740784\n",
      "epoch 6 loss: 0.1805649846792221\n",
      "epoch 7 loss: 0.18700964748859406\n",
      "epoch 8 loss: 0.157109335064888\n",
      "epoch 9 loss: 0.18340517580509186\n",
      "epoch 10 loss: 0.14791807532310486\n",
      "epoch 11 loss: 0.15385277569293976\n",
      "epoch 12 loss: 0.18884149193763733\n",
      "epoch 13 loss: 0.15334734320640564\n",
      "epoch 14 loss: 0.14137998223304749\n",
      "epoch 15 loss: 0.14926005899906158\n",
      "epoch 16 loss: 0.13958632946014404\n",
      "epoch 17 loss: 0.1662750393152237\n",
      "epoch 18 loss: 0.15132227540016174\n",
      "epoch 19 loss: 0.13990607857704163\n",
      "epoch 20 loss: 0.15978601574897766\n",
      "epoch 21 loss: 0.11951345950365067\n",
      "epoch 22 loss: 0.14581847190856934\n",
      "epoch 23 loss: 0.15631689131259918\n",
      "epoch 24 loss: 0.1596464067697525\n",
      "epoch 25 loss: 0.14830130338668823\n",
      "epoch 26 loss: 0.1607566475868225\n",
      "epoch 27 loss: 0.1365046203136444\n",
      "epoch 28 loss: 0.10166777670383453\n",
      "epoch 29 loss: 0.1362558901309967\n",
      "epoch 30 loss: 0.13931521773338318\n",
      "39\n",
      "epoch 1 loss: 0.8083112835884094\n",
      "epoch 2 loss: 0.5533363819122314\n",
      "epoch 3 loss: 0.2922338843345642\n",
      "epoch 4 loss: 0.18227159976959229\n",
      "epoch 5 loss: 0.16759252548217773\n",
      "epoch 6 loss: 0.1607162058353424\n",
      "epoch 7 loss: 0.17951758205890656\n",
      "epoch 8 loss: 0.12691454589366913\n",
      "epoch 9 loss: 0.17626602947711945\n",
      "epoch 10 loss: 0.1722254753112793\n",
      "epoch 11 loss: 0.16972137987613678\n",
      "epoch 12 loss: 0.11152663081884384\n",
      "epoch 13 loss: 0.17624084651470184\n",
      "epoch 14 loss: 0.16308799386024475\n",
      "epoch 15 loss: 0.16213849186897278\n",
      "epoch 16 loss: 0.1813688725233078\n",
      "epoch 17 loss: 0.1579493135213852\n",
      "epoch 18 loss: 0.15421812236309052\n",
      "epoch 19 loss: 0.11954592913389206\n",
      "epoch 20 loss: 0.17287184298038483\n",
      "epoch 21 loss: 0.1511857956647873\n",
      "epoch 22 loss: 0.14232636988162994\n",
      "epoch 23 loss: 0.13363687694072723\n",
      "epoch 24 loss: 0.07987994700670242\n",
      "epoch 25 loss: 0.09361055493354797\n",
      "epoch 26 loss: 0.14355267584323883\n",
      "epoch 27 loss: 0.08883430063724518\n",
      "epoch 28 loss: 0.12784910202026367\n",
      "epoch 29 loss: 0.1500861793756485\n",
      "epoch 30 loss: 0.0974850282073021\n",
      "40\n",
      "epoch 1 loss: 0.8059984445571899\n",
      "epoch 2 loss: 0.6903121471405029\n",
      "epoch 3 loss: 0.6568877696990967\n",
      "epoch 4 loss: 0.37080246210098267\n",
      "epoch 5 loss: 0.15454711019992828\n",
      "epoch 6 loss: 0.2229081243276596\n",
      "epoch 7 loss: 0.18568108975887299\n",
      "epoch 8 loss: 0.16935785114765167\n",
      "epoch 9 loss: 0.2064257115125656\n",
      "epoch 10 loss: 0.1734435111284256\n",
      "epoch 11 loss: 0.1530243307352066\n",
      "epoch 12 loss: 0.18185001611709595\n",
      "epoch 13 loss: 0.16374558210372925\n",
      "epoch 14 loss: 0.14898724853992462\n",
      "epoch 15 loss: 0.1611500233411789\n",
      "epoch 16 loss: 0.19519898295402527\n",
      "epoch 17 loss: 0.1834731251001358\n",
      "epoch 18 loss: 0.16268357634544373\n",
      "epoch 19 loss: 0.19572655856609344\n",
      "epoch 20 loss: 0.15751336514949799\n",
      "epoch 21 loss: 0.17715218663215637\n",
      "epoch 22 loss: 0.1485937535762787\n",
      "epoch 23 loss: 0.17212314903736115\n",
      "epoch 24 loss: 0.14742684364318848\n",
      "epoch 25 loss: 0.175802081823349\n",
      "epoch 26 loss: 0.11174854636192322\n",
      "epoch 27 loss: 0.150822252035141\n",
      "epoch 28 loss: 0.18108774721622467\n",
      "epoch 29 loss: 0.19747985899448395\n",
      "epoch 30 loss: 0.12114430218935013\n",
      "41\n",
      "epoch 1 loss: 1.0112979412078857\n",
      "epoch 2 loss: 0.5588756799697876\n",
      "epoch 3 loss: 0.47152379155158997\n",
      "epoch 4 loss: 0.22416190803050995\n",
      "epoch 5 loss: 0.15534108877182007\n",
      "epoch 6 loss: 0.16211192309856415\n",
      "epoch 7 loss: 0.14404676854610443\n",
      "epoch 8 loss: 0.21160823106765747\n",
      "epoch 9 loss: 0.18216225504875183\n",
      "epoch 10 loss: 0.1461048275232315\n",
      "epoch 11 loss: 0.1685696393251419\n",
      "epoch 12 loss: 0.168124258518219\n",
      "epoch 13 loss: 0.1485777199268341\n",
      "epoch 14 loss: 0.16538457572460175\n",
      "epoch 15 loss: 0.16799785196781158\n",
      "epoch 16 loss: 0.18318308889865875\n",
      "epoch 17 loss: 0.22932562232017517\n",
      "epoch 18 loss: 0.16029056906700134\n",
      "epoch 19 loss: 0.13589057326316833\n",
      "epoch 20 loss: 0.13204972445964813\n",
      "epoch 21 loss: 0.18290962278842926\n",
      "epoch 22 loss: 0.10848121345043182\n",
      "epoch 23 loss: 0.14474450051784515\n",
      "epoch 24 loss: 0.1798366755247116\n",
      "epoch 25 loss: 0.1281411051750183\n",
      "epoch 26 loss: 0.10344718396663666\n",
      "epoch 27 loss: 0.1279071420431137\n",
      "epoch 28 loss: 0.105765201151371\n",
      "epoch 29 loss: 0.10383816063404083\n",
      "epoch 30 loss: 0.13587981462478638\n",
      "42\n",
      "epoch 1 loss: 0.7111073732376099\n",
      "epoch 2 loss: 0.7171412706375122\n",
      "epoch 3 loss: 0.3065946400165558\n",
      "epoch 4 loss: 0.23229648172855377\n",
      "epoch 5 loss: 0.17536121606826782\n",
      "epoch 6 loss: 0.198306143283844\n",
      "epoch 7 loss: 0.1639268547296524\n",
      "epoch 8 loss: 0.1688726395368576\n",
      "epoch 9 loss: 0.213758185505867\n",
      "epoch 10 loss: 0.1684170812368393\n",
      "epoch 11 loss: 0.1682451069355011\n",
      "epoch 12 loss: 0.1735837757587433\n",
      "epoch 13 loss: 0.13886098563671112\n",
      "epoch 14 loss: 0.16538521647453308\n",
      "epoch 15 loss: 0.16482724249362946\n",
      "epoch 16 loss: 0.16225938498973846\n",
      "epoch 17 loss: 0.12675103545188904\n",
      "epoch 18 loss: 0.1915835589170456\n",
      "epoch 19 loss: 0.1652122288942337\n",
      "epoch 20 loss: 0.15730468928813934\n",
      "epoch 21 loss: 0.14945170283317566\n",
      "epoch 22 loss: 0.15181690454483032\n",
      "epoch 23 loss: 0.11996689438819885\n",
      "epoch 24 loss: 0.14472311735153198\n",
      "epoch 25 loss: 0.11012538522481918\n",
      "epoch 26 loss: 0.1425178050994873\n",
      "epoch 27 loss: 0.1411547064781189\n",
      "epoch 28 loss: 0.11486918479204178\n",
      "epoch 29 loss: 0.09862612932920456\n",
      "epoch 30 loss: 0.10525571554899216\n",
      "43\n",
      "epoch 1 loss: 0.796028196811676\n",
      "epoch 2 loss: 0.5941596031188965\n",
      "epoch 3 loss: 0.3402694761753082\n",
      "epoch 4 loss: 0.20466233789920807\n",
      "epoch 5 loss: 0.18914923071861267\n",
      "epoch 6 loss: 0.18096813559532166\n",
      "epoch 7 loss: 0.1736437976360321\n",
      "epoch 8 loss: 0.12872812151908875\n",
      "epoch 9 loss: 0.18661101162433624\n",
      "epoch 10 loss: 0.16567155718803406\n",
      "epoch 11 loss: 0.14611943066120148\n",
      "epoch 12 loss: 0.153763085603714\n",
      "epoch 13 loss: 0.19729891419410706\n",
      "epoch 14 loss: 0.17208459973335266\n",
      "epoch 15 loss: 0.1535560041666031\n",
      "epoch 16 loss: 0.1617508977651596\n",
      "epoch 17 loss: 0.15044285356998444\n",
      "epoch 18 loss: 0.1238672211766243\n",
      "epoch 19 loss: 0.1431068629026413\n",
      "epoch 20 loss: 0.15415997803211212\n",
      "epoch 21 loss: 0.1360424906015396\n",
      "epoch 22 loss: 0.15391232073307037\n",
      "epoch 23 loss: 0.1561916470527649\n",
      "epoch 24 loss: 0.15720458328723907\n",
      "epoch 25 loss: 0.10163331776857376\n",
      "epoch 26 loss: 0.13166019320487976\n",
      "epoch 27 loss: 0.10789165645837784\n",
      "epoch 28 loss: 0.13030101358890533\n",
      "epoch 29 loss: 0.14795635640621185\n",
      "epoch 30 loss: 0.11704574525356293\n",
      "44\n",
      "epoch 1 loss: 0.6498115062713623\n",
      "epoch 2 loss: 0.7153095602989197\n",
      "epoch 3 loss: 0.9325834512710571\n",
      "epoch 4 loss: 0.5421473383903503\n",
      "epoch 5 loss: 0.3236365020275116\n",
      "epoch 6 loss: 0.18339227139949799\n",
      "epoch 7 loss: 0.1913103461265564\n",
      "epoch 8 loss: 0.16814865171909332\n",
      "epoch 9 loss: 0.18743498623371124\n",
      "epoch 10 loss: 0.16995275020599365\n",
      "epoch 11 loss: 0.19180800020694733\n",
      "epoch 12 loss: 0.20538882911205292\n",
      "epoch 13 loss: 0.18987032771110535\n",
      "epoch 14 loss: 0.13881507515907288\n",
      "epoch 15 loss: 0.17229868471622467\n",
      "epoch 16 loss: 0.16649404168128967\n",
      "epoch 17 loss: 0.16556912660598755\n",
      "epoch 18 loss: 0.16430437564849854\n",
      "epoch 19 loss: 0.1954694539308548\n",
      "epoch 20 loss: 0.13192866742610931\n",
      "epoch 21 loss: 0.16133509576320648\n",
      "epoch 22 loss: 0.16752031445503235\n",
      "epoch 23 loss: 0.17263294756412506\n",
      "epoch 24 loss: 0.11899054795503616\n",
      "epoch 25 loss: 0.13974687457084656\n",
      "epoch 26 loss: 0.1249125748872757\n",
      "epoch 27 loss: 0.12980102002620697\n",
      "epoch 28 loss: 0.1487949937582016\n",
      "epoch 29 loss: 0.1520996242761612\n",
      "epoch 30 loss: 0.10814297944307327\n",
      "45\n",
      "epoch 1 loss: 1.0321907997131348\n",
      "epoch 2 loss: 0.849037766456604\n",
      "epoch 3 loss: 0.4402845799922943\n",
      "epoch 4 loss: 0.25326189398765564\n",
      "epoch 5 loss: 0.1743163913488388\n",
      "epoch 6 loss: 0.1708112210035324\n",
      "epoch 7 loss: 0.19484823942184448\n",
      "epoch 8 loss: 0.16058368980884552\n",
      "epoch 9 loss: 0.17079925537109375\n",
      "epoch 10 loss: 0.1937175989151001\n",
      "epoch 11 loss: 0.21083205938339233\n",
      "epoch 12 loss: 0.19674420356750488\n",
      "epoch 13 loss: 0.17092037200927734\n",
      "epoch 14 loss: 0.14590145647525787\n",
      "epoch 15 loss: 0.18501606583595276\n",
      "epoch 16 loss: 0.16851526498794556\n",
      "epoch 17 loss: 0.14933136105537415\n",
      "epoch 18 loss: 0.149175226688385\n",
      "epoch 19 loss: 0.12792102992534637\n",
      "epoch 20 loss: 0.15870410203933716\n",
      "epoch 21 loss: 0.1513071358203888\n",
      "epoch 22 loss: 0.14233744144439697\n",
      "epoch 23 loss: 0.14365339279174805\n",
      "epoch 24 loss: 0.1742708534002304\n",
      "epoch 25 loss: 0.17852286994457245\n",
      "epoch 26 loss: 0.13905778527259827\n",
      "epoch 27 loss: 0.15682733058929443\n",
      "epoch 28 loss: 0.08831634372472763\n",
      "epoch 29 loss: 0.15630188584327698\n",
      "epoch 30 loss: 0.11864998936653137\n",
      "46\n",
      "epoch 1 loss: 0.9125304818153381\n",
      "epoch 2 loss: 0.5448297262191772\n",
      "epoch 3 loss: 0.6584616303443909\n",
      "epoch 4 loss: 0.6566238403320312\n",
      "epoch 5 loss: 0.32446277141571045\n",
      "epoch 6 loss: 0.17702682316303253\n",
      "epoch 7 loss: 0.19399738311767578\n",
      "epoch 8 loss: 0.15128836035728455\n",
      "epoch 9 loss: 0.14930976927280426\n",
      "epoch 10 loss: 0.15336818993091583\n",
      "epoch 11 loss: 0.16912025213241577\n",
      "epoch 12 loss: 0.14076218008995056\n",
      "epoch 13 loss: 0.1550176590681076\n",
      "epoch 14 loss: 0.18640707433223724\n",
      "epoch 15 loss: 0.18297536671161652\n",
      "epoch 16 loss: 0.1428729146718979\n",
      "epoch 17 loss: 0.1584041863679886\n",
      "epoch 18 loss: 0.11677789688110352\n",
      "epoch 19 loss: 0.10214173793792725\n",
      "epoch 20 loss: 0.13158850371837616\n",
      "epoch 21 loss: 0.16177810728549957\n",
      "epoch 22 loss: 0.1411965936422348\n",
      "epoch 23 loss: 0.17093512415885925\n",
      "epoch 24 loss: 0.15440082550048828\n",
      "epoch 25 loss: 0.11240065097808838\n",
      "epoch 26 loss: 0.1236191913485527\n",
      "epoch 27 loss: 0.14792582392692566\n",
      "epoch 28 loss: 0.15147675573825836\n",
      "epoch 29 loss: 0.18326260149478912\n",
      "epoch 30 loss: 0.10310051590204239\n",
      "47\n",
      "epoch 1 loss: 0.7372975945472717\n",
      "epoch 2 loss: 0.546754777431488\n",
      "epoch 3 loss: 0.41539567708969116\n",
      "epoch 4 loss: 0.21757681667804718\n",
      "epoch 5 loss: 0.1794377565383911\n",
      "epoch 6 loss: 0.15447665750980377\n",
      "epoch 7 loss: 0.16873319447040558\n",
      "epoch 8 loss: 0.13970763981342316\n",
      "epoch 9 loss: 0.13648420572280884\n",
      "epoch 10 loss: 0.1504584550857544\n",
      "epoch 11 loss: 0.1759786605834961\n",
      "epoch 12 loss: 0.1673761010169983\n",
      "epoch 13 loss: 0.17031744122505188\n",
      "epoch 14 loss: 0.11218232661485672\n",
      "epoch 15 loss: 0.16701911389827728\n",
      "epoch 16 loss: 0.12333627045154572\n",
      "epoch 17 loss: 0.13170313835144043\n",
      "epoch 18 loss: 0.14443127810955048\n",
      "epoch 19 loss: 0.1610913872718811\n",
      "epoch 20 loss: 0.13493499159812927\n",
      "epoch 21 loss: 0.10577232390642166\n",
      "epoch 22 loss: 0.1373256891965866\n",
      "epoch 23 loss: 0.15635062754154205\n",
      "epoch 24 loss: 0.13762588798999786\n",
      "epoch 25 loss: 0.10643372684717178\n",
      "epoch 26 loss: 0.14810621738433838\n",
      "epoch 27 loss: 0.12357902526855469\n",
      "epoch 28 loss: 0.14490635693073273\n",
      "epoch 29 loss: 0.12098139524459839\n",
      "epoch 30 loss: 0.11444615572690964\n",
      "48\n",
      "epoch 1 loss: 0.8793599605560303\n",
      "epoch 2 loss: 0.47038137912750244\n",
      "epoch 3 loss: 0.3279191553592682\n",
      "epoch 4 loss: 0.18509481847286224\n",
      "epoch 5 loss: 0.20467804372310638\n",
      "epoch 6 loss: 0.16807126998901367\n",
      "epoch 7 loss: 0.22999319434165955\n",
      "epoch 8 loss: 0.1880558580160141\n",
      "epoch 9 loss: 0.17371892929077148\n",
      "epoch 10 loss: 0.14916539192199707\n",
      "epoch 11 loss: 0.1769011914730072\n",
      "epoch 12 loss: 0.17819418013095856\n",
      "epoch 13 loss: 0.15229502320289612\n",
      "epoch 14 loss: 0.16635724902153015\n",
      "epoch 15 loss: 0.13307741284370422\n",
      "epoch 16 loss: 0.16777729988098145\n",
      "epoch 17 loss: 0.13720925152301788\n",
      "epoch 18 loss: 0.14439722895622253\n",
      "epoch 19 loss: 0.15812015533447266\n",
      "epoch 20 loss: 0.1864795684814453\n",
      "epoch 21 loss: 0.157815620303154\n",
      "epoch 22 loss: 0.10328135639429092\n",
      "epoch 23 loss: 0.15081076323986053\n",
      "epoch 24 loss: 0.1641445904970169\n",
      "epoch 25 loss: 0.1726081222295761\n",
      "epoch 26 loss: 0.11968984454870224\n",
      "epoch 27 loss: 0.12063755840063095\n",
      "epoch 28 loss: 0.15481413900852203\n",
      "epoch 29 loss: 0.14490777254104614\n",
      "epoch 30 loss: 0.11853134632110596\n",
      "49\n",
      "epoch 1 loss: 0.8545165657997131\n",
      "epoch 2 loss: 0.6474851965904236\n",
      "epoch 3 loss: 0.5332666039466858\n",
      "epoch 4 loss: 0.25361934304237366\n",
      "epoch 5 loss: 0.1751805543899536\n",
      "epoch 6 loss: 0.16648390889167786\n",
      "epoch 7 loss: 0.2095196694135666\n",
      "epoch 8 loss: 0.1497897207736969\n",
      "epoch 9 loss: 0.1618015468120575\n",
      "epoch 10 loss: 0.17465755343437195\n",
      "epoch 11 loss: 0.16663849353790283\n",
      "epoch 12 loss: 0.16303128004074097\n",
      "epoch 13 loss: 0.1614675521850586\n",
      "epoch 14 loss: 0.14641404151916504\n",
      "epoch 15 loss: 0.15191635489463806\n",
      "epoch 16 loss: 0.14446087181568146\n",
      "epoch 17 loss: 0.16833586990833282\n",
      "epoch 18 loss: 0.15952858328819275\n",
      "epoch 19 loss: 0.14790096879005432\n",
      "epoch 20 loss: 0.12962929904460907\n",
      "epoch 21 loss: 0.16615711152553558\n",
      "epoch 22 loss: 0.12347382307052612\n",
      "epoch 23 loss: 0.1253226399421692\n",
      "epoch 24 loss: 0.12485460191965103\n",
      "epoch 25 loss: 0.13502202928066254\n",
      "epoch 26 loss: 0.16851292550563812\n",
      "epoch 27 loss: 0.1595325917005539\n",
      "epoch 28 loss: 0.14288118481636047\n",
      "epoch 29 loss: 0.1233287900686264\n",
      "epoch 30 loss: 0.13569989800453186\n",
      "50\n",
      "epoch 1 loss: 0.7215640544891357\n",
      "epoch 2 loss: 0.579552412033081\n",
      "epoch 3 loss: 0.3555945158004761\n",
      "epoch 4 loss: 0.24276287853717804\n",
      "epoch 5 loss: 0.14312328398227692\n",
      "epoch 6 loss: 0.1532260775566101\n",
      "epoch 7 loss: 0.1737976372241974\n",
      "epoch 8 loss: 0.16010603308677673\n",
      "epoch 9 loss: 0.14109516143798828\n",
      "epoch 10 loss: 0.17571239173412323\n",
      "epoch 11 loss: 0.1714530885219574\n",
      "epoch 12 loss: 0.15431317687034607\n",
      "epoch 13 loss: 0.19887953996658325\n",
      "epoch 14 loss: 0.19040632247924805\n",
      "epoch 15 loss: 0.16571976244449615\n",
      "epoch 16 loss: 0.15877191722393036\n",
      "epoch 17 loss: 0.14223118126392365\n",
      "epoch 18 loss: 0.13650617003440857\n",
      "epoch 19 loss: 0.16980651021003723\n",
      "epoch 20 loss: 0.13731424510478973\n",
      "epoch 21 loss: 0.1765054166316986\n",
      "epoch 22 loss: 0.16096548736095428\n",
      "epoch 23 loss: 0.17112517356872559\n",
      "epoch 24 loss: 0.12993404269218445\n",
      "epoch 25 loss: 0.12410560995340347\n",
      "epoch 26 loss: 0.1643228828907013\n",
      "epoch 27 loss: 0.11136998981237411\n",
      "epoch 28 loss: 0.11807478219270706\n",
      "epoch 29 loss: 0.10375382751226425\n",
      "epoch 30 loss: 0.17330089211463928\n",
      "51\n",
      "epoch 1 loss: 1.140100121498108\n",
      "epoch 2 loss: 0.8835234045982361\n",
      "epoch 3 loss: 0.38108283281326294\n",
      "epoch 4 loss: 0.2202269285917282\n",
      "epoch 5 loss: 0.17245148122310638\n",
      "epoch 6 loss: 0.15678775310516357\n",
      "epoch 7 loss: 0.18396736681461334\n",
      "epoch 8 loss: 0.1526269018650055\n",
      "epoch 9 loss: 0.16933675110340118\n",
      "epoch 10 loss: 0.20427174866199493\n",
      "epoch 11 loss: 0.1704718917608261\n",
      "epoch 12 loss: 0.20180973410606384\n",
      "epoch 13 loss: 0.1658521145582199\n",
      "epoch 14 loss: 0.18537147343158722\n",
      "epoch 15 loss: 0.15101608633995056\n",
      "epoch 16 loss: 0.19655098021030426\n",
      "epoch 17 loss: 0.17190788686275482\n",
      "epoch 18 loss: 0.19264362752437592\n",
      "epoch 19 loss: 0.17262811958789825\n",
      "epoch 20 loss: 0.18322041630744934\n",
      "epoch 21 loss: 0.1561931073665619\n",
      "epoch 22 loss: 0.15687064826488495\n",
      "epoch 23 loss: 0.16185130178928375\n",
      "epoch 24 loss: 0.13943204283714294\n",
      "epoch 25 loss: 0.17015458643436432\n",
      "epoch 26 loss: 0.15432067215442657\n",
      "epoch 27 loss: 0.1308993399143219\n",
      "epoch 28 loss: 0.1373489946126938\n",
      "epoch 29 loss: 0.17526772618293762\n",
      "epoch 30 loss: 0.12874673306941986\n",
      "52\n",
      "epoch 1 loss: 0.9508475065231323\n",
      "epoch 2 loss: 0.7397453784942627\n",
      "epoch 3 loss: 0.3409211337566376\n",
      "epoch 4 loss: 0.17926892638206482\n",
      "epoch 5 loss: 0.24109399318695068\n",
      "epoch 6 loss: 0.20843590795993805\n",
      "epoch 7 loss: 0.1918199360370636\n",
      "epoch 8 loss: 0.18265406787395477\n",
      "epoch 9 loss: 0.16840389370918274\n",
      "epoch 10 loss: 0.17514970898628235\n",
      "epoch 11 loss: 0.16834226250648499\n",
      "epoch 12 loss: 0.15801388025283813\n",
      "epoch 13 loss: 0.17187583446502686\n",
      "epoch 14 loss: 0.17906366288661957\n",
      "epoch 15 loss: 0.1583145707845688\n",
      "epoch 16 loss: 0.20905959606170654\n",
      "epoch 17 loss: 0.17287658154964447\n",
      "epoch 18 loss: 0.17730388045310974\n",
      "epoch 19 loss: 0.1133619099855423\n",
      "epoch 20 loss: 0.11436626315116882\n",
      "epoch 21 loss: 0.1554405391216278\n",
      "epoch 22 loss: 0.14580242335796356\n",
      "epoch 23 loss: 0.18253985047340393\n",
      "epoch 24 loss: 0.125559002161026\n",
      "epoch 25 loss: 0.13889819383621216\n",
      "epoch 26 loss: 0.15059435367584229\n",
      "epoch 27 loss: 0.11476342380046844\n",
      "epoch 28 loss: 0.14014175534248352\n",
      "epoch 29 loss: 0.1382591277360916\n",
      "epoch 30 loss: 0.10866179317235947\n",
      "53\n",
      "epoch 1 loss: 0.7769748568534851\n",
      "epoch 2 loss: 0.8281227946281433\n",
      "epoch 3 loss: 0.48387929797172546\n",
      "epoch 4 loss: 0.21929815411567688\n",
      "epoch 5 loss: 0.17300982773303986\n",
      "epoch 6 loss: 0.16995097696781158\n",
      "epoch 7 loss: 0.18846210837364197\n",
      "epoch 8 loss: 0.1773226112127304\n",
      "epoch 9 loss: 0.1986309140920639\n",
      "epoch 10 loss: 0.18244759738445282\n",
      "epoch 11 loss: 0.1730014532804489\n",
      "epoch 12 loss: 0.13423742353916168\n",
      "epoch 13 loss: 0.16340510547161102\n",
      "epoch 14 loss: 0.12150727957487106\n",
      "epoch 15 loss: 0.12175527215003967\n",
      "epoch 16 loss: 0.16527444124221802\n",
      "epoch 17 loss: 0.16419032216072083\n",
      "epoch 18 loss: 0.14870208501815796\n",
      "epoch 19 loss: 0.1519307792186737\n",
      "epoch 20 loss: 0.1620011031627655\n",
      "epoch 21 loss: 0.12693136930465698\n",
      "epoch 22 loss: 0.12327113002538681\n",
      "epoch 23 loss: 0.15940441191196442\n",
      "epoch 24 loss: 0.1283062994480133\n",
      "epoch 25 loss: 0.1576397567987442\n",
      "epoch 26 loss: 0.12031421810388565\n",
      "epoch 27 loss: 0.1357480138540268\n",
      "epoch 28 loss: 0.10348816215991974\n",
      "epoch 29 loss: 0.135433629155159\n",
      "epoch 30 loss: 0.11230918020009995\n",
      "54\n",
      "epoch 1 loss: 0.9936986565589905\n",
      "epoch 2 loss: 0.9843109250068665\n",
      "epoch 3 loss: 0.7659100890159607\n",
      "epoch 4 loss: 0.5900854468345642\n",
      "epoch 5 loss: 0.35548630356788635\n",
      "epoch 6 loss: 0.1739834100008011\n",
      "epoch 7 loss: 0.15087909996509552\n",
      "epoch 8 loss: 0.18722766637802124\n",
      "epoch 9 loss: 0.18238817155361176\n",
      "epoch 10 loss: 0.14847661554813385\n",
      "epoch 11 loss: 0.21708600223064423\n",
      "epoch 12 loss: 0.17463915050029755\n",
      "epoch 13 loss: 0.16046707332134247\n",
      "epoch 14 loss: 0.15825068950653076\n",
      "epoch 15 loss: 0.17667730152606964\n",
      "epoch 16 loss: 0.14858977496623993\n",
      "epoch 17 loss: 0.15260061621665955\n",
      "epoch 18 loss: 0.1634191870689392\n",
      "epoch 19 loss: 0.15298780798912048\n",
      "epoch 20 loss: 0.09139711409807205\n",
      "epoch 21 loss: 0.14275790750980377\n",
      "epoch 22 loss: 0.17104867100715637\n",
      "epoch 23 loss: 0.15441523492336273\n",
      "epoch 24 loss: 0.17107975482940674\n",
      "epoch 25 loss: 0.174696683883667\n",
      "epoch 26 loss: 0.14440281689167023\n",
      "epoch 27 loss: 0.0979851558804512\n",
      "epoch 28 loss: 0.12505869567394257\n",
      "epoch 29 loss: 0.11910098791122437\n",
      "epoch 30 loss: 0.13112308084964752\n",
      "55\n",
      "epoch 1 loss: 0.8784818649291992\n",
      "epoch 2 loss: 1.0154775381088257\n",
      "epoch 3 loss: 0.9013726115226746\n",
      "epoch 4 loss: 0.41168656945228577\n",
      "epoch 5 loss: 0.21278589963912964\n",
      "epoch 6 loss: 0.15697789192199707\n",
      "epoch 7 loss: 0.16929657757282257\n",
      "epoch 8 loss: 0.15945401787757874\n",
      "epoch 9 loss: 0.23391273617744446\n",
      "epoch 10 loss: 0.15441930294036865\n",
      "epoch 11 loss: 0.15891891717910767\n",
      "epoch 12 loss: 0.1873571276664734\n",
      "epoch 13 loss: 0.17124208807945251\n",
      "epoch 14 loss: 0.16852028667926788\n",
      "epoch 15 loss: 0.14121435582637787\n",
      "epoch 16 loss: 0.14935417473316193\n",
      "epoch 17 loss: 0.1627664864063263\n",
      "epoch 18 loss: 0.1607838124036789\n",
      "epoch 19 loss: 0.1347198784351349\n",
      "epoch 20 loss: 0.14704321324825287\n",
      "epoch 21 loss: 0.15577025711536407\n",
      "epoch 22 loss: 0.16116531193256378\n",
      "epoch 23 loss: 0.14990350604057312\n",
      "epoch 24 loss: 0.13190217316150665\n",
      "epoch 25 loss: 0.11744042485952377\n",
      "epoch 26 loss: 0.14003878831863403\n",
      "epoch 27 loss: 0.16654768586158752\n",
      "epoch 28 loss: 0.14084425568580627\n",
      "epoch 29 loss: 0.11852973699569702\n",
      "epoch 30 loss: 0.15261906385421753\n",
      "56\n",
      "epoch 1 loss: 0.7805429697036743\n",
      "epoch 2 loss: 0.7519885301589966\n",
      "epoch 3 loss: 0.5176911354064941\n",
      "epoch 4 loss: 0.2570468485355377\n",
      "epoch 5 loss: 0.1735570728778839\n",
      "epoch 6 loss: 0.151358500123024\n",
      "epoch 7 loss: 0.19695153832435608\n",
      "epoch 8 loss: 0.15105986595153809\n",
      "epoch 9 loss: 0.17064087092876434\n",
      "epoch 10 loss: 0.17708061635494232\n",
      "epoch 11 loss: 0.17200316488742828\n",
      "epoch 12 loss: 0.15098322927951813\n",
      "epoch 13 loss: 0.1612028032541275\n",
      "epoch 14 loss: 0.1716298907995224\n",
      "epoch 15 loss: 0.17422989010810852\n",
      "epoch 16 loss: 0.14394420385360718\n",
      "epoch 17 loss: 0.1554255485534668\n",
      "epoch 18 loss: 0.16432757675647736\n",
      "epoch 19 loss: 0.12905584275722504\n",
      "epoch 20 loss: 0.13146866858005524\n",
      "epoch 21 loss: 0.12754486501216888\n",
      "epoch 22 loss: 0.11954718828201294\n",
      "epoch 23 loss: 0.1332157701253891\n",
      "epoch 24 loss: 0.10549306124448776\n",
      "epoch 25 loss: 0.1403295397758484\n",
      "epoch 26 loss: 0.1280321478843689\n",
      "epoch 27 loss: 0.10442560166120529\n",
      "epoch 28 loss: 0.07917024940252304\n",
      "epoch 29 loss: 0.0866706594824791\n",
      "epoch 30 loss: 0.13688941299915314\n",
      "57\n",
      "epoch 1 loss: 0.8222846984863281\n",
      "epoch 2 loss: 0.6571291089057922\n",
      "epoch 3 loss: 0.5895628333091736\n",
      "epoch 4 loss: 0.3158864676952362\n",
      "epoch 5 loss: 0.20083008706569672\n",
      "epoch 6 loss: 0.18753935396671295\n",
      "epoch 7 loss: 0.1869983822107315\n",
      "epoch 8 loss: 0.17748066782951355\n",
      "epoch 9 loss: 0.16192707419395447\n",
      "epoch 10 loss: 0.17957809567451477\n",
      "epoch 11 loss: 0.12257929146289825\n",
      "epoch 12 loss: 0.18271100521087646\n",
      "epoch 13 loss: 0.19040261209011078\n",
      "epoch 14 loss: 0.1544838845729828\n",
      "epoch 15 loss: 0.16702263057231903\n",
      "epoch 16 loss: 0.1455242931842804\n",
      "epoch 17 loss: 0.18731772899627686\n",
      "epoch 18 loss: 0.16576798260211945\n",
      "epoch 19 loss: 0.12974533438682556\n",
      "epoch 20 loss: 0.18050195276737213\n",
      "epoch 21 loss: 0.14614331722259521\n",
      "epoch 22 loss: 0.1665799766778946\n",
      "epoch 23 loss: 0.1395789384841919\n",
      "epoch 24 loss: 0.1461970955133438\n",
      "epoch 25 loss: 0.14464421570301056\n",
      "epoch 26 loss: 0.15551958978176117\n",
      "epoch 27 loss: 0.14498816430568695\n",
      "epoch 28 loss: 0.13952988386154175\n",
      "epoch 29 loss: 0.10925798863172531\n",
      "epoch 30 loss: 0.12510523200035095\n",
      "58\n",
      "epoch 1 loss: 0.8856176733970642\n",
      "epoch 2 loss: 0.5554451942443848\n",
      "epoch 3 loss: 0.29959893226623535\n",
      "epoch 4 loss: 0.20021432638168335\n",
      "epoch 5 loss: 0.16225577890872955\n",
      "epoch 6 loss: 0.16062012314796448\n",
      "epoch 7 loss: 0.17043274641036987\n",
      "epoch 8 loss: 0.18171009421348572\n",
      "epoch 9 loss: 0.15622051060199738\n",
      "epoch 10 loss: 0.1852596551179886\n",
      "epoch 11 loss: 0.14381641149520874\n",
      "epoch 12 loss: 0.16756866872310638\n",
      "epoch 13 loss: 0.18168635666370392\n",
      "epoch 14 loss: 0.16576893627643585\n",
      "epoch 15 loss: 0.14366257190704346\n",
      "epoch 16 loss: 0.14412371814250946\n",
      "epoch 17 loss: 0.1661415845155716\n",
      "epoch 18 loss: 0.18170538544654846\n",
      "epoch 19 loss: 0.13732212781906128\n",
      "epoch 20 loss: 0.18527081608772278\n",
      "epoch 21 loss: 0.1310567706823349\n",
      "epoch 22 loss: 0.16539284586906433\n",
      "epoch 23 loss: 0.13830216228961945\n",
      "epoch 24 loss: 0.19714084267616272\n",
      "epoch 25 loss: 0.11493095010519028\n",
      "epoch 26 loss: 0.12226942926645279\n",
      "epoch 27 loss: 0.14567576348781586\n",
      "epoch 28 loss: 0.12410411238670349\n",
      "epoch 29 loss: 0.12150228023529053\n",
      "epoch 30 loss: 0.0900634303689003\n",
      "59\n",
      "epoch 1 loss: 0.7494639754295349\n",
      "epoch 2 loss: 0.605792224407196\n",
      "epoch 3 loss: 0.2886052429676056\n",
      "epoch 4 loss: 0.19815990328788757\n",
      "epoch 5 loss: 0.19209794700145721\n",
      "epoch 6 loss: 0.15515516698360443\n",
      "epoch 7 loss: 0.20706835389137268\n",
      "epoch 8 loss: 0.16574984788894653\n",
      "epoch 9 loss: 0.15081240236759186\n",
      "epoch 10 loss: 0.15928995609283447\n",
      "epoch 11 loss: 0.15356095135211945\n",
      "epoch 12 loss: 0.18184560537338257\n",
      "epoch 13 loss: 0.1570357084274292\n",
      "epoch 14 loss: 0.13734403252601624\n",
      "epoch 15 loss: 0.1876816600561142\n",
      "epoch 16 loss: 0.14731130003929138\n",
      "epoch 17 loss: 0.16477824747562408\n",
      "epoch 18 loss: 0.16280589997768402\n",
      "epoch 19 loss: 0.15547306835651398\n",
      "epoch 20 loss: 0.17971478402614594\n",
      "epoch 21 loss: 0.15672443807125092\n",
      "epoch 22 loss: 0.12537384033203125\n",
      "epoch 23 loss: 0.14192654192447662\n",
      "epoch 24 loss: 0.16436758637428284\n",
      "epoch 25 loss: 0.162602961063385\n",
      "epoch 26 loss: 0.17487378418445587\n",
      "epoch 27 loss: 0.11948639899492264\n",
      "epoch 28 loss: 0.11193238198757172\n",
      "epoch 29 loss: 0.17289014160633087\n",
      "epoch 30 loss: 0.10477370768785477\n",
      "60\n",
      "epoch 1 loss: 0.8435725569725037\n",
      "epoch 2 loss: 0.8617220520973206\n",
      "epoch 3 loss: 0.6386488080024719\n",
      "epoch 4 loss: 0.2966363728046417\n",
      "epoch 5 loss: 0.19001473486423492\n",
      "epoch 6 loss: 0.2042609453201294\n",
      "epoch 7 loss: 0.14451627433300018\n",
      "epoch 8 loss: 0.14598311483860016\n",
      "epoch 9 loss: 0.15191569924354553\n",
      "epoch 10 loss: 0.15596303343772888\n",
      "epoch 11 loss: 0.1574885994195938\n",
      "epoch 12 loss: 0.16891217231750488\n",
      "epoch 13 loss: 0.20177091658115387\n",
      "epoch 14 loss: 0.1728024035692215\n",
      "epoch 15 loss: 0.12801918387413025\n",
      "epoch 16 loss: 0.15914033353328705\n",
      "epoch 17 loss: 0.20866861939430237\n",
      "epoch 18 loss: 0.1753634661436081\n",
      "epoch 19 loss: 0.1376367062330246\n",
      "epoch 20 loss: 0.1004892960190773\n",
      "epoch 21 loss: 0.12559321522712708\n",
      "epoch 22 loss: 0.16846072673797607\n",
      "epoch 23 loss: 0.14129601418972015\n",
      "epoch 24 loss: 0.1500236690044403\n",
      "epoch 25 loss: 0.10253389179706573\n",
      "epoch 26 loss: 0.10617239773273468\n",
      "epoch 27 loss: 0.11849582940340042\n",
      "epoch 28 loss: 0.0982917845249176\n",
      "epoch 29 loss: 0.10736856609582901\n",
      "epoch 30 loss: 0.13167938590049744\n",
      "61\n",
      "epoch 1 loss: 0.8974136114120483\n",
      "epoch 2 loss: 0.4952065348625183\n",
      "epoch 3 loss: 0.32182782888412476\n",
      "epoch 4 loss: 0.1855313628911972\n",
      "epoch 5 loss: 0.18179672956466675\n",
      "epoch 6 loss: 0.1783691942691803\n",
      "epoch 7 loss: 0.16117027401924133\n",
      "epoch 8 loss: 0.1780526041984558\n",
      "epoch 9 loss: 0.18089193105697632\n",
      "epoch 10 loss: 0.13505040109157562\n",
      "epoch 11 loss: 0.16614191234111786\n",
      "epoch 12 loss: 0.1469072699546814\n",
      "epoch 13 loss: 0.1266770213842392\n",
      "epoch 14 loss: 0.16650648415088654\n",
      "epoch 15 loss: 0.14483439922332764\n",
      "epoch 16 loss: 0.15075525641441345\n",
      "epoch 17 loss: 0.17063705623149872\n",
      "epoch 18 loss: 0.14855560660362244\n",
      "epoch 19 loss: 0.1419379562139511\n",
      "epoch 20 loss: 0.182119220495224\n",
      "epoch 21 loss: 0.13520483672618866\n",
      "epoch 22 loss: 0.17310425639152527\n",
      "epoch 23 loss: 0.13074161112308502\n",
      "epoch 24 loss: 0.11218448728322983\n",
      "epoch 25 loss: 0.10092362016439438\n",
      "epoch 26 loss: 0.12365405261516571\n",
      "epoch 27 loss: 0.12236509472131729\n",
      "epoch 28 loss: 0.10728147625923157\n",
      "epoch 29 loss: 0.14683140814304352\n",
      "epoch 30 loss: 0.10416314750909805\n",
      "62\n",
      "epoch 1 loss: 0.7552048563957214\n",
      "epoch 2 loss: 0.6449775695800781\n",
      "epoch 3 loss: 1.3045963048934937\n",
      "epoch 4 loss: 0.6660122871398926\n",
      "epoch 5 loss: 0.5325588583946228\n",
      "epoch 6 loss: 0.2466650903224945\n",
      "epoch 7 loss: 0.19941900670528412\n",
      "epoch 8 loss: 0.19017505645751953\n",
      "epoch 9 loss: 0.19903412461280823\n",
      "epoch 10 loss: 0.18867012858390808\n",
      "epoch 11 loss: 0.16249637305736542\n",
      "epoch 12 loss: 0.1537775844335556\n",
      "epoch 13 loss: 0.13668569922447205\n",
      "epoch 14 loss: 0.13949666917324066\n",
      "epoch 15 loss: 0.1396329700946808\n",
      "epoch 16 loss: 0.18210671842098236\n",
      "epoch 17 loss: 0.19614866375923157\n",
      "epoch 18 loss: 0.17155030369758606\n",
      "epoch 19 loss: 0.13790017366409302\n",
      "epoch 20 loss: 0.17805561423301697\n",
      "epoch 21 loss: 0.13377976417541504\n",
      "epoch 22 loss: 0.16279421746730804\n",
      "epoch 23 loss: 0.14813993871212006\n",
      "epoch 24 loss: 0.17879368364810944\n",
      "epoch 25 loss: 0.14097462594509125\n",
      "epoch 26 loss: 0.13846400380134583\n",
      "epoch 27 loss: 0.12312941253185272\n",
      "epoch 28 loss: 0.1606479287147522\n",
      "epoch 29 loss: 0.13841883838176727\n",
      "epoch 30 loss: 0.13717877864837646\n",
      "63\n",
      "epoch 1 loss: 0.9123833775520325\n",
      "epoch 2 loss: 0.4998020529747009\n",
      "epoch 3 loss: 0.5104116201400757\n",
      "epoch 4 loss: 0.22411811351776123\n",
      "epoch 5 loss: 0.20992769300937653\n",
      "epoch 6 loss: 0.21053378283977509\n",
      "epoch 7 loss: 0.13940827548503876\n",
      "epoch 8 loss: 0.1450178325176239\n",
      "epoch 9 loss: 0.1365746706724167\n",
      "epoch 10 loss: 0.1660398542881012\n",
      "epoch 11 loss: 0.14912055432796478\n",
      "epoch 12 loss: 0.14297161996364594\n",
      "epoch 13 loss: 0.1529006063938141\n",
      "epoch 14 loss: 0.18131503462791443\n",
      "epoch 15 loss: 0.1724022626876831\n",
      "epoch 16 loss: 0.1771472841501236\n",
      "epoch 17 loss: 0.1750289797782898\n",
      "epoch 18 loss: 0.1298936903476715\n",
      "epoch 19 loss: 0.17085987329483032\n",
      "epoch 20 loss: 0.16889198124408722\n",
      "epoch 21 loss: 0.1295321136713028\n",
      "epoch 22 loss: 0.13287636637687683\n",
      "epoch 23 loss: 0.15155544877052307\n",
      "epoch 24 loss: 0.129774272441864\n",
      "epoch 25 loss: 0.15235000848770142\n",
      "epoch 26 loss: 0.1375269740819931\n",
      "epoch 27 loss: 0.11004405468702316\n",
      "epoch 28 loss: 0.12249349057674408\n",
      "epoch 29 loss: 0.11386149376630783\n",
      "epoch 30 loss: 0.10323262959718704\n",
      "64\n",
      "epoch 1 loss: 0.8156387805938721\n",
      "epoch 2 loss: 0.7740557193756104\n",
      "epoch 3 loss: 0.5988971590995789\n",
      "epoch 4 loss: 0.24906674027442932\n",
      "epoch 5 loss: 0.16963177919387817\n",
      "epoch 6 loss: 0.1960262656211853\n",
      "epoch 7 loss: 0.18930216133594513\n",
      "epoch 8 loss: 0.1922839879989624\n",
      "epoch 9 loss: 0.15059006214141846\n",
      "epoch 10 loss: 0.15532618761062622\n",
      "epoch 11 loss: 0.19347649812698364\n",
      "epoch 12 loss: 0.16939690709114075\n",
      "epoch 13 loss: 0.15823641419410706\n",
      "epoch 14 loss: 0.1567942351102829\n",
      "epoch 15 loss: 0.15869708359241486\n",
      "epoch 16 loss: 0.1222565770149231\n",
      "epoch 17 loss: 0.17267687618732452\n",
      "epoch 18 loss: 0.14322663843631744\n",
      "epoch 19 loss: 0.1907522827386856\n",
      "epoch 20 loss: 0.16264048218727112\n",
      "epoch 21 loss: 0.20381230115890503\n",
      "epoch 22 loss: 0.1555822491645813\n",
      "epoch 23 loss: 0.16578906774520874\n",
      "epoch 24 loss: 0.19225192070007324\n",
      "epoch 25 loss: 0.21052446961402893\n",
      "epoch 26 loss: 0.20283998548984528\n",
      "epoch 27 loss: 0.18198519945144653\n",
      "epoch 28 loss: 0.15299823880195618\n",
      "epoch 29 loss: 0.14416363835334778\n",
      "epoch 30 loss: 0.12804646790027618\n",
      "65\n",
      "epoch 1 loss: 0.7495816349983215\n",
      "epoch 2 loss: 0.9224705100059509\n",
      "epoch 3 loss: 0.7302213907241821\n",
      "epoch 4 loss: 0.6121023893356323\n",
      "epoch 5 loss: 0.30140212178230286\n",
      "epoch 6 loss: 0.17155605554580688\n",
      "epoch 7 loss: 0.19280076026916504\n",
      "epoch 8 loss: 0.176009401679039\n",
      "epoch 9 loss: 0.16672523319721222\n",
      "epoch 10 loss: 0.16822385787963867\n",
      "epoch 11 loss: 0.1422574520111084\n",
      "epoch 12 loss: 0.14636515080928802\n",
      "epoch 13 loss: 0.16410447657108307\n",
      "epoch 14 loss: 0.18071569502353668\n",
      "epoch 15 loss: 0.16951707005500793\n",
      "epoch 16 loss: 0.17783014476299286\n",
      "epoch 17 loss: 0.16537164151668549\n",
      "epoch 18 loss: 0.15442703664302826\n",
      "epoch 19 loss: 0.16809828579425812\n",
      "epoch 20 loss: 0.1591278314590454\n",
      "epoch 21 loss: 0.14971905946731567\n",
      "epoch 22 loss: 0.14355126023292542\n",
      "epoch 23 loss: 0.13698551058769226\n",
      "epoch 24 loss: 0.19736118614673615\n",
      "epoch 25 loss: 0.16620676219463348\n",
      "epoch 26 loss: 0.19279223680496216\n",
      "epoch 27 loss: 0.13619211316108704\n",
      "epoch 28 loss: 0.11929288506507874\n",
      "epoch 29 loss: 0.11020343750715256\n",
      "epoch 30 loss: 0.1354309618473053\n",
      "66\n",
      "epoch 1 loss: 0.7999565005302429\n",
      "epoch 2 loss: 0.48867425322532654\n",
      "epoch 3 loss: 0.4339904487133026\n",
      "epoch 4 loss: 0.2796805500984192\n",
      "epoch 5 loss: 0.16479255259037018\n",
      "epoch 6 loss: 0.20823556184768677\n",
      "epoch 7 loss: 0.1735231578350067\n",
      "epoch 8 loss: 0.19265224039554596\n",
      "epoch 9 loss: 0.19781751930713654\n",
      "epoch 10 loss: 0.15835732221603394\n",
      "epoch 11 loss: 0.11725971847772598\n",
      "epoch 12 loss: 0.15169960260391235\n",
      "epoch 13 loss: 0.1960088461637497\n",
      "epoch 14 loss: 0.17800699174404144\n",
      "epoch 15 loss: 0.16110993921756744\n",
      "epoch 16 loss: 0.16969040036201477\n",
      "epoch 17 loss: 0.15628190338611603\n",
      "epoch 18 loss: 0.1976444125175476\n",
      "epoch 19 loss: 0.18873682618141174\n",
      "epoch 20 loss: 0.11764461547136307\n",
      "epoch 21 loss: 0.16445699334144592\n",
      "epoch 22 loss: 0.19573983550071716\n",
      "epoch 23 loss: 0.12077458202838898\n",
      "epoch 24 loss: 0.18527694046497345\n",
      "epoch 25 loss: 0.12100769579410553\n",
      "epoch 26 loss: 0.12573358416557312\n",
      "epoch 27 loss: 0.08393322676420212\n",
      "epoch 28 loss: 0.10372757166624069\n",
      "epoch 29 loss: 0.1264115273952484\n",
      "epoch 30 loss: 0.10953808575868607\n",
      "67\n",
      "epoch 1 loss: 0.7670949697494507\n",
      "epoch 2 loss: 0.5528218150138855\n",
      "epoch 3 loss: 0.36674439907073975\n",
      "epoch 4 loss: 0.26371923089027405\n",
      "epoch 5 loss: 0.1788504272699356\n",
      "epoch 6 loss: 0.1688128560781479\n",
      "epoch 7 loss: 0.1863722950220108\n",
      "epoch 8 loss: 0.15016980469226837\n",
      "epoch 9 loss: 0.16450411081314087\n",
      "epoch 10 loss: 0.16910505294799805\n",
      "epoch 11 loss: 0.14985302090644836\n",
      "epoch 12 loss: 0.16598375141620636\n",
      "epoch 13 loss: 0.14562132954597473\n",
      "epoch 14 loss: 0.16248968243598938\n",
      "epoch 15 loss: 0.14967013895511627\n",
      "epoch 16 loss: 0.17166899144649506\n",
      "epoch 17 loss: 0.17094317078590393\n",
      "epoch 18 loss: 0.18845759332180023\n",
      "epoch 19 loss: 0.15582060813903809\n",
      "epoch 20 loss: 0.15423394739627838\n",
      "epoch 21 loss: 0.17245329916477203\n",
      "epoch 22 loss: 0.16676856577396393\n",
      "epoch 23 loss: 0.14645223319530487\n",
      "epoch 24 loss: 0.1507849097251892\n",
      "epoch 25 loss: 0.13290418684482574\n",
      "epoch 26 loss: 0.14873209595680237\n",
      "epoch 27 loss: 0.12333928048610687\n",
      "epoch 28 loss: 0.10783276706933975\n",
      "epoch 29 loss: 0.1538994163274765\n",
      "epoch 30 loss: 0.14916281402111053\n",
      "68\n",
      "epoch 1 loss: 0.6354622840881348\n",
      "epoch 2 loss: 0.6958308219909668\n",
      "epoch 3 loss: 0.41383230686187744\n",
      "epoch 4 loss: 0.22140143811702728\n",
      "epoch 5 loss: 0.1835939735174179\n",
      "epoch 6 loss: 0.19990183413028717\n",
      "epoch 7 loss: 0.17768709361553192\n",
      "epoch 8 loss: 0.13437123596668243\n",
      "epoch 9 loss: 0.20393577218055725\n",
      "epoch 10 loss: 0.16655519604682922\n",
      "epoch 11 loss: 0.138766348361969\n",
      "epoch 12 loss: 0.16915875673294067\n",
      "epoch 13 loss: 0.1625012904405594\n",
      "epoch 14 loss: 0.18104751408100128\n",
      "epoch 15 loss: 0.16061753034591675\n",
      "epoch 16 loss: 0.16401858627796173\n",
      "epoch 17 loss: 0.14954279363155365\n",
      "epoch 18 loss: 0.14961405098438263\n",
      "epoch 19 loss: 0.17691153287887573\n",
      "epoch 20 loss: 0.20924463868141174\n",
      "epoch 21 loss: 0.1892441213130951\n",
      "epoch 22 loss: 0.17046920955181122\n",
      "epoch 23 loss: 0.14006805419921875\n",
      "epoch 24 loss: 0.1697966605424881\n",
      "epoch 25 loss: 0.15998594462871552\n",
      "epoch 26 loss: 0.1406974345445633\n",
      "epoch 27 loss: 0.19356928765773773\n",
      "epoch 28 loss: 0.17671936750411987\n",
      "epoch 29 loss: 0.12672239542007446\n",
      "epoch 30 loss: 0.10888954252004623\n",
      "69\n",
      "epoch 1 loss: 0.7406206130981445\n",
      "epoch 2 loss: 0.9925708174705505\n",
      "epoch 3 loss: 0.6706936955451965\n",
      "epoch 4 loss: 0.2911919355392456\n",
      "epoch 5 loss: 0.16161289811134338\n",
      "epoch 6 loss: 0.14402024447917938\n",
      "epoch 7 loss: 0.21177558600902557\n",
      "epoch 8 loss: 0.16036361455917358\n",
      "epoch 9 loss: 0.15810666978359222\n",
      "epoch 10 loss: 0.16836455464363098\n",
      "epoch 11 loss: 0.16233235597610474\n",
      "epoch 12 loss: 0.12295027077198029\n",
      "epoch 13 loss: 0.14238834381103516\n",
      "epoch 14 loss: 0.16079193353652954\n",
      "epoch 15 loss: 0.18564282357692719\n",
      "epoch 16 loss: 0.2002628743648529\n",
      "epoch 17 loss: 0.2089066356420517\n",
      "epoch 18 loss: 0.17122288048267365\n",
      "epoch 19 loss: 0.2052547037601471\n",
      "epoch 20 loss: 0.11614444106817245\n",
      "epoch 21 loss: 0.13637997210025787\n",
      "epoch 22 loss: 0.13762931525707245\n",
      "epoch 23 loss: 0.1627495288848877\n",
      "epoch 24 loss: 0.15373016893863678\n",
      "epoch 25 loss: 0.1556919366121292\n",
      "epoch 26 loss: 0.15040062367916107\n",
      "epoch 27 loss: 0.17174707353115082\n",
      "epoch 28 loss: 0.15130126476287842\n",
      "epoch 29 loss: 0.10560331493616104\n",
      "epoch 30 loss: 0.08881386369466782\n",
      "70\n",
      "epoch 1 loss: 0.8105940818786621\n",
      "epoch 2 loss: 0.5805707573890686\n",
      "epoch 3 loss: 0.38990816473960876\n",
      "epoch 4 loss: 0.25340622663497925\n",
      "epoch 5 loss: 0.1729438155889511\n",
      "epoch 6 loss: 0.14992405474185944\n",
      "epoch 7 loss: 0.17898908257484436\n",
      "epoch 8 loss: 0.16233065724372864\n",
      "epoch 9 loss: 0.17437124252319336\n",
      "epoch 10 loss: 0.12949524819850922\n",
      "epoch 11 loss: 0.1582980751991272\n",
      "epoch 12 loss: 0.17613694071769714\n",
      "epoch 13 loss: 0.17998380959033966\n",
      "epoch 14 loss: 0.19287408888339996\n",
      "epoch 15 loss: 0.14244875311851501\n",
      "epoch 16 loss: 0.151478573679924\n",
      "epoch 17 loss: 0.14979878067970276\n",
      "epoch 18 loss: 0.177307590842247\n",
      "epoch 19 loss: 0.14912918210029602\n",
      "epoch 20 loss: 0.14832375943660736\n",
      "epoch 21 loss: 0.16128316521644592\n",
      "epoch 22 loss: 0.15154080092906952\n",
      "epoch 23 loss: 0.12187692523002625\n",
      "epoch 24 loss: 0.1337290108203888\n",
      "epoch 25 loss: 0.13961714506149292\n",
      "epoch 26 loss: 0.16714714467525482\n",
      "epoch 27 loss: 0.1304367333650589\n",
      "epoch 28 loss: 0.1448863446712494\n",
      "epoch 29 loss: 0.11051125079393387\n",
      "epoch 30 loss: 0.11176992207765579\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "516ef30e-8db6-402f-8734-7ad8a9fb3b61",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + numerical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a3c678a-f2ff-4500-bd32-28f713423daf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T21:30:48.161907Z",
     "start_time": "2025-10-03T20:27:28.361193Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wn = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wn()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wn = pd.concat([results_aep_self_con_wn, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con_wn.to_csv(out_dir + '/results_aep_self_con_wn.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1 loss: 0.6841861009597778\n",
      "epoch 2 loss: 0.5988009572029114\n",
      "epoch 3 loss: 0.2329423874616623\n",
      "epoch 4 loss: 0.18408723175525665\n",
      "epoch 5 loss: 0.17501644790172577\n",
      "epoch 6 loss: 0.15250727534294128\n",
      "epoch 7 loss: 0.16848231852054596\n",
      "epoch 8 loss: 0.16918827593326569\n",
      "epoch 9 loss: 0.14645668864250183\n",
      "epoch 10 loss: 0.15509141981601715\n",
      "epoch 11 loss: 0.1391536295413971\n",
      "epoch 12 loss: 0.18266505002975464\n",
      "epoch 13 loss: 0.1422642320394516\n",
      "epoch 14 loss: 0.16787512600421906\n",
      "epoch 15 loss: 0.15880224108695984\n",
      "epoch 16 loss: 0.185583233833313\n",
      "epoch 17 loss: 0.1351071447134018\n",
      "epoch 18 loss: 0.1505209058523178\n",
      "epoch 19 loss: 0.16360563039779663\n",
      "epoch 20 loss: 0.14969904720783234\n",
      "epoch 21 loss: 0.14457431435585022\n",
      "epoch 22 loss: 0.10642094910144806\n",
      "epoch 23 loss: 0.1525767594575882\n",
      "epoch 24 loss: 0.10663477331399918\n",
      "epoch 25 loss: 0.10171978920698166\n",
      "epoch 26 loss: 0.12593424320220947\n",
      "epoch 27 loss: 0.12140392512083054\n",
      "epoch 28 loss: 0.1121976375579834\n",
      "epoch 29 loss: 0.13153794407844543\n",
      "epoch 30 loss: 0.111446313560009\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_74380/4088566383.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_self_con_wn = pd.concat([results_aep_self_con_wn, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.8629924654960632\n",
      "epoch 2 loss: 0.824164092540741\n",
      "epoch 3 loss: 0.4823002517223358\n",
      "epoch 4 loss: 0.18309421837329865\n",
      "epoch 5 loss: 0.17974115908145905\n",
      "epoch 6 loss: 0.1758941411972046\n",
      "epoch 7 loss: 0.15091736614704132\n",
      "epoch 8 loss: 0.15926307439804077\n",
      "epoch 9 loss: 0.1398368924856186\n",
      "epoch 10 loss: 0.1389441341161728\n",
      "epoch 11 loss: 0.12791688740253448\n",
      "epoch 12 loss: 0.14611530303955078\n",
      "epoch 13 loss: 0.16228079795837402\n",
      "epoch 14 loss: 0.1351272165775299\n",
      "epoch 15 loss: 0.17304496467113495\n",
      "epoch 16 loss: 0.1147528886795044\n",
      "epoch 17 loss: 0.10164619237184525\n",
      "epoch 18 loss: 0.14238737523555756\n",
      "epoch 19 loss: 0.12427179515361786\n",
      "epoch 20 loss: 0.11978431791067123\n",
      "epoch 21 loss: 0.22159510850906372\n",
      "epoch 22 loss: 0.16907761991024017\n",
      "epoch 23 loss: 0.11241931468248367\n",
      "epoch 24 loss: 0.13163064420223236\n",
      "epoch 25 loss: 0.11044519394636154\n",
      "epoch 26 loss: 0.10771441459655762\n",
      "epoch 27 loss: 0.08891842514276505\n",
      "epoch 28 loss: 0.10253387689590454\n",
      "epoch 29 loss: 0.10507652163505554\n",
      "epoch 30 loss: 0.11148564517498016\n",
      "3\n",
      "epoch 1 loss: 0.8635984659194946\n",
      "epoch 2 loss: 0.47595325112342834\n",
      "epoch 3 loss: 0.2869226634502411\n",
      "epoch 4 loss: 0.2055274099111557\n",
      "epoch 5 loss: 0.2061319351196289\n",
      "epoch 6 loss: 0.16789110004901886\n",
      "epoch 7 loss: 0.18505360186100006\n",
      "epoch 8 loss: 0.15445446968078613\n",
      "epoch 9 loss: 0.16200043261051178\n",
      "epoch 10 loss: 0.1693473756313324\n",
      "epoch 11 loss: 0.14415132999420166\n",
      "epoch 12 loss: 0.153899148106575\n",
      "epoch 13 loss: 0.19645513594150543\n",
      "epoch 14 loss: 0.12331914901733398\n",
      "epoch 15 loss: 0.15934385359287262\n",
      "epoch 16 loss: 0.1728508174419403\n",
      "epoch 17 loss: 0.16636554896831512\n",
      "epoch 18 loss: 0.18220458924770355\n",
      "epoch 19 loss: 0.14023269712924957\n",
      "epoch 20 loss: 0.1321708858013153\n",
      "epoch 21 loss: 0.12250616401433945\n",
      "epoch 22 loss: 0.11572182923555374\n",
      "epoch 23 loss: 0.09885790199041367\n",
      "epoch 24 loss: 0.10656972974538803\n",
      "epoch 25 loss: 0.10902050137519836\n",
      "epoch 26 loss: 0.14206641912460327\n",
      "epoch 27 loss: 0.12899239361286163\n",
      "epoch 28 loss: 0.12775367498397827\n",
      "epoch 29 loss: 0.13224589824676514\n",
      "epoch 30 loss: 0.10572972893714905\n",
      "4\n",
      "epoch 1 loss: 0.9163751006126404\n",
      "epoch 2 loss: 0.5688163042068481\n",
      "epoch 3 loss: 0.2805052399635315\n",
      "epoch 4 loss: 0.21585629880428314\n",
      "epoch 5 loss: 0.1504366099834442\n",
      "epoch 6 loss: 0.18959109485149384\n",
      "epoch 7 loss: 0.13877183198928833\n",
      "epoch 8 loss: 0.13965828716754913\n",
      "epoch 9 loss: 0.14842766523361206\n",
      "epoch 10 loss: 0.1512349247932434\n",
      "epoch 11 loss: 0.1599980741739273\n",
      "epoch 12 loss: 0.11870869994163513\n",
      "epoch 13 loss: 0.12104063481092453\n",
      "epoch 14 loss: 0.17188361287117004\n",
      "epoch 15 loss: 0.1898772269487381\n",
      "epoch 16 loss: 0.13155701756477356\n",
      "epoch 17 loss: 0.1562778651714325\n",
      "epoch 18 loss: 0.09128623455762863\n",
      "epoch 19 loss: 0.16923314332962036\n",
      "epoch 20 loss: 0.11266486346721649\n",
      "epoch 21 loss: 0.0955854058265686\n",
      "epoch 22 loss: 0.10203558206558228\n",
      "epoch 23 loss: 0.10324540734291077\n",
      "epoch 24 loss: 0.08960232138633728\n",
      "epoch 25 loss: 0.09891433268785477\n",
      "epoch 26 loss: 0.10970226675271988\n",
      "epoch 27 loss: 0.11205810308456421\n",
      "epoch 28 loss: 0.11331766098737717\n",
      "epoch 29 loss: 0.10947722941637039\n",
      "epoch 30 loss: 0.10645356774330139\n",
      "5\n",
      "epoch 1 loss: 0.8941348195075989\n",
      "epoch 2 loss: 0.5900502800941467\n",
      "epoch 3 loss: 0.3167997896671295\n",
      "epoch 4 loss: 0.23938293755054474\n",
      "epoch 5 loss: 0.17543193697929382\n",
      "epoch 6 loss: 0.1767975091934204\n",
      "epoch 7 loss: 0.1580524891614914\n",
      "epoch 8 loss: 0.14265930652618408\n",
      "epoch 9 loss: 0.18610791862010956\n",
      "epoch 10 loss: 0.16674087941646576\n",
      "epoch 11 loss: 0.17669761180877686\n",
      "epoch 12 loss: 0.13156338036060333\n",
      "epoch 13 loss: 0.13178832828998566\n",
      "epoch 14 loss: 0.13679251074790955\n",
      "epoch 15 loss: 0.17180632054805756\n",
      "epoch 16 loss: 0.1670200228691101\n",
      "epoch 17 loss: 0.11931345611810684\n",
      "epoch 18 loss: 0.11039218306541443\n",
      "epoch 19 loss: 0.19840338826179504\n",
      "epoch 20 loss: 0.10341240465641022\n",
      "epoch 21 loss: 0.12504126131534576\n",
      "epoch 22 loss: 0.11456834524869919\n",
      "epoch 23 loss: 0.10706060379743576\n",
      "epoch 24 loss: 0.08716627955436707\n",
      "epoch 25 loss: 0.10024809092283249\n",
      "epoch 26 loss: 0.10747893899679184\n",
      "epoch 27 loss: 0.11028067767620087\n",
      "epoch 28 loss: 0.10932815074920654\n",
      "epoch 29 loss: 0.07481405884027481\n",
      "epoch 30 loss: 0.10671160370111465\n",
      "6\n",
      "epoch 1 loss: 0.8651706576347351\n",
      "epoch 2 loss: 0.45100319385528564\n",
      "epoch 3 loss: 0.2222001701593399\n",
      "epoch 4 loss: 0.12888194620609283\n",
      "epoch 5 loss: 0.14983896911144257\n",
      "epoch 6 loss: 0.1596166342496872\n",
      "epoch 7 loss: 0.17305400967597961\n",
      "epoch 8 loss: 0.14760127663612366\n",
      "epoch 9 loss: 0.1879049390554428\n",
      "epoch 10 loss: 0.15227115154266357\n",
      "epoch 11 loss: 0.14183463156223297\n",
      "epoch 12 loss: 0.15402455627918243\n",
      "epoch 13 loss: 0.16997365653514862\n",
      "epoch 14 loss: 0.12438695877790451\n",
      "epoch 15 loss: 0.13552197813987732\n",
      "epoch 16 loss: 0.1705988496541977\n",
      "epoch 17 loss: 0.16231085360050201\n",
      "epoch 18 loss: 0.13817381858825684\n",
      "epoch 19 loss: 0.1008714884519577\n",
      "epoch 20 loss: 0.13198865950107574\n",
      "epoch 21 loss: 0.1208472028374672\n",
      "epoch 22 loss: 0.11676932871341705\n",
      "epoch 23 loss: 0.16090281307697296\n",
      "epoch 24 loss: 0.09551740437746048\n",
      "epoch 25 loss: 0.10425595194101334\n",
      "epoch 26 loss: 0.07489664852619171\n",
      "epoch 27 loss: 0.09132025390863419\n",
      "epoch 28 loss: 0.10863246768712997\n",
      "epoch 29 loss: 0.12108877301216125\n",
      "epoch 30 loss: 0.11377817392349243\n",
      "7\n",
      "epoch 1 loss: 0.8314249515533447\n",
      "epoch 2 loss: 0.5746016502380371\n",
      "epoch 3 loss: 0.25838950276374817\n",
      "epoch 4 loss: 0.21857789158821106\n",
      "epoch 5 loss: 0.15357816219329834\n",
      "epoch 6 loss: 0.1821552962064743\n",
      "epoch 7 loss: 0.14347630739212036\n",
      "epoch 8 loss: 0.15833835303783417\n",
      "epoch 9 loss: 0.13949064910411835\n",
      "epoch 10 loss: 0.14779900014400482\n",
      "epoch 11 loss: 0.16305133700370789\n",
      "epoch 12 loss: 0.14041461050510406\n",
      "epoch 13 loss: 0.1358475387096405\n",
      "epoch 14 loss: 0.1635296642780304\n",
      "epoch 15 loss: 0.20433233678340912\n",
      "epoch 16 loss: 0.12583598494529724\n",
      "epoch 17 loss: 0.1462148129940033\n",
      "epoch 18 loss: 0.1403270661830902\n",
      "epoch 19 loss: 0.15542325377464294\n",
      "epoch 20 loss: 0.16665410995483398\n",
      "epoch 21 loss: 0.18939806520938873\n",
      "epoch 22 loss: 0.15471619367599487\n",
      "epoch 23 loss: 0.15191617608070374\n",
      "epoch 24 loss: 0.1378747671842575\n",
      "epoch 25 loss: 0.1542087346315384\n",
      "epoch 26 loss: 0.09967260807752609\n",
      "epoch 27 loss: 0.11169064790010452\n",
      "epoch 28 loss: 0.12038914859294891\n",
      "epoch 29 loss: 0.12945860624313354\n",
      "epoch 30 loss: 0.11122316867113113\n",
      "8\n",
      "epoch 1 loss: 0.9917729496955872\n",
      "epoch 2 loss: 0.45168980956077576\n",
      "epoch 3 loss: 0.3262638747692108\n",
      "epoch 4 loss: 0.23460547626018524\n",
      "epoch 5 loss: 0.1824941486120224\n",
      "epoch 6 loss: 0.16691936552524567\n",
      "epoch 7 loss: 0.16344918310642242\n",
      "epoch 8 loss: 0.17428520321846008\n",
      "epoch 9 loss: 0.1465398073196411\n",
      "epoch 10 loss: 0.1686033308506012\n",
      "epoch 11 loss: 0.1557897925376892\n",
      "epoch 12 loss: 0.18795695900917053\n",
      "epoch 13 loss: 0.15389476716518402\n",
      "epoch 14 loss: 0.14431960880756378\n",
      "epoch 15 loss: 0.15986678004264832\n",
      "epoch 16 loss: 0.15163758397102356\n",
      "epoch 17 loss: 0.10787470638751984\n",
      "epoch 18 loss: 0.12836132943630219\n",
      "epoch 19 loss: 0.13799245655536652\n",
      "epoch 20 loss: 0.1648896038532257\n",
      "epoch 21 loss: 0.1291123479604721\n",
      "epoch 22 loss: 0.11410844326019287\n",
      "epoch 23 loss: 0.1071014329791069\n",
      "epoch 24 loss: 0.10146892815828323\n",
      "epoch 25 loss: 0.09942840784788132\n",
      "epoch 26 loss: 0.1068912148475647\n",
      "epoch 27 loss: 0.10758805274963379\n",
      "epoch 28 loss: 0.10044430196285248\n",
      "epoch 29 loss: 0.09333040565252304\n",
      "epoch 30 loss: 0.0872802585363388\n",
      "9\n",
      "epoch 1 loss: 0.8421700596809387\n",
      "epoch 2 loss: 0.5718388557434082\n",
      "epoch 3 loss: 0.32242003083229065\n",
      "epoch 4 loss: 0.19493119418621063\n",
      "epoch 5 loss: 0.16509783267974854\n",
      "epoch 6 loss: 0.1631353795528412\n",
      "epoch 7 loss: 0.19208386540412903\n",
      "epoch 8 loss: 0.1407519429922104\n",
      "epoch 9 loss: 0.16370819509029388\n",
      "epoch 10 loss: 0.17002831399440765\n",
      "epoch 11 loss: 0.16108477115631104\n",
      "epoch 12 loss: 0.1813037097454071\n",
      "epoch 13 loss: 0.19372864067554474\n",
      "epoch 14 loss: 0.13487614691257477\n",
      "epoch 15 loss: 0.19458119571208954\n",
      "epoch 16 loss: 0.1597088873386383\n",
      "epoch 17 loss: 0.162554070353508\n",
      "epoch 18 loss: 0.14586302638053894\n",
      "epoch 19 loss: 0.15136758983135223\n",
      "epoch 20 loss: 0.1453302502632141\n",
      "epoch 21 loss: 0.15578654408454895\n",
      "epoch 22 loss: 0.11943932622671127\n",
      "epoch 23 loss: 0.15560047328472137\n",
      "epoch 24 loss: 0.112733393907547\n",
      "epoch 25 loss: 0.1513298898935318\n",
      "epoch 26 loss: 0.14464817941188812\n",
      "epoch 27 loss: 0.1310121864080429\n",
      "epoch 28 loss: 0.12357112765312195\n",
      "epoch 29 loss: 0.1234612688422203\n",
      "epoch 30 loss: 0.10851209610700607\n",
      "10\n",
      "epoch 1 loss: 0.8529213070869446\n",
      "epoch 2 loss: 0.5535246729850769\n",
      "epoch 3 loss: 0.6118950247764587\n",
      "epoch 4 loss: 0.36476340889930725\n",
      "epoch 5 loss: 0.22719962894916534\n",
      "epoch 6 loss: 0.1547791063785553\n",
      "epoch 7 loss: 0.1941005438566208\n",
      "epoch 8 loss: 0.1765550673007965\n",
      "epoch 9 loss: 0.16696542501449585\n",
      "epoch 10 loss: 0.1547115445137024\n",
      "epoch 11 loss: 0.153795525431633\n",
      "epoch 12 loss: 0.15389567613601685\n",
      "epoch 13 loss: 0.15331320464611053\n",
      "epoch 14 loss: 0.15499527752399445\n",
      "epoch 15 loss: 0.1632801592350006\n",
      "epoch 16 loss: 0.14835597574710846\n",
      "epoch 17 loss: 0.11664785444736481\n",
      "epoch 18 loss: 0.12815359234809875\n",
      "epoch 19 loss: 0.14663250744342804\n",
      "epoch 20 loss: 0.1199854165315628\n",
      "epoch 21 loss: 0.11660872399806976\n",
      "epoch 22 loss: 0.148479163646698\n",
      "epoch 23 loss: 0.07974814623594284\n",
      "epoch 24 loss: 0.13316482305526733\n",
      "epoch 25 loss: 0.09050817787647247\n",
      "epoch 26 loss: 0.09638336300849915\n",
      "epoch 27 loss: 0.09037194401025772\n",
      "epoch 28 loss: 0.1032448410987854\n",
      "epoch 29 loss: 0.08703051507472992\n",
      "epoch 30 loss: 0.12503410875797272\n",
      "11\n",
      "epoch 1 loss: 0.7911883592605591\n",
      "epoch 2 loss: 0.5077165961265564\n",
      "epoch 3 loss: 0.30545732378959656\n",
      "epoch 4 loss: 0.1830594390630722\n",
      "epoch 5 loss: 0.18013247847557068\n",
      "epoch 6 loss: 0.1521119773387909\n",
      "epoch 7 loss: 0.16135191917419434\n",
      "epoch 8 loss: 0.1339784413576126\n",
      "epoch 9 loss: 0.14891396462917328\n",
      "epoch 10 loss: 0.1590576320886612\n",
      "epoch 11 loss: 0.18203164637088776\n",
      "epoch 12 loss: 0.1468910425901413\n",
      "epoch 13 loss: 0.17379552125930786\n",
      "epoch 14 loss: 0.1409224420785904\n",
      "epoch 15 loss: 0.15261581540107727\n",
      "epoch 16 loss: 0.13988201320171356\n",
      "epoch 17 loss: 0.16227945685386658\n",
      "epoch 18 loss: 0.12875887751579285\n",
      "epoch 19 loss: 0.11120263487100601\n",
      "epoch 20 loss: 0.11200826615095139\n",
      "epoch 21 loss: 0.15712127089500427\n",
      "epoch 22 loss: 0.11759472638368607\n",
      "epoch 23 loss: 0.12365999817848206\n",
      "epoch 24 loss: 0.14512720704078674\n",
      "epoch 25 loss: 0.1368199735879898\n",
      "epoch 26 loss: 0.13114145398139954\n",
      "epoch 27 loss: 0.1408987045288086\n",
      "epoch 28 loss: 0.09051931649446487\n",
      "epoch 29 loss: 0.08333974331617355\n",
      "epoch 30 loss: 0.0873400941491127\n",
      "12\n",
      "epoch 1 loss: 0.6952536106109619\n",
      "epoch 2 loss: 0.3997979164123535\n",
      "epoch 3 loss: 0.2755392789840698\n",
      "epoch 4 loss: 0.16498790681362152\n",
      "epoch 5 loss: 0.1554528772830963\n",
      "epoch 6 loss: 0.12948738038539886\n",
      "epoch 7 loss: 0.15652009844779968\n",
      "epoch 8 loss: 0.13214579224586487\n",
      "epoch 9 loss: 0.15810607373714447\n",
      "epoch 10 loss: 0.13013872504234314\n",
      "epoch 11 loss: 0.11925560981035233\n",
      "epoch 12 loss: 0.18411411345005035\n",
      "epoch 13 loss: 0.14568138122558594\n",
      "epoch 14 loss: 0.17052358388900757\n",
      "epoch 15 loss: 0.17239706218242645\n",
      "epoch 16 loss: 0.13262784481048584\n",
      "epoch 17 loss: 0.1663602888584137\n",
      "epoch 18 loss: 0.11732648313045502\n",
      "epoch 19 loss: 0.1616954356431961\n",
      "epoch 20 loss: 0.14247646927833557\n",
      "epoch 21 loss: 0.12813763320446014\n",
      "epoch 22 loss: 0.09312174469232559\n",
      "epoch 23 loss: 0.1127418726682663\n",
      "epoch 24 loss: 0.09242554754018784\n",
      "epoch 25 loss: 0.10524502396583557\n",
      "epoch 26 loss: 0.11688752472400665\n",
      "epoch 27 loss: 0.10115861892700195\n",
      "epoch 28 loss: 0.11080639809370041\n",
      "epoch 29 loss: 0.09464335441589355\n",
      "epoch 30 loss: 0.06900327652692795\n",
      "13\n",
      "epoch 1 loss: 0.6174325942993164\n",
      "epoch 2 loss: 0.569039523601532\n",
      "epoch 3 loss: 0.27688834071159363\n",
      "epoch 4 loss: 0.24178773164749146\n",
      "epoch 5 loss: 0.1836385726928711\n",
      "epoch 6 loss: 0.14235255122184753\n",
      "epoch 7 loss: 0.18666870892047882\n",
      "epoch 8 loss: 0.2087482362985611\n",
      "epoch 9 loss: 0.20385290682315826\n",
      "epoch 10 loss: 0.1983693540096283\n",
      "epoch 11 loss: 0.18443775177001953\n",
      "epoch 12 loss: 0.17133989930152893\n",
      "epoch 13 loss: 0.1695437729358673\n",
      "epoch 14 loss: 0.1775730848312378\n",
      "epoch 15 loss: 0.12937644124031067\n",
      "epoch 16 loss: 0.1590302586555481\n",
      "epoch 17 loss: 0.12135890871286392\n",
      "epoch 18 loss: 0.13254769146442413\n",
      "epoch 19 loss: 0.1499864012002945\n",
      "epoch 20 loss: 0.16106870770454407\n",
      "epoch 21 loss: 0.13084650039672852\n",
      "epoch 22 loss: 0.11213086545467377\n",
      "epoch 23 loss: 0.11940604448318481\n",
      "epoch 24 loss: 0.1831282377243042\n",
      "epoch 25 loss: 0.14805366098880768\n",
      "epoch 26 loss: 0.11941595375537872\n",
      "epoch 27 loss: 0.12790732085704803\n",
      "epoch 28 loss: 0.14027267694473267\n",
      "epoch 29 loss: 0.11869262903928757\n",
      "epoch 30 loss: 0.1397222876548767\n",
      "14\n",
      "epoch 1 loss: 0.7899746894836426\n",
      "epoch 2 loss: 0.46353989839553833\n",
      "epoch 3 loss: 0.368304044008255\n",
      "epoch 4 loss: 0.22716784477233887\n",
      "epoch 5 loss: 0.1999007761478424\n",
      "epoch 6 loss: 0.17393624782562256\n",
      "epoch 7 loss: 0.16752003133296967\n",
      "epoch 8 loss: 0.14300379157066345\n",
      "epoch 9 loss: 0.13939639925956726\n",
      "epoch 10 loss: 0.1610989272594452\n",
      "epoch 11 loss: 0.15383540093898773\n",
      "epoch 12 loss: 0.18639393150806427\n",
      "epoch 13 loss: 0.14560115337371826\n",
      "epoch 14 loss: 0.19402986764907837\n",
      "epoch 15 loss: 0.1630549430847168\n",
      "epoch 16 loss: 0.18816430866718292\n",
      "epoch 17 loss: 0.13608942925930023\n",
      "epoch 18 loss: 0.1456001102924347\n",
      "epoch 19 loss: 0.13143426179885864\n",
      "epoch 20 loss: 0.14173996448516846\n",
      "epoch 21 loss: 0.16846351325511932\n",
      "epoch 22 loss: 0.10997273027896881\n",
      "epoch 23 loss: 0.11204443126916885\n",
      "epoch 24 loss: 0.11000126600265503\n",
      "epoch 25 loss: 0.12436738610267639\n",
      "epoch 26 loss: 0.09113645553588867\n",
      "epoch 27 loss: 0.10398423671722412\n",
      "epoch 28 loss: 0.09403026103973389\n",
      "epoch 29 loss: 0.08852788805961609\n",
      "epoch 30 loss: 0.09639501571655273\n",
      "15\n",
      "epoch 1 loss: 0.659238338470459\n",
      "epoch 2 loss: 0.9289047718048096\n",
      "epoch 3 loss: 0.7974434494972229\n",
      "epoch 4 loss: 0.36804601550102234\n",
      "epoch 5 loss: 0.24177640676498413\n",
      "epoch 6 loss: 0.14030781388282776\n",
      "epoch 7 loss: 0.2097734808921814\n",
      "epoch 8 loss: 0.14963479340076447\n",
      "epoch 9 loss: 0.18002532422542572\n",
      "epoch 10 loss: 0.18132032454013824\n",
      "epoch 11 loss: 0.1458832025527954\n",
      "epoch 12 loss: 0.1657705008983612\n",
      "epoch 13 loss: 0.14905661344528198\n",
      "epoch 14 loss: 0.18459554016590118\n",
      "epoch 15 loss: 0.17382018268108368\n",
      "epoch 16 loss: 0.14567823708057404\n",
      "epoch 17 loss: 0.13921070098876953\n",
      "epoch 18 loss: 0.12707799673080444\n",
      "epoch 19 loss: 0.1353723257780075\n",
      "epoch 20 loss: 0.10368402302265167\n",
      "epoch 21 loss: 0.1311190277338028\n",
      "epoch 22 loss: 0.11522068083286285\n",
      "epoch 23 loss: 0.11409192532300949\n",
      "epoch 24 loss: 0.12286970764398575\n",
      "epoch 25 loss: 0.1298077255487442\n",
      "epoch 26 loss: 0.10593662410974503\n",
      "epoch 27 loss: 0.09912169724702835\n",
      "epoch 28 loss: 0.11325906217098236\n",
      "epoch 29 loss: 0.11750946193933487\n",
      "epoch 30 loss: 0.09064894169569016\n",
      "16\n",
      "epoch 1 loss: 0.755389928817749\n",
      "epoch 2 loss: 0.5384509563446045\n",
      "epoch 3 loss: 0.263435423374176\n",
      "epoch 4 loss: 0.24623164534568787\n",
      "epoch 5 loss: 0.18682995438575745\n",
      "epoch 6 loss: 0.16765561699867249\n",
      "epoch 7 loss: 0.23557570576667786\n",
      "epoch 8 loss: 0.19075028598308563\n",
      "epoch 9 loss: 0.20519331097602844\n",
      "epoch 10 loss: 0.15270011126995087\n",
      "epoch 11 loss: 0.13153527677059174\n",
      "epoch 12 loss: 0.18452227115631104\n",
      "epoch 13 loss: 0.14887407422065735\n",
      "epoch 14 loss: 0.1461382955312729\n",
      "epoch 15 loss: 0.15630650520324707\n",
      "epoch 16 loss: 0.16648980975151062\n",
      "epoch 17 loss: 0.15619006752967834\n",
      "epoch 18 loss: 0.15022523701190948\n",
      "epoch 19 loss: 0.13504467904567719\n",
      "epoch 20 loss: 0.13865213096141815\n",
      "epoch 21 loss: 0.14795146882534027\n",
      "epoch 22 loss: 0.13674266636371613\n",
      "epoch 23 loss: 0.13775476813316345\n",
      "epoch 24 loss: 0.1389220952987671\n",
      "epoch 25 loss: 0.1224796324968338\n",
      "epoch 26 loss: 0.11335648596286774\n",
      "epoch 27 loss: 0.11542607098817825\n",
      "epoch 28 loss: 0.1869988739490509\n",
      "epoch 29 loss: 0.09562192857265472\n",
      "epoch 30 loss: 0.1364961713552475\n",
      "17\n",
      "epoch 1 loss: 0.893298864364624\n",
      "epoch 2 loss: 1.0091190338134766\n",
      "epoch 3 loss: 0.3880789577960968\n",
      "epoch 4 loss: 0.2591576874256134\n",
      "epoch 5 loss: 0.16267187893390656\n",
      "epoch 6 loss: 0.19176271557807922\n",
      "epoch 7 loss: 0.16465802490711212\n",
      "epoch 8 loss: 0.17630544304847717\n",
      "epoch 9 loss: 0.1506090760231018\n",
      "epoch 10 loss: 0.1340923309326172\n",
      "epoch 11 loss: 0.1520960032939911\n",
      "epoch 12 loss: 0.16832110285758972\n",
      "epoch 13 loss: 0.17415694892406464\n",
      "epoch 14 loss: 0.1733120232820511\n",
      "epoch 15 loss: 0.13715556263923645\n",
      "epoch 16 loss: 0.1862793266773224\n",
      "epoch 17 loss: 0.11563150584697723\n",
      "epoch 18 loss: 0.15354764461517334\n",
      "epoch 19 loss: 0.13748909533023834\n",
      "epoch 20 loss: 0.1547180563211441\n",
      "epoch 21 loss: 0.14345215260982513\n",
      "epoch 22 loss: 0.13010737299919128\n",
      "epoch 23 loss: 0.12747077643871307\n",
      "epoch 24 loss: 0.10403694212436676\n",
      "epoch 25 loss: 0.09680650383234024\n",
      "epoch 26 loss: 0.18768584728240967\n",
      "epoch 27 loss: 0.11915362626314163\n",
      "epoch 28 loss: 0.1186203807592392\n",
      "epoch 29 loss: 0.08893843740224838\n",
      "epoch 30 loss: 0.11706740409135818\n",
      "18\n",
      "epoch 1 loss: 0.9011970162391663\n",
      "epoch 2 loss: 0.5485180020332336\n",
      "epoch 3 loss: 0.375657856464386\n",
      "epoch 4 loss: 0.2544673979282379\n",
      "epoch 5 loss: 0.16406865417957306\n",
      "epoch 6 loss: 0.1807621419429779\n",
      "epoch 7 loss: 0.1337706595659256\n",
      "epoch 8 loss: 0.1813254952430725\n",
      "epoch 9 loss: 0.1761484295129776\n",
      "epoch 10 loss: 0.15407238900661469\n",
      "epoch 11 loss: 0.19859306514263153\n",
      "epoch 12 loss: 0.18923619389533997\n",
      "epoch 13 loss: 0.16993437707424164\n",
      "epoch 14 loss: 0.16297000646591187\n",
      "epoch 15 loss: 0.14287172257900238\n",
      "epoch 16 loss: 0.16191212832927704\n",
      "epoch 17 loss: 0.12109025567770004\n",
      "epoch 18 loss: 0.19900524616241455\n",
      "epoch 19 loss: 0.1441086232662201\n",
      "epoch 20 loss: 0.15929892659187317\n",
      "epoch 21 loss: 0.14196069538593292\n",
      "epoch 22 loss: 0.1323838084936142\n",
      "epoch 23 loss: 0.1089276447892189\n",
      "epoch 24 loss: 0.12467430531978607\n",
      "epoch 25 loss: 0.15936897695064545\n",
      "epoch 26 loss: 0.16289006173610687\n",
      "epoch 27 loss: 0.1279015988111496\n",
      "epoch 28 loss: 0.12960843741893768\n",
      "epoch 29 loss: 0.12827983498573303\n",
      "epoch 30 loss: 0.13876497745513916\n",
      "19\n",
      "epoch 1 loss: 0.9817320704460144\n",
      "epoch 2 loss: 0.5983188152313232\n",
      "epoch 3 loss: 0.37603187561035156\n",
      "epoch 4 loss: 0.21851828694343567\n",
      "epoch 5 loss: 0.16267074644565582\n",
      "epoch 6 loss: 0.1512513905763626\n",
      "epoch 7 loss: 0.14297893643379211\n",
      "epoch 8 loss: 0.1737356334924698\n",
      "epoch 9 loss: 0.14540906250476837\n",
      "epoch 10 loss: 0.20780952274799347\n",
      "epoch 11 loss: 0.1783275157213211\n",
      "epoch 12 loss: 0.13394047319889069\n",
      "epoch 13 loss: 0.16075913608074188\n",
      "epoch 14 loss: 0.13343536853790283\n",
      "epoch 15 loss: 0.17035935819149017\n",
      "epoch 16 loss: 0.1223394125699997\n",
      "epoch 17 loss: 0.15399986505508423\n",
      "epoch 18 loss: 0.11510893702507019\n",
      "epoch 19 loss: 0.1342756599187851\n",
      "epoch 20 loss: 0.11309769749641418\n",
      "epoch 21 loss: 0.10602246969938278\n",
      "epoch 22 loss: 0.10870581865310669\n",
      "epoch 23 loss: 0.11930042505264282\n",
      "epoch 24 loss: 0.12499356269836426\n",
      "epoch 25 loss: 0.13251997530460358\n",
      "epoch 26 loss: 0.10721860080957413\n",
      "epoch 27 loss: 0.12484366446733475\n",
      "epoch 28 loss: 0.09728699922561646\n",
      "epoch 29 loss: 0.07696221023797989\n",
      "epoch 30 loss: 0.09155590087175369\n",
      "20\n",
      "epoch 1 loss: 0.7622499465942383\n",
      "epoch 2 loss: 0.47610750794410706\n",
      "epoch 3 loss: 0.363077312707901\n",
      "epoch 4 loss: 0.20768091082572937\n",
      "epoch 5 loss: 0.18958178162574768\n",
      "epoch 6 loss: 0.15142002701759338\n",
      "epoch 7 loss: 0.18139268457889557\n",
      "epoch 8 loss: 0.14754925668239594\n",
      "epoch 9 loss: 0.15626971423625946\n",
      "epoch 10 loss: 0.1751633733510971\n",
      "epoch 11 loss: 0.16049104928970337\n",
      "epoch 12 loss: 0.1569751650094986\n",
      "epoch 13 loss: 0.12152764946222305\n",
      "epoch 14 loss: 0.1545698195695877\n",
      "epoch 15 loss: 0.16990402340888977\n",
      "epoch 16 loss: 0.14770260453224182\n",
      "epoch 17 loss: 0.1650490015745163\n",
      "epoch 18 loss: 0.11100423336029053\n",
      "epoch 19 loss: 0.1274876445531845\n",
      "epoch 20 loss: 0.14050936698913574\n",
      "epoch 21 loss: 0.19979378581047058\n",
      "epoch 22 loss: 0.15581421554088593\n",
      "epoch 23 loss: 0.15549762547016144\n",
      "epoch 24 loss: 0.18619538843631744\n",
      "epoch 25 loss: 0.12755461037158966\n",
      "epoch 26 loss: 0.11148358881473541\n",
      "epoch 27 loss: 0.16089941561222076\n",
      "epoch 28 loss: 0.09599079191684723\n",
      "epoch 29 loss: 0.11831047385931015\n",
      "epoch 30 loss: 0.12816545367240906\n",
      "21\n",
      "epoch 1 loss: 0.8193804621696472\n",
      "epoch 2 loss: 0.544431746006012\n",
      "epoch 3 loss: 0.4200742840766907\n",
      "epoch 4 loss: 0.2506598234176636\n",
      "epoch 5 loss: 0.18860088288784027\n",
      "epoch 6 loss: 0.1622341275215149\n",
      "epoch 7 loss: 0.13559173047542572\n",
      "epoch 8 loss: 0.13576878607273102\n",
      "epoch 9 loss: 0.14192615449428558\n",
      "epoch 10 loss: 0.169974684715271\n",
      "epoch 11 loss: 0.12373243272304535\n",
      "epoch 12 loss: 0.19591452181339264\n",
      "epoch 13 loss: 0.19318637251853943\n",
      "epoch 14 loss: 0.18055038154125214\n",
      "epoch 15 loss: 0.15965428948402405\n",
      "epoch 16 loss: 0.13358643651008606\n",
      "epoch 17 loss: 0.1709093153476715\n",
      "epoch 18 loss: 0.15383391082286835\n",
      "epoch 19 loss: 0.11008897423744202\n",
      "epoch 20 loss: 0.13966822624206543\n",
      "epoch 21 loss: 0.1140187680721283\n",
      "epoch 22 loss: 0.14269623160362244\n",
      "epoch 23 loss: 0.16584958136081696\n",
      "epoch 24 loss: 0.10500951111316681\n",
      "epoch 25 loss: 0.12857145071029663\n",
      "epoch 26 loss: 0.09740683436393738\n",
      "epoch 27 loss: 0.13620182871818542\n",
      "epoch 28 loss: 0.12262016534805298\n",
      "epoch 29 loss: 0.1063862070441246\n",
      "epoch 30 loss: 0.11528582125902176\n",
      "22\n",
      "epoch 1 loss: 0.8260577321052551\n",
      "epoch 2 loss: 0.42254793643951416\n",
      "epoch 3 loss: 0.2379351258277893\n",
      "epoch 4 loss: 0.16127614676952362\n",
      "epoch 5 loss: 0.18881410360336304\n",
      "epoch 6 loss: 0.17567792534828186\n",
      "epoch 7 loss: 0.13904021680355072\n",
      "epoch 8 loss: 0.13491620123386383\n",
      "epoch 9 loss: 0.1880708485841751\n",
      "epoch 10 loss: 0.1497909128665924\n",
      "epoch 11 loss: 0.13898590207099915\n",
      "epoch 12 loss: 0.17122314870357513\n",
      "epoch 13 loss: 0.1912779062986374\n",
      "epoch 14 loss: 0.16033585369586945\n",
      "epoch 15 loss: 0.12548969686031342\n",
      "epoch 16 loss: 0.1706356555223465\n",
      "epoch 17 loss: 0.13958291709423065\n",
      "epoch 18 loss: 0.14910581707954407\n",
      "epoch 19 loss: 0.15789707005023956\n",
      "epoch 20 loss: 0.1111622229218483\n",
      "epoch 21 loss: 0.12641067802906036\n",
      "epoch 22 loss: 0.11735479533672333\n",
      "epoch 23 loss: 0.1134299710392952\n",
      "epoch 24 loss: 0.11216272413730621\n",
      "epoch 25 loss: 0.12119138240814209\n",
      "epoch 26 loss: 0.1258191615343094\n",
      "epoch 27 loss: 0.09992675483226776\n",
      "epoch 28 loss: 0.179251566529274\n",
      "epoch 29 loss: 0.09534458070993423\n",
      "epoch 30 loss: 0.11326620727777481\n",
      "23\n",
      "epoch 1 loss: 0.7501683831214905\n",
      "epoch 2 loss: 0.5574878454208374\n",
      "epoch 3 loss: 0.31384047865867615\n",
      "epoch 4 loss: 0.20326387882232666\n",
      "epoch 5 loss: 0.1428675353527069\n",
      "epoch 6 loss: 0.16814164817333221\n",
      "epoch 7 loss: 0.15842841565608978\n",
      "epoch 8 loss: 0.17033129930496216\n",
      "epoch 9 loss: 0.14373385906219482\n",
      "epoch 10 loss: 0.1772962063550949\n",
      "epoch 11 loss: 0.17074786126613617\n",
      "epoch 12 loss: 0.16631343960762024\n",
      "epoch 13 loss: 0.13007651269435883\n",
      "epoch 14 loss: 0.22231723368167877\n",
      "epoch 15 loss: 0.13852570950984955\n",
      "epoch 16 loss: 0.1107407882809639\n",
      "epoch 17 loss: 0.21116355061531067\n",
      "epoch 18 loss: 0.11589739471673965\n",
      "epoch 19 loss: 0.12467867881059647\n",
      "epoch 20 loss: 0.12032774090766907\n",
      "epoch 21 loss: 0.15033946931362152\n",
      "epoch 22 loss: 0.09602238237857819\n",
      "epoch 23 loss: 0.10849199444055557\n",
      "epoch 24 loss: 0.11598660051822662\n",
      "epoch 25 loss: 0.11887001246213913\n",
      "epoch 26 loss: 0.12280087918043137\n",
      "epoch 27 loss: 0.11637105792760849\n",
      "epoch 28 loss: 0.131517231464386\n",
      "epoch 29 loss: 0.13544151186943054\n",
      "epoch 30 loss: 0.1282123625278473\n",
      "24\n",
      "epoch 1 loss: 0.7885109782218933\n",
      "epoch 2 loss: 0.5122559070587158\n",
      "epoch 3 loss: 0.30617305636405945\n",
      "epoch 4 loss: 0.18279731273651123\n",
      "epoch 5 loss: 0.15837985277175903\n",
      "epoch 6 loss: 0.1950950175523758\n",
      "epoch 7 loss: 0.17788159847259521\n",
      "epoch 8 loss: 0.1600116491317749\n",
      "epoch 9 loss: 0.1567246913909912\n",
      "epoch 10 loss: 0.1643398553133011\n",
      "epoch 11 loss: 0.15155735611915588\n",
      "epoch 12 loss: 0.12941136956214905\n",
      "epoch 13 loss: 0.16395603120326996\n",
      "epoch 14 loss: 0.14182910323143005\n",
      "epoch 15 loss: 0.1649497002363205\n",
      "epoch 16 loss: 0.15333417057991028\n",
      "epoch 17 loss: 0.15866722166538239\n",
      "epoch 18 loss: 0.13846488296985626\n",
      "epoch 19 loss: 0.15945430099964142\n",
      "epoch 20 loss: 0.10348913818597794\n",
      "epoch 21 loss: 0.10657808929681778\n",
      "epoch 22 loss: 0.12439095973968506\n",
      "epoch 23 loss: 0.09430805593729019\n",
      "epoch 24 loss: 0.0957460105419159\n",
      "epoch 25 loss: 0.09337896853685379\n",
      "epoch 26 loss: 0.10555149614810944\n",
      "epoch 27 loss: 0.10091867297887802\n",
      "epoch 28 loss: 0.09915614873170853\n",
      "epoch 29 loss: 0.10962188988924026\n",
      "epoch 30 loss: 0.10675735771656036\n",
      "25\n",
      "epoch 1 loss: 0.6163931488990784\n",
      "epoch 2 loss: 0.4623481333255768\n",
      "epoch 3 loss: 0.2582476735115051\n",
      "epoch 4 loss: 0.19756777584552765\n",
      "epoch 5 loss: 0.13232667744159698\n",
      "epoch 6 loss: 0.13413386046886444\n",
      "epoch 7 loss: 0.16028417646884918\n",
      "epoch 8 loss: 0.14511729776859283\n",
      "epoch 9 loss: 0.20887833833694458\n",
      "epoch 10 loss: 0.18049383163452148\n",
      "epoch 11 loss: 0.13067848980426788\n",
      "epoch 12 loss: 0.17785094678401947\n",
      "epoch 13 loss: 0.13517068326473236\n",
      "epoch 14 loss: 0.14029912650585175\n",
      "epoch 15 loss: 0.1622040569782257\n",
      "epoch 16 loss: 0.14952124655246735\n",
      "epoch 17 loss: 0.1277836710214615\n",
      "epoch 18 loss: 0.14610706269741058\n",
      "epoch 19 loss: 0.14788000285625458\n",
      "epoch 20 loss: 0.12357691675424576\n",
      "epoch 21 loss: 0.1485896110534668\n",
      "epoch 22 loss: 0.1272212266921997\n",
      "epoch 23 loss: 0.14226600527763367\n",
      "epoch 24 loss: 0.12027930468320847\n",
      "epoch 25 loss: 0.11352487653493881\n",
      "epoch 26 loss: 0.14652782678604126\n",
      "epoch 27 loss: 0.12483134865760803\n",
      "epoch 28 loss: 0.1277235895395279\n",
      "epoch 29 loss: 0.08288180083036423\n",
      "epoch 30 loss: 0.1064404621720314\n",
      "26\n",
      "epoch 1 loss: 0.6940585970878601\n",
      "epoch 2 loss: 0.7331206202507019\n",
      "epoch 3 loss: 0.4111315608024597\n",
      "epoch 4 loss: 0.22603479027748108\n",
      "epoch 5 loss: 0.17937077581882477\n",
      "epoch 6 loss: 0.1431005597114563\n",
      "epoch 7 loss: 0.15744079649448395\n",
      "epoch 8 loss: 0.15404526889324188\n",
      "epoch 9 loss: 0.16691388189792633\n",
      "epoch 10 loss: 0.17876560986042023\n",
      "epoch 11 loss: 0.16615888476371765\n",
      "epoch 12 loss: 0.1522156149148941\n",
      "epoch 13 loss: 0.13311012089252472\n",
      "epoch 14 loss: 0.1703815907239914\n",
      "epoch 15 loss: 0.11664179712533951\n",
      "epoch 16 loss: 0.16146177053451538\n",
      "epoch 17 loss: 0.12905676662921906\n",
      "epoch 18 loss: 0.12377633154392242\n",
      "epoch 19 loss: 0.12389900535345078\n",
      "epoch 20 loss: 0.1661527454853058\n",
      "epoch 21 loss: 0.11265457421541214\n",
      "epoch 22 loss: 0.1705157607793808\n",
      "epoch 23 loss: 0.10244203358888626\n",
      "epoch 24 loss: 0.11616712063550949\n",
      "epoch 25 loss: 0.1064981073141098\n",
      "epoch 26 loss: 0.13558730483055115\n",
      "epoch 27 loss: 0.1514786332845688\n",
      "epoch 28 loss: 0.09734729677438736\n",
      "epoch 29 loss: 0.09578167647123337\n",
      "epoch 30 loss: 0.13002832233905792\n",
      "27\n",
      "epoch 1 loss: 0.7789041996002197\n",
      "epoch 2 loss: 0.7346460223197937\n",
      "epoch 3 loss: 0.5303428769111633\n",
      "epoch 4 loss: 0.6714485883712769\n",
      "epoch 5 loss: 0.2860570251941681\n",
      "epoch 6 loss: 0.18121081590652466\n",
      "epoch 7 loss: 0.18686443567276\n",
      "epoch 8 loss: 0.1481029987335205\n",
      "epoch 9 loss: 0.15183500945568085\n",
      "epoch 10 loss: 0.16905298829078674\n",
      "epoch 11 loss: 0.14210058748722076\n",
      "epoch 12 loss: 0.16209116578102112\n",
      "epoch 13 loss: 0.12162768095731735\n",
      "epoch 14 loss: 0.14380140602588654\n",
      "epoch 15 loss: 0.16795068979263306\n",
      "epoch 16 loss: 0.16918319463729858\n",
      "epoch 17 loss: 0.17664943635463715\n",
      "epoch 18 loss: 0.1685974895954132\n",
      "epoch 19 loss: 0.14759033918380737\n",
      "epoch 20 loss: 0.12987244129180908\n",
      "epoch 21 loss: 0.13812263309955597\n",
      "epoch 22 loss: 0.10102946311235428\n",
      "epoch 23 loss: 0.11172997951507568\n",
      "epoch 24 loss: 0.15721745789051056\n",
      "epoch 25 loss: 0.13006135821342468\n",
      "epoch 26 loss: 0.0867086797952652\n",
      "epoch 27 loss: 0.12959441542625427\n",
      "epoch 28 loss: 0.1273440420627594\n",
      "epoch 29 loss: 0.10799162834882736\n",
      "epoch 30 loss: 0.11716880649328232\n",
      "28\n",
      "epoch 1 loss: 0.7088703513145447\n",
      "epoch 2 loss: 0.6230452060699463\n",
      "epoch 3 loss: 0.534451961517334\n",
      "epoch 4 loss: 0.9464678168296814\n",
      "epoch 5 loss: 0.6229717135429382\n",
      "epoch 6 loss: 0.2687638998031616\n",
      "epoch 7 loss: 0.26375749707221985\n",
      "epoch 8 loss: 0.2154170423746109\n",
      "epoch 9 loss: 0.18099439144134521\n",
      "epoch 10 loss: 0.17791828513145447\n",
      "epoch 11 loss: 0.17253458499908447\n",
      "epoch 12 loss: 0.201995849609375\n",
      "epoch 13 loss: 0.1564977467060089\n",
      "epoch 14 loss: 0.15775594115257263\n",
      "epoch 15 loss: 0.14110592007637024\n",
      "epoch 16 loss: 0.1466255635023117\n",
      "epoch 17 loss: 0.1548011302947998\n",
      "epoch 18 loss: 0.1504846215248108\n",
      "epoch 19 loss: 0.18997445702552795\n",
      "epoch 20 loss: 0.17714816331863403\n",
      "epoch 21 loss: 0.13896504044532776\n",
      "epoch 22 loss: 0.13523411750793457\n",
      "epoch 23 loss: 0.13601067662239075\n",
      "epoch 24 loss: 0.14461839199066162\n",
      "epoch 25 loss: 0.13985151052474976\n",
      "epoch 26 loss: 0.16077472269535065\n",
      "epoch 27 loss: 0.16292820870876312\n",
      "epoch 28 loss: 0.1414034217596054\n",
      "epoch 29 loss: 0.13835668563842773\n",
      "epoch 30 loss: 0.17663702368736267\n",
      "29\n",
      "epoch 1 loss: 0.865366518497467\n",
      "epoch 2 loss: 0.5424720048904419\n",
      "epoch 3 loss: 0.2952742576599121\n",
      "epoch 4 loss: 0.21626988053321838\n",
      "epoch 5 loss: 0.2021239846944809\n",
      "epoch 6 loss: 0.18597963452339172\n",
      "epoch 7 loss: 0.14020968973636627\n",
      "epoch 8 loss: 0.17221443355083466\n",
      "epoch 9 loss: 0.12316246330738068\n",
      "epoch 10 loss: 0.14531844854354858\n",
      "epoch 11 loss: 0.1746620088815689\n",
      "epoch 12 loss: 0.12939460575580597\n",
      "epoch 13 loss: 0.17616091668605804\n",
      "epoch 14 loss: 0.21006223559379578\n",
      "epoch 15 loss: 0.14449095726013184\n",
      "epoch 16 loss: 0.150892972946167\n",
      "epoch 17 loss: 0.15371525287628174\n",
      "epoch 18 loss: 0.14791563153266907\n",
      "epoch 19 loss: 0.1687183976173401\n",
      "epoch 20 loss: 0.11000284552574158\n",
      "epoch 21 loss: 0.16805334389209747\n",
      "epoch 22 loss: 0.12306501716375351\n",
      "epoch 23 loss: 0.09662118554115295\n",
      "epoch 24 loss: 0.1634557843208313\n",
      "epoch 25 loss: 0.10952489823102951\n",
      "epoch 26 loss: 0.10159069299697876\n",
      "epoch 27 loss: 0.11498036980628967\n",
      "epoch 28 loss: 0.18059119582176208\n",
      "epoch 29 loss: 0.11953942477703094\n",
      "epoch 30 loss: 0.11699370294809341\n",
      "30\n",
      "epoch 1 loss: 0.8933869004249573\n",
      "epoch 2 loss: 0.5482165217399597\n",
      "epoch 3 loss: 0.21829630434513092\n",
      "epoch 4 loss: 0.2112855613231659\n",
      "epoch 5 loss: 0.17708826065063477\n",
      "epoch 6 loss: 0.15502606332302094\n",
      "epoch 7 loss: 0.18460804224014282\n",
      "epoch 8 loss: 0.17600683867931366\n",
      "epoch 9 loss: 0.1697082221508026\n",
      "epoch 10 loss: 0.18640540540218353\n",
      "epoch 11 loss: 0.1806960105895996\n",
      "epoch 12 loss: 0.16622282564640045\n",
      "epoch 13 loss: 0.1899709403514862\n",
      "epoch 14 loss: 0.14525367319583893\n",
      "epoch 15 loss: 0.15664096176624298\n",
      "epoch 16 loss: 0.14253045618534088\n",
      "epoch 17 loss: 0.13271000981330872\n",
      "epoch 18 loss: 0.12363795936107635\n",
      "epoch 19 loss: 0.14881518483161926\n",
      "epoch 20 loss: 0.10607217997312546\n",
      "epoch 21 loss: 0.1339792013168335\n",
      "epoch 22 loss: 0.1292748600244522\n",
      "epoch 23 loss: 0.11579665541648865\n",
      "epoch 24 loss: 0.07515400648117065\n",
      "epoch 25 loss: 0.11107587814331055\n",
      "epoch 26 loss: 0.08945027738809586\n",
      "epoch 27 loss: 0.13070803880691528\n",
      "epoch 28 loss: 0.116451196372509\n",
      "epoch 29 loss: 0.16608570516109467\n",
      "epoch 30 loss: 0.0860661193728447\n",
      "31\n",
      "epoch 1 loss: 0.9536559581756592\n",
      "epoch 2 loss: 0.587149441242218\n",
      "epoch 3 loss: 0.2807934582233429\n",
      "epoch 4 loss: 0.17491890490055084\n",
      "epoch 5 loss: 0.212276428937912\n",
      "epoch 6 loss: 0.17993350327014923\n",
      "epoch 7 loss: 0.1599249541759491\n",
      "epoch 8 loss: 0.15637382864952087\n",
      "epoch 9 loss: 0.1702558696269989\n",
      "epoch 10 loss: 0.17179042100906372\n",
      "epoch 11 loss: 0.17028778791427612\n",
      "epoch 12 loss: 0.1658189594745636\n",
      "epoch 13 loss: 0.14688296616077423\n",
      "epoch 14 loss: 0.1637478619813919\n",
      "epoch 15 loss: 0.16341625154018402\n",
      "epoch 16 loss: 0.15366147458553314\n",
      "epoch 17 loss: 0.16762834787368774\n",
      "epoch 18 loss: 0.1374315619468689\n",
      "epoch 19 loss: 0.1849157214164734\n",
      "epoch 20 loss: 0.1117449626326561\n",
      "epoch 21 loss: 0.13975563645362854\n",
      "epoch 22 loss: 0.14878125488758087\n",
      "epoch 23 loss: 0.10872647166252136\n",
      "epoch 24 loss: 0.11598474532365799\n",
      "epoch 25 loss: 0.10809393227100372\n",
      "epoch 26 loss: 0.07634519040584564\n",
      "epoch 27 loss: 0.11946599185466766\n",
      "epoch 28 loss: 0.1258508265018463\n",
      "epoch 29 loss: 0.11553766578435898\n",
      "epoch 30 loss: 0.09822407364845276\n",
      "32\n",
      "epoch 1 loss: 1.0071830749511719\n",
      "epoch 2 loss: 0.6530688405036926\n",
      "epoch 3 loss: 0.39221999049186707\n",
      "epoch 4 loss: 0.33406397700309753\n",
      "epoch 5 loss: 0.19955623149871826\n",
      "epoch 6 loss: 0.19439581036567688\n",
      "epoch 7 loss: 0.19428132474422455\n",
      "epoch 8 loss: 0.1327161341905594\n",
      "epoch 9 loss: 0.18171420693397522\n",
      "epoch 10 loss: 0.15395723283290863\n",
      "epoch 11 loss: 0.1589009165763855\n",
      "epoch 12 loss: 0.14008386433124542\n",
      "epoch 13 loss: 0.1728322058916092\n",
      "epoch 14 loss: 0.142301544547081\n",
      "epoch 15 loss: 0.1694098711013794\n",
      "epoch 16 loss: 0.14356152713298798\n",
      "epoch 17 loss: 0.17596642673015594\n",
      "epoch 18 loss: 0.15132935345172882\n",
      "epoch 19 loss: 0.13336385786533356\n",
      "epoch 20 loss: 0.1449320763349533\n",
      "epoch 21 loss: 0.14252573251724243\n",
      "epoch 22 loss: 0.1422196328639984\n",
      "epoch 23 loss: 0.11617264151573181\n",
      "epoch 24 loss: 0.14709001779556274\n",
      "epoch 25 loss: 0.1297018975019455\n",
      "epoch 26 loss: 0.10198134928941727\n",
      "epoch 27 loss: 0.0841565653681755\n",
      "epoch 28 loss: 0.0848034918308258\n",
      "epoch 29 loss: 0.12136689573526382\n",
      "epoch 30 loss: 0.10080869495868683\n",
      "33\n",
      "epoch 1 loss: 1.3072603940963745\n",
      "epoch 2 loss: 0.5871149301528931\n",
      "epoch 3 loss: 0.29886573553085327\n",
      "epoch 4 loss: 0.1799340397119522\n",
      "epoch 5 loss: 0.20379695296287537\n",
      "epoch 6 loss: 0.16993457078933716\n",
      "epoch 7 loss: 0.17824093997478485\n",
      "epoch 8 loss: 0.15833425521850586\n",
      "epoch 9 loss: 0.16042110323905945\n",
      "epoch 10 loss: 0.16035398840904236\n",
      "epoch 11 loss: 0.17727941274642944\n",
      "epoch 12 loss: 0.15067298710346222\n",
      "epoch 13 loss: 0.1369394212961197\n",
      "epoch 14 loss: 0.13130952417850494\n",
      "epoch 15 loss: 0.12806765735149384\n",
      "epoch 16 loss: 0.16845177114009857\n",
      "epoch 17 loss: 0.14052416384220123\n",
      "epoch 18 loss: 0.11719357967376709\n",
      "epoch 19 loss: 0.11456463485956192\n",
      "epoch 20 loss: 0.08906830102205276\n",
      "epoch 21 loss: 0.11554549634456635\n",
      "epoch 22 loss: 0.10234721004962921\n",
      "epoch 23 loss: 0.09601999074220657\n",
      "epoch 24 loss: 0.14235307276248932\n",
      "epoch 25 loss: 0.09793294966220856\n",
      "epoch 26 loss: 0.07756268233060837\n",
      "epoch 27 loss: 0.09457571059465408\n",
      "epoch 28 loss: 0.11729598790407181\n",
      "epoch 29 loss: 0.09897672384977341\n",
      "epoch 30 loss: 0.08703137189149857\n",
      "34\n",
      "epoch 1 loss: 0.9790176749229431\n",
      "epoch 2 loss: 0.5169505476951599\n",
      "epoch 3 loss: 0.35584303736686707\n",
      "epoch 4 loss: 0.23356083035469055\n",
      "epoch 5 loss: 0.1445053070783615\n",
      "epoch 6 loss: 0.15810203552246094\n",
      "epoch 7 loss: 0.2013048231601715\n",
      "epoch 8 loss: 0.13724909722805023\n",
      "epoch 9 loss: 0.15838061273097992\n",
      "epoch 10 loss: 0.16269832849502563\n",
      "epoch 11 loss: 0.16658100485801697\n",
      "epoch 12 loss: 0.15973909199237823\n",
      "epoch 13 loss: 0.16009271144866943\n",
      "epoch 14 loss: 0.1443469077348709\n",
      "epoch 15 loss: 0.13931356370449066\n",
      "epoch 16 loss: 0.13517498970031738\n",
      "epoch 17 loss: 0.15240125358104706\n",
      "epoch 18 loss: 0.1020435094833374\n",
      "epoch 19 loss: 0.19687245786190033\n",
      "epoch 20 loss: 0.12772278487682343\n",
      "epoch 21 loss: 0.12172915786504745\n",
      "epoch 22 loss: 0.11534963548183441\n",
      "epoch 23 loss: 0.12909629940986633\n",
      "epoch 24 loss: 0.130741149187088\n",
      "epoch 25 loss: 0.11438987404108047\n",
      "epoch 26 loss: 0.10730019211769104\n",
      "epoch 27 loss: 0.09581300616264343\n",
      "epoch 28 loss: 0.13359209895133972\n",
      "epoch 29 loss: 0.10131476074457169\n",
      "epoch 30 loss: 0.10399758815765381\n",
      "35\n",
      "epoch 1 loss: 0.879269540309906\n",
      "epoch 2 loss: 0.5607381463050842\n",
      "epoch 3 loss: 0.3009595274925232\n",
      "epoch 4 loss: 0.2333909422159195\n",
      "epoch 5 loss: 0.1875060498714447\n",
      "epoch 6 loss: 0.1480732560157776\n",
      "epoch 7 loss: 0.1468384712934494\n",
      "epoch 8 loss: 0.1641763597726822\n",
      "epoch 9 loss: 0.16116754710674286\n",
      "epoch 10 loss: 0.19464194774627686\n",
      "epoch 11 loss: 0.21120430529117584\n",
      "epoch 12 loss: 0.1693943291902542\n",
      "epoch 13 loss: 0.14949548244476318\n",
      "epoch 14 loss: 0.20190639793872833\n",
      "epoch 15 loss: 0.16089531779289246\n",
      "epoch 16 loss: 0.1456165611743927\n",
      "epoch 17 loss: 0.13705706596374512\n",
      "epoch 18 loss: 0.15213388204574585\n",
      "epoch 19 loss: 0.1364666074514389\n",
      "epoch 20 loss: 0.12980219721794128\n",
      "epoch 21 loss: 0.10941563546657562\n",
      "epoch 22 loss: 0.16653446853160858\n",
      "epoch 23 loss: 0.12266039848327637\n",
      "epoch 24 loss: 0.12779146432876587\n",
      "epoch 25 loss: 0.10524394363164902\n",
      "epoch 26 loss: 0.12646861374378204\n",
      "epoch 27 loss: 0.11878328770399094\n",
      "epoch 28 loss: 0.11081605404615402\n",
      "epoch 29 loss: 0.1069326177239418\n",
      "epoch 30 loss: 0.10846097022294998\n",
      "36\n",
      "epoch 1 loss: 0.8354312777519226\n",
      "epoch 2 loss: 0.42843595147132874\n",
      "epoch 3 loss: 0.18513177335262299\n",
      "epoch 4 loss: 0.21262118220329285\n",
      "epoch 5 loss: 0.16544969379901886\n",
      "epoch 6 loss: 0.16186155378818512\n",
      "epoch 7 loss: 0.19669660925865173\n",
      "epoch 8 loss: 0.14195731282234192\n",
      "epoch 9 loss: 0.14872464537620544\n",
      "epoch 10 loss: 0.1298341602087021\n",
      "epoch 11 loss: 0.19391120970249176\n",
      "epoch 12 loss: 0.12480933219194412\n",
      "epoch 13 loss: 0.13775166869163513\n",
      "epoch 14 loss: 0.14337174594402313\n",
      "epoch 15 loss: 0.14591749012470245\n",
      "epoch 16 loss: 0.12884609401226044\n",
      "epoch 17 loss: 0.12510725855827332\n",
      "epoch 18 loss: 0.15018144249916077\n",
      "epoch 19 loss: 0.16251283884048462\n",
      "epoch 20 loss: 0.16958226263523102\n",
      "epoch 21 loss: 0.13819614052772522\n",
      "epoch 22 loss: 0.1280534416437149\n",
      "epoch 23 loss: 0.14983466267585754\n",
      "epoch 24 loss: 0.08359768986701965\n",
      "epoch 25 loss: 0.10216601192951202\n",
      "epoch 26 loss: 0.14751186966896057\n",
      "epoch 27 loss: 0.14920251071453094\n",
      "epoch 28 loss: 0.13539938628673553\n",
      "epoch 29 loss: 0.09514099359512329\n",
      "epoch 30 loss: 0.13638530671596527\n",
      "37\n",
      "epoch 1 loss: 0.8678292632102966\n",
      "epoch 2 loss: 0.6290515661239624\n",
      "epoch 3 loss: 0.46130701899528503\n",
      "epoch 4 loss: 0.22256410121917725\n",
      "epoch 5 loss: 0.22366869449615479\n",
      "epoch 6 loss: 0.16899371147155762\n",
      "epoch 7 loss: 0.16799196600914001\n",
      "epoch 8 loss: 0.15752558410167694\n",
      "epoch 9 loss: 0.1789853572845459\n",
      "epoch 10 loss: 0.1378823220729828\n",
      "epoch 11 loss: 0.17238806188106537\n",
      "epoch 12 loss: 0.1389082372188568\n",
      "epoch 13 loss: 0.1420055329799652\n",
      "epoch 14 loss: 0.18761926889419556\n",
      "epoch 15 loss: 0.13344810903072357\n",
      "epoch 16 loss: 0.16129791736602783\n",
      "epoch 17 loss: 0.14929018914699554\n",
      "epoch 18 loss: 0.16079895198345184\n",
      "epoch 19 loss: 0.16728030145168304\n",
      "epoch 20 loss: 0.15360359847545624\n",
      "epoch 21 loss: 0.13069112598896027\n",
      "epoch 22 loss: 0.11787457764148712\n",
      "epoch 23 loss: 0.11724783480167389\n",
      "epoch 24 loss: 0.12274155765771866\n",
      "epoch 25 loss: 0.12695209681987762\n",
      "epoch 26 loss: 0.1388135403394699\n",
      "epoch 27 loss: 0.10108763724565506\n",
      "epoch 28 loss: 0.1237335279583931\n",
      "epoch 29 loss: 0.12651020288467407\n",
      "epoch 30 loss: 0.13841630518436432\n",
      "38\n",
      "epoch 1 loss: 0.9524657130241394\n",
      "epoch 2 loss: 0.830750048160553\n",
      "epoch 3 loss: 0.48870334029197693\n",
      "epoch 4 loss: 0.2545660734176636\n",
      "epoch 5 loss: 0.20855580270290375\n",
      "epoch 6 loss: 0.1665402203798294\n",
      "epoch 7 loss: 0.15735076367855072\n",
      "epoch 8 loss: 0.16676892340183258\n",
      "epoch 9 loss: 0.1739259511232376\n",
      "epoch 10 loss: 0.1527998298406601\n",
      "epoch 11 loss: 0.14486084878444672\n",
      "epoch 12 loss: 0.20694509148597717\n",
      "epoch 13 loss: 0.17366309463977814\n",
      "epoch 14 loss: 0.2010924220085144\n",
      "epoch 15 loss: 0.13046510517597198\n",
      "epoch 16 loss: 0.13850490748882294\n",
      "epoch 17 loss: 0.14027902483940125\n",
      "epoch 18 loss: 0.18761806190013885\n",
      "epoch 19 loss: 0.13474689424037933\n",
      "epoch 20 loss: 0.12874504923820496\n",
      "epoch 21 loss: 0.13409189879894257\n",
      "epoch 22 loss: 0.18035702407360077\n",
      "epoch 23 loss: 0.10325111448764801\n",
      "epoch 24 loss: 0.11234697699546814\n",
      "epoch 25 loss: 0.11625947803258896\n",
      "epoch 26 loss: 0.10442288219928741\n",
      "epoch 27 loss: 0.1162697970867157\n",
      "epoch 28 loss: 0.11782976239919662\n",
      "epoch 29 loss: 0.10902132838964462\n",
      "epoch 30 loss: 0.10044880956411362\n",
      "39\n",
      "epoch 1 loss: 0.7441560626029968\n",
      "epoch 2 loss: 0.5312454104423523\n",
      "epoch 3 loss: 0.336089551448822\n",
      "epoch 4 loss: 0.23141120374202728\n",
      "epoch 5 loss: 0.20245826244354248\n",
      "epoch 6 loss: 0.15574151277542114\n",
      "epoch 7 loss: 0.1582537293434143\n",
      "epoch 8 loss: 0.1572323888540268\n",
      "epoch 9 loss: 0.18203075230121613\n",
      "epoch 10 loss: 0.16325296461582184\n",
      "epoch 11 loss: 0.15596908330917358\n",
      "epoch 12 loss: 0.16455133259296417\n",
      "epoch 13 loss: 0.17906256020069122\n",
      "epoch 14 loss: 0.152025043964386\n",
      "epoch 15 loss: 0.14725686609745026\n",
      "epoch 16 loss: 0.11161939799785614\n",
      "epoch 17 loss: 0.10595351457595825\n",
      "epoch 18 loss: 0.14231882989406586\n",
      "epoch 19 loss: 0.13855481147766113\n",
      "epoch 20 loss: 0.10345891118049622\n",
      "epoch 21 loss: 0.140043705701828\n",
      "epoch 22 loss: 0.12424154579639435\n",
      "epoch 23 loss: 0.08345009386539459\n",
      "epoch 24 loss: 0.12502814829349518\n",
      "epoch 25 loss: 0.14006316661834717\n",
      "epoch 26 loss: 0.1204570010304451\n",
      "epoch 27 loss: 0.10510796308517456\n",
      "epoch 28 loss: 0.11291584372520447\n",
      "epoch 29 loss: 0.10984481871128082\n",
      "epoch 30 loss: 0.10462918877601624\n",
      "40\n",
      "epoch 1 loss: 0.8122873306274414\n",
      "epoch 2 loss: 0.7779856324195862\n",
      "epoch 3 loss: 0.7764664888381958\n",
      "epoch 4 loss: 0.3776082992553711\n",
      "epoch 5 loss: 0.467911958694458\n",
      "epoch 6 loss: 0.22750674188137054\n",
      "epoch 7 loss: 0.1587340086698532\n",
      "epoch 8 loss: 0.1857406198978424\n",
      "epoch 9 loss: 0.18255670368671417\n",
      "epoch 10 loss: 0.16706250607967377\n",
      "epoch 11 loss: 0.15650464594364166\n",
      "epoch 12 loss: 0.1755519062280655\n",
      "epoch 13 loss: 0.1415359079837799\n",
      "epoch 14 loss: 0.17203399538993835\n",
      "epoch 15 loss: 0.14445215463638306\n",
      "epoch 16 loss: 0.15236155688762665\n",
      "epoch 17 loss: 0.14306102693080902\n",
      "epoch 18 loss: 0.1912326216697693\n",
      "epoch 19 loss: 0.14449356496334076\n",
      "epoch 20 loss: 0.16067644953727722\n",
      "epoch 21 loss: 0.13752895593643188\n",
      "epoch 22 loss: 0.1776552051305771\n",
      "epoch 23 loss: 0.1485898792743683\n",
      "epoch 24 loss: 0.12938500940799713\n",
      "epoch 25 loss: 0.2321118712425232\n",
      "epoch 26 loss: 0.1382141411304474\n",
      "epoch 27 loss: 0.1416458636522293\n",
      "epoch 28 loss: 0.12382105737924576\n",
      "epoch 29 loss: 0.16277605295181274\n",
      "epoch 30 loss: 0.11070685088634491\n",
      "41\n",
      "epoch 1 loss: 0.8466268181800842\n",
      "epoch 2 loss: 0.45468389987945557\n",
      "epoch 3 loss: 0.35495439171791077\n",
      "epoch 4 loss: 0.20592284202575684\n",
      "epoch 5 loss: 0.23766164481639862\n",
      "epoch 6 loss: 0.14685416221618652\n",
      "epoch 7 loss: 0.15077222883701324\n",
      "epoch 8 loss: 0.15620654821395874\n",
      "epoch 9 loss: 0.150642529129982\n",
      "epoch 10 loss: 0.15447568893432617\n",
      "epoch 11 loss: 0.16757214069366455\n",
      "epoch 12 loss: 0.14994429051876068\n",
      "epoch 13 loss: 0.148887500166893\n",
      "epoch 14 loss: 0.14118577539920807\n",
      "epoch 15 loss: 0.1702256053686142\n",
      "epoch 16 loss: 0.1505349576473236\n",
      "epoch 17 loss: 0.13889212906360626\n",
      "epoch 18 loss: 0.11116676777601242\n",
      "epoch 19 loss: 0.12887798249721527\n",
      "epoch 20 loss: 0.1615811437368393\n",
      "epoch 21 loss: 0.1138477623462677\n",
      "epoch 22 loss: 0.13796178996562958\n",
      "epoch 23 loss: 0.16323749721050262\n",
      "epoch 24 loss: 0.11333827674388885\n",
      "epoch 25 loss: 0.127945676445961\n",
      "epoch 26 loss: 0.11318700760602951\n",
      "epoch 27 loss: 0.11525047570466995\n",
      "epoch 28 loss: 0.11332863569259644\n",
      "epoch 29 loss: 0.09713581949472427\n",
      "epoch 30 loss: 0.09457527846097946\n",
      "42\n",
      "epoch 1 loss: 0.8042124509811401\n",
      "epoch 2 loss: 0.5148783326148987\n",
      "epoch 3 loss: 0.2869672477245331\n",
      "epoch 4 loss: 0.1748257726430893\n",
      "epoch 5 loss: 0.2143690139055252\n",
      "epoch 6 loss: 0.14937250316143036\n",
      "epoch 7 loss: 0.1999402940273285\n",
      "epoch 8 loss: 0.1914987564086914\n",
      "epoch 9 loss: 0.16647741198539734\n",
      "epoch 10 loss: 0.1715846061706543\n",
      "epoch 11 loss: 0.1275782585144043\n",
      "epoch 12 loss: 0.15462876856327057\n",
      "epoch 13 loss: 0.15089420974254608\n",
      "epoch 14 loss: 0.1473122239112854\n",
      "epoch 15 loss: 0.14828379452228546\n",
      "epoch 16 loss: 0.15904562175273895\n",
      "epoch 17 loss: 0.14451570808887482\n",
      "epoch 18 loss: 0.22270993888378143\n",
      "epoch 19 loss: 0.13118718564510345\n",
      "epoch 20 loss: 0.12859177589416504\n",
      "epoch 21 loss: 0.11408611387014389\n",
      "epoch 22 loss: 0.17033830285072327\n",
      "epoch 23 loss: 0.11991985887289047\n",
      "epoch 24 loss: 0.11640365421772003\n",
      "epoch 25 loss: 0.14700190722942352\n",
      "epoch 26 loss: 0.11060847342014313\n",
      "epoch 27 loss: 0.09943743795156479\n",
      "epoch 28 loss: 0.10333093255758286\n",
      "epoch 29 loss: 0.09936685860157013\n",
      "epoch 30 loss: 0.0801469162106514\n",
      "43\n",
      "epoch 1 loss: 0.7363334894180298\n",
      "epoch 2 loss: 0.4219750761985779\n",
      "epoch 3 loss: 0.2878553867340088\n",
      "epoch 4 loss: 0.20485273003578186\n",
      "epoch 5 loss: 0.16222421824932098\n",
      "epoch 6 loss: 0.20128798484802246\n",
      "epoch 7 loss: 0.18250539898872375\n",
      "epoch 8 loss: 0.18741896748542786\n",
      "epoch 9 loss: 0.18558654189109802\n",
      "epoch 10 loss: 0.18658827245235443\n",
      "epoch 11 loss: 0.15442292392253876\n",
      "epoch 12 loss: 0.16829489171504974\n",
      "epoch 13 loss: 0.1624670922756195\n",
      "epoch 14 loss: 0.17245987057685852\n",
      "epoch 15 loss: 0.1441808044910431\n",
      "epoch 16 loss: 0.12051540613174438\n",
      "epoch 17 loss: 0.16475124657154083\n",
      "epoch 18 loss: 0.18433120846748352\n",
      "epoch 19 loss: 0.13253706693649292\n",
      "epoch 20 loss: 0.14552411437034607\n",
      "epoch 21 loss: 0.12522611021995544\n",
      "epoch 22 loss: 0.11644763499498367\n",
      "epoch 23 loss: 0.147233247756958\n",
      "epoch 24 loss: 0.09503825008869171\n",
      "epoch 25 loss: 0.1516478806734085\n",
      "epoch 26 loss: 0.09623798727989197\n",
      "epoch 27 loss: 0.10264337062835693\n",
      "epoch 28 loss: 0.11608254164457321\n",
      "epoch 29 loss: 0.09866448491811752\n",
      "epoch 30 loss: 0.11522723734378815\n",
      "44\n",
      "epoch 1 loss: 0.7150202393531799\n",
      "epoch 2 loss: 0.44564729928970337\n",
      "epoch 3 loss: 0.27774521708488464\n",
      "epoch 4 loss: 0.16491660475730896\n",
      "epoch 5 loss: 0.15428456664085388\n",
      "epoch 6 loss: 0.18219809234142303\n",
      "epoch 7 loss: 0.196499302983284\n",
      "epoch 8 loss: 0.18702669441699982\n",
      "epoch 9 loss: 0.17167270183563232\n",
      "epoch 10 loss: 0.1533166766166687\n",
      "epoch 11 loss: 0.15208852291107178\n",
      "epoch 12 loss: 0.17613177001476288\n",
      "epoch 13 loss: 0.17798258364200592\n",
      "epoch 14 loss: 0.16742868721485138\n",
      "epoch 15 loss: 0.10925847291946411\n",
      "epoch 16 loss: 0.15329144895076752\n",
      "epoch 17 loss: 0.16588197648525238\n",
      "epoch 18 loss: 0.14006781578063965\n",
      "epoch 19 loss: 0.15902066230773926\n",
      "epoch 20 loss: 0.16946633160114288\n",
      "epoch 21 loss: 0.19640205800533295\n",
      "epoch 22 loss: 0.1494836062192917\n",
      "epoch 23 loss: 0.1438784897327423\n",
      "epoch 24 loss: 0.12946735322475433\n",
      "epoch 25 loss: 0.14906838536262512\n",
      "epoch 26 loss: 0.1383480578660965\n",
      "epoch 27 loss: 0.1300763338804245\n",
      "epoch 28 loss: 0.13027074933052063\n",
      "epoch 29 loss: 0.15211614966392517\n",
      "epoch 30 loss: 0.09825707972049713\n",
      "45\n",
      "epoch 1 loss: 0.7496638894081116\n",
      "epoch 2 loss: 0.4677669405937195\n",
      "epoch 3 loss: 0.25844889879226685\n",
      "epoch 4 loss: 0.21752649545669556\n",
      "epoch 5 loss: 0.20555812120437622\n",
      "epoch 6 loss: 0.14762061834335327\n",
      "epoch 7 loss: 0.15737582743167877\n",
      "epoch 8 loss: 0.15576787292957306\n",
      "epoch 9 loss: 0.14555929601192474\n",
      "epoch 10 loss: 0.17241448163986206\n",
      "epoch 11 loss: 0.177761971950531\n",
      "epoch 12 loss: 0.14330945909023285\n",
      "epoch 13 loss: 0.17717789113521576\n",
      "epoch 14 loss: 0.13436472415924072\n",
      "epoch 15 loss: 0.1453918069601059\n",
      "epoch 16 loss: 0.190533846616745\n",
      "epoch 17 loss: 0.15231941640377045\n",
      "epoch 18 loss: 0.15892332792282104\n",
      "epoch 19 loss: 0.15347430109977722\n",
      "epoch 20 loss: 0.11929785460233688\n",
      "epoch 21 loss: 0.09501400589942932\n",
      "epoch 22 loss: 0.1168983206152916\n",
      "epoch 23 loss: 0.16257552802562714\n",
      "epoch 24 loss: 0.10142385959625244\n",
      "epoch 25 loss: 0.11995070427656174\n",
      "epoch 26 loss: 0.1336030215024948\n",
      "epoch 27 loss: 0.07666850090026855\n",
      "epoch 28 loss: 0.08225234597921371\n",
      "epoch 29 loss: 0.09167776256799698\n",
      "epoch 30 loss: 0.09173990041017532\n",
      "46\n",
      "epoch 1 loss: 0.8359594345092773\n",
      "epoch 2 loss: 0.7176241874694824\n",
      "epoch 3 loss: 0.3487950563430786\n",
      "epoch 4 loss: 0.22200746834278107\n",
      "epoch 5 loss: 0.1817728728055954\n",
      "epoch 6 loss: 0.1693957895040512\n",
      "epoch 7 loss: 0.15556709468364716\n",
      "epoch 8 loss: 0.16085098683834076\n",
      "epoch 9 loss: 0.12991684675216675\n",
      "epoch 10 loss: 0.1615474373102188\n",
      "epoch 11 loss: 0.18090727925300598\n",
      "epoch 12 loss: 0.15749084949493408\n",
      "epoch 13 loss: 0.16036711633205414\n",
      "epoch 14 loss: 0.13299305737018585\n",
      "epoch 15 loss: 0.19565360248088837\n",
      "epoch 16 loss: 0.17000766098499298\n",
      "epoch 17 loss: 0.15683138370513916\n",
      "epoch 18 loss: 0.16962070763111115\n",
      "epoch 19 loss: 0.10625510662794113\n",
      "epoch 20 loss: 0.12808530032634735\n",
      "epoch 21 loss: 0.14407919347286224\n",
      "epoch 22 loss: 0.12170321494340897\n",
      "epoch 23 loss: 0.1413826048374176\n",
      "epoch 24 loss: 0.11047173291444778\n",
      "epoch 25 loss: 0.11807861924171448\n",
      "epoch 26 loss: 0.08144674450159073\n",
      "epoch 27 loss: 0.10594801604747772\n",
      "epoch 28 loss: 0.09887193143367767\n",
      "epoch 29 loss: 0.12528294324874878\n",
      "epoch 30 loss: 0.08807938545942307\n",
      "47\n",
      "epoch 1 loss: 0.7812246084213257\n",
      "epoch 2 loss: 0.4688737094402313\n",
      "epoch 3 loss: 0.20201104879379272\n",
      "epoch 4 loss: 0.17512445151805878\n",
      "epoch 5 loss: 0.19617384672164917\n",
      "epoch 6 loss: 0.21603688597679138\n",
      "epoch 7 loss: 0.1758720427751541\n",
      "epoch 8 loss: 0.19036263227462769\n",
      "epoch 9 loss: 0.15977802872657776\n",
      "epoch 10 loss: 0.1886574625968933\n",
      "epoch 11 loss: 0.18855158984661102\n",
      "epoch 12 loss: 0.1036776676774025\n",
      "epoch 13 loss: 0.18042869865894318\n",
      "epoch 14 loss: 0.12426542490720749\n",
      "epoch 15 loss: 0.16382865607738495\n",
      "epoch 16 loss: 0.16239963471889496\n",
      "epoch 17 loss: 0.16976690292358398\n",
      "epoch 18 loss: 0.17316728830337524\n",
      "epoch 19 loss: 0.18029774725437164\n",
      "epoch 20 loss: 0.15590104460716248\n",
      "epoch 21 loss: 0.1497165709733963\n",
      "epoch 22 loss: 0.14249542355537415\n",
      "epoch 23 loss: 0.11919432878494263\n",
      "epoch 24 loss: 0.14280849695205688\n",
      "epoch 25 loss: 0.13709348440170288\n",
      "epoch 26 loss: 0.14043666422367096\n",
      "epoch 27 loss: 0.16423247754573822\n",
      "epoch 28 loss: 0.15965257585048676\n",
      "epoch 29 loss: 0.1476757973432541\n",
      "epoch 30 loss: 0.1085636168718338\n",
      "48\n",
      "epoch 1 loss: 0.9070432782173157\n",
      "epoch 2 loss: 0.7000823616981506\n",
      "epoch 3 loss: 0.46278873085975647\n",
      "epoch 4 loss: 0.29453328251838684\n",
      "epoch 5 loss: 0.21456220746040344\n",
      "epoch 6 loss: 0.15642394125461578\n",
      "epoch 7 loss: 0.20991012454032898\n",
      "epoch 8 loss: 0.17194971442222595\n",
      "epoch 9 loss: 0.16914598643779755\n",
      "epoch 10 loss: 0.15986382961273193\n",
      "epoch 11 loss: 0.18294757604599\n",
      "epoch 12 loss: 0.19202697277069092\n",
      "epoch 13 loss: 0.16716377437114716\n",
      "epoch 14 loss: 0.16825389862060547\n",
      "epoch 15 loss: 0.18992143869400024\n",
      "epoch 16 loss: 0.14460590481758118\n",
      "epoch 17 loss: 0.1750299483537674\n",
      "epoch 18 loss: 0.17308935523033142\n",
      "epoch 19 loss: 0.163659006357193\n",
      "epoch 20 loss: 0.1659185141324997\n",
      "epoch 21 loss: 0.138654425740242\n",
      "epoch 22 loss: 0.14707671105861664\n",
      "epoch 23 loss: 0.12798365950584412\n",
      "epoch 24 loss: 0.13853494822978973\n",
      "epoch 25 loss: 0.09134279191493988\n",
      "epoch 26 loss: 0.09361550956964493\n",
      "epoch 27 loss: 0.10481321811676025\n",
      "epoch 28 loss: 0.13781695067882538\n",
      "epoch 29 loss: 0.11369945853948593\n",
      "epoch 30 loss: 0.12781119346618652\n",
      "49\n",
      "epoch 1 loss: 0.8423487544059753\n",
      "epoch 2 loss: 0.510384202003479\n",
      "epoch 3 loss: 0.31086334586143494\n",
      "epoch 4 loss: 0.21992842853069305\n",
      "epoch 5 loss: 0.19368848204612732\n",
      "epoch 6 loss: 0.18605683743953705\n",
      "epoch 7 loss: 0.13932374119758606\n",
      "epoch 8 loss: 0.13799305260181427\n",
      "epoch 9 loss: 0.14623869955539703\n",
      "epoch 10 loss: 0.1702110916376114\n",
      "epoch 11 loss: 0.14708450436592102\n",
      "epoch 12 loss: 0.17756421864032745\n",
      "epoch 13 loss: 0.13300850987434387\n",
      "epoch 14 loss: 0.16291779279708862\n",
      "epoch 15 loss: 0.1717502772808075\n",
      "epoch 16 loss: 0.17165976762771606\n",
      "epoch 17 loss: 0.19811484217643738\n",
      "epoch 18 loss: 0.16592690348625183\n",
      "epoch 19 loss: 0.14864425361156464\n",
      "epoch 20 loss: 0.13194461166858673\n",
      "epoch 21 loss: 0.16078397631645203\n",
      "epoch 22 loss: 0.12132366746664047\n",
      "epoch 23 loss: 0.11643136292695999\n",
      "epoch 24 loss: 0.11799465864896774\n",
      "epoch 25 loss: 0.14514893293380737\n",
      "epoch 26 loss: 0.13063892722129822\n",
      "epoch 27 loss: 0.10155846178531647\n",
      "epoch 28 loss: 0.1025606319308281\n",
      "epoch 29 loss: 0.11614631861448288\n",
      "epoch 30 loss: 0.13869069516658783\n",
      "50\n",
      "epoch 1 loss: 1.0867823362350464\n",
      "epoch 2 loss: 0.7241861820220947\n",
      "epoch 3 loss: 0.4319944977760315\n",
      "epoch 4 loss: 0.2413933128118515\n",
      "epoch 5 loss: 0.21654434502124786\n",
      "epoch 6 loss: 0.1783779412508011\n",
      "epoch 7 loss: 0.12897443771362305\n",
      "epoch 8 loss: 0.1464133858680725\n",
      "epoch 9 loss: 0.1374017596244812\n",
      "epoch 10 loss: 0.16981005668640137\n",
      "epoch 11 loss: 0.14915387332439423\n",
      "epoch 12 loss: 0.15490557253360748\n",
      "epoch 13 loss: 0.11171956360340118\n",
      "epoch 14 loss: 0.15380685031414032\n",
      "epoch 15 loss: 0.12547580897808075\n",
      "epoch 16 loss: 0.18311722576618195\n",
      "epoch 17 loss: 0.1249060183763504\n",
      "epoch 18 loss: 0.15461225807666779\n",
      "epoch 19 loss: 0.16997286677360535\n",
      "epoch 20 loss: 0.13158439099788666\n",
      "epoch 21 loss: 0.16591310501098633\n",
      "epoch 22 loss: 0.16921380162239075\n",
      "epoch 23 loss: 0.11834481358528137\n",
      "epoch 24 loss: 0.11287698894739151\n",
      "epoch 25 loss: 0.13182827830314636\n",
      "epoch 26 loss: 0.12309776246547699\n",
      "epoch 27 loss: 0.10182426869869232\n",
      "epoch 28 loss: 0.09145237505435944\n",
      "epoch 29 loss: 0.13113385438919067\n",
      "epoch 30 loss: 0.1390918642282486\n",
      "51\n",
      "epoch 1 loss: 0.7529314160346985\n",
      "epoch 2 loss: 0.46730032563209534\n",
      "epoch 3 loss: 0.4217599630355835\n",
      "epoch 4 loss: 0.1754109263420105\n",
      "epoch 5 loss: 0.21734866499900818\n",
      "epoch 6 loss: 0.17317938804626465\n",
      "epoch 7 loss: 0.1565353125333786\n",
      "epoch 8 loss: 0.18849371373653412\n",
      "epoch 9 loss: 0.14507803320884705\n",
      "epoch 10 loss: 0.12941767275333405\n",
      "epoch 11 loss: 0.1535130888223648\n",
      "epoch 12 loss: 0.19852687418460846\n",
      "epoch 13 loss: 0.14013151824474335\n",
      "epoch 14 loss: 0.1482580602169037\n",
      "epoch 15 loss: 0.1447555124759674\n",
      "epoch 16 loss: 0.1576773077249527\n",
      "epoch 17 loss: 0.14373338222503662\n",
      "epoch 18 loss: 0.12778034806251526\n",
      "epoch 19 loss: 0.1258963942527771\n",
      "epoch 20 loss: 0.21757405996322632\n",
      "epoch 21 loss: 0.17580902576446533\n",
      "epoch 22 loss: 0.14715862274169922\n",
      "epoch 23 loss: 0.15995663404464722\n",
      "epoch 24 loss: 0.1302577704191208\n",
      "epoch 25 loss: 0.10873376578092575\n",
      "epoch 26 loss: 0.09954573959112167\n",
      "epoch 27 loss: 0.1369582563638687\n",
      "epoch 28 loss: 0.11623954027891159\n",
      "epoch 29 loss: 0.12267172336578369\n",
      "epoch 30 loss: 0.10510139167308807\n",
      "52\n",
      "epoch 1 loss: 0.9144101738929749\n",
      "epoch 2 loss: 0.7225435376167297\n",
      "epoch 3 loss: 0.4867199659347534\n",
      "epoch 4 loss: 0.2769853174686432\n",
      "epoch 5 loss: 0.23156170547008514\n",
      "epoch 6 loss: 0.16824373602867126\n",
      "epoch 7 loss: 0.18584710359573364\n",
      "epoch 8 loss: 0.13093514740467072\n",
      "epoch 9 loss: 0.17090268433094025\n",
      "epoch 10 loss: 0.15035758912563324\n",
      "epoch 11 loss: 0.14859332144260406\n",
      "epoch 12 loss: 0.17958642542362213\n",
      "epoch 13 loss: 0.15974478423595428\n",
      "epoch 14 loss: 0.20671431720256805\n",
      "epoch 15 loss: 0.19165097177028656\n",
      "epoch 16 loss: 0.1521800011396408\n",
      "epoch 17 loss: 0.12046083807945251\n",
      "epoch 18 loss: 0.15562227368354797\n",
      "epoch 19 loss: 0.18228310346603394\n",
      "epoch 20 loss: 0.157182514667511\n",
      "epoch 21 loss: 0.15008699893951416\n",
      "epoch 22 loss: 0.17127123475074768\n",
      "epoch 23 loss: 0.15472441911697388\n",
      "epoch 24 loss: 0.14841732382774353\n",
      "epoch 25 loss: 0.11937512457370758\n",
      "epoch 26 loss: 0.1443055272102356\n",
      "epoch 27 loss: 0.15410293638706207\n",
      "epoch 28 loss: 0.1344498246908188\n",
      "epoch 29 loss: 0.09399659931659698\n",
      "epoch 30 loss: 0.08266264945268631\n",
      "53\n",
      "epoch 1 loss: 0.8850502371788025\n",
      "epoch 2 loss: 0.401636004447937\n",
      "epoch 3 loss: 0.336881548166275\n",
      "epoch 4 loss: 0.23046185076236725\n",
      "epoch 5 loss: 0.21816150844097137\n",
      "epoch 6 loss: 0.16414600610733032\n",
      "epoch 7 loss: 0.17899969220161438\n",
      "epoch 8 loss: 0.18412727117538452\n",
      "epoch 9 loss: 0.14992721378803253\n",
      "epoch 10 loss: 0.13660570979118347\n",
      "epoch 11 loss: 0.1556197851896286\n",
      "epoch 12 loss: 0.2130567878484726\n",
      "epoch 13 loss: 0.10813584178686142\n",
      "epoch 14 loss: 0.1300235390663147\n",
      "epoch 15 loss: 0.13076479732990265\n",
      "epoch 16 loss: 0.12387942522764206\n",
      "epoch 17 loss: 0.1611696034669876\n",
      "epoch 18 loss: 0.16454467177391052\n",
      "epoch 19 loss: 0.18603472411632538\n",
      "epoch 20 loss: 0.13211794197559357\n",
      "epoch 21 loss: 0.2047380954027176\n",
      "epoch 22 loss: 0.1471807062625885\n",
      "epoch 23 loss: 0.11698088049888611\n",
      "epoch 24 loss: 0.10155894607305527\n",
      "epoch 25 loss: 0.13937978446483612\n",
      "epoch 26 loss: 0.1291688084602356\n",
      "epoch 27 loss: 0.12183086574077606\n",
      "epoch 28 loss: 0.11999153345823288\n",
      "epoch 29 loss: 0.09448081254959106\n",
      "epoch 30 loss: 0.10621809214353561\n",
      "54\n",
      "epoch 1 loss: 0.9822724461555481\n",
      "epoch 2 loss: 0.5618730783462524\n",
      "epoch 3 loss: 0.34056541323661804\n",
      "epoch 4 loss: 0.21083569526672363\n",
      "epoch 5 loss: 0.21244044601917267\n",
      "epoch 6 loss: 0.16373339295387268\n",
      "epoch 7 loss: 0.15568424761295319\n",
      "epoch 8 loss: 0.1656457930803299\n",
      "epoch 9 loss: 0.15478532016277313\n",
      "epoch 10 loss: 0.16658441722393036\n",
      "epoch 11 loss: 0.14739491045475006\n",
      "epoch 12 loss: 0.14605939388275146\n",
      "epoch 13 loss: 0.16587473452091217\n",
      "epoch 14 loss: 0.14970624446868896\n",
      "epoch 15 loss: 0.1676621288061142\n",
      "epoch 16 loss: 0.1440773755311966\n",
      "epoch 17 loss: 0.1376226395368576\n",
      "epoch 18 loss: 0.12444295734167099\n",
      "epoch 19 loss: 0.14911244809627533\n",
      "epoch 20 loss: 0.14833879470825195\n",
      "epoch 21 loss: 0.18171820044517517\n",
      "epoch 22 loss: 0.11511991173028946\n",
      "epoch 23 loss: 0.1612354815006256\n",
      "epoch 24 loss: 0.1525782197713852\n",
      "epoch 25 loss: 0.1724097579717636\n",
      "epoch 26 loss: 0.1774768978357315\n",
      "epoch 27 loss: 0.13521964848041534\n",
      "epoch 28 loss: 0.09708118438720703\n",
      "epoch 29 loss: 0.1350487768650055\n",
      "epoch 30 loss: 0.1318761259317398\n",
      "55\n",
      "epoch 1 loss: 0.8521450757980347\n",
      "epoch 2 loss: 0.6922087073326111\n",
      "epoch 3 loss: 0.5031721591949463\n",
      "epoch 4 loss: 0.2179495096206665\n",
      "epoch 5 loss: 0.16113436222076416\n",
      "epoch 6 loss: 0.17033612728118896\n",
      "epoch 7 loss: 0.17825092375278473\n",
      "epoch 8 loss: 0.1357201486825943\n",
      "epoch 9 loss: 0.16099770367145538\n",
      "epoch 10 loss: 0.13147301971912384\n",
      "epoch 11 loss: 0.16822119057178497\n",
      "epoch 12 loss: 0.12273652851581573\n",
      "epoch 13 loss: 0.16917438805103302\n",
      "epoch 14 loss: 0.16122464835643768\n",
      "epoch 15 loss: 0.1804186850786209\n",
      "epoch 16 loss: 0.17804212868213654\n",
      "epoch 17 loss: 0.13914936780929565\n",
      "epoch 18 loss: 0.14022839069366455\n",
      "epoch 19 loss: 0.1340428590774536\n",
      "epoch 20 loss: 0.12895096838474274\n",
      "epoch 21 loss: 0.13292290270328522\n",
      "epoch 22 loss: 0.11461911350488663\n",
      "epoch 23 loss: 0.157869353890419\n",
      "epoch 24 loss: 0.10962561517953873\n",
      "epoch 25 loss: 0.14708055555820465\n",
      "epoch 26 loss: 0.10500858724117279\n",
      "epoch 27 loss: 0.129194438457489\n",
      "epoch 28 loss: 0.07920555025339127\n",
      "epoch 29 loss: 0.12517541646957397\n",
      "epoch 30 loss: 0.08617603033781052\n",
      "56\n",
      "epoch 1 loss: 0.934079647064209\n",
      "epoch 2 loss: 0.491980642080307\n",
      "epoch 3 loss: 0.2316044270992279\n",
      "epoch 4 loss: 0.20008736848831177\n",
      "epoch 5 loss: 0.17916031181812286\n",
      "epoch 6 loss: 0.173704132437706\n",
      "epoch 7 loss: 0.15898850560188293\n",
      "epoch 8 loss: 0.2091590017080307\n",
      "epoch 9 loss: 0.1709924191236496\n",
      "epoch 10 loss: 0.1867610216140747\n",
      "epoch 11 loss: 0.1353062093257904\n",
      "epoch 12 loss: 0.1567990481853485\n",
      "epoch 13 loss: 0.15946821868419647\n",
      "epoch 14 loss: 0.17200569808483124\n",
      "epoch 15 loss: 0.15274402499198914\n",
      "epoch 16 loss: 0.15047095715999603\n",
      "epoch 17 loss: 0.1668519824743271\n",
      "epoch 18 loss: 0.14495757222175598\n",
      "epoch 19 loss: 0.12418889999389648\n",
      "epoch 20 loss: 0.1220078319311142\n",
      "epoch 21 loss: 0.2341516762971878\n",
      "epoch 22 loss: 0.12939545512199402\n",
      "epoch 23 loss: 0.14001886546611786\n",
      "epoch 24 loss: 0.10923697054386139\n",
      "epoch 25 loss: 0.10948237776756287\n",
      "epoch 26 loss: 0.14510725438594818\n",
      "epoch 27 loss: 0.12221518158912659\n",
      "epoch 28 loss: 0.12368715554475784\n",
      "epoch 29 loss: 0.09542960673570633\n",
      "epoch 30 loss: 0.13211321830749512\n",
      "57\n",
      "epoch 1 loss: 0.9520857334136963\n",
      "epoch 2 loss: 0.4210732579231262\n",
      "epoch 3 loss: 0.3110814392566681\n",
      "epoch 4 loss: 0.21417313814163208\n",
      "epoch 5 loss: 0.16373103857040405\n",
      "epoch 6 loss: 0.15835177898406982\n",
      "epoch 7 loss: 0.18546831607818604\n",
      "epoch 8 loss: 0.14179734885692596\n",
      "epoch 9 loss: 0.1864750236272812\n",
      "epoch 10 loss: 0.1482478380203247\n",
      "epoch 11 loss: 0.1746266484260559\n",
      "epoch 12 loss: 0.17187033593654633\n",
      "epoch 13 loss: 0.1200423613190651\n",
      "epoch 14 loss: 0.1810740977525711\n",
      "epoch 15 loss: 0.166612446308136\n",
      "epoch 16 loss: 0.10387865453958511\n",
      "epoch 17 loss: 0.1716267615556717\n",
      "epoch 18 loss: 0.16307879984378815\n",
      "epoch 19 loss: 0.12457230687141418\n",
      "epoch 20 loss: 0.13261538743972778\n",
      "epoch 21 loss: 0.16729043424129486\n",
      "epoch 22 loss: 0.14741770923137665\n",
      "epoch 23 loss: 0.12342612445354462\n",
      "epoch 24 loss: 0.12338310480117798\n",
      "epoch 25 loss: 0.12786118686199188\n",
      "epoch 26 loss: 0.09784679114818573\n",
      "epoch 27 loss: 0.08054903149604797\n",
      "epoch 28 loss: 0.1257852464914322\n",
      "epoch 29 loss: 0.10735492408275604\n",
      "epoch 30 loss: 0.06976780295372009\n",
      "58\n",
      "epoch 1 loss: 0.8464182615280151\n",
      "epoch 2 loss: 0.5153852105140686\n",
      "epoch 3 loss: 0.2666483223438263\n",
      "epoch 4 loss: 0.19624507427215576\n",
      "epoch 5 loss: 0.18587777018547058\n",
      "epoch 6 loss: 0.16061322391033173\n",
      "epoch 7 loss: 0.19877557456493378\n",
      "epoch 8 loss: 0.2085402011871338\n",
      "epoch 9 loss: 0.16461512446403503\n",
      "epoch 10 loss: 0.1300961673259735\n",
      "epoch 11 loss: 0.17382098734378815\n",
      "epoch 12 loss: 0.14985863864421844\n",
      "epoch 13 loss: 0.19155243039131165\n",
      "epoch 14 loss: 0.1395287811756134\n",
      "epoch 15 loss: 0.1389462947845459\n",
      "epoch 16 loss: 0.11832945048809052\n",
      "epoch 17 loss: 0.12521368265151978\n",
      "epoch 18 loss: 0.13802984356880188\n",
      "epoch 19 loss: 0.1483169049024582\n",
      "epoch 20 loss: 0.12261306494474411\n",
      "epoch 21 loss: 0.15128017961978912\n",
      "epoch 22 loss: 0.09607671201229095\n",
      "epoch 23 loss: 0.10595857352018356\n",
      "epoch 24 loss: 0.09184770286083221\n",
      "epoch 25 loss: 0.10001499205827713\n",
      "epoch 26 loss: 0.10013914853334427\n",
      "epoch 27 loss: 0.12613917887210846\n",
      "epoch 28 loss: 0.08055741339921951\n",
      "epoch 29 loss: 0.0923534631729126\n",
      "epoch 30 loss: 0.13777592778205872\n",
      "59\n",
      "epoch 1 loss: 0.8347564935684204\n",
      "epoch 2 loss: 0.6929160356521606\n",
      "epoch 3 loss: 0.36923515796661377\n",
      "epoch 4 loss: 0.2527949810028076\n",
      "epoch 5 loss: 0.15039807558059692\n",
      "epoch 6 loss: 0.15655642747879028\n",
      "epoch 7 loss: 0.17454136908054352\n",
      "epoch 8 loss: 0.12814749777317047\n",
      "epoch 9 loss: 0.147552028298378\n",
      "epoch 10 loss: 0.18312662839889526\n",
      "epoch 11 loss: 0.14217160642147064\n",
      "epoch 12 loss: 0.1448403149843216\n",
      "epoch 13 loss: 0.13800068199634552\n",
      "epoch 14 loss: 0.15593871474266052\n",
      "epoch 15 loss: 0.11669132858514786\n",
      "epoch 16 loss: 0.17570161819458008\n",
      "epoch 17 loss: 0.17942368984222412\n",
      "epoch 18 loss: 0.096696637570858\n",
      "epoch 19 loss: 0.08810989558696747\n",
      "epoch 20 loss: 0.11598348617553711\n",
      "epoch 21 loss: 0.1333804726600647\n",
      "epoch 22 loss: 0.09091824293136597\n",
      "epoch 23 loss: 0.14987191557884216\n",
      "epoch 24 loss: 0.13658837974071503\n",
      "epoch 25 loss: 0.11756023019552231\n",
      "epoch 26 loss: 0.08852822333574295\n",
      "epoch 27 loss: 0.08978238701820374\n",
      "epoch 28 loss: 0.15735146403312683\n",
      "epoch 29 loss: 0.12891632318496704\n",
      "epoch 30 loss: 0.07516749203205109\n",
      "60\n",
      "epoch 1 loss: 0.7362093925476074\n",
      "epoch 2 loss: 0.6067416667938232\n",
      "epoch 3 loss: 0.5202730894088745\n",
      "epoch 4 loss: 0.2861829698085785\n",
      "epoch 5 loss: 0.16650328040122986\n",
      "epoch 6 loss: 0.1307724267244339\n",
      "epoch 7 loss: 0.16317912936210632\n",
      "epoch 8 loss: 0.16700416803359985\n",
      "epoch 9 loss: 0.14229325950145721\n",
      "epoch 10 loss: 0.1654079705476761\n",
      "epoch 11 loss: 0.1852446347475052\n",
      "epoch 12 loss: 0.19248810410499573\n",
      "epoch 13 loss: 0.13654851913452148\n",
      "epoch 14 loss: 0.12039370089769363\n",
      "epoch 15 loss: 0.14665266871452332\n",
      "epoch 16 loss: 0.13326051831245422\n",
      "epoch 17 loss: 0.17819759249687195\n",
      "epoch 18 loss: 0.17778010666370392\n",
      "epoch 19 loss: 0.1614721417427063\n",
      "epoch 20 loss: 0.15246745944023132\n",
      "epoch 21 loss: 0.11308595538139343\n",
      "epoch 22 loss: 0.19597426056861877\n",
      "epoch 23 loss: 0.15164130926132202\n",
      "epoch 24 loss: 0.1282671093940735\n",
      "epoch 25 loss: 0.1077989712357521\n",
      "epoch 26 loss: 0.17148348689079285\n",
      "epoch 27 loss: 0.13108329474925995\n",
      "epoch 28 loss: 0.1843421310186386\n",
      "epoch 29 loss: 0.10849446058273315\n",
      "epoch 30 loss: 0.10467062145471573\n",
      "61\n",
      "epoch 1 loss: 0.7555254697799683\n",
      "epoch 2 loss: 0.46529513597488403\n",
      "epoch 3 loss: 0.2706904113292694\n",
      "epoch 4 loss: 0.2297224998474121\n",
      "epoch 5 loss: 0.14907383918762207\n",
      "epoch 6 loss: 0.17651672661304474\n",
      "epoch 7 loss: 0.16551780700683594\n",
      "epoch 8 loss: 0.16824977099895477\n",
      "epoch 9 loss: 0.13801127672195435\n",
      "epoch 10 loss: 0.14104731380939484\n",
      "epoch 11 loss: 0.1466926783323288\n",
      "epoch 12 loss: 0.1250944882631302\n",
      "epoch 13 loss: 0.15572170913219452\n",
      "epoch 14 loss: 0.17836494743824005\n",
      "epoch 15 loss: 0.14629855751991272\n",
      "epoch 16 loss: 0.1561097651720047\n",
      "epoch 17 loss: 0.15609046816825867\n",
      "epoch 18 loss: 0.15101808309555054\n",
      "epoch 19 loss: 0.12707743048667908\n",
      "epoch 20 loss: 0.107905812561512\n",
      "epoch 21 loss: 0.12727013230323792\n",
      "epoch 22 loss: 0.10369358211755753\n",
      "epoch 23 loss: 0.10693402588367462\n",
      "epoch 24 loss: 0.11016771197319031\n",
      "epoch 25 loss: 0.11605393886566162\n",
      "epoch 26 loss: 0.16448502242565155\n",
      "epoch 27 loss: 0.09345633536577225\n",
      "epoch 28 loss: 0.11984139680862427\n",
      "epoch 29 loss: 0.086378313601017\n",
      "epoch 30 loss: 0.10477394610643387\n",
      "62\n",
      "epoch 1 loss: 0.7773523330688477\n",
      "epoch 2 loss: 0.5694966912269592\n",
      "epoch 3 loss: 0.2657850384712219\n",
      "epoch 4 loss: 0.17088942229747772\n",
      "epoch 5 loss: 0.1735888123512268\n",
      "epoch 6 loss: 0.12957246601581573\n",
      "epoch 7 loss: 0.14381299912929535\n",
      "epoch 8 loss: 0.1751272976398468\n",
      "epoch 9 loss: 0.16639076173305511\n",
      "epoch 10 loss: 0.1295718550682068\n",
      "epoch 11 loss: 0.1530647724866867\n",
      "epoch 12 loss: 0.1383846551179886\n",
      "epoch 13 loss: 0.12269844114780426\n",
      "epoch 14 loss: 0.13497619330883026\n",
      "epoch 15 loss: 0.2002597451210022\n",
      "epoch 16 loss: 0.14733083546161652\n",
      "epoch 17 loss: 0.13825365900993347\n",
      "epoch 18 loss: 0.12503837049007416\n",
      "epoch 19 loss: 0.12283536791801453\n",
      "epoch 20 loss: 0.10454230010509491\n",
      "epoch 21 loss: 0.13396410644054413\n",
      "epoch 22 loss: 0.1169644370675087\n",
      "epoch 23 loss: 0.09831152111291885\n",
      "epoch 24 loss: 0.1429564505815506\n",
      "epoch 25 loss: 0.12268642336130142\n",
      "epoch 26 loss: 0.1332557648420334\n",
      "epoch 27 loss: 0.13326428830623627\n",
      "epoch 28 loss: 0.08965764939785004\n",
      "epoch 29 loss: 0.08632300049066544\n",
      "epoch 30 loss: 0.10178019851446152\n",
      "63\n",
      "epoch 1 loss: 0.9445036053657532\n",
      "epoch 2 loss: 0.5805203914642334\n",
      "epoch 3 loss: 0.32729199528694153\n",
      "epoch 4 loss: 0.20371735095977783\n",
      "epoch 5 loss: 0.16871941089630127\n",
      "epoch 6 loss: 0.20254583656787872\n",
      "epoch 7 loss: 0.17300143837928772\n",
      "epoch 8 loss: 0.18690013885498047\n",
      "epoch 9 loss: 0.13563798367977142\n",
      "epoch 10 loss: 0.18144699931144714\n",
      "epoch 11 loss: 0.147141233086586\n",
      "epoch 12 loss: 0.1595267355442047\n",
      "epoch 13 loss: 0.15355515480041504\n",
      "epoch 14 loss: 0.1784205436706543\n",
      "epoch 15 loss: 0.15608251094818115\n",
      "epoch 16 loss: 0.16247662901878357\n",
      "epoch 17 loss: 0.174237459897995\n",
      "epoch 18 loss: 0.11117221415042877\n",
      "epoch 19 loss: 0.22185419499874115\n",
      "epoch 20 loss: 0.11964892596006393\n",
      "epoch 21 loss: 0.13148365914821625\n",
      "epoch 22 loss: 0.09867364913225174\n",
      "epoch 23 loss: 0.18704181909561157\n",
      "epoch 24 loss: 0.12141303718090057\n",
      "epoch 25 loss: 0.12438950687646866\n",
      "epoch 26 loss: 0.09230406582355499\n",
      "epoch 27 loss: 0.08658067137002945\n",
      "epoch 28 loss: 0.11982929706573486\n",
      "epoch 29 loss: 0.12433064728975296\n",
      "epoch 30 loss: 0.0729440227150917\n",
      "64\n",
      "epoch 1 loss: 0.9293473958969116\n",
      "epoch 2 loss: 0.5625765919685364\n",
      "epoch 3 loss: 0.25857260823249817\n",
      "epoch 4 loss: 0.20146022737026215\n",
      "epoch 5 loss: 0.16267730295658112\n",
      "epoch 6 loss: 0.1844479739665985\n",
      "epoch 7 loss: 0.19980838894844055\n",
      "epoch 8 loss: 0.17340371012687683\n",
      "epoch 9 loss: 0.14194537699222565\n",
      "epoch 10 loss: 0.11982400715351105\n",
      "epoch 11 loss: 0.14874744415283203\n",
      "epoch 12 loss: 0.17131787538528442\n",
      "epoch 13 loss: 0.19372305274009705\n",
      "epoch 14 loss: 0.13637633621692657\n",
      "epoch 15 loss: 0.14603666961193085\n",
      "epoch 16 loss: 0.14201702177524567\n",
      "epoch 17 loss: 0.12494255602359772\n",
      "epoch 18 loss: 0.15502113103866577\n",
      "epoch 19 loss: 0.17381790280342102\n",
      "epoch 20 loss: 0.12870322167873383\n",
      "epoch 21 loss: 0.14697569608688354\n",
      "epoch 22 loss: 0.11001317203044891\n",
      "epoch 23 loss: 0.11998499184846878\n",
      "epoch 24 loss: 0.1126215010881424\n",
      "epoch 25 loss: 0.1793457567691803\n",
      "epoch 26 loss: 0.10097024589776993\n",
      "epoch 27 loss: 0.12594008445739746\n",
      "epoch 28 loss: 0.12148265540599823\n",
      "epoch 29 loss: 0.10514193028211594\n",
      "epoch 30 loss: 0.09483978152275085\n",
      "65\n",
      "epoch 1 loss: 0.8563371300697327\n",
      "epoch 2 loss: 0.6865754127502441\n",
      "epoch 3 loss: 0.34403350949287415\n",
      "epoch 4 loss: 0.2168104350566864\n",
      "epoch 5 loss: 0.18545351922512054\n",
      "epoch 6 loss: 0.19086526334285736\n",
      "epoch 7 loss: 0.16734375059604645\n",
      "epoch 8 loss: 0.14756011962890625\n",
      "epoch 9 loss: 0.14243687689304352\n",
      "epoch 10 loss: 0.1707044392824173\n",
      "epoch 11 loss: 0.1791462004184723\n",
      "epoch 12 loss: 0.16200792789459229\n",
      "epoch 13 loss: 0.18343082070350647\n",
      "epoch 14 loss: 0.1310655027627945\n",
      "epoch 15 loss: 0.1700626015663147\n",
      "epoch 16 loss: 0.14197009801864624\n",
      "epoch 17 loss: 0.13490183651447296\n",
      "epoch 18 loss: 0.1634799838066101\n",
      "epoch 19 loss: 0.15267375111579895\n",
      "epoch 20 loss: 0.15015706419944763\n",
      "epoch 21 loss: 0.15140168368816376\n",
      "epoch 22 loss: 0.16087880730628967\n",
      "epoch 23 loss: 0.09816320240497589\n",
      "epoch 24 loss: 0.11432629078626633\n",
      "epoch 25 loss: 0.14403721690177917\n",
      "epoch 26 loss: 0.11608844250440598\n",
      "epoch 27 loss: 0.09823349863290787\n",
      "epoch 28 loss: 0.09496628493070602\n",
      "epoch 29 loss: 0.10038205236196518\n",
      "epoch 30 loss: 0.09086663275957108\n",
      "66\n",
      "epoch 1 loss: 0.7301321029663086\n",
      "epoch 2 loss: 0.9574112296104431\n",
      "epoch 3 loss: 0.5163031220436096\n",
      "epoch 4 loss: 0.18556669354438782\n",
      "epoch 5 loss: 0.20618581771850586\n",
      "epoch 6 loss: 0.19373224675655365\n",
      "epoch 7 loss: 0.12804685533046722\n",
      "epoch 8 loss: 0.17584873735904694\n",
      "epoch 9 loss: 0.17468807101249695\n",
      "epoch 10 loss: 0.14569348096847534\n",
      "epoch 11 loss: 0.19186419248580933\n",
      "epoch 12 loss: 0.16836024820804596\n",
      "epoch 13 loss: 0.13549163937568665\n",
      "epoch 14 loss: 0.1688806712627411\n",
      "epoch 15 loss: 0.1420741081237793\n",
      "epoch 16 loss: 0.16564014554023743\n",
      "epoch 17 loss: 0.1428920328617096\n",
      "epoch 18 loss: 0.12290026247501373\n",
      "epoch 19 loss: 0.16036099195480347\n",
      "epoch 20 loss: 0.16937585175037384\n",
      "epoch 21 loss: 0.18182522058486938\n",
      "epoch 22 loss: 0.14425623416900635\n",
      "epoch 23 loss: 0.13473641872406006\n",
      "epoch 24 loss: 0.16511161625385284\n",
      "epoch 25 loss: 0.12733902037143707\n",
      "epoch 26 loss: 0.14333941042423248\n",
      "epoch 27 loss: 0.10871553421020508\n",
      "epoch 28 loss: 0.10346245020627975\n",
      "epoch 29 loss: 0.12307844310998917\n",
      "epoch 30 loss: 0.11450834572315216\n",
      "67\n",
      "epoch 1 loss: 0.8543448448181152\n",
      "epoch 2 loss: 0.6466614603996277\n",
      "epoch 3 loss: 0.388435035943985\n",
      "epoch 4 loss: 0.2994188964366913\n",
      "epoch 5 loss: 0.19860105216503143\n",
      "epoch 6 loss: 0.15999475121498108\n",
      "epoch 7 loss: 0.1919565498828888\n",
      "epoch 8 loss: 0.15623366832733154\n",
      "epoch 9 loss: 0.15017971396446228\n",
      "epoch 10 loss: 0.16410988569259644\n",
      "epoch 11 loss: 0.17034603655338287\n",
      "epoch 12 loss: 0.17041945457458496\n",
      "epoch 13 loss: 0.17389145493507385\n",
      "epoch 14 loss: 0.1603442132472992\n",
      "epoch 15 loss: 0.17271193861961365\n",
      "epoch 16 loss: 0.1150255873799324\n",
      "epoch 17 loss: 0.13905347883701324\n",
      "epoch 18 loss: 0.13156791031360626\n",
      "epoch 19 loss: 0.12051475793123245\n",
      "epoch 20 loss: 0.11323073506355286\n",
      "epoch 21 loss: 0.11752600222826004\n",
      "epoch 22 loss: 0.13158032298088074\n",
      "epoch 23 loss: 0.1210237443447113\n",
      "epoch 24 loss: 0.11017360538244247\n",
      "epoch 25 loss: 0.12345075607299805\n",
      "epoch 26 loss: 0.1126982793211937\n",
      "epoch 27 loss: 0.16764883697032928\n",
      "epoch 28 loss: 0.14527134597301483\n",
      "epoch 29 loss: 0.13374429941177368\n",
      "epoch 30 loss: 0.11666753888130188\n",
      "68\n",
      "epoch 1 loss: 0.8646485805511475\n",
      "epoch 2 loss: 0.7798765301704407\n",
      "epoch 3 loss: 0.35191261768341064\n",
      "epoch 4 loss: 0.22510693967342377\n",
      "epoch 5 loss: 0.14935697615146637\n",
      "epoch 6 loss: 0.20500628650188446\n",
      "epoch 7 loss: 0.17771384119987488\n",
      "epoch 8 loss: 0.18576988577842712\n",
      "epoch 9 loss: 0.1714615672826767\n",
      "epoch 10 loss: 0.18070361018180847\n",
      "epoch 11 loss: 0.182182177901268\n",
      "epoch 12 loss: 0.14996296167373657\n",
      "epoch 13 loss: 0.14817537367343903\n",
      "epoch 14 loss: 0.12006784975528717\n",
      "epoch 15 loss: 0.17959187924861908\n",
      "epoch 16 loss: 0.16883450746536255\n",
      "epoch 17 loss: 0.15534643828868866\n",
      "epoch 18 loss: 0.14408515393733978\n",
      "epoch 19 loss: 0.1417422890663147\n",
      "epoch 20 loss: 0.11277196556329727\n",
      "epoch 21 loss: 0.10596171766519547\n",
      "epoch 22 loss: 0.10471007227897644\n",
      "epoch 23 loss: 0.11650733649730682\n",
      "epoch 24 loss: 0.11525954306125641\n",
      "epoch 25 loss: 0.13332819938659668\n",
      "epoch 26 loss: 0.11331954598426819\n",
      "epoch 27 loss: 0.11792406439781189\n",
      "epoch 28 loss: 0.11581586301326752\n",
      "epoch 29 loss: 0.10656064748764038\n",
      "epoch 30 loss: 0.09215478599071503\n",
      "69\n",
      "epoch 1 loss: 0.798086404800415\n",
      "epoch 2 loss: 0.9944681525230408\n",
      "epoch 3 loss: 0.41899535059928894\n",
      "epoch 4 loss: 0.19912375509738922\n",
      "epoch 5 loss: 0.14746715128421783\n",
      "epoch 6 loss: 0.17116810381412506\n",
      "epoch 7 loss: 0.16848084330558777\n",
      "epoch 8 loss: 0.17464536428451538\n",
      "epoch 9 loss: 0.1734653264284134\n",
      "epoch 10 loss: 0.12388265132904053\n",
      "epoch 11 loss: 0.1309792846441269\n",
      "epoch 12 loss: 0.15229815244674683\n",
      "epoch 13 loss: 0.18305106461048126\n",
      "epoch 14 loss: 0.17584562301635742\n",
      "epoch 15 loss: 0.17956994473934174\n",
      "epoch 16 loss: 0.14212103188037872\n",
      "epoch 17 loss: 0.13735643029212952\n",
      "epoch 18 loss: 0.1679820567369461\n",
      "epoch 19 loss: 0.17088526487350464\n",
      "epoch 20 loss: 0.10275717079639435\n",
      "epoch 21 loss: 0.15311501920223236\n",
      "epoch 22 loss: 0.11815253645181656\n",
      "epoch 23 loss: 0.12256880104541779\n",
      "epoch 24 loss: 0.1332024186849594\n",
      "epoch 25 loss: 0.11645849794149399\n",
      "epoch 26 loss: 0.12568499147891998\n",
      "epoch 27 loss: 0.13347923755645752\n",
      "epoch 28 loss: 0.1257261037826538\n",
      "epoch 29 loss: 0.1020517647266388\n",
      "epoch 30 loss: 0.14103221893310547\n",
      "70\n",
      "epoch 1 loss: 0.9145998358726501\n",
      "epoch 2 loss: 0.8403776288032532\n",
      "epoch 3 loss: 0.5190848112106323\n",
      "epoch 4 loss: 0.248726487159729\n",
      "epoch 5 loss: 0.20513932406902313\n",
      "epoch 6 loss: 0.1410619467496872\n",
      "epoch 7 loss: 0.16277629137039185\n",
      "epoch 8 loss: 0.1684693694114685\n",
      "epoch 9 loss: 0.16743004322052002\n",
      "epoch 10 loss: 0.15542460978031158\n",
      "epoch 11 loss: 0.1652270257472992\n",
      "epoch 12 loss: 0.15041612088680267\n",
      "epoch 13 loss: 0.1498325765132904\n",
      "epoch 14 loss: 0.13216835260391235\n",
      "epoch 15 loss: 0.16852694749832153\n",
      "epoch 16 loss: 0.13908034563064575\n",
      "epoch 17 loss: 0.15384884178638458\n",
      "epoch 18 loss: 0.12214729189872742\n",
      "epoch 19 loss: 0.18164102733135223\n",
      "epoch 20 loss: 0.12811079621315002\n",
      "epoch 21 loss: 0.14973753690719604\n",
      "epoch 22 loss: 0.12169668823480606\n",
      "epoch 23 loss: 0.10104027390480042\n",
      "epoch 24 loss: 0.08105383068323135\n",
      "epoch 25 loss: 0.1280742883682251\n",
      "epoch 26 loss: 0.10488224774599075\n",
      "epoch 27 loss: 0.09411291033029556\n",
      "epoch 28 loss: 0.08620088547468185\n",
      "epoch 29 loss: 0.12101098150014877\n",
      "epoch 30 loss: 0.09690947085618973\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "0270a4ad-425a-48d9-8556-e4110c38d332",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + categorical weekday"
   ]
  },
  {
   "cell_type": "code",
   "id": "7d71860d-6bd7-40b6-bce6-7e6f464f36d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T22:33:26.871220Z",
     "start_time": "2025-10-03T21:30:48.250779Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wc = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wc()\n",
    "    trainer = model_class.RNN_train_2(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "results_aep_self_con_wc.to_csv(out_dir + '/results_aep_self_con_wc.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1 loss: 0.8191321492195129\n",
      "epoch 2 loss: 0.5870351195335388\n",
      "epoch 3 loss: 0.38221508264541626\n",
      "epoch 4 loss: 0.24898682534694672\n",
      "epoch 5 loss: 0.18089719116687775\n",
      "epoch 6 loss: 0.182883620262146\n",
      "epoch 7 loss: 0.16006335616111755\n",
      "epoch 8 loss: 0.1428573578596115\n",
      "epoch 9 loss: 0.15570026636123657\n",
      "epoch 10 loss: 0.1574164628982544\n",
      "epoch 11 loss: 0.16987362504005432\n",
      "epoch 12 loss: 0.15905995666980743\n",
      "epoch 13 loss: 0.19655367732048035\n",
      "epoch 14 loss: 0.1828727424144745\n",
      "epoch 15 loss: 0.16033180058002472\n",
      "epoch 16 loss: 0.17209362983703613\n",
      "epoch 17 loss: 0.17336928844451904\n",
      "epoch 18 loss: 0.16569817066192627\n",
      "epoch 19 loss: 0.1268313229084015\n",
      "epoch 20 loss: 0.14280572533607483\n",
      "epoch 21 loss: 0.16921383142471313\n",
      "epoch 22 loss: 0.13318413496017456\n",
      "epoch 23 loss: 0.12118727713823318\n",
      "epoch 24 loss: 0.09081951528787613\n",
      "epoch 25 loss: 0.10585596412420273\n",
      "epoch 26 loss: 0.09949834644794464\n",
      "epoch 27 loss: 0.10542371869087219\n",
      "epoch 28 loss: 0.1101817786693573\n",
      "epoch 29 loss: 0.10610384494066238\n",
      "epoch 30 loss: 0.10308171063661575\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_74380/3578828895.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.9077210426330566\n",
      "epoch 2 loss: 0.5069284439086914\n",
      "epoch 3 loss: 0.22441674768924713\n",
      "epoch 4 loss: 0.18112707138061523\n",
      "epoch 5 loss: 0.1811114251613617\n",
      "epoch 6 loss: 0.15765829384326935\n",
      "epoch 7 loss: 0.16533997654914856\n",
      "epoch 8 loss: 0.17041465640068054\n",
      "epoch 9 loss: 0.14592640101909637\n",
      "epoch 10 loss: 0.12414997816085815\n",
      "epoch 11 loss: 0.1581663191318512\n",
      "epoch 12 loss: 0.1378629505634308\n",
      "epoch 13 loss: 0.1478809267282486\n",
      "epoch 14 loss: 0.16473138332366943\n",
      "epoch 15 loss: 0.14138072729110718\n",
      "epoch 16 loss: 0.15481819212436676\n",
      "epoch 17 loss: 0.14232750236988068\n",
      "epoch 18 loss: 0.14942342042922974\n",
      "epoch 19 loss: 0.17991547286510468\n",
      "epoch 20 loss: 0.11451659351587296\n",
      "epoch 21 loss: 0.1302776038646698\n",
      "epoch 22 loss: 0.08612099289894104\n",
      "epoch 23 loss: 0.15715275704860687\n",
      "epoch 24 loss: 0.13312265276908875\n",
      "epoch 25 loss: 0.0933072492480278\n",
      "epoch 26 loss: 0.1012747660279274\n",
      "epoch 27 loss: 0.13144569098949432\n",
      "epoch 28 loss: 0.12185546010732651\n",
      "epoch 29 loss: 0.10005547106266022\n",
      "epoch 30 loss: 0.08510112017393112\n",
      "3\n",
      "epoch 1 loss: 1.0181505680084229\n",
      "epoch 2 loss: 0.7324082255363464\n",
      "epoch 3 loss: 0.4412026107311249\n",
      "epoch 4 loss: 0.19065412878990173\n",
      "epoch 5 loss: 0.23838277161121368\n",
      "epoch 6 loss: 0.17574036121368408\n",
      "epoch 7 loss: 0.18744803965091705\n",
      "epoch 8 loss: 0.16259872913360596\n",
      "epoch 9 loss: 0.1379648894071579\n",
      "epoch 10 loss: 0.12485408037900925\n",
      "epoch 11 loss: 0.2196805626153946\n",
      "epoch 12 loss: 0.15694573521614075\n",
      "epoch 13 loss: 0.176555797457695\n",
      "epoch 14 loss: 0.1746528297662735\n",
      "epoch 15 loss: 0.1662764996290207\n",
      "epoch 16 loss: 0.13654890656471252\n",
      "epoch 17 loss: 0.19367478787899017\n",
      "epoch 18 loss: 0.12964078783988953\n",
      "epoch 19 loss: 0.13806694746017456\n",
      "epoch 20 loss: 0.14839206635951996\n",
      "epoch 21 loss: 0.17001108825206757\n",
      "epoch 22 loss: 0.1742720603942871\n",
      "epoch 23 loss: 0.10943710058927536\n",
      "epoch 24 loss: 0.11696386337280273\n",
      "epoch 25 loss: 0.1097465381026268\n",
      "epoch 26 loss: 0.14743037521839142\n",
      "epoch 27 loss: 0.12235953658819199\n",
      "epoch 28 loss: 0.13162389397621155\n",
      "epoch 29 loss: 0.2587418556213379\n",
      "epoch 30 loss: 0.13287314772605896\n",
      "4\n",
      "epoch 1 loss: 0.887969434261322\n",
      "epoch 2 loss: 0.6275632977485657\n",
      "epoch 3 loss: 0.35679224133491516\n",
      "epoch 4 loss: 0.2426081746816635\n",
      "epoch 5 loss: 0.17710550129413605\n",
      "epoch 6 loss: 0.16597706079483032\n",
      "epoch 7 loss: 0.18269510567188263\n",
      "epoch 8 loss: 0.1995421200990677\n",
      "epoch 9 loss: 0.20614755153656006\n",
      "epoch 10 loss: 0.1682514101266861\n",
      "epoch 11 loss: 0.14536689221858978\n",
      "epoch 12 loss: 0.17373570799827576\n",
      "epoch 13 loss: 0.15769599378108978\n",
      "epoch 14 loss: 0.15149350464344025\n",
      "epoch 15 loss: 0.12477228790521622\n",
      "epoch 16 loss: 0.1441398561000824\n",
      "epoch 17 loss: 0.2055942416191101\n",
      "epoch 18 loss: 0.18497462570667267\n",
      "epoch 19 loss: 0.16052177548408508\n",
      "epoch 20 loss: 0.18874260783195496\n",
      "epoch 21 loss: 0.12186945229768753\n",
      "epoch 22 loss: 0.10518305003643036\n",
      "epoch 23 loss: 0.10384198278188705\n",
      "epoch 24 loss: 0.13616575300693512\n",
      "epoch 25 loss: 0.08382579684257507\n",
      "epoch 26 loss: 0.10077927261590958\n",
      "epoch 27 loss: 0.0982133224606514\n",
      "epoch 28 loss: 0.11404436081647873\n",
      "epoch 29 loss: 0.1011292040348053\n",
      "epoch 30 loss: 0.08683443069458008\n",
      "5\n",
      "epoch 1 loss: 0.8269196152687073\n",
      "epoch 2 loss: 0.49805164337158203\n",
      "epoch 3 loss: 0.3339282274246216\n",
      "epoch 4 loss: 0.1792483925819397\n",
      "epoch 5 loss: 0.15213966369628906\n",
      "epoch 6 loss: 0.15006475150585175\n",
      "epoch 7 loss: 0.16369463503360748\n",
      "epoch 8 loss: 0.19369862973690033\n",
      "epoch 9 loss: 0.16665932536125183\n",
      "epoch 10 loss: 0.16758179664611816\n",
      "epoch 11 loss: 0.1620635688304901\n",
      "epoch 12 loss: 0.1762515902519226\n",
      "epoch 13 loss: 0.1011638268828392\n",
      "epoch 14 loss: 0.12134959548711777\n",
      "epoch 15 loss: 0.13984040915966034\n",
      "epoch 16 loss: 0.13507689535617828\n",
      "epoch 17 loss: 0.14149591326713562\n",
      "epoch 18 loss: 0.11457075923681259\n",
      "epoch 19 loss: 0.1367553323507309\n",
      "epoch 20 loss: 0.16053007543087006\n",
      "epoch 21 loss: 0.12022140622138977\n",
      "epoch 22 loss: 0.09454481303691864\n",
      "epoch 23 loss: 0.09677869081497192\n",
      "epoch 24 loss: 0.09444477409124374\n",
      "epoch 25 loss: 0.11487637460231781\n",
      "epoch 26 loss: 0.10529685020446777\n",
      "epoch 27 loss: 0.13515111804008484\n",
      "epoch 28 loss: 0.11260592192411423\n",
      "epoch 29 loss: 0.08503376692533493\n",
      "epoch 30 loss: 0.07672208547592163\n",
      "6\n",
      "epoch 1 loss: 0.7907624840736389\n",
      "epoch 2 loss: 0.8436989188194275\n",
      "epoch 3 loss: 0.46677830815315247\n",
      "epoch 4 loss: 0.23781819641590118\n",
      "epoch 5 loss: 0.1645027995109558\n",
      "epoch 6 loss: 0.16601602733135223\n",
      "epoch 7 loss: 0.14852505922317505\n",
      "epoch 8 loss: 0.14488933980464935\n",
      "epoch 9 loss: 0.15728534758090973\n",
      "epoch 10 loss: 0.16594496369361877\n",
      "epoch 11 loss: 0.16704484820365906\n",
      "epoch 12 loss: 0.1399783194065094\n",
      "epoch 13 loss: 0.15882602334022522\n",
      "epoch 14 loss: 0.1800675243139267\n",
      "epoch 15 loss: 0.18867626786231995\n",
      "epoch 16 loss: 0.16469620168209076\n",
      "epoch 17 loss: 0.1508830040693283\n",
      "epoch 18 loss: 0.15540750324726105\n",
      "epoch 19 loss: 0.14963363111019135\n",
      "epoch 20 loss: 0.2249179482460022\n",
      "epoch 21 loss: 0.15339407324790955\n",
      "epoch 22 loss: 0.13673655688762665\n",
      "epoch 23 loss: 0.1408008486032486\n",
      "epoch 24 loss: 0.13308371603488922\n",
      "epoch 25 loss: 0.14184370636940002\n",
      "epoch 26 loss: 0.12291941791772842\n",
      "epoch 27 loss: 0.1118813306093216\n",
      "epoch 28 loss: 0.1341342180967331\n",
      "epoch 29 loss: 0.09278534352779388\n",
      "epoch 30 loss: 0.10740329325199127\n",
      "7\n",
      "epoch 1 loss: 0.7663785219192505\n",
      "epoch 2 loss: 0.45955944061279297\n",
      "epoch 3 loss: 0.348639577627182\n",
      "epoch 4 loss: 0.3030908405780792\n",
      "epoch 5 loss: 0.21190017461776733\n",
      "epoch 6 loss: 0.199822336435318\n",
      "epoch 7 loss: 0.1863497644662857\n",
      "epoch 8 loss: 0.15191715955734253\n",
      "epoch 9 loss: 0.17111223936080933\n",
      "epoch 10 loss: 0.16340284049510956\n",
      "epoch 11 loss: 0.14337873458862305\n",
      "epoch 12 loss: 0.16103212535381317\n",
      "epoch 13 loss: 0.1480548232793808\n",
      "epoch 14 loss: 0.1463165432214737\n",
      "epoch 15 loss: 0.17028528451919556\n",
      "epoch 16 loss: 0.15079517662525177\n",
      "epoch 17 loss: 0.20227736234664917\n",
      "epoch 18 loss: 0.14677898585796356\n",
      "epoch 19 loss: 0.16819757223129272\n",
      "epoch 20 loss: 0.1803901642560959\n",
      "epoch 21 loss: 0.14411282539367676\n",
      "epoch 22 loss: 0.16962167620658875\n",
      "epoch 23 loss: 0.154582679271698\n",
      "epoch 24 loss: 0.16262173652648926\n",
      "epoch 25 loss: 0.16656824946403503\n",
      "epoch 26 loss: 0.12544730305671692\n",
      "epoch 27 loss: 0.14019520580768585\n",
      "epoch 28 loss: 0.10323063284158707\n",
      "epoch 29 loss: 0.12002895772457123\n",
      "epoch 30 loss: 0.1427862048149109\n",
      "8\n",
      "epoch 1 loss: 0.7662164568901062\n",
      "epoch 2 loss: 0.6857921481132507\n",
      "epoch 3 loss: 0.49146515130996704\n",
      "epoch 4 loss: 0.22953592240810394\n",
      "epoch 5 loss: 0.18159249424934387\n",
      "epoch 6 loss: 0.1770464926958084\n",
      "epoch 7 loss: 0.17741189897060394\n",
      "epoch 8 loss: 0.14248283207416534\n",
      "epoch 9 loss: 0.127468541264534\n",
      "epoch 10 loss: 0.1898331195116043\n",
      "epoch 11 loss: 0.16956458985805511\n",
      "epoch 12 loss: 0.168089359998703\n",
      "epoch 13 loss: 0.13144944608211517\n",
      "epoch 14 loss: 0.2018050253391266\n",
      "epoch 15 loss: 0.16192497313022614\n",
      "epoch 16 loss: 0.14948564767837524\n",
      "epoch 17 loss: 0.17498736083507538\n",
      "epoch 18 loss: 0.1336868405342102\n",
      "epoch 19 loss: 0.13098078966140747\n",
      "epoch 20 loss: 0.12216360867023468\n",
      "epoch 21 loss: 0.06853584200143814\n",
      "epoch 22 loss: 0.11429328471422195\n",
      "epoch 23 loss: 0.11256920546293259\n",
      "epoch 24 loss: 0.18420061469078064\n",
      "epoch 25 loss: 0.16265913844108582\n",
      "epoch 26 loss: 0.13262346386909485\n",
      "epoch 27 loss: 0.10791449248790741\n",
      "epoch 28 loss: 0.12399919331073761\n",
      "epoch 29 loss: 0.08986815810203552\n",
      "epoch 30 loss: 0.12685507535934448\n",
      "9\n",
      "epoch 1 loss: 0.8116783499717712\n",
      "epoch 2 loss: 0.8327453136444092\n",
      "epoch 3 loss: 0.41025570034980774\n",
      "epoch 4 loss: 0.1858193576335907\n",
      "epoch 5 loss: 0.20059390366077423\n",
      "epoch 6 loss: 0.17609454691410065\n",
      "epoch 7 loss: 0.12900550663471222\n",
      "epoch 8 loss: 0.19045133888721466\n",
      "epoch 9 loss: 0.1479956954717636\n",
      "epoch 10 loss: 0.16039849817752838\n",
      "epoch 11 loss: 0.16831348836421967\n",
      "epoch 12 loss: 0.15056638419628143\n",
      "epoch 13 loss: 0.18411600589752197\n",
      "epoch 14 loss: 0.16179773211479187\n",
      "epoch 15 loss: 0.15286464989185333\n",
      "epoch 16 loss: 0.19425256550312042\n",
      "epoch 17 loss: 0.17226006090641022\n",
      "epoch 18 loss: 0.1426348090171814\n",
      "epoch 19 loss: 0.18267986178398132\n",
      "epoch 20 loss: 0.15094439685344696\n",
      "epoch 21 loss: 0.19033345580101013\n",
      "epoch 22 loss: 0.1538398116827011\n",
      "epoch 23 loss: 0.12958116829395294\n",
      "epoch 24 loss: 0.14328248798847198\n",
      "epoch 25 loss: 0.12273795157670975\n",
      "epoch 26 loss: 0.12639829516410828\n",
      "epoch 27 loss: 0.1259714961051941\n",
      "epoch 28 loss: 0.09884440153837204\n",
      "epoch 29 loss: 0.09404896199703217\n",
      "epoch 30 loss: 0.13032974302768707\n",
      "10\n",
      "epoch 1 loss: 0.8694136142730713\n",
      "epoch 2 loss: 0.6813405752182007\n",
      "epoch 3 loss: 0.43430766463279724\n",
      "epoch 4 loss: 0.3107234835624695\n",
      "epoch 5 loss: 0.1694282591342926\n",
      "epoch 6 loss: 0.19131165742874146\n",
      "epoch 7 loss: 0.17721712589263916\n",
      "epoch 8 loss: 0.18159906566143036\n",
      "epoch 9 loss: 0.17045338451862335\n",
      "epoch 10 loss: 0.1469903439283371\n",
      "epoch 11 loss: 0.16591715812683105\n",
      "epoch 12 loss: 0.15091799199581146\n",
      "epoch 13 loss: 0.16310374438762665\n",
      "epoch 14 loss: 0.14256596565246582\n",
      "epoch 15 loss: 0.15601952373981476\n",
      "epoch 16 loss: 0.14182056486606598\n",
      "epoch 17 loss: 0.15175296366214752\n",
      "epoch 18 loss: 0.1301661878824234\n",
      "epoch 19 loss: 0.1556379646062851\n",
      "epoch 20 loss: 0.15442577004432678\n",
      "epoch 21 loss: 0.12278929352760315\n",
      "epoch 22 loss: 0.13657952845096588\n",
      "epoch 23 loss: 0.12232136726379395\n",
      "epoch 24 loss: 0.1515493392944336\n",
      "epoch 25 loss: 0.09817046672105789\n",
      "epoch 26 loss: 0.11155280470848083\n",
      "epoch 27 loss: 0.12356854975223541\n",
      "epoch 28 loss: 0.11512979865074158\n",
      "epoch 29 loss: 0.09552591294050217\n",
      "epoch 30 loss: 0.11594244092702866\n",
      "11\n",
      "epoch 1 loss: 0.9465102553367615\n",
      "epoch 2 loss: 0.53534996509552\n",
      "epoch 3 loss: 0.2603698968887329\n",
      "epoch 4 loss: 0.2497190237045288\n",
      "epoch 5 loss: 0.18817627429962158\n",
      "epoch 6 loss: 0.1897737830877304\n",
      "epoch 7 loss: 0.1594202220439911\n",
      "epoch 8 loss: 0.15097811818122864\n",
      "epoch 9 loss: 0.1669640988111496\n",
      "epoch 10 loss: 0.1632043868303299\n",
      "epoch 11 loss: 0.13537393510341644\n",
      "epoch 12 loss: 0.13443590700626373\n",
      "epoch 13 loss: 0.15535970032215118\n",
      "epoch 14 loss: 0.126610666513443\n",
      "epoch 15 loss: 0.15500754117965698\n",
      "epoch 16 loss: 0.13889852166175842\n",
      "epoch 17 loss: 0.17345339059829712\n",
      "epoch 18 loss: 0.11077110469341278\n",
      "epoch 19 loss: 0.12958981096744537\n",
      "epoch 20 loss: 0.15700668096542358\n",
      "epoch 21 loss: 0.15228663384914398\n",
      "epoch 22 loss: 0.1166745200753212\n",
      "epoch 23 loss: 0.1534298211336136\n",
      "epoch 24 loss: 0.13435494899749756\n",
      "epoch 25 loss: 0.13243317604064941\n",
      "epoch 26 loss: 0.09295231103897095\n",
      "epoch 27 loss: 0.1414109766483307\n",
      "epoch 28 loss: 0.09909871220588684\n",
      "epoch 29 loss: 0.15914252400398254\n",
      "epoch 30 loss: 0.15412591397762299\n",
      "12\n",
      "epoch 1 loss: 0.9123964309692383\n",
      "epoch 2 loss: 0.6413906216621399\n",
      "epoch 3 loss: 0.32775580883026123\n",
      "epoch 4 loss: 0.23731552064418793\n",
      "epoch 5 loss: 0.18569588661193848\n",
      "epoch 6 loss: 0.17267873883247375\n",
      "epoch 7 loss: 0.1523718237876892\n",
      "epoch 8 loss: 0.17895761132240295\n",
      "epoch 9 loss: 0.15925435721874237\n",
      "epoch 10 loss: 0.15759192407131195\n",
      "epoch 11 loss: 0.13413511216640472\n",
      "epoch 12 loss: 0.1566801369190216\n",
      "epoch 13 loss: 0.13930743932724\n",
      "epoch 14 loss: 0.14187945425510406\n",
      "epoch 15 loss: 0.1866951584815979\n",
      "epoch 16 loss: 0.11197036504745483\n",
      "epoch 17 loss: 0.12725020945072174\n",
      "epoch 18 loss: 0.16869084537029266\n",
      "epoch 19 loss: 0.1498153954744339\n",
      "epoch 20 loss: 0.11513873934745789\n",
      "epoch 21 loss: 0.12388890981674194\n",
      "epoch 22 loss: 0.11974996328353882\n",
      "epoch 23 loss: 0.087761789560318\n",
      "epoch 24 loss: 0.09321784228086472\n",
      "epoch 25 loss: 0.09978756308555603\n",
      "epoch 26 loss: 0.12516891956329346\n",
      "epoch 27 loss: 0.11923306435346603\n",
      "epoch 28 loss: 0.16025395691394806\n",
      "epoch 29 loss: 0.09437824785709381\n",
      "epoch 30 loss: 0.09753601253032684\n",
      "13\n",
      "epoch 1 loss: 0.8179483413696289\n",
      "epoch 2 loss: 0.6734122037887573\n",
      "epoch 3 loss: 0.3620234429836273\n",
      "epoch 4 loss: 0.23270530998706818\n",
      "epoch 5 loss: 0.1473449319601059\n",
      "epoch 6 loss: 0.16000016033649445\n",
      "epoch 7 loss: 0.14363619685173035\n",
      "epoch 8 loss: 0.1479635089635849\n",
      "epoch 9 loss: 0.1824098378419876\n",
      "epoch 10 loss: 0.15991093218326569\n",
      "epoch 11 loss: 0.1787986159324646\n",
      "epoch 12 loss: 0.15307043492794037\n",
      "epoch 13 loss: 0.1392783522605896\n",
      "epoch 14 loss: 0.1371782422065735\n",
      "epoch 15 loss: 0.18551556766033173\n",
      "epoch 16 loss: 0.17746303975582123\n",
      "epoch 17 loss: 0.20294034481048584\n",
      "epoch 18 loss: 0.11338607221841812\n",
      "epoch 19 loss: 0.0943581759929657\n",
      "epoch 20 loss: 0.15640293061733246\n",
      "epoch 21 loss: 0.2321842461824417\n",
      "epoch 22 loss: 0.10319402068853378\n",
      "epoch 23 loss: 0.1125316396355629\n",
      "epoch 24 loss: 0.1301707625389099\n",
      "epoch 25 loss: 0.12604598701000214\n",
      "epoch 26 loss: 0.09279090911149979\n",
      "epoch 27 loss: 0.1039893701672554\n",
      "epoch 28 loss: 0.10304240882396698\n",
      "epoch 29 loss: 0.12469629943370819\n",
      "epoch 30 loss: 0.1418510377407074\n",
      "14\n",
      "epoch 1 loss: 0.8498069643974304\n",
      "epoch 2 loss: 0.37076422572135925\n",
      "epoch 3 loss: 0.3568151295185089\n",
      "epoch 4 loss: 0.22546349465847015\n",
      "epoch 5 loss: 0.1910623013973236\n",
      "epoch 6 loss: 0.1747264415025711\n",
      "epoch 7 loss: 0.16804184019565582\n",
      "epoch 8 loss: 0.14770880341529846\n",
      "epoch 9 loss: 0.16373877227306366\n",
      "epoch 10 loss: 0.14891071617603302\n",
      "epoch 11 loss: 0.11648309975862503\n",
      "epoch 12 loss: 0.16743382811546326\n",
      "epoch 13 loss: 0.15256638824939728\n",
      "epoch 14 loss: 0.15046505630016327\n",
      "epoch 15 loss: 0.12850557267665863\n",
      "epoch 16 loss: 0.1395602524280548\n",
      "epoch 17 loss: 0.13596120476722717\n",
      "epoch 18 loss: 0.16782350838184357\n",
      "epoch 19 loss: 0.08689552545547485\n",
      "epoch 20 loss: 0.092417411506176\n",
      "epoch 21 loss: 0.11882144957780838\n",
      "epoch 22 loss: 0.1221793070435524\n",
      "epoch 23 loss: 0.10906460881233215\n",
      "epoch 24 loss: 0.07546815276145935\n",
      "epoch 25 loss: 0.10617510974407196\n",
      "epoch 26 loss: 0.0780147984623909\n",
      "epoch 27 loss: 0.11553169786930084\n",
      "epoch 28 loss: 0.11209926009178162\n",
      "epoch 29 loss: 0.08954562991857529\n",
      "epoch 30 loss: 0.08413638919591904\n",
      "15\n",
      "epoch 1 loss: 0.8044925332069397\n",
      "epoch 2 loss: 0.6227817535400391\n",
      "epoch 3 loss: 0.29190629720687866\n",
      "epoch 4 loss: 0.1810162365436554\n",
      "epoch 5 loss: 0.14734242856502533\n",
      "epoch 6 loss: 0.13874810934066772\n",
      "epoch 7 loss: 0.20184674859046936\n",
      "epoch 8 loss: 0.15573066473007202\n",
      "epoch 9 loss: 0.16503697633743286\n",
      "epoch 10 loss: 0.17220035195350647\n",
      "epoch 11 loss: 0.15958596765995026\n",
      "epoch 12 loss: 0.13951613008975983\n",
      "epoch 13 loss: 0.19649268686771393\n",
      "epoch 14 loss: 0.13988971710205078\n",
      "epoch 15 loss: 0.1422336995601654\n",
      "epoch 16 loss: 0.15553292632102966\n",
      "epoch 17 loss: 0.18729929625988007\n",
      "epoch 18 loss: 0.12571321427822113\n",
      "epoch 19 loss: 0.1399325132369995\n",
      "epoch 20 loss: 0.10665258020162582\n",
      "epoch 21 loss: 0.10905265808105469\n",
      "epoch 22 loss: 0.10258255898952484\n",
      "epoch 23 loss: 0.1273754984140396\n",
      "epoch 24 loss: 0.10250910371541977\n",
      "epoch 25 loss: 0.09288164973258972\n",
      "epoch 26 loss: 0.10461945086717606\n",
      "epoch 27 loss: 0.14666900038719177\n",
      "epoch 28 loss: 0.08057667315006256\n",
      "epoch 29 loss: 0.08480207622051239\n",
      "epoch 30 loss: 0.1456076055765152\n",
      "16\n",
      "epoch 1 loss: 0.7531080842018127\n",
      "epoch 2 loss: 0.856656014919281\n",
      "epoch 3 loss: 0.8132032752037048\n",
      "epoch 4 loss: 0.41276049613952637\n",
      "epoch 5 loss: 0.18950678408145905\n",
      "epoch 6 loss: 0.19056305289268494\n",
      "epoch 7 loss: 0.14537858963012695\n",
      "epoch 8 loss: 0.18199731409549713\n",
      "epoch 9 loss: 0.1590568721294403\n",
      "epoch 10 loss: 0.19209448993206024\n",
      "epoch 11 loss: 0.167454794049263\n",
      "epoch 12 loss: 0.15494735538959503\n",
      "epoch 13 loss: 0.1446247100830078\n",
      "epoch 14 loss: 0.17567889392375946\n",
      "epoch 15 loss: 0.12229663133621216\n",
      "epoch 16 loss: 0.10848407447338104\n",
      "epoch 17 loss: 0.20141994953155518\n",
      "epoch 18 loss: 0.10395190119743347\n",
      "epoch 19 loss: 0.1940550059080124\n",
      "epoch 20 loss: 0.11932782083749771\n",
      "epoch 21 loss: 0.144287571310997\n",
      "epoch 22 loss: 0.11372864246368408\n",
      "epoch 23 loss: 0.07693460583686829\n",
      "epoch 24 loss: 0.0904325470328331\n",
      "epoch 25 loss: 0.09411881864070892\n",
      "epoch 26 loss: 0.07974278181791306\n",
      "epoch 27 loss: 0.09804340451955795\n",
      "epoch 28 loss: 0.07844046503305435\n",
      "epoch 29 loss: 0.11549894511699677\n",
      "epoch 30 loss: 0.09360101073980331\n",
      "17\n",
      "epoch 1 loss: 0.8101571798324585\n",
      "epoch 2 loss: 0.5452196598052979\n",
      "epoch 3 loss: 0.29166680574417114\n",
      "epoch 4 loss: 0.21279600262641907\n",
      "epoch 5 loss: 0.21074044704437256\n",
      "epoch 6 loss: 0.17734195291996002\n",
      "epoch 7 loss: 0.1543109267950058\n",
      "epoch 8 loss: 0.18692956864833832\n",
      "epoch 9 loss: 0.1507948935031891\n",
      "epoch 10 loss: 0.15717831254005432\n",
      "epoch 11 loss: 0.16865625977516174\n",
      "epoch 12 loss: 0.12408867478370667\n",
      "epoch 13 loss: 0.13992248475551605\n",
      "epoch 14 loss: 0.146771639585495\n",
      "epoch 15 loss: 0.142673522233963\n",
      "epoch 16 loss: 0.1608952134847641\n",
      "epoch 17 loss: 0.1579083502292633\n",
      "epoch 18 loss: 0.1753385365009308\n",
      "epoch 19 loss: 0.19516052305698395\n",
      "epoch 20 loss: 0.15134941041469574\n",
      "epoch 21 loss: 0.1473086029291153\n",
      "epoch 22 loss: 0.1572040468454361\n",
      "epoch 23 loss: 0.15229395031929016\n",
      "epoch 24 loss: 0.16432668268680573\n",
      "epoch 25 loss: 0.13538521528244019\n",
      "epoch 26 loss: 0.14441607892513275\n",
      "epoch 27 loss: 0.12957128882408142\n",
      "epoch 28 loss: 0.14357852935791016\n",
      "epoch 29 loss: 0.11697248369455338\n",
      "epoch 30 loss: 0.16387207806110382\n",
      "18\n",
      "epoch 1 loss: 0.9167747497558594\n",
      "epoch 2 loss: 0.6673868894577026\n",
      "epoch 3 loss: 0.6039068698883057\n",
      "epoch 4 loss: 0.23627115786075592\n",
      "epoch 5 loss: 0.19826547801494598\n",
      "epoch 6 loss: 0.18793609738349915\n",
      "epoch 7 loss: 0.15250873565673828\n",
      "epoch 8 loss: 0.19276808202266693\n",
      "epoch 9 loss: 0.17964304983615875\n",
      "epoch 10 loss: 0.16467861831188202\n",
      "epoch 11 loss: 0.20926882326602936\n",
      "epoch 12 loss: 0.15891695022583008\n",
      "epoch 13 loss: 0.17174223065376282\n",
      "epoch 14 loss: 0.15387371182441711\n",
      "epoch 15 loss: 0.14316794276237488\n",
      "epoch 16 loss: 0.1633879691362381\n",
      "epoch 17 loss: 0.18458427488803864\n",
      "epoch 18 loss: 0.14219076931476593\n",
      "epoch 19 loss: 0.17022815346717834\n",
      "epoch 20 loss: 0.10516773164272308\n",
      "epoch 21 loss: 0.14815248548984528\n",
      "epoch 22 loss: 0.15389540791511536\n",
      "epoch 23 loss: 0.13846713304519653\n",
      "epoch 24 loss: 0.1213718056678772\n",
      "epoch 25 loss: 0.10278210043907166\n",
      "epoch 26 loss: 0.12089813500642776\n",
      "epoch 27 loss: 0.0979236289858818\n",
      "epoch 28 loss: 0.13503582775592804\n",
      "epoch 29 loss: 0.1068662479519844\n",
      "epoch 30 loss: 0.11728249490261078\n",
      "19\n",
      "epoch 1 loss: 0.8916827440261841\n",
      "epoch 2 loss: 0.5973886251449585\n",
      "epoch 3 loss: 0.4191927909851074\n",
      "epoch 4 loss: 0.25259625911712646\n",
      "epoch 5 loss: 0.1810469776391983\n",
      "epoch 6 loss: 0.14617428183555603\n",
      "epoch 7 loss: 0.17903509736061096\n",
      "epoch 8 loss: 0.11860570311546326\n",
      "epoch 9 loss: 0.17007914185523987\n",
      "epoch 10 loss: 0.14364838600158691\n",
      "epoch 11 loss: 0.17141440510749817\n",
      "epoch 12 loss: 0.19223731756210327\n",
      "epoch 13 loss: 0.16342058777809143\n",
      "epoch 14 loss: 0.14099149405956268\n",
      "epoch 15 loss: 0.13969144225120544\n",
      "epoch 16 loss: 0.16695336997509003\n",
      "epoch 17 loss: 0.14669369161128998\n",
      "epoch 18 loss: 0.13496893644332886\n",
      "epoch 19 loss: 0.12576855719089508\n",
      "epoch 20 loss: 0.15148769319057465\n",
      "epoch 21 loss: 0.15545713901519775\n",
      "epoch 22 loss: 0.1838127225637436\n",
      "epoch 23 loss: 0.15548264980316162\n",
      "epoch 24 loss: 0.12580756843090057\n",
      "epoch 25 loss: 0.1571093201637268\n",
      "epoch 26 loss: 0.1318282037973404\n",
      "epoch 27 loss: 0.1100754365324974\n",
      "epoch 28 loss: 0.11244135349988937\n",
      "epoch 29 loss: 0.11489062011241913\n",
      "epoch 30 loss: 0.09549211710691452\n",
      "20\n",
      "epoch 1 loss: 0.8527193665504456\n",
      "epoch 2 loss: 0.536724328994751\n",
      "epoch 3 loss: 0.3043487071990967\n",
      "epoch 4 loss: 0.17881841957569122\n",
      "epoch 5 loss: 0.14878864586353302\n",
      "epoch 6 loss: 0.1487012654542923\n",
      "epoch 7 loss: 0.16987228393554688\n",
      "epoch 8 loss: 0.16072049736976624\n",
      "epoch 9 loss: 0.1636899709701538\n",
      "epoch 10 loss: 0.19237437844276428\n",
      "epoch 11 loss: 0.1618063896894455\n",
      "epoch 12 loss: 0.17461247742176056\n",
      "epoch 13 loss: 0.17291240394115448\n",
      "epoch 14 loss: 0.16436758637428284\n",
      "epoch 15 loss: 0.16226768493652344\n",
      "epoch 16 loss: 0.17961503565311432\n",
      "epoch 17 loss: 0.1651710718870163\n",
      "epoch 18 loss: 0.15942659974098206\n",
      "epoch 19 loss: 0.21229827404022217\n",
      "epoch 20 loss: 0.15377601981163025\n",
      "epoch 21 loss: 0.14983664453029633\n",
      "epoch 22 loss: 0.16156749427318573\n",
      "epoch 23 loss: 0.08854865282773972\n",
      "epoch 24 loss: 0.12304343283176422\n",
      "epoch 25 loss: 0.1418239176273346\n",
      "epoch 26 loss: 0.08112713694572449\n",
      "epoch 27 loss: 0.1299406737089157\n",
      "epoch 28 loss: 0.10801556706428528\n",
      "epoch 29 loss: 0.11773430556058884\n",
      "epoch 30 loss: 0.09238525480031967\n",
      "21\n",
      "epoch 1 loss: 0.9816858768463135\n",
      "epoch 2 loss: 0.4308791160583496\n",
      "epoch 3 loss: 0.5606083273887634\n",
      "epoch 4 loss: 0.20446906983852386\n",
      "epoch 5 loss: 0.18469959497451782\n",
      "epoch 6 loss: 0.1764766275882721\n",
      "epoch 7 loss: 0.16309408843517303\n",
      "epoch 8 loss: 0.14555078744888306\n",
      "epoch 9 loss: 0.19789907336235046\n",
      "epoch 10 loss: 0.1501600295305252\n",
      "epoch 11 loss: 0.18122458457946777\n",
      "epoch 12 loss: 0.17758716642856598\n",
      "epoch 13 loss: 0.1536320298910141\n",
      "epoch 14 loss: 0.18613781034946442\n",
      "epoch 15 loss: 0.16768689453601837\n",
      "epoch 16 loss: 0.1482883095741272\n",
      "epoch 17 loss: 0.1472625583410263\n",
      "epoch 18 loss: 0.13905595242977142\n",
      "epoch 19 loss: 0.15769587457180023\n",
      "epoch 20 loss: 0.19487173855304718\n",
      "epoch 21 loss: 0.1519511491060257\n",
      "epoch 22 loss: 0.16509456932544708\n",
      "epoch 23 loss: 0.10259904712438583\n",
      "epoch 24 loss: 0.15326131880283356\n",
      "epoch 25 loss: 0.1719183325767517\n",
      "epoch 26 loss: 0.11882006376981735\n",
      "epoch 27 loss: 0.07991204410791397\n",
      "epoch 28 loss: 0.09789485484361649\n",
      "epoch 29 loss: 0.09732753038406372\n",
      "epoch 30 loss: 0.1366792768239975\n",
      "22\n",
      "epoch 1 loss: 0.8119238018989563\n",
      "epoch 2 loss: 0.5133568048477173\n",
      "epoch 3 loss: 0.25630730390548706\n",
      "epoch 4 loss: 0.22286376357078552\n",
      "epoch 5 loss: 0.1703997552394867\n",
      "epoch 6 loss: 0.19207601249217987\n",
      "epoch 7 loss: 0.21242931485176086\n",
      "epoch 8 loss: 0.19040527939796448\n",
      "epoch 9 loss: 0.1260472685098648\n",
      "epoch 10 loss: 0.12830489873886108\n",
      "epoch 11 loss: 0.13555455207824707\n",
      "epoch 12 loss: 0.16495981812477112\n",
      "epoch 13 loss: 0.191514790058136\n",
      "epoch 14 loss: 0.17014820873737335\n",
      "epoch 15 loss: 0.17712906002998352\n",
      "epoch 16 loss: 0.16419361531734467\n",
      "epoch 17 loss: 0.15761135518550873\n",
      "epoch 18 loss: 0.18439467251300812\n",
      "epoch 19 loss: 0.16964462399482727\n",
      "epoch 20 loss: 0.14856798946857452\n",
      "epoch 21 loss: 0.15635468065738678\n",
      "epoch 22 loss: 0.17725101113319397\n",
      "epoch 23 loss: 0.15751130878925323\n",
      "epoch 24 loss: 0.13075079023838043\n",
      "epoch 25 loss: 0.22922442853450775\n",
      "epoch 26 loss: 0.11468076705932617\n",
      "epoch 27 loss: 0.2086493968963623\n",
      "epoch 28 loss: 0.10777166485786438\n",
      "epoch 29 loss: 0.09932490438222885\n",
      "epoch 30 loss: 0.08877376466989517\n",
      "23\n",
      "epoch 1 loss: 0.8697341680526733\n",
      "epoch 2 loss: 0.5758400559425354\n",
      "epoch 3 loss: 0.8109832406044006\n",
      "epoch 4 loss: 0.45680925250053406\n",
      "epoch 5 loss: 0.22291506826877594\n",
      "epoch 6 loss: 0.16935069859027863\n",
      "epoch 7 loss: 0.17640450596809387\n",
      "epoch 8 loss: 0.17424406111240387\n",
      "epoch 9 loss: 0.1502043604850769\n",
      "epoch 10 loss: 0.17978551983833313\n",
      "epoch 11 loss: 0.14510440826416016\n",
      "epoch 12 loss: 0.14557501673698425\n",
      "epoch 13 loss: 0.20053383708000183\n",
      "epoch 14 loss: 0.1825183779001236\n",
      "epoch 15 loss: 0.14847268164157867\n",
      "epoch 16 loss: 0.1488080471754074\n",
      "epoch 17 loss: 0.1535642296075821\n",
      "epoch 18 loss: 0.17418886721134186\n",
      "epoch 19 loss: 0.13028493523597717\n",
      "epoch 20 loss: 0.1380782127380371\n",
      "epoch 21 loss: 0.13938894867897034\n",
      "epoch 22 loss: 0.13799132406711578\n",
      "epoch 23 loss: 0.1251237839460373\n",
      "epoch 24 loss: 0.13239407539367676\n",
      "epoch 25 loss: 0.09243088215589523\n",
      "epoch 26 loss: 0.10969915241003036\n",
      "epoch 27 loss: 0.09884580969810486\n",
      "epoch 28 loss: 0.09963767230510712\n",
      "epoch 29 loss: 0.1393531709909439\n",
      "epoch 30 loss: 0.12229340523481369\n",
      "24\n",
      "epoch 1 loss: 0.6614115238189697\n",
      "epoch 2 loss: 0.7564821243286133\n",
      "epoch 3 loss: 0.43424785137176514\n",
      "epoch 4 loss: 0.1938842236995697\n",
      "epoch 5 loss: 0.18741974234580994\n",
      "epoch 6 loss: 0.1431007832288742\n",
      "epoch 7 loss: 0.1449144184589386\n",
      "epoch 8 loss: 0.16248610615730286\n",
      "epoch 9 loss: 0.16255269944667816\n",
      "epoch 10 loss: 0.15957558155059814\n",
      "epoch 11 loss: 0.15239761769771576\n",
      "epoch 12 loss: 0.16901065409183502\n",
      "epoch 13 loss: 0.15253712236881256\n",
      "epoch 14 loss: 0.17072828114032745\n",
      "epoch 15 loss: 0.15029969811439514\n",
      "epoch 16 loss: 0.12725263833999634\n",
      "epoch 17 loss: 0.1679888516664505\n",
      "epoch 18 loss: 0.16763481497764587\n",
      "epoch 19 loss: 0.14238691329956055\n",
      "epoch 20 loss: 0.1252439320087433\n",
      "epoch 21 loss: 0.11152497678995132\n",
      "epoch 22 loss: 0.10138203203678131\n",
      "epoch 23 loss: 0.11086765676736832\n",
      "epoch 24 loss: 0.13332760334014893\n",
      "epoch 25 loss: 0.12585516273975372\n",
      "epoch 26 loss: 0.10162866115570068\n",
      "epoch 27 loss: 0.1024651825428009\n",
      "epoch 28 loss: 0.10298383235931396\n",
      "epoch 29 loss: 0.09525985270738602\n",
      "epoch 30 loss: 0.10493277758359909\n",
      "25\n",
      "epoch 1 loss: 1.062089443206787\n",
      "epoch 2 loss: 0.6704702377319336\n",
      "epoch 3 loss: 0.46802493929862976\n",
      "epoch 4 loss: 0.2928144931793213\n",
      "epoch 5 loss: 0.23379738628864288\n",
      "epoch 6 loss: 0.16971664130687714\n",
      "epoch 7 loss: 0.1508500576019287\n",
      "epoch 8 loss: 0.18005967140197754\n",
      "epoch 9 loss: 0.12868013978004456\n",
      "epoch 10 loss: 0.1834854930639267\n",
      "epoch 11 loss: 0.16922374069690704\n",
      "epoch 12 loss: 0.16415062546730042\n",
      "epoch 13 loss: 0.15222887694835663\n",
      "epoch 14 loss: 0.18368405103683472\n",
      "epoch 15 loss: 0.16385991871356964\n",
      "epoch 16 loss: 0.17322517931461334\n",
      "epoch 17 loss: 0.15776707231998444\n",
      "epoch 18 loss: 0.12666209042072296\n",
      "epoch 19 loss: 0.15091660618782043\n",
      "epoch 20 loss: 0.1383797973394394\n",
      "epoch 21 loss: 0.13484928011894226\n",
      "epoch 22 loss: 0.138640359044075\n",
      "epoch 23 loss: 0.15979206562042236\n",
      "epoch 24 loss: 0.12667231261730194\n",
      "epoch 25 loss: 0.1137286052107811\n",
      "epoch 26 loss: 0.16340021789073944\n",
      "epoch 27 loss: 0.1340540051460266\n",
      "epoch 28 loss: 0.11499599367380142\n",
      "epoch 29 loss: 0.12156631797552109\n",
      "epoch 30 loss: 0.1330866813659668\n",
      "26\n",
      "epoch 1 loss: 1.1225907802581787\n",
      "epoch 2 loss: 0.5112594962120056\n",
      "epoch 3 loss: 0.2880128026008606\n",
      "epoch 4 loss: 0.19494158029556274\n",
      "epoch 5 loss: 0.1820094734430313\n",
      "epoch 6 loss: 0.1599566787481308\n",
      "epoch 7 loss: 0.16563157737255096\n",
      "epoch 8 loss: 0.15425077080726624\n",
      "epoch 9 loss: 0.17122702300548553\n",
      "epoch 10 loss: 0.14044451713562012\n",
      "epoch 11 loss: 0.1627308428287506\n",
      "epoch 12 loss: 0.17423534393310547\n",
      "epoch 13 loss: 0.16939999163150787\n",
      "epoch 14 loss: 0.1899251788854599\n",
      "epoch 15 loss: 0.16672013700008392\n",
      "epoch 16 loss: 0.15856263041496277\n",
      "epoch 17 loss: 0.14868727326393127\n",
      "epoch 18 loss: 0.15379200875759125\n",
      "epoch 19 loss: 0.16821478307247162\n",
      "epoch 20 loss: 0.17813852429389954\n",
      "epoch 21 loss: 0.11707790940999985\n",
      "epoch 22 loss: 0.17824022471904755\n",
      "epoch 23 loss: 0.12831419706344604\n",
      "epoch 24 loss: 0.1477680653333664\n",
      "epoch 25 loss: 0.1476934403181076\n",
      "epoch 26 loss: 0.14100205898284912\n",
      "epoch 27 loss: 0.1425279825925827\n",
      "epoch 28 loss: 0.18429218232631683\n",
      "epoch 29 loss: 0.09206205606460571\n",
      "epoch 30 loss: 0.1144852489233017\n",
      "27\n",
      "epoch 1 loss: 1.0557997226715088\n",
      "epoch 2 loss: 0.5124872922897339\n",
      "epoch 3 loss: 0.41483795642852783\n",
      "epoch 4 loss: 0.19925211369991302\n",
      "epoch 5 loss: 0.19417323172092438\n",
      "epoch 6 loss: 0.1549859344959259\n",
      "epoch 7 loss: 0.18851414322853088\n",
      "epoch 8 loss: 0.16513921320438385\n",
      "epoch 9 loss: 0.14894454181194305\n",
      "epoch 10 loss: 0.16046449542045593\n",
      "epoch 11 loss: 0.14670802652835846\n",
      "epoch 12 loss: 0.16365842521190643\n",
      "epoch 13 loss: 0.17767208814620972\n",
      "epoch 14 loss: 0.16807067394256592\n",
      "epoch 15 loss: 0.15111421048641205\n",
      "epoch 16 loss: 0.1620965451002121\n",
      "epoch 17 loss: 0.17343464493751526\n",
      "epoch 18 loss: 0.18532469868659973\n",
      "epoch 19 loss: 0.1879810094833374\n",
      "epoch 20 loss: 0.14946290850639343\n",
      "epoch 21 loss: 0.22285409271717072\n",
      "epoch 22 loss: 0.14840033650398254\n",
      "epoch 23 loss: 0.13830986618995667\n",
      "epoch 24 loss: 0.13828663527965546\n",
      "epoch 25 loss: 0.10892711579799652\n",
      "epoch 26 loss: 0.09641439467668533\n",
      "epoch 27 loss: 0.11985594779253006\n",
      "epoch 28 loss: 0.10386957228183746\n",
      "epoch 29 loss: 0.12268151342868805\n",
      "epoch 30 loss: 0.10471966862678528\n",
      "28\n",
      "epoch 1 loss: 0.664784848690033\n",
      "epoch 2 loss: 0.48508569598197937\n",
      "epoch 3 loss: 0.2752528488636017\n",
      "epoch 4 loss: 0.2661142647266388\n",
      "epoch 5 loss: 0.25683358311653137\n",
      "epoch 6 loss: 0.1844421923160553\n",
      "epoch 7 loss: 0.14371609687805176\n",
      "epoch 8 loss: 0.1953052431344986\n",
      "epoch 9 loss: 0.17375487089157104\n",
      "epoch 10 loss: 0.1465565264225006\n",
      "epoch 11 loss: 0.11790922284126282\n",
      "epoch 12 loss: 0.19560176134109497\n",
      "epoch 13 loss: 0.10775978863239288\n",
      "epoch 14 loss: 0.1413068324327469\n",
      "epoch 15 loss: 0.14379198849201202\n",
      "epoch 16 loss: 0.13151709735393524\n",
      "epoch 17 loss: 0.14698758721351624\n",
      "epoch 18 loss: 0.17390258610248566\n",
      "epoch 19 loss: 0.15453597903251648\n",
      "epoch 20 loss: 0.13349176943302155\n",
      "epoch 21 loss: 0.14039450883865356\n",
      "epoch 22 loss: 0.1565912961959839\n",
      "epoch 23 loss: 0.13437628746032715\n",
      "epoch 24 loss: 0.1653507500886917\n",
      "epoch 25 loss: 0.13011066615581512\n",
      "epoch 26 loss: 0.1266907900571823\n",
      "epoch 27 loss: 0.10940758883953094\n",
      "epoch 28 loss: 0.11349991708993912\n",
      "epoch 29 loss: 0.17224213480949402\n",
      "epoch 30 loss: 0.1452903151512146\n",
      "29\n",
      "epoch 1 loss: 0.9598895311355591\n",
      "epoch 2 loss: 0.6015392541885376\n",
      "epoch 3 loss: 0.36080002784729004\n",
      "epoch 4 loss: 0.18888621032238007\n",
      "epoch 5 loss: 0.17425096035003662\n",
      "epoch 6 loss: 0.14197304844856262\n",
      "epoch 7 loss: 0.20339538156986237\n",
      "epoch 8 loss: 0.20244157314300537\n",
      "epoch 9 loss: 0.18241390585899353\n",
      "epoch 10 loss: 0.15766726434230804\n",
      "epoch 11 loss: 0.1682741791009903\n",
      "epoch 12 loss: 0.16821330785751343\n",
      "epoch 13 loss: 0.16572359204292297\n",
      "epoch 14 loss: 0.16763849556446075\n",
      "epoch 15 loss: 0.1405652016401291\n",
      "epoch 16 loss: 0.18314172327518463\n",
      "epoch 17 loss: 0.11216636747121811\n",
      "epoch 18 loss: 0.14277422428131104\n",
      "epoch 19 loss: 0.10119189321994781\n",
      "epoch 20 loss: 0.1405540406703949\n",
      "epoch 21 loss: 0.10269412398338318\n",
      "epoch 22 loss: 0.11109095066785812\n",
      "epoch 23 loss: 0.1123838946223259\n",
      "epoch 24 loss: 0.16046170890331268\n",
      "epoch 25 loss: 0.0968131348490715\n",
      "epoch 26 loss: 0.1126568615436554\n",
      "epoch 27 loss: 0.10897362977266312\n",
      "epoch 28 loss: 0.09018941968679428\n",
      "epoch 29 loss: 0.10275460034608841\n",
      "epoch 30 loss: 0.10647597163915634\n",
      "30\n",
      "epoch 1 loss: 0.8137974739074707\n",
      "epoch 2 loss: 0.5603949427604675\n",
      "epoch 3 loss: 0.3763231337070465\n",
      "epoch 4 loss: 0.27173924446105957\n",
      "epoch 5 loss: 0.16362154483795166\n",
      "epoch 6 loss: 0.20191234350204468\n",
      "epoch 7 loss: 0.19238877296447754\n",
      "epoch 8 loss: 0.1252405196428299\n",
      "epoch 9 loss: 0.17147591710090637\n",
      "epoch 10 loss: 0.20836620032787323\n",
      "epoch 11 loss: 0.15229561924934387\n",
      "epoch 12 loss: 0.142754927277565\n",
      "epoch 13 loss: 0.14445790648460388\n",
      "epoch 14 loss: 0.15070390701293945\n",
      "epoch 15 loss: 0.18590056896209717\n",
      "epoch 16 loss: 0.12582798302173615\n",
      "epoch 17 loss: 0.14704753458499908\n",
      "epoch 18 loss: 0.14780093729496002\n",
      "epoch 19 loss: 0.1737012267112732\n",
      "epoch 20 loss: 0.13551759719848633\n",
      "epoch 21 loss: 0.16309325397014618\n",
      "epoch 22 loss: 0.15057721734046936\n",
      "epoch 23 loss: 0.11960947513580322\n",
      "epoch 24 loss: 0.11683036386966705\n",
      "epoch 25 loss: 0.1344890296459198\n",
      "epoch 26 loss: 0.0985703319311142\n",
      "epoch 27 loss: 0.13835199177265167\n",
      "epoch 28 loss: 0.12526197731494904\n",
      "epoch 29 loss: 0.09610270708799362\n",
      "epoch 30 loss: 0.13830162584781647\n",
      "31\n",
      "epoch 1 loss: 0.8311701416969299\n",
      "epoch 2 loss: 0.534938633441925\n",
      "epoch 3 loss: 0.3872978091239929\n",
      "epoch 4 loss: 0.2786467671394348\n",
      "epoch 5 loss: 0.21970795094966888\n",
      "epoch 6 loss: 0.18090949952602386\n",
      "epoch 7 loss: 0.17027290165424347\n",
      "epoch 8 loss: 0.1526104062795639\n",
      "epoch 9 loss: 0.20001187920570374\n",
      "epoch 10 loss: 0.18806369602680206\n",
      "epoch 11 loss: 0.18392880260944366\n",
      "epoch 12 loss: 0.17630381882190704\n",
      "epoch 13 loss: 0.19879914820194244\n",
      "epoch 14 loss: 0.15234564244747162\n",
      "epoch 15 loss: 0.15027718245983124\n",
      "epoch 16 loss: 0.17106617987155914\n",
      "epoch 17 loss: 0.16206611692905426\n",
      "epoch 18 loss: 0.17744691669940948\n",
      "epoch 19 loss: 0.1672360748052597\n",
      "epoch 20 loss: 0.21330101788043976\n",
      "epoch 21 loss: 0.16225582361221313\n",
      "epoch 22 loss: 0.12356390058994293\n",
      "epoch 23 loss: 0.1158750057220459\n",
      "epoch 24 loss: 0.17016509175300598\n",
      "epoch 25 loss: 0.16499608755111694\n",
      "epoch 26 loss: 0.13982313871383667\n",
      "epoch 27 loss: 0.14527460932731628\n",
      "epoch 28 loss: 0.13421934843063354\n",
      "epoch 29 loss: 0.13323771953582764\n",
      "epoch 30 loss: 0.16262969374656677\n",
      "32\n",
      "epoch 1 loss: 0.8178896903991699\n",
      "epoch 2 loss: 0.43319928646087646\n",
      "epoch 3 loss: 0.20095708966255188\n",
      "epoch 4 loss: 0.17738524079322815\n",
      "epoch 5 loss: 0.17261353135108948\n",
      "epoch 6 loss: 0.1301451474428177\n",
      "epoch 7 loss: 0.17829272150993347\n",
      "epoch 8 loss: 0.15528537333011627\n",
      "epoch 9 loss: 0.179989755153656\n",
      "epoch 10 loss: 0.13376867771148682\n",
      "epoch 11 loss: 0.15286186337471008\n",
      "epoch 12 loss: 0.1371476948261261\n",
      "epoch 13 loss: 0.1707915961742401\n",
      "epoch 14 loss: 0.12806931138038635\n",
      "epoch 15 loss: 0.15621785819530487\n",
      "epoch 16 loss: 0.15987148880958557\n",
      "epoch 17 loss: 0.18125468492507935\n",
      "epoch 18 loss: 0.1910572201013565\n",
      "epoch 19 loss: 0.11726709455251694\n",
      "epoch 20 loss: 0.12795862555503845\n",
      "epoch 21 loss: 0.16301016509532928\n",
      "epoch 22 loss: 0.16651827096939087\n",
      "epoch 23 loss: 0.11927277594804764\n",
      "epoch 24 loss: 0.11700690537691116\n",
      "epoch 25 loss: 0.10733822733163834\n",
      "epoch 26 loss: 0.10580351948738098\n",
      "epoch 27 loss: 0.11123614013195038\n",
      "epoch 28 loss: 0.10570202022790909\n",
      "epoch 29 loss: 0.08142150938510895\n",
      "epoch 30 loss: 0.1152370497584343\n",
      "33\n",
      "epoch 1 loss: 0.9278936982154846\n",
      "epoch 2 loss: 0.49561741948127747\n",
      "epoch 3 loss: 0.34158721566200256\n",
      "epoch 4 loss: 0.23372280597686768\n",
      "epoch 5 loss: 0.18854936957359314\n",
      "epoch 6 loss: 0.14267976582050323\n",
      "epoch 7 loss: 0.20794852077960968\n",
      "epoch 8 loss: 0.15418727695941925\n",
      "epoch 9 loss: 0.15782691538333893\n",
      "epoch 10 loss: 0.09995555132627487\n",
      "epoch 11 loss: 0.17709924280643463\n",
      "epoch 12 loss: 0.1961195319890976\n",
      "epoch 13 loss: 0.14541848003864288\n",
      "epoch 14 loss: 0.14732737839221954\n",
      "epoch 15 loss: 0.15219523012638092\n",
      "epoch 16 loss: 0.1777217835187912\n",
      "epoch 17 loss: 0.14715640246868134\n",
      "epoch 18 loss: 0.1488976627588272\n",
      "epoch 19 loss: 0.10994812101125717\n",
      "epoch 20 loss: 0.11162520200014114\n",
      "epoch 21 loss: 0.09967539459466934\n",
      "epoch 22 loss: 0.16911622881889343\n",
      "epoch 23 loss: 0.11739996075630188\n",
      "epoch 24 loss: 0.10977668315172195\n",
      "epoch 25 loss: 0.11473070085048676\n",
      "epoch 26 loss: 0.08338872343301773\n",
      "epoch 27 loss: 0.1033109575510025\n",
      "epoch 28 loss: 0.0931224599480629\n",
      "epoch 29 loss: 0.07929246127605438\n",
      "epoch 30 loss: 0.09814830869436264\n",
      "34\n",
      "epoch 1 loss: 0.6943447589874268\n",
      "epoch 2 loss: 0.5174611806869507\n",
      "epoch 3 loss: 0.2893708050251007\n",
      "epoch 4 loss: 0.23773027956485748\n",
      "epoch 5 loss: 0.2353512942790985\n",
      "epoch 6 loss: 0.17685972154140472\n",
      "epoch 7 loss: 0.16895151138305664\n",
      "epoch 8 loss: 0.17450261116027832\n",
      "epoch 9 loss: 0.15151257812976837\n",
      "epoch 10 loss: 0.19060905277729034\n",
      "epoch 11 loss: 0.17963318526744843\n",
      "epoch 12 loss: 0.13836252689361572\n",
      "epoch 13 loss: 0.17892275750637054\n",
      "epoch 14 loss: 0.1663539856672287\n",
      "epoch 15 loss: 0.19400818645954132\n",
      "epoch 16 loss: 0.1597556322813034\n",
      "epoch 17 loss: 0.17140786349773407\n",
      "epoch 18 loss: 0.1235705092549324\n",
      "epoch 19 loss: 0.17198218405246735\n",
      "epoch 20 loss: 0.13924990594387054\n",
      "epoch 21 loss: 0.10685394704341888\n",
      "epoch 22 loss: 0.13356824219226837\n",
      "epoch 23 loss: 0.16694575548171997\n",
      "epoch 24 loss: 0.1741376370191574\n",
      "epoch 25 loss: 0.15174607932567596\n",
      "epoch 26 loss: 0.1649024337530136\n",
      "epoch 27 loss: 0.12938183546066284\n",
      "epoch 28 loss: 0.12640923261642456\n",
      "epoch 29 loss: 0.13619166612625122\n",
      "epoch 30 loss: 0.12422917783260345\n",
      "35\n",
      "epoch 1 loss: 1.157510757446289\n",
      "epoch 2 loss: 0.49338752031326294\n",
      "epoch 3 loss: 0.32949164509773254\n",
      "epoch 4 loss: 0.24662107229232788\n",
      "epoch 5 loss: 0.15098707377910614\n",
      "epoch 6 loss: 0.15846587717533112\n",
      "epoch 7 loss: 0.18037624657154083\n",
      "epoch 8 loss: 0.1661071628332138\n",
      "epoch 9 loss: 0.13295461237430573\n",
      "epoch 10 loss: 0.1625348925590515\n",
      "epoch 11 loss: 0.16966460645198822\n",
      "epoch 12 loss: 0.14977437257766724\n",
      "epoch 13 loss: 0.16616973280906677\n",
      "epoch 14 loss: 0.1605430543422699\n",
      "epoch 15 loss: 0.16916051506996155\n",
      "epoch 16 loss: 0.17054679989814758\n",
      "epoch 17 loss: 0.16970379650592804\n",
      "epoch 18 loss: 0.14748777449131012\n",
      "epoch 19 loss: 0.13976046442985535\n",
      "epoch 20 loss: 0.15744668245315552\n",
      "epoch 21 loss: 0.17111416161060333\n",
      "epoch 22 loss: 0.147543266415596\n",
      "epoch 23 loss: 0.11664927750825882\n",
      "epoch 24 loss: 0.09673117846250534\n",
      "epoch 25 loss: 0.10285643488168716\n",
      "epoch 26 loss: 0.14280059933662415\n",
      "epoch 27 loss: 0.12006523460149765\n",
      "epoch 28 loss: 0.12579312920570374\n",
      "epoch 29 loss: 0.18203070759773254\n",
      "epoch 30 loss: 0.16289426386356354\n",
      "36\n",
      "epoch 1 loss: 0.7054066061973572\n",
      "epoch 2 loss: 0.6143953204154968\n",
      "epoch 3 loss: 0.2931211590766907\n",
      "epoch 4 loss: 0.14230063557624817\n",
      "epoch 5 loss: 0.19021804630756378\n",
      "epoch 6 loss: 0.19168272614479065\n",
      "epoch 7 loss: 0.1766572892665863\n",
      "epoch 8 loss: 0.17071649432182312\n",
      "epoch 9 loss: 0.15401986241340637\n",
      "epoch 10 loss: 0.14031995832920074\n",
      "epoch 11 loss: 0.15034011006355286\n",
      "epoch 12 loss: 0.16973574459552765\n",
      "epoch 13 loss: 0.17363208532333374\n",
      "epoch 14 loss: 0.18483024835586548\n",
      "epoch 15 loss: 0.21727173030376434\n",
      "epoch 16 loss: 0.14765016734600067\n",
      "epoch 17 loss: 0.11435236036777496\n",
      "epoch 18 loss: 0.15192779898643494\n",
      "epoch 19 loss: 0.18885202705860138\n",
      "epoch 20 loss: 0.12673214077949524\n",
      "epoch 21 loss: 0.1166851669549942\n",
      "epoch 22 loss: 0.17379479110240936\n",
      "epoch 23 loss: 0.14353181421756744\n",
      "epoch 24 loss: 0.11841293424367905\n",
      "epoch 25 loss: 0.12285400927066803\n",
      "epoch 26 loss: 0.19603724777698517\n",
      "epoch 27 loss: 0.1234092190861702\n",
      "epoch 28 loss: 0.1137385368347168\n",
      "epoch 29 loss: 0.12970474362373352\n",
      "epoch 30 loss: 0.10883631557226181\n",
      "37\n",
      "epoch 1 loss: 0.7070327401161194\n",
      "epoch 2 loss: 0.5535739064216614\n",
      "epoch 3 loss: 0.35016727447509766\n",
      "epoch 4 loss: 0.19852741062641144\n",
      "epoch 5 loss: 0.15479344129562378\n",
      "epoch 6 loss: 0.17498666048049927\n",
      "epoch 7 loss: 0.184771329164505\n",
      "epoch 8 loss: 0.14110594987869263\n",
      "epoch 9 loss: 0.16693240404129028\n",
      "epoch 10 loss: 0.12148097157478333\n",
      "epoch 11 loss: 0.1535610407590866\n",
      "epoch 12 loss: 0.16154681146144867\n",
      "epoch 13 loss: 0.19234512746334076\n",
      "epoch 14 loss: 0.15732041001319885\n",
      "epoch 15 loss: 0.1651189774274826\n",
      "epoch 16 loss: 0.1816720962524414\n",
      "epoch 17 loss: 0.15919721126556396\n",
      "epoch 18 loss: 0.17992578446865082\n",
      "epoch 19 loss: 0.10231003165245056\n",
      "epoch 20 loss: 0.15079081058502197\n",
      "epoch 21 loss: 0.14765183627605438\n",
      "epoch 22 loss: 0.1674632728099823\n",
      "epoch 23 loss: 0.14748120307922363\n",
      "epoch 24 loss: 0.14696237444877625\n",
      "epoch 25 loss: 0.14846034348011017\n",
      "epoch 26 loss: 0.1258058249950409\n",
      "epoch 27 loss: 0.14900413155555725\n",
      "epoch 28 loss: 0.10584723949432373\n",
      "epoch 29 loss: 0.12606647610664368\n",
      "epoch 30 loss: 0.0913364589214325\n",
      "38\n",
      "epoch 1 loss: 0.7112075686454773\n",
      "epoch 2 loss: 0.7759742140769958\n",
      "epoch 3 loss: 0.31911909580230713\n",
      "epoch 4 loss: 0.2047605663537979\n",
      "epoch 5 loss: 0.18820533156394958\n",
      "epoch 6 loss: 0.13537274301052094\n",
      "epoch 7 loss: 0.13692790269851685\n",
      "epoch 8 loss: 0.15717525780200958\n",
      "epoch 9 loss: 0.15603092312812805\n",
      "epoch 10 loss: 0.1237657219171524\n",
      "epoch 11 loss: 0.15271282196044922\n",
      "epoch 12 loss: 0.14704571664333344\n",
      "epoch 13 loss: 0.1494700163602829\n",
      "epoch 14 loss: 0.14386820793151855\n",
      "epoch 15 loss: 0.15559174120426178\n",
      "epoch 16 loss: 0.09324153512716293\n",
      "epoch 17 loss: 0.17827662825584412\n",
      "epoch 18 loss: 0.15534555912017822\n",
      "epoch 19 loss: 0.13003654778003693\n",
      "epoch 20 loss: 0.13723815977573395\n",
      "epoch 21 loss: 0.13204306364059448\n",
      "epoch 22 loss: 0.1018066331744194\n",
      "epoch 23 loss: 0.10647962242364883\n",
      "epoch 24 loss: 0.120939239859581\n",
      "epoch 25 loss: 0.09860560297966003\n",
      "epoch 26 loss: 0.11158651858568192\n",
      "epoch 27 loss: 0.10908941179513931\n",
      "epoch 28 loss: 0.1055610328912735\n",
      "epoch 29 loss: 0.12209387868642807\n",
      "epoch 30 loss: 0.17255769670009613\n",
      "39\n",
      "epoch 1 loss: 0.6869114637374878\n",
      "epoch 2 loss: 0.4592907726764679\n",
      "epoch 3 loss: 0.3471659719944\n",
      "epoch 4 loss: 0.20756685733795166\n",
      "epoch 5 loss: 0.1722104847431183\n",
      "epoch 6 loss: 0.16243614256381989\n",
      "epoch 7 loss: 0.1487755924463272\n",
      "epoch 8 loss: 0.18317952752113342\n",
      "epoch 9 loss: 0.1616532802581787\n",
      "epoch 10 loss: 0.17061613500118256\n",
      "epoch 11 loss: 0.1650683879852295\n",
      "epoch 12 loss: 0.13680729269981384\n",
      "epoch 13 loss: 0.15926767885684967\n",
      "epoch 14 loss: 0.1534184068441391\n",
      "epoch 15 loss: 0.16476161777973175\n",
      "epoch 16 loss: 0.15445898473262787\n",
      "epoch 17 loss: 0.17343546450138092\n",
      "epoch 18 loss: 0.12654685974121094\n",
      "epoch 19 loss: 0.12006911635398865\n",
      "epoch 20 loss: 0.10341119766235352\n",
      "epoch 21 loss: 0.12934330105781555\n",
      "epoch 22 loss: 0.12027832865715027\n",
      "epoch 23 loss: 0.11436568945646286\n",
      "epoch 24 loss: 0.07868725061416626\n",
      "epoch 25 loss: 0.1134926825761795\n",
      "epoch 26 loss: 0.1011400818824768\n",
      "epoch 27 loss: 0.08987704664468765\n",
      "epoch 28 loss: 0.11055141687393188\n",
      "epoch 29 loss: 0.08703310787677765\n",
      "epoch 30 loss: 0.08898019790649414\n",
      "40\n",
      "epoch 1 loss: 0.8986109495162964\n",
      "epoch 2 loss: 0.5131168961524963\n",
      "epoch 3 loss: 0.46709322929382324\n",
      "epoch 4 loss: 0.255807489156723\n",
      "epoch 5 loss: 0.16766633093357086\n",
      "epoch 6 loss: 0.1639442890882492\n",
      "epoch 7 loss: 0.15804682672023773\n",
      "epoch 8 loss: 0.15967503190040588\n",
      "epoch 9 loss: 0.1373913437128067\n",
      "epoch 10 loss: 0.16492466628551483\n",
      "epoch 11 loss: 0.15333515405654907\n",
      "epoch 12 loss: 0.14366267621517181\n",
      "epoch 13 loss: 0.17263291776180267\n",
      "epoch 14 loss: 0.17337781190872192\n",
      "epoch 15 loss: 0.1610044538974762\n",
      "epoch 16 loss: 0.13201911747455597\n",
      "epoch 17 loss: 0.11219897121191025\n",
      "epoch 18 loss: 0.15534593164920807\n",
      "epoch 19 loss: 0.1700962781906128\n",
      "epoch 20 loss: 0.15816883742809296\n",
      "epoch 21 loss: 0.11219411343336105\n",
      "epoch 22 loss: 0.1356196403503418\n",
      "epoch 23 loss: 0.11284114420413971\n",
      "epoch 24 loss: 0.13505376875400543\n",
      "epoch 25 loss: 0.10891947150230408\n",
      "epoch 26 loss: 0.10687326639890671\n",
      "epoch 27 loss: 0.11000966280698776\n",
      "epoch 28 loss: 0.1262217015028\n",
      "epoch 29 loss: 0.11191118508577347\n",
      "epoch 30 loss: 0.07798779010772705\n",
      "41\n",
      "epoch 1 loss: 0.8381951451301575\n",
      "epoch 2 loss: 0.513129711151123\n",
      "epoch 3 loss: 0.28097572922706604\n",
      "epoch 4 loss: 0.21237987279891968\n",
      "epoch 5 loss: 0.2088773101568222\n",
      "epoch 6 loss: 0.1708337813615799\n",
      "epoch 7 loss: 0.188482865691185\n",
      "epoch 8 loss: 0.15894849598407745\n",
      "epoch 9 loss: 0.1350007951259613\n",
      "epoch 10 loss: 0.14601260423660278\n",
      "epoch 11 loss: 0.19016529619693756\n",
      "epoch 12 loss: 0.16106003522872925\n",
      "epoch 13 loss: 0.1263989955186844\n",
      "epoch 14 loss: 0.16907504200935364\n",
      "epoch 15 loss: 0.12636110186576843\n",
      "epoch 16 loss: 0.1817786693572998\n",
      "epoch 17 loss: 0.15876887738704681\n",
      "epoch 18 loss: 0.14078089594841003\n",
      "epoch 19 loss: 0.18111811578273773\n",
      "epoch 20 loss: 0.1401095986366272\n",
      "epoch 21 loss: 0.23221051692962646\n",
      "epoch 22 loss: 0.1457512080669403\n",
      "epoch 23 loss: 0.1841309666633606\n",
      "epoch 24 loss: 0.16125880181789398\n",
      "epoch 25 loss: 0.15260207653045654\n",
      "epoch 26 loss: 0.113052599132061\n",
      "epoch 27 loss: 0.14815764129161835\n",
      "epoch 28 loss: 0.19186089932918549\n",
      "epoch 29 loss: 0.09951560199260712\n",
      "epoch 30 loss: 0.12099651247262955\n",
      "42\n",
      "epoch 1 loss: 0.83895343542099\n",
      "epoch 2 loss: 0.6267170310020447\n",
      "epoch 3 loss: 0.2873699367046356\n",
      "epoch 4 loss: 0.16081303358078003\n",
      "epoch 5 loss: 0.18271741271018982\n",
      "epoch 6 loss: 0.16159945726394653\n",
      "epoch 7 loss: 0.16395018994808197\n",
      "epoch 8 loss: 0.1753261536359787\n",
      "epoch 9 loss: 0.17135892808437347\n",
      "epoch 10 loss: 0.13125211000442505\n",
      "epoch 11 loss: 0.1337713599205017\n",
      "epoch 12 loss: 0.1620681881904602\n",
      "epoch 13 loss: 0.1954544335603714\n",
      "epoch 14 loss: 0.17656615376472473\n",
      "epoch 15 loss: 0.16726452112197876\n",
      "epoch 16 loss: 0.1366080790758133\n",
      "epoch 17 loss: 0.13269591331481934\n",
      "epoch 18 loss: 0.14756934344768524\n",
      "epoch 19 loss: 0.10577940195798874\n",
      "epoch 20 loss: 0.12242013961076736\n",
      "epoch 21 loss: 0.1102740615606308\n",
      "epoch 22 loss: 0.0901818498969078\n",
      "epoch 23 loss: 0.10036975145339966\n",
      "epoch 24 loss: 0.12410946190357208\n",
      "epoch 25 loss: 0.10429000854492188\n",
      "epoch 26 loss: 0.12365493923425674\n",
      "epoch 27 loss: 0.1286998987197876\n",
      "epoch 28 loss: 0.1329277604818344\n",
      "epoch 29 loss: 0.11898209154605865\n",
      "epoch 30 loss: 0.10253286361694336\n",
      "43\n",
      "epoch 1 loss: 0.9714853167533875\n",
      "epoch 2 loss: 0.44266176223754883\n",
      "epoch 3 loss: 0.20414292812347412\n",
      "epoch 4 loss: 0.19357305765151978\n",
      "epoch 5 loss: 0.1652499884366989\n",
      "epoch 6 loss: 0.20464156568050385\n",
      "epoch 7 loss: 0.16643106937408447\n",
      "epoch 8 loss: 0.12996205687522888\n",
      "epoch 9 loss: 0.16911816596984863\n",
      "epoch 10 loss: 0.17874497175216675\n",
      "epoch 11 loss: 0.14836278557777405\n",
      "epoch 12 loss: 0.15505748987197876\n",
      "epoch 13 loss: 0.16594688594341278\n",
      "epoch 14 loss: 0.17160513997077942\n",
      "epoch 15 loss: 0.15679828822612762\n",
      "epoch 16 loss: 0.1791449785232544\n",
      "epoch 17 loss: 0.16483384370803833\n",
      "epoch 18 loss: 0.15884868800640106\n",
      "epoch 19 loss: 0.16324590146541595\n",
      "epoch 20 loss: 0.1345510482788086\n",
      "epoch 21 loss: 0.16979266703128815\n",
      "epoch 22 loss: 0.1597369760274887\n",
      "epoch 23 loss: 0.1875070035457611\n",
      "epoch 24 loss: 0.20356440544128418\n",
      "epoch 25 loss: 0.1260116547346115\n",
      "epoch 26 loss: 0.14138391613960266\n",
      "epoch 27 loss: 0.15473602712154388\n",
      "epoch 28 loss: 0.15037065744400024\n",
      "epoch 29 loss: 0.1627410501241684\n",
      "epoch 30 loss: 0.10746423900127411\n",
      "44\n",
      "epoch 1 loss: 1.0261013507843018\n",
      "epoch 2 loss: 0.6918784379959106\n",
      "epoch 3 loss: 0.5831669569015503\n",
      "epoch 4 loss: 0.35120889544487\n",
      "epoch 5 loss: 0.22180722653865814\n",
      "epoch 6 loss: 0.1531210094690323\n",
      "epoch 7 loss: 0.15642470121383667\n",
      "epoch 8 loss: 0.1738872081041336\n",
      "epoch 9 loss: 0.15158125758171082\n",
      "epoch 10 loss: 0.15934252738952637\n",
      "epoch 11 loss: 0.16986021399497986\n",
      "epoch 12 loss: 0.15944060683250427\n",
      "epoch 13 loss: 0.17890304327011108\n",
      "epoch 14 loss: 0.15211927890777588\n",
      "epoch 15 loss: 0.17046049237251282\n",
      "epoch 16 loss: 0.12657073140144348\n",
      "epoch 17 loss: 0.1608370542526245\n",
      "epoch 18 loss: 0.14783525466918945\n",
      "epoch 19 loss: 0.19560912251472473\n",
      "epoch 20 loss: 0.12465282529592514\n",
      "epoch 21 loss: 0.138351172208786\n",
      "epoch 22 loss: 0.11677798628807068\n",
      "epoch 23 loss: 0.11676444113254547\n",
      "epoch 24 loss: 0.11904781311750412\n",
      "epoch 25 loss: 0.10951270908117294\n",
      "epoch 26 loss: 0.15823279321193695\n",
      "epoch 27 loss: 0.11585331708192825\n",
      "epoch 28 loss: 0.10521568357944489\n",
      "epoch 29 loss: 0.10220902413129807\n",
      "epoch 30 loss: 0.10743848979473114\n",
      "45\n",
      "epoch 1 loss: 0.9097378849983215\n",
      "epoch 2 loss: 0.6066570281982422\n",
      "epoch 3 loss: 0.42616868019104004\n",
      "epoch 4 loss: 0.3175833225250244\n",
      "epoch 5 loss: 0.250176340341568\n",
      "epoch 6 loss: 0.16479843854904175\n",
      "epoch 7 loss: 0.16585706174373627\n",
      "epoch 8 loss: 0.15357886254787445\n",
      "epoch 9 loss: 0.16841460764408112\n",
      "epoch 10 loss: 0.16501307487487793\n",
      "epoch 11 loss: 0.20440131425857544\n",
      "epoch 12 loss: 0.1636137068271637\n",
      "epoch 13 loss: 0.14302422106266022\n",
      "epoch 14 loss: 0.13490928709506989\n",
      "epoch 15 loss: 0.19955819845199585\n",
      "epoch 16 loss: 0.16408580541610718\n",
      "epoch 17 loss: 0.15398627519607544\n",
      "epoch 18 loss: 0.15283270180225372\n",
      "epoch 19 loss: 0.1480492502450943\n",
      "epoch 20 loss: 0.17125384509563446\n",
      "epoch 21 loss: 0.1496741622686386\n",
      "epoch 22 loss: 0.1277693510055542\n",
      "epoch 23 loss: 0.16381153464317322\n",
      "epoch 24 loss: 0.11872672289609909\n",
      "epoch 25 loss: 0.14843492209911346\n",
      "epoch 26 loss: 0.11337538063526154\n",
      "epoch 27 loss: 0.12374422699213028\n",
      "epoch 28 loss: 0.15802811086177826\n",
      "epoch 29 loss: 0.15583567321300507\n",
      "epoch 30 loss: 0.09754455834627151\n",
      "46\n",
      "epoch 1 loss: 0.7795843482017517\n",
      "epoch 2 loss: 0.6680504083633423\n",
      "epoch 3 loss: 0.3309137225151062\n",
      "epoch 4 loss: 0.22594280540943146\n",
      "epoch 5 loss: 0.15185196697711945\n",
      "epoch 6 loss: 0.16892410814762115\n",
      "epoch 7 loss: 0.1620328724384308\n",
      "epoch 8 loss: 0.15461412072181702\n",
      "epoch 9 loss: 0.14687994122505188\n",
      "epoch 10 loss: 0.15878406167030334\n",
      "epoch 11 loss: 0.1737578958272934\n",
      "epoch 12 loss: 0.16029031574726105\n",
      "epoch 13 loss: 0.17796605825424194\n",
      "epoch 14 loss: 0.18456962704658508\n",
      "epoch 15 loss: 0.16368120908737183\n",
      "epoch 16 loss: 0.15563230216503143\n",
      "epoch 17 loss: 0.16109827160835266\n",
      "epoch 18 loss: 0.16930772364139557\n",
      "epoch 19 loss: 0.13970382511615753\n",
      "epoch 20 loss: 0.1671873778104782\n",
      "epoch 21 loss: 0.14868836104869843\n",
      "epoch 22 loss: 0.18375204503536224\n",
      "epoch 23 loss: 0.12962977588176727\n",
      "epoch 24 loss: 0.13311044871807098\n",
      "epoch 25 loss: 0.15409334003925323\n",
      "epoch 26 loss: 0.14013293385505676\n",
      "epoch 27 loss: 0.1194550171494484\n",
      "epoch 28 loss: 0.14121881127357483\n",
      "epoch 29 loss: 0.10456666350364685\n",
      "epoch 30 loss: 0.11421756446361542\n",
      "47\n",
      "epoch 1 loss: 0.7586994767189026\n",
      "epoch 2 loss: 0.5020060539245605\n",
      "epoch 3 loss: 0.3547315001487732\n",
      "epoch 4 loss: 0.23472535610198975\n",
      "epoch 5 loss: 0.15384872257709503\n",
      "epoch 6 loss: 0.14904789626598358\n",
      "epoch 7 loss: 0.17907270789146423\n",
      "epoch 8 loss: 0.21405243873596191\n",
      "epoch 9 loss: 0.17923088371753693\n",
      "epoch 10 loss: 0.16218513250350952\n",
      "epoch 11 loss: 0.170291930437088\n",
      "epoch 12 loss: 0.18440485000610352\n",
      "epoch 13 loss: 0.1506103128194809\n",
      "epoch 14 loss: 0.12619075179100037\n",
      "epoch 15 loss: 0.15703502297401428\n",
      "epoch 16 loss: 0.15379919111728668\n",
      "epoch 17 loss: 0.15613442659378052\n",
      "epoch 18 loss: 0.14509537816047668\n",
      "epoch 19 loss: 0.15150995552539825\n",
      "epoch 20 loss: 0.15018784999847412\n",
      "epoch 21 loss: 0.20367929339408875\n",
      "epoch 22 loss: 0.17568622529506683\n",
      "epoch 23 loss: 0.1601153016090393\n",
      "epoch 24 loss: 0.1536964625120163\n",
      "epoch 25 loss: 0.12392433732748032\n",
      "epoch 26 loss: 0.1226920336484909\n",
      "epoch 27 loss: 0.0816219300031662\n",
      "epoch 28 loss: 0.12331988662481308\n",
      "epoch 29 loss: 0.0933438092470169\n",
      "epoch 30 loss: 0.12166022509336472\n",
      "48\n",
      "epoch 1 loss: 0.9328198432922363\n",
      "epoch 2 loss: 0.3826720714569092\n",
      "epoch 3 loss: 0.2999474108219147\n",
      "epoch 4 loss: 0.1926436424255371\n",
      "epoch 5 loss: 0.17569003999233246\n",
      "epoch 6 loss: 0.1914449781179428\n",
      "epoch 7 loss: 0.17229850590229034\n",
      "epoch 8 loss: 0.14082801342010498\n",
      "epoch 9 loss: 0.15656012296676636\n",
      "epoch 10 loss: 0.16780661046504974\n",
      "epoch 11 loss: 0.17126525938510895\n",
      "epoch 12 loss: 0.14983992278575897\n",
      "epoch 13 loss: 0.1832263469696045\n",
      "epoch 14 loss: 0.14250540733337402\n",
      "epoch 15 loss: 0.14954036474227905\n",
      "epoch 16 loss: 0.2024480402469635\n",
      "epoch 17 loss: 0.13240446150302887\n",
      "epoch 18 loss: 0.13592036068439484\n",
      "epoch 19 loss: 0.19095611572265625\n",
      "epoch 20 loss: 0.14305360615253448\n",
      "epoch 21 loss: 0.13940024375915527\n",
      "epoch 22 loss: 0.09911045432090759\n",
      "epoch 23 loss: 0.13983766734600067\n",
      "epoch 24 loss: 0.10320848971605301\n",
      "epoch 25 loss: 0.10143823176622391\n",
      "epoch 26 loss: 0.10561536252498627\n",
      "epoch 27 loss: 0.10453204810619354\n",
      "epoch 28 loss: 0.10366399586200714\n",
      "epoch 29 loss: 0.10124989598989487\n",
      "epoch 30 loss: 0.0854891836643219\n",
      "49\n",
      "epoch 1 loss: 0.8256092667579651\n",
      "epoch 2 loss: 0.5483586192131042\n",
      "epoch 3 loss: 0.32135945558547974\n",
      "epoch 4 loss: 0.15579287707805634\n",
      "epoch 5 loss: 0.13772840797901154\n",
      "epoch 6 loss: 0.1047167181968689\n",
      "epoch 7 loss: 0.1564895659685135\n",
      "epoch 8 loss: 0.15714237093925476\n",
      "epoch 9 loss: 0.1809806525707245\n",
      "epoch 10 loss: 0.1449057012796402\n",
      "epoch 11 loss: 0.14456269145011902\n",
      "epoch 12 loss: 0.18158742785453796\n",
      "epoch 13 loss: 0.14297360181808472\n",
      "epoch 14 loss: 0.14900432527065277\n",
      "epoch 15 loss: 0.15350764989852905\n",
      "epoch 16 loss: 0.14414654672145844\n",
      "epoch 17 loss: 0.14815127849578857\n",
      "epoch 18 loss: 0.15990282595157623\n",
      "epoch 19 loss: 0.14170105755329132\n",
      "epoch 20 loss: 0.13794998824596405\n",
      "epoch 21 loss: 0.20073454082012177\n",
      "epoch 22 loss: 0.19435493648052216\n",
      "epoch 23 loss: 0.18641652166843414\n",
      "epoch 24 loss: 0.14621774852275848\n",
      "epoch 25 loss: 0.12558642029762268\n",
      "epoch 26 loss: 0.140106663107872\n",
      "epoch 27 loss: 0.1081329882144928\n",
      "epoch 28 loss: 0.16932494938373566\n",
      "epoch 29 loss: 0.09322269260883331\n",
      "epoch 30 loss: 0.1007785052061081\n",
      "50\n",
      "epoch 1 loss: 1.0381296873092651\n",
      "epoch 2 loss: 0.5266271233558655\n",
      "epoch 3 loss: 0.29494696855545044\n",
      "epoch 4 loss: 0.15018826723098755\n",
      "epoch 5 loss: 0.19574646651744843\n",
      "epoch 6 loss: 0.18909509479999542\n",
      "epoch 7 loss: 0.16535472869873047\n",
      "epoch 8 loss: 0.16241857409477234\n",
      "epoch 9 loss: 0.15956100821495056\n",
      "epoch 10 loss: 0.18750251829624176\n",
      "epoch 11 loss: 0.13481085002422333\n",
      "epoch 12 loss: 0.19893257319927216\n",
      "epoch 13 loss: 0.14976289868354797\n",
      "epoch 14 loss: 0.14658686518669128\n",
      "epoch 15 loss: 0.16962575912475586\n",
      "epoch 16 loss: 0.13465897738933563\n",
      "epoch 17 loss: 0.14006860554218292\n",
      "epoch 18 loss: 0.12415013462305069\n",
      "epoch 19 loss: 0.16616615653038025\n",
      "epoch 20 loss: 0.11538621038198471\n",
      "epoch 21 loss: 0.11152608692646027\n",
      "epoch 22 loss: 0.1368795484304428\n",
      "epoch 23 loss: 0.11389530450105667\n",
      "epoch 24 loss: 0.11280187964439392\n",
      "epoch 25 loss: 0.11216992139816284\n",
      "epoch 26 loss: 0.10539939254522324\n",
      "epoch 27 loss: 0.13730388879776\n",
      "epoch 28 loss: 0.09662222862243652\n",
      "epoch 29 loss: 0.10862037539482117\n",
      "epoch 30 loss: 0.1070697009563446\n",
      "51\n",
      "epoch 1 loss: 0.9212172627449036\n",
      "epoch 2 loss: 0.48872923851013184\n",
      "epoch 3 loss: 0.36407381296157837\n",
      "epoch 4 loss: 0.29782676696777344\n",
      "epoch 5 loss: 0.2018219381570816\n",
      "epoch 6 loss: 0.17147909104824066\n",
      "epoch 7 loss: 0.20924076437950134\n",
      "epoch 8 loss: 0.12329237163066864\n",
      "epoch 9 loss: 0.15826746821403503\n",
      "epoch 10 loss: 0.15608403086662292\n",
      "epoch 11 loss: 0.14818058907985687\n",
      "epoch 12 loss: 0.12238992750644684\n",
      "epoch 13 loss: 0.17699381709098816\n",
      "epoch 14 loss: 0.14720727503299713\n",
      "epoch 15 loss: 0.15086862444877625\n",
      "epoch 16 loss: 0.18363364040851593\n",
      "epoch 17 loss: 0.17101304233074188\n",
      "epoch 18 loss: 0.13260596990585327\n",
      "epoch 19 loss: 0.12915381789207458\n",
      "epoch 20 loss: 0.18211419880390167\n",
      "epoch 21 loss: 0.15462321043014526\n",
      "epoch 22 loss: 0.11896021664142609\n",
      "epoch 23 loss: 0.12960153818130493\n",
      "epoch 24 loss: 0.16175690293312073\n",
      "epoch 25 loss: 0.17749544978141785\n",
      "epoch 26 loss: 0.13365104794502258\n",
      "epoch 27 loss: 0.10288064181804657\n",
      "epoch 28 loss: 0.10444185882806778\n",
      "epoch 29 loss: 0.08532736450433731\n",
      "epoch 30 loss: 0.11297830939292908\n",
      "52\n",
      "epoch 1 loss: 0.7985292673110962\n",
      "epoch 2 loss: 0.5467137694358826\n",
      "epoch 3 loss: 0.35351866483688354\n",
      "epoch 4 loss: 0.24293971061706543\n",
      "epoch 5 loss: 0.11585020273923874\n",
      "epoch 6 loss: 0.18460284173488617\n",
      "epoch 7 loss: 0.15008892118930817\n",
      "epoch 8 loss: 0.18165747821331024\n",
      "epoch 9 loss: 0.14877435564994812\n",
      "epoch 10 loss: 0.1763276755809784\n",
      "epoch 11 loss: 0.16827987134456635\n",
      "epoch 12 loss: 0.17117886245250702\n",
      "epoch 13 loss: 0.15152238309383392\n",
      "epoch 14 loss: 0.15773575007915497\n",
      "epoch 15 loss: 0.17710314691066742\n",
      "epoch 16 loss: 0.18544283509254456\n",
      "epoch 17 loss: 0.14977149665355682\n",
      "epoch 18 loss: 0.1565827578306198\n",
      "epoch 19 loss: 0.17176665365695953\n",
      "epoch 20 loss: 0.11374898254871368\n",
      "epoch 21 loss: 0.1908978819847107\n",
      "epoch 22 loss: 0.10954266786575317\n",
      "epoch 23 loss: 0.16596020758152008\n",
      "epoch 24 loss: 0.139101043343544\n",
      "epoch 25 loss: 0.12494318187236786\n",
      "epoch 26 loss: 0.10751935094594955\n",
      "epoch 27 loss: 0.1406077742576599\n",
      "epoch 28 loss: 0.09184589982032776\n",
      "epoch 29 loss: 0.15453188121318817\n",
      "epoch 30 loss: 0.12481469660997391\n",
      "53\n",
      "epoch 1 loss: 0.7648023962974548\n",
      "epoch 2 loss: 0.4244070053100586\n",
      "epoch 3 loss: 0.2726963758468628\n",
      "epoch 4 loss: 0.20569859445095062\n",
      "epoch 5 loss: 0.14429713785648346\n",
      "epoch 6 loss: 0.13633933663368225\n",
      "epoch 7 loss: 0.14941678941249847\n",
      "epoch 8 loss: 0.1409035176038742\n",
      "epoch 9 loss: 0.17686742544174194\n",
      "epoch 10 loss: 0.16702404618263245\n",
      "epoch 11 loss: 0.17042672634124756\n",
      "epoch 12 loss: 0.14232859015464783\n",
      "epoch 13 loss: 0.17288419604301453\n",
      "epoch 14 loss: 0.10301888734102249\n",
      "epoch 15 loss: 0.13081267476081848\n",
      "epoch 16 loss: 0.11457432061433792\n",
      "epoch 17 loss: 0.10655397921800613\n",
      "epoch 18 loss: 0.11660865694284439\n",
      "epoch 19 loss: 0.11040366441011429\n",
      "epoch 20 loss: 0.12421616166830063\n",
      "epoch 21 loss: 0.1102999746799469\n",
      "epoch 22 loss: 0.08544635027647018\n",
      "epoch 23 loss: 0.12350429594516754\n",
      "epoch 24 loss: 0.09963036328554153\n",
      "epoch 25 loss: 0.11001584678888321\n",
      "epoch 26 loss: 0.1221901923418045\n",
      "epoch 27 loss: 0.09304403513669968\n",
      "epoch 28 loss: 0.1007455363869667\n",
      "epoch 29 loss: 0.08925751596689224\n",
      "epoch 30 loss: 0.10330948233604431\n",
      "54\n",
      "epoch 1 loss: 0.8020058870315552\n",
      "epoch 2 loss: 0.5371543169021606\n",
      "epoch 3 loss: 0.36987510323524475\n",
      "epoch 4 loss: 0.22051453590393066\n",
      "epoch 5 loss: 0.17478251457214355\n",
      "epoch 6 loss: 0.14081519842147827\n",
      "epoch 7 loss: 0.13052257895469666\n",
      "epoch 8 loss: 0.16260644793510437\n",
      "epoch 9 loss: 0.1859249770641327\n",
      "epoch 10 loss: 0.13717544078826904\n",
      "epoch 11 loss: 0.1869090050458908\n",
      "epoch 12 loss: 0.12149791419506073\n",
      "epoch 13 loss: 0.15367238223552704\n",
      "epoch 14 loss: 0.18345540761947632\n",
      "epoch 15 loss: 0.18860046565532684\n",
      "epoch 16 loss: 0.14176055788993835\n",
      "epoch 17 loss: 0.1551263928413391\n",
      "epoch 18 loss: 0.14694899320602417\n",
      "epoch 19 loss: 0.17266976833343506\n",
      "epoch 20 loss: 0.18740896880626678\n",
      "epoch 21 loss: 0.17478275299072266\n",
      "epoch 22 loss: 0.1303757131099701\n",
      "epoch 23 loss: 0.14550748467445374\n",
      "epoch 24 loss: 0.15837906301021576\n",
      "epoch 25 loss: 0.1410672962665558\n",
      "epoch 26 loss: 0.14073044061660767\n",
      "epoch 27 loss: 0.1330537050962448\n",
      "epoch 28 loss: 0.1324799507856369\n",
      "epoch 29 loss: 0.08839248865842819\n",
      "epoch 30 loss: 0.12288900464773178\n",
      "55\n",
      "epoch 1 loss: 0.6215135455131531\n",
      "epoch 2 loss: 0.8313283324241638\n",
      "epoch 3 loss: 0.9871082305908203\n",
      "epoch 4 loss: 0.6221976280212402\n",
      "epoch 5 loss: 0.28809988498687744\n",
      "epoch 6 loss: 0.14819082617759705\n",
      "epoch 7 loss: 0.193682461977005\n",
      "epoch 8 loss: 0.18849587440490723\n",
      "epoch 9 loss: 0.11688800156116486\n",
      "epoch 10 loss: 0.1789361834526062\n",
      "epoch 11 loss: 0.14836081862449646\n",
      "epoch 12 loss: 0.1430698186159134\n",
      "epoch 13 loss: 0.1529126614332199\n",
      "epoch 14 loss: 0.18163621425628662\n",
      "epoch 15 loss: 0.15220284461975098\n",
      "epoch 16 loss: 0.15307258069515228\n",
      "epoch 17 loss: 0.1429588347673416\n",
      "epoch 18 loss: 0.1639285385608673\n",
      "epoch 19 loss: 0.11417413502931595\n",
      "epoch 20 loss: 0.14777101576328278\n",
      "epoch 21 loss: 0.11463531106710434\n",
      "epoch 22 loss: 0.17180673778057098\n",
      "epoch 23 loss: 0.14305627346038818\n",
      "epoch 24 loss: 0.12262673676013947\n",
      "epoch 25 loss: 0.14711225032806396\n",
      "epoch 26 loss: 0.14153853058815002\n",
      "epoch 27 loss: 0.1406955122947693\n",
      "epoch 28 loss: 0.11413481086492538\n",
      "epoch 29 loss: 0.12738235294818878\n",
      "epoch 30 loss: 0.1301117241382599\n",
      "56\n",
      "epoch 1 loss: 0.8003110885620117\n",
      "epoch 2 loss: 0.8191283345222473\n",
      "epoch 3 loss: 0.36543184518814087\n",
      "epoch 4 loss: 0.21233409643173218\n",
      "epoch 5 loss: 0.20765350759029388\n",
      "epoch 6 loss: 0.19789345562458038\n",
      "epoch 7 loss: 0.17310497164726257\n",
      "epoch 8 loss: 0.16322673857212067\n",
      "epoch 9 loss: 0.1537931263446808\n",
      "epoch 10 loss: 0.14174818992614746\n",
      "epoch 11 loss: 0.16776210069656372\n",
      "epoch 12 loss: 0.17101942002773285\n",
      "epoch 13 loss: 0.13158629834651947\n",
      "epoch 14 loss: 0.13555997610092163\n",
      "epoch 15 loss: 0.16199228167533875\n",
      "epoch 16 loss: 0.1807863563299179\n",
      "epoch 17 loss: 0.12489018589258194\n",
      "epoch 18 loss: 0.13395452499389648\n",
      "epoch 19 loss: 0.14921672642230988\n",
      "epoch 20 loss: 0.1411770135164261\n",
      "epoch 21 loss: 0.16352462768554688\n",
      "epoch 22 loss: 0.15443077683448792\n",
      "epoch 23 loss: 0.1744798719882965\n",
      "epoch 24 loss: 0.11036567389965057\n",
      "epoch 25 loss: 0.13534048199653625\n",
      "epoch 26 loss: 0.13051149249076843\n",
      "epoch 27 loss: 0.11480507999658585\n",
      "epoch 28 loss: 0.08786662667989731\n",
      "epoch 29 loss: 0.097359299659729\n",
      "epoch 30 loss: 0.09980025142431259\n",
      "57\n",
      "epoch 1 loss: 0.9190089702606201\n",
      "epoch 2 loss: 0.5107241868972778\n",
      "epoch 3 loss: 0.26619625091552734\n",
      "epoch 4 loss: 0.1973767876625061\n",
      "epoch 5 loss: 0.12201476097106934\n",
      "epoch 6 loss: 0.16683754324913025\n",
      "epoch 7 loss: 0.17336168885231018\n",
      "epoch 8 loss: 0.15879450738430023\n",
      "epoch 9 loss: 0.16554826498031616\n",
      "epoch 10 loss: 0.15479415655136108\n",
      "epoch 11 loss: 0.1240340992808342\n",
      "epoch 12 loss: 0.1600540280342102\n",
      "epoch 13 loss: 0.15856453776359558\n",
      "epoch 14 loss: 0.15311072766780853\n",
      "epoch 15 loss: 0.10497170686721802\n",
      "epoch 16 loss: 0.14826148748397827\n",
      "epoch 17 loss: 0.15157105028629303\n",
      "epoch 18 loss: 0.12771885097026825\n",
      "epoch 19 loss: 0.1092165857553482\n",
      "epoch 20 loss: 0.11325203627347946\n",
      "epoch 21 loss: 0.11687058210372925\n",
      "epoch 22 loss: 0.12246499955654144\n",
      "epoch 23 loss: 0.11775830388069153\n",
      "epoch 24 loss: 0.10850661247968674\n",
      "epoch 25 loss: 0.10939245671033859\n",
      "epoch 26 loss: 0.10261958092451096\n",
      "epoch 27 loss: 0.10589691251516342\n",
      "epoch 28 loss: 0.09097006171941757\n",
      "epoch 29 loss: 0.10216863453388214\n",
      "epoch 30 loss: 0.08176019042730331\n",
      "58\n",
      "epoch 1 loss: 1.0806077718734741\n",
      "epoch 2 loss: 0.6278364658355713\n",
      "epoch 3 loss: 0.7381306290626526\n",
      "epoch 4 loss: 0.2869267761707306\n",
      "epoch 5 loss: 0.22402213513851166\n",
      "epoch 6 loss: 0.16971828043460846\n",
      "epoch 7 loss: 0.16049760580062866\n",
      "epoch 8 loss: 0.16553428769111633\n",
      "epoch 9 loss: 0.12504762411117554\n",
      "epoch 10 loss: 0.13873504102230072\n",
      "epoch 11 loss: 0.18296405673027039\n",
      "epoch 12 loss: 0.1649480164051056\n",
      "epoch 13 loss: 0.15644818544387817\n",
      "epoch 14 loss: 0.15876922011375427\n",
      "epoch 15 loss: 0.16757625341415405\n",
      "epoch 16 loss: 0.185688316822052\n",
      "epoch 17 loss: 0.12122946977615356\n",
      "epoch 18 loss: 0.163471981883049\n",
      "epoch 19 loss: 0.13031679391860962\n",
      "epoch 20 loss: 0.12553484737873077\n",
      "epoch 21 loss: 0.16425855457782745\n",
      "epoch 22 loss: 0.14408813416957855\n",
      "epoch 23 loss: 0.17154040932655334\n",
      "epoch 24 loss: 0.14661765098571777\n",
      "epoch 25 loss: 0.14311982691287994\n",
      "epoch 26 loss: 0.1145862340927124\n",
      "epoch 27 loss: 0.14352090656757355\n",
      "epoch 28 loss: 0.1316864788532257\n",
      "epoch 29 loss: 0.1363527774810791\n",
      "epoch 30 loss: 0.09557866305112839\n",
      "59\n",
      "epoch 1 loss: 0.7585574984550476\n",
      "epoch 2 loss: 0.6135156154632568\n",
      "epoch 3 loss: 0.37094971537590027\n",
      "epoch 4 loss: 0.22990620136260986\n",
      "epoch 5 loss: 0.17864347994327545\n",
      "epoch 6 loss: 0.13976098597049713\n",
      "epoch 7 loss: 0.1707242727279663\n",
      "epoch 8 loss: 0.16035105288028717\n",
      "epoch 9 loss: 0.1329210102558136\n",
      "epoch 10 loss: 0.1536419838666916\n",
      "epoch 11 loss: 0.17199203372001648\n",
      "epoch 12 loss: 0.15587253868579865\n",
      "epoch 13 loss: 0.14355552196502686\n",
      "epoch 14 loss: 0.16941094398498535\n",
      "epoch 15 loss: 0.14501453936100006\n",
      "epoch 16 loss: 0.15118427574634552\n",
      "epoch 17 loss: 0.13792619109153748\n",
      "epoch 18 loss: 0.17464245855808258\n",
      "epoch 19 loss: 0.13261885941028595\n",
      "epoch 20 loss: 0.14118941128253937\n",
      "epoch 21 loss: 0.14814437925815582\n",
      "epoch 22 loss: 0.14108943939208984\n",
      "epoch 23 loss: 0.12414328753948212\n",
      "epoch 24 loss: 0.16585735976696014\n",
      "epoch 25 loss: 0.09005981683731079\n",
      "epoch 26 loss: 0.14315363764762878\n",
      "epoch 27 loss: 0.11549714207649231\n",
      "epoch 28 loss: 0.1206321194767952\n",
      "epoch 29 loss: 0.10081835091114044\n",
      "epoch 30 loss: 0.12605910003185272\n",
      "60\n",
      "epoch 1 loss: 0.8041961193084717\n",
      "epoch 2 loss: 0.7883488535881042\n",
      "epoch 3 loss: 0.4693474769592285\n",
      "epoch 4 loss: 0.23596912622451782\n",
      "epoch 5 loss: 0.1460603028535843\n",
      "epoch 6 loss: 0.19922998547554016\n",
      "epoch 7 loss: 0.1823880970478058\n",
      "epoch 8 loss: 0.145532488822937\n",
      "epoch 9 loss: 0.17235629260540009\n",
      "epoch 10 loss: 0.1367740035057068\n",
      "epoch 11 loss: 0.13110119104385376\n",
      "epoch 12 loss: 0.1703943908214569\n",
      "epoch 13 loss: 0.17030607163906097\n",
      "epoch 14 loss: 0.15766994655132294\n",
      "epoch 15 loss: 0.16523627936840057\n",
      "epoch 16 loss: 0.17972597479820251\n",
      "epoch 17 loss: 0.1525426059961319\n",
      "epoch 18 loss: 0.14604653418064117\n",
      "epoch 19 loss: 0.1642581671476364\n",
      "epoch 20 loss: 0.12872359156608582\n",
      "epoch 21 loss: 0.09666617214679718\n",
      "epoch 22 loss: 0.15005360543727875\n",
      "epoch 23 loss: 0.12901628017425537\n",
      "epoch 24 loss: 0.07917927205562592\n",
      "epoch 25 loss: 0.17039306461811066\n",
      "epoch 26 loss: 0.1320895403623581\n",
      "epoch 27 loss: 0.1573961228132248\n",
      "epoch 28 loss: 0.10622582584619522\n",
      "epoch 29 loss: 0.11325176805257797\n",
      "epoch 30 loss: 0.1342807114124298\n",
      "61\n",
      "epoch 1 loss: 0.9648051857948303\n",
      "epoch 2 loss: 0.5180760025978088\n",
      "epoch 3 loss: 0.3673461675643921\n",
      "epoch 4 loss: 0.27955836057662964\n",
      "epoch 5 loss: 0.14893598854541779\n",
      "epoch 6 loss: 0.16660843789577484\n",
      "epoch 7 loss: 0.14970871806144714\n",
      "epoch 8 loss: 0.155913844704628\n",
      "epoch 9 loss: 0.14225630462169647\n",
      "epoch 10 loss: 0.16793642938137054\n",
      "epoch 11 loss: 0.1816190630197525\n",
      "epoch 12 loss: 0.17878273129463196\n",
      "epoch 13 loss: 0.16252392530441284\n",
      "epoch 14 loss: 0.15859146416187286\n",
      "epoch 15 loss: 0.1428992748260498\n",
      "epoch 16 loss: 0.18535716831684113\n",
      "epoch 17 loss: 0.16644766926765442\n",
      "epoch 18 loss: 0.16705693304538727\n",
      "epoch 19 loss: 0.11509900540113449\n",
      "epoch 20 loss: 0.142863929271698\n",
      "epoch 21 loss: 0.10689940303564072\n",
      "epoch 22 loss: 0.11979293078184128\n",
      "epoch 23 loss: 0.10614342987537384\n",
      "epoch 24 loss: 0.17210595309734344\n",
      "epoch 25 loss: 0.10984700173139572\n",
      "epoch 26 loss: 0.11514806747436523\n",
      "epoch 27 loss: 0.12431125342845917\n",
      "epoch 28 loss: 0.09967118501663208\n",
      "epoch 29 loss: 0.09423771500587463\n",
      "epoch 30 loss: 0.0913698598742485\n",
      "62\n",
      "epoch 1 loss: 0.9618436098098755\n",
      "epoch 2 loss: 0.9857276082038879\n",
      "epoch 3 loss: 0.8660237193107605\n",
      "epoch 4 loss: 0.7104204297065735\n",
      "epoch 5 loss: 0.40137580037117004\n",
      "epoch 6 loss: 0.21879182755947113\n",
      "epoch 7 loss: 0.15890568494796753\n",
      "epoch 8 loss: 0.1568983495235443\n",
      "epoch 9 loss: 0.17134052515029907\n",
      "epoch 10 loss: 0.1473851054906845\n",
      "epoch 11 loss: 0.16846756637096405\n",
      "epoch 12 loss: 0.17779633402824402\n",
      "epoch 13 loss: 0.13347017765045166\n",
      "epoch 14 loss: 0.1531275510787964\n",
      "epoch 15 loss: 0.17298977077007294\n",
      "epoch 16 loss: 0.10444487631320953\n",
      "epoch 17 loss: 0.1443643569946289\n",
      "epoch 18 loss: 0.13700570166110992\n",
      "epoch 19 loss: 0.13885188102722168\n",
      "epoch 20 loss: 0.14021067321300507\n",
      "epoch 21 loss: 0.20072756707668304\n",
      "epoch 22 loss: 0.1353139877319336\n",
      "epoch 23 loss: 0.15819931030273438\n",
      "epoch 24 loss: 0.1675998568534851\n",
      "epoch 25 loss: 0.15533016622066498\n",
      "epoch 26 loss: 0.16052782535552979\n",
      "epoch 27 loss: 0.16562584042549133\n",
      "epoch 28 loss: 0.14228859543800354\n",
      "epoch 29 loss: 0.1585119664669037\n",
      "epoch 30 loss: 0.1351567506790161\n",
      "63\n",
      "epoch 1 loss: 0.6949954032897949\n",
      "epoch 2 loss: 0.3991813659667969\n",
      "epoch 3 loss: 0.21161368489265442\n",
      "epoch 4 loss: 0.16230390965938568\n",
      "epoch 5 loss: 0.1651657372713089\n",
      "epoch 6 loss: 0.16319558024406433\n",
      "epoch 7 loss: 0.17827284336090088\n",
      "epoch 8 loss: 0.16321732103824615\n",
      "epoch 9 loss: 0.14769726991653442\n",
      "epoch 10 loss: 0.16415061056613922\n",
      "epoch 11 loss: 0.16322709619998932\n",
      "epoch 12 loss: 0.16963735222816467\n",
      "epoch 13 loss: 0.1487395018339157\n",
      "epoch 14 loss: 0.18007463216781616\n",
      "epoch 15 loss: 0.1222546324133873\n",
      "epoch 16 loss: 0.16322021186351776\n",
      "epoch 17 loss: 0.17521938681602478\n",
      "epoch 18 loss: 0.16443665325641632\n",
      "epoch 19 loss: 0.17196209728717804\n",
      "epoch 20 loss: 0.14173179864883423\n",
      "epoch 21 loss: 0.1373232901096344\n",
      "epoch 22 loss: 0.13861726224422455\n",
      "epoch 23 loss: 0.1221807524561882\n",
      "epoch 24 loss: 0.1284334510564804\n",
      "epoch 25 loss: 0.10141834616661072\n",
      "epoch 26 loss: 0.10991716384887695\n",
      "epoch 27 loss: 0.11184823513031006\n",
      "epoch 28 loss: 0.11586474627256393\n",
      "epoch 29 loss: 0.0904090628027916\n",
      "epoch 30 loss: 0.10380130261182785\n",
      "64\n",
      "epoch 1 loss: 0.9285846948623657\n",
      "epoch 2 loss: 0.9917437434196472\n",
      "epoch 3 loss: 0.9269562363624573\n",
      "epoch 4 loss: 0.4500378668308258\n",
      "epoch 5 loss: 0.2376263439655304\n",
      "epoch 6 loss: 0.2395155280828476\n",
      "epoch 7 loss: 0.19338732957839966\n",
      "epoch 8 loss: 0.15787839889526367\n",
      "epoch 9 loss: 0.17301952838897705\n",
      "epoch 10 loss: 0.1583591103553772\n",
      "epoch 11 loss: 0.12932556867599487\n",
      "epoch 12 loss: 0.2142733782529831\n",
      "epoch 13 loss: 0.13263168931007385\n",
      "epoch 14 loss: 0.1680564284324646\n",
      "epoch 15 loss: 0.1614573746919632\n",
      "epoch 16 loss: 0.15452158451080322\n",
      "epoch 17 loss: 0.16164834797382355\n",
      "epoch 18 loss: 0.17872504889965057\n",
      "epoch 19 loss: 0.18033455312252045\n",
      "epoch 20 loss: 0.1726023107767105\n",
      "epoch 21 loss: 0.1495319902896881\n",
      "epoch 22 loss: 0.1710692048072815\n",
      "epoch 23 loss: 0.13913552463054657\n",
      "epoch 24 loss: 0.1656908094882965\n",
      "epoch 25 loss: 0.1305960863828659\n",
      "epoch 26 loss: 0.1320643126964569\n",
      "epoch 27 loss: 0.1335468292236328\n",
      "epoch 28 loss: 0.17547520995140076\n",
      "epoch 29 loss: 0.1475657969713211\n",
      "epoch 30 loss: 0.12739385664463043\n",
      "65\n",
      "epoch 1 loss: 1.1047954559326172\n",
      "epoch 2 loss: 0.6751210689544678\n",
      "epoch 3 loss: 0.3192238211631775\n",
      "epoch 4 loss: 0.1816672831773758\n",
      "epoch 5 loss: 0.1853061467409134\n",
      "epoch 6 loss: 0.15431736409664154\n",
      "epoch 7 loss: 0.1537007987499237\n",
      "epoch 8 loss: 0.1728610396385193\n",
      "epoch 9 loss: 0.18274502456188202\n",
      "epoch 10 loss: 0.1413746029138565\n",
      "epoch 11 loss: 0.11899461597204208\n",
      "epoch 12 loss: 0.18849040567874908\n",
      "epoch 13 loss: 0.1230902150273323\n",
      "epoch 14 loss: 0.10728307068347931\n",
      "epoch 15 loss: 0.1300351321697235\n",
      "epoch 16 loss: 0.15972194075584412\n",
      "epoch 17 loss: 0.14320822060108185\n",
      "epoch 18 loss: 0.16457223892211914\n",
      "epoch 19 loss: 0.1192784532904625\n",
      "epoch 20 loss: 0.20462694764137268\n",
      "epoch 21 loss: 0.14138947427272797\n",
      "epoch 22 loss: 0.12821364402770996\n",
      "epoch 23 loss: 0.1379096359014511\n",
      "epoch 24 loss: 0.13378356397151947\n",
      "epoch 25 loss: 0.10919516533613205\n",
      "epoch 26 loss: 0.10501978546380997\n",
      "epoch 27 loss: 0.10060878843069077\n",
      "epoch 28 loss: 0.1085515022277832\n",
      "epoch 29 loss: 0.09462770074605942\n",
      "epoch 30 loss: 0.1267874389886856\n",
      "66\n",
      "epoch 1 loss: 0.7301918268203735\n",
      "epoch 2 loss: 0.8149779438972473\n",
      "epoch 3 loss: 0.4731586277484894\n",
      "epoch 4 loss: 0.32565951347351074\n",
      "epoch 5 loss: 0.21789540350437164\n",
      "epoch 6 loss: 0.1845935434103012\n",
      "epoch 7 loss: 0.1989641636610031\n",
      "epoch 8 loss: 0.15217047929763794\n",
      "epoch 9 loss: 0.1755439192056656\n",
      "epoch 10 loss: 0.16588471829891205\n",
      "epoch 11 loss: 0.18078060448169708\n",
      "epoch 12 loss: 0.17266516387462616\n",
      "epoch 13 loss: 0.14579759538173676\n",
      "epoch 14 loss: 0.13990482687950134\n",
      "epoch 15 loss: 0.1638680398464203\n",
      "epoch 16 loss: 0.16210421919822693\n",
      "epoch 17 loss: 0.22503210604190826\n",
      "epoch 18 loss: 0.1967560052871704\n",
      "epoch 19 loss: 0.1580663025379181\n",
      "epoch 20 loss: 0.1431310772895813\n",
      "epoch 21 loss: 0.18114811182022095\n",
      "epoch 22 loss: 0.1282157599925995\n",
      "epoch 23 loss: 0.13155294954776764\n",
      "epoch 24 loss: 0.1319420337677002\n",
      "epoch 25 loss: 0.13981711864471436\n",
      "epoch 26 loss: 0.11597605049610138\n",
      "epoch 27 loss: 0.1327146291732788\n",
      "epoch 28 loss: 0.13998734951019287\n",
      "epoch 29 loss: 0.09089676290750504\n",
      "epoch 30 loss: 0.08859310299158096\n",
      "67\n",
      "epoch 1 loss: 0.603415310382843\n",
      "epoch 2 loss: 0.44135406613349915\n",
      "epoch 3 loss: 0.2978193759918213\n",
      "epoch 4 loss: 0.23017482459545135\n",
      "epoch 5 loss: 0.15504369139671326\n",
      "epoch 6 loss: 0.17119865119457245\n",
      "epoch 7 loss: 0.15298369526863098\n",
      "epoch 8 loss: 0.1415717452764511\n",
      "epoch 9 loss: 0.20195074379444122\n",
      "epoch 10 loss: 0.12457449734210968\n",
      "epoch 11 loss: 0.18968388438224792\n",
      "epoch 12 loss: 0.18615993857383728\n",
      "epoch 13 loss: 0.16271936893463135\n",
      "epoch 14 loss: 0.1449127048254013\n",
      "epoch 15 loss: 0.18648886680603027\n",
      "epoch 16 loss: 0.1416151374578476\n",
      "epoch 17 loss: 0.09202506393194199\n",
      "epoch 18 loss: 0.13209062814712524\n",
      "epoch 19 loss: 0.08742859214544296\n",
      "epoch 20 loss: 0.08680813759565353\n",
      "epoch 21 loss: 0.1134534701704979\n",
      "epoch 22 loss: 0.11929051578044891\n",
      "epoch 23 loss: 0.08737312257289886\n",
      "epoch 24 loss: 0.10141436755657196\n",
      "epoch 25 loss: 0.1281498223543167\n",
      "epoch 26 loss: 0.1439565122127533\n",
      "epoch 27 loss: 0.10295554995536804\n",
      "epoch 28 loss: 0.10675685107707977\n",
      "epoch 29 loss: 0.0976698100566864\n",
      "epoch 30 loss: 0.09461767971515656\n",
      "68\n",
      "epoch 1 loss: 0.6713592410087585\n",
      "epoch 2 loss: 0.412178635597229\n",
      "epoch 3 loss: 0.24824349582195282\n",
      "epoch 4 loss: 0.19995862245559692\n",
      "epoch 5 loss: 0.16450819373130798\n",
      "epoch 6 loss: 0.1658519208431244\n",
      "epoch 7 loss: 0.13054808974266052\n",
      "epoch 8 loss: 0.15444998443126678\n",
      "epoch 9 loss: 0.21301761269569397\n",
      "epoch 10 loss: 0.18394684791564941\n",
      "epoch 11 loss: 0.15642376244068146\n",
      "epoch 12 loss: 0.15436086058616638\n",
      "epoch 13 loss: 0.14637546241283417\n",
      "epoch 14 loss: 0.16609731316566467\n",
      "epoch 15 loss: 0.1980796456336975\n",
      "epoch 16 loss: 0.1281372308731079\n",
      "epoch 17 loss: 0.1615486592054367\n",
      "epoch 18 loss: 0.176102414727211\n",
      "epoch 19 loss: 0.1359347105026245\n",
      "epoch 20 loss: 0.1570989191532135\n",
      "epoch 21 loss: 0.12700054049491882\n",
      "epoch 22 loss: 0.1369566023349762\n",
      "epoch 23 loss: 0.11993148177862167\n",
      "epoch 24 loss: 0.13257606327533722\n",
      "epoch 25 loss: 0.10105272382497787\n",
      "epoch 26 loss: 0.13562843203544617\n",
      "epoch 27 loss: 0.13187363743782043\n",
      "epoch 28 loss: 0.12203803658485413\n",
      "epoch 29 loss: 0.08534056693315506\n",
      "epoch 30 loss: 0.12477395683526993\n",
      "69\n",
      "epoch 1 loss: 0.7593860030174255\n",
      "epoch 2 loss: 0.9525611996650696\n",
      "epoch 3 loss: 0.4335232973098755\n",
      "epoch 4 loss: 0.17230390012264252\n",
      "epoch 5 loss: 0.17075195908546448\n",
      "epoch 6 loss: 0.1427001804113388\n",
      "epoch 7 loss: 0.1626935750246048\n",
      "epoch 8 loss: 0.16840188205242157\n",
      "epoch 9 loss: 0.15082883834838867\n",
      "epoch 10 loss: 0.1460154503583908\n",
      "epoch 11 loss: 0.14920879900455475\n",
      "epoch 12 loss: 0.15619729459285736\n",
      "epoch 13 loss: 0.15114448964595795\n",
      "epoch 14 loss: 0.1344907432794571\n",
      "epoch 15 loss: 0.1449795961380005\n",
      "epoch 16 loss: 0.13828182220458984\n",
      "epoch 17 loss: 0.12466327100992203\n",
      "epoch 18 loss: 0.1281668096780777\n",
      "epoch 19 loss: 0.10890248417854309\n",
      "epoch 20 loss: 0.11681654304265976\n",
      "epoch 21 loss: 0.10130006819963455\n",
      "epoch 22 loss: 0.13131378591060638\n",
      "epoch 23 loss: 0.1177452877163887\n",
      "epoch 24 loss: 0.11815594136714935\n",
      "epoch 25 loss: 0.11502140760421753\n",
      "epoch 26 loss: 0.12910234928131104\n",
      "epoch 27 loss: 0.09781870990991592\n",
      "epoch 28 loss: 0.11826279014348984\n",
      "epoch 29 loss: 0.10448286682367325\n",
      "epoch 30 loss: 0.11786239594221115\n",
      "70\n",
      "epoch 1 loss: 1.2354938983917236\n",
      "epoch 2 loss: 0.6335196495056152\n",
      "epoch 3 loss: 0.8027852773666382\n",
      "epoch 4 loss: 0.46849116683006287\n",
      "epoch 5 loss: 0.3365853428840637\n",
      "epoch 6 loss: 0.1594294160604477\n",
      "epoch 7 loss: 0.19572176039218903\n",
      "epoch 8 loss: 0.15113873779773712\n",
      "epoch 9 loss: 0.2048371434211731\n",
      "epoch 10 loss: 0.18159432709217072\n",
      "epoch 11 loss: 0.16166181862354279\n",
      "epoch 12 loss: 0.15320773422718048\n",
      "epoch 13 loss: 0.18115340173244476\n",
      "epoch 14 loss: 0.15487004816532135\n",
      "epoch 15 loss: 0.15910694003105164\n",
      "epoch 16 loss: 0.1388871669769287\n",
      "epoch 17 loss: 0.1653742790222168\n",
      "epoch 18 loss: 0.14860986173152924\n",
      "epoch 19 loss: 0.16192390024662018\n",
      "epoch 20 loss: 0.15190906822681427\n",
      "epoch 21 loss: 0.20502978563308716\n",
      "epoch 22 loss: 0.14475783705711365\n",
      "epoch 23 loss: 0.1880260705947876\n",
      "epoch 24 loss: 0.15330888330936432\n",
      "epoch 25 loss: 0.1588861495256424\n",
      "epoch 26 loss: 0.12672226130962372\n",
      "epoch 27 loss: 0.13058403134346008\n",
      "epoch 28 loss: 0.1190069392323494\n",
      "epoch 29 loss: 0.11237215995788574\n",
      "epoch 30 loss: 0.11670910567045212\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "486d9b49-266f-4d7a-adf2-50330ce2b43c",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier vector (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf602c0e-24fa-4fdb-9d15-ea7053c447c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"vector\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w = pd.concat([results_aep_fourier_w, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w.to_csv(out_dir + '/results_aep_fourier_w.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3833363e-8d81-4830-a91a-7669368eb946",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier matrix (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6bc4a3c9-4a45-4412-8ddb-702e2ef86549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T00:42:08.103590Z",
     "start_time": "2025-10-03T23:37:37.216840Z"
    }
   },
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_w_matrix.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:921: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {ep+1} loss: {float(loss):.4f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7729\n",
      "epoch 2 loss: 0.5945\n",
      "epoch 3 loss: 0.4687\n",
      "epoch 4 loss: 0.2746\n",
      "epoch 5 loss: 0.2250\n",
      "epoch 6 loss: 0.1746\n",
      "epoch 7 loss: 0.2098\n",
      "epoch 8 loss: 0.1669\n",
      "epoch 9 loss: 0.1898\n",
      "epoch 10 loss: 0.1545\n",
      "epoch 11 loss: 0.1768\n",
      "epoch 12 loss: 0.1581\n",
      "epoch 13 loss: 0.1501\n",
      "epoch 14 loss: 0.1833\n",
      "epoch 15 loss: 0.1395\n",
      "epoch 16 loss: 0.1614\n",
      "epoch 17 loss: 0.1394\n",
      "epoch 18 loss: 0.1041\n",
      "epoch 19 loss: 0.1545\n",
      "epoch 20 loss: 0.1392\n",
      "epoch 21 loss: 0.1692\n",
      "epoch 22 loss: 0.1572\n",
      "epoch 23 loss: 0.1426\n",
      "epoch 24 loss: 0.1000\n",
      "epoch 25 loss: 0.1357\n",
      "epoch 26 loss: 0.1532\n",
      "epoch 27 loss: 0.1533\n",
      "epoch 28 loss: 0.1193\n",
      "epoch 29 loss: 0.1108\n",
      "epoch 30 loss: 0.1765\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_78663/661564195.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.9912\n",
      "epoch 2 loss: 0.7911\n",
      "epoch 3 loss: 0.4966\n",
      "epoch 4 loss: 0.3459\n",
      "epoch 5 loss: 0.1888\n",
      "epoch 6 loss: 0.2639\n",
      "epoch 7 loss: 0.1748\n",
      "epoch 8 loss: 0.1741\n",
      "epoch 9 loss: 0.1915\n",
      "epoch 10 loss: 0.1670\n",
      "epoch 11 loss: 0.1430\n",
      "epoch 12 loss: 0.1551\n",
      "epoch 13 loss: 0.1708\n",
      "epoch 14 loss: 0.1340\n",
      "epoch 15 loss: 0.1432\n",
      "epoch 16 loss: 0.1526\n",
      "epoch 17 loss: 0.1558\n",
      "epoch 18 loss: 0.1661\n",
      "epoch 19 loss: 0.1683\n",
      "epoch 20 loss: 0.1806\n",
      "epoch 21 loss: 0.1673\n",
      "epoch 22 loss: 0.1149\n",
      "epoch 23 loss: 0.1268\n",
      "epoch 24 loss: 0.1418\n",
      "epoch 25 loss: 0.1670\n",
      "epoch 26 loss: 0.1369\n",
      "epoch 27 loss: 0.2370\n",
      "epoch 28 loss: 0.1582\n",
      "epoch 29 loss: 0.1617\n",
      "epoch 30 loss: 0.1235\n",
      "3\n",
      "epoch 1 loss: 0.7367\n",
      "epoch 2 loss: 0.5357\n",
      "epoch 3 loss: 0.6606\n",
      "epoch 4 loss: 0.4180\n",
      "epoch 5 loss: 0.2952\n",
      "epoch 6 loss: 0.1727\n",
      "epoch 7 loss: 0.1720\n",
      "epoch 8 loss: 0.1778\n",
      "epoch 9 loss: 0.1843\n",
      "epoch 10 loss: 0.2063\n",
      "epoch 11 loss: 0.1235\n",
      "epoch 12 loss: 0.1787\n",
      "epoch 13 loss: 0.2195\n",
      "epoch 14 loss: 0.1339\n",
      "epoch 15 loss: 0.1324\n",
      "epoch 16 loss: 0.1414\n",
      "epoch 17 loss: 0.1345\n",
      "epoch 18 loss: 0.1492\n",
      "epoch 19 loss: 0.1369\n",
      "epoch 20 loss: 0.1309\n",
      "epoch 21 loss: 0.1927\n",
      "epoch 22 loss: 0.1961\n",
      "epoch 23 loss: 0.1372\n",
      "epoch 24 loss: 0.0962\n",
      "epoch 25 loss: 0.1241\n",
      "epoch 26 loss: 0.1722\n",
      "epoch 27 loss: 0.1280\n",
      "epoch 28 loss: 0.1658\n",
      "epoch 29 loss: 0.1785\n",
      "epoch 30 loss: 0.1398\n",
      "4\n",
      "epoch 1 loss: 0.8596\n",
      "epoch 2 loss: 0.8517\n",
      "epoch 3 loss: 0.7483\n",
      "epoch 4 loss: 0.4412\n",
      "epoch 5 loss: 0.2891\n",
      "epoch 6 loss: 0.2097\n",
      "epoch 7 loss: 0.1381\n",
      "epoch 8 loss: 0.1841\n",
      "epoch 9 loss: 0.1796\n",
      "epoch 10 loss: 0.1589\n",
      "epoch 11 loss: 0.1602\n",
      "epoch 12 loss: 0.1759\n",
      "epoch 13 loss: 0.1519\n",
      "epoch 14 loss: 0.1579\n",
      "epoch 15 loss: 0.1614\n",
      "epoch 16 loss: 0.1450\n",
      "epoch 17 loss: 0.1434\n",
      "epoch 18 loss: 0.1121\n",
      "epoch 19 loss: 0.1556\n",
      "epoch 20 loss: 0.1393\n",
      "epoch 21 loss: 0.1645\n",
      "epoch 22 loss: 0.1387\n",
      "epoch 23 loss: 0.1224\n",
      "epoch 24 loss: 0.1110\n",
      "epoch 25 loss: 0.1366\n",
      "epoch 26 loss: 0.0915\n",
      "epoch 27 loss: 0.1051\n",
      "epoch 28 loss: 0.1397\n",
      "epoch 29 loss: 0.1306\n",
      "epoch 30 loss: 0.0895\n",
      "5\n",
      "epoch 1 loss: 0.8877\n",
      "epoch 2 loss: 0.6402\n",
      "epoch 3 loss: 0.5924\n",
      "epoch 4 loss: 0.3019\n",
      "epoch 5 loss: 0.2193\n",
      "epoch 6 loss: 0.2590\n",
      "epoch 7 loss: 0.1893\n",
      "epoch 8 loss: 0.1799\n",
      "epoch 9 loss: 0.1692\n",
      "epoch 10 loss: 0.1629\n",
      "epoch 11 loss: 0.1338\n",
      "epoch 12 loss: 0.1559\n",
      "epoch 13 loss: 0.1324\n",
      "epoch 14 loss: 0.1344\n",
      "epoch 15 loss: 0.1423\n",
      "epoch 16 loss: 0.1670\n",
      "epoch 17 loss: 0.1744\n",
      "epoch 18 loss: 0.1665\n",
      "epoch 19 loss: 0.1435\n",
      "epoch 20 loss: 0.1517\n",
      "epoch 21 loss: 0.1450\n",
      "epoch 22 loss: 0.1414\n",
      "epoch 23 loss: 0.1430\n",
      "epoch 24 loss: 0.1902\n",
      "epoch 25 loss: 0.0954\n",
      "epoch 26 loss: 0.1582\n",
      "epoch 27 loss: 0.1374\n",
      "epoch 28 loss: 0.1493\n",
      "epoch 29 loss: 0.2108\n",
      "epoch 30 loss: 0.1824\n",
      "6\n",
      "epoch 1 loss: 0.8762\n",
      "epoch 2 loss: 0.6065\n",
      "epoch 3 loss: 0.6928\n",
      "epoch 4 loss: 0.6360\n",
      "epoch 5 loss: 0.3056\n",
      "epoch 6 loss: 0.2082\n",
      "epoch 7 loss: 0.1580\n",
      "epoch 8 loss: 0.1754\n",
      "epoch 9 loss: 0.1632\n",
      "epoch 10 loss: 0.1466\n",
      "epoch 11 loss: 0.1622\n",
      "epoch 12 loss: 0.1881\n",
      "epoch 13 loss: 0.1539\n",
      "epoch 14 loss: 0.1746\n",
      "epoch 15 loss: 0.1690\n",
      "epoch 16 loss: 0.1650\n",
      "epoch 17 loss: 0.1342\n",
      "epoch 18 loss: 0.1278\n",
      "epoch 19 loss: 0.1323\n",
      "epoch 20 loss: 0.1357\n",
      "epoch 21 loss: 0.1195\n",
      "epoch 22 loss: 0.1446\n",
      "epoch 23 loss: 0.1488\n",
      "epoch 24 loss: 0.1455\n",
      "epoch 25 loss: 0.1260\n",
      "epoch 26 loss: 0.1103\n",
      "epoch 27 loss: 0.0975\n",
      "epoch 28 loss: 0.1458\n",
      "epoch 29 loss: 0.1302\n",
      "epoch 30 loss: 0.1050\n",
      "7\n",
      "epoch 1 loss: 1.1004\n",
      "epoch 2 loss: 0.6138\n",
      "epoch 3 loss: 0.5947\n",
      "epoch 4 loss: 0.4286\n",
      "epoch 5 loss: 0.3111\n",
      "epoch 6 loss: 0.2796\n",
      "epoch 7 loss: 0.2370\n",
      "epoch 8 loss: 0.1827\n",
      "epoch 9 loss: 0.2109\n",
      "epoch 10 loss: 0.1861\n",
      "epoch 11 loss: 0.1761\n",
      "epoch 12 loss: 0.1666\n",
      "epoch 13 loss: 0.1687\n",
      "epoch 14 loss: 0.1383\n",
      "epoch 15 loss: 0.1522\n",
      "epoch 16 loss: 0.1961\n",
      "epoch 17 loss: 0.1694\n",
      "epoch 18 loss: 0.1541\n",
      "epoch 19 loss: 0.1587\n",
      "epoch 20 loss: 0.1698\n",
      "epoch 21 loss: 0.1457\n",
      "epoch 22 loss: 0.1688\n",
      "epoch 23 loss: 0.1497\n",
      "epoch 24 loss: 0.1858\n",
      "epoch 25 loss: 0.1424\n",
      "epoch 26 loss: 0.1755\n",
      "epoch 27 loss: 0.1596\n",
      "epoch 28 loss: 0.1746\n",
      "epoch 29 loss: 0.1200\n",
      "epoch 30 loss: 0.1529\n",
      "8\n",
      "epoch 1 loss: 0.9228\n",
      "epoch 2 loss: 0.5658\n",
      "epoch 3 loss: 0.4518\n",
      "epoch 4 loss: 0.3163\n",
      "epoch 5 loss: 0.2180\n",
      "epoch 6 loss: 0.1902\n",
      "epoch 7 loss: 0.1608\n",
      "epoch 8 loss: 0.1509\n",
      "epoch 9 loss: 0.1143\n",
      "epoch 10 loss: 0.1401\n",
      "epoch 11 loss: 0.1314\n",
      "epoch 12 loss: 0.1777\n",
      "epoch 13 loss: 0.1642\n",
      "epoch 14 loss: 0.1366\n",
      "epoch 15 loss: 0.1385\n",
      "epoch 16 loss: 0.1086\n",
      "epoch 17 loss: 0.1155\n",
      "epoch 18 loss: 0.1431\n",
      "epoch 19 loss: 0.0796\n",
      "epoch 20 loss: 0.1169\n",
      "epoch 21 loss: 0.1184\n",
      "epoch 22 loss: 0.0713\n",
      "epoch 23 loss: 0.1022\n",
      "epoch 24 loss: 0.1122\n",
      "epoch 25 loss: 0.0885\n",
      "epoch 26 loss: 0.0794\n",
      "epoch 27 loss: 0.0781\n",
      "epoch 28 loss: 0.0979\n",
      "epoch 29 loss: 0.1137\n",
      "epoch 30 loss: 0.0991\n",
      "9\n",
      "epoch 1 loss: 0.9803\n",
      "epoch 2 loss: 0.7915\n",
      "epoch 3 loss: 0.5128\n",
      "epoch 4 loss: 0.3520\n",
      "epoch 5 loss: 0.2282\n",
      "epoch 6 loss: 0.2276\n",
      "epoch 7 loss: 0.1747\n",
      "epoch 8 loss: 0.1833\n",
      "epoch 9 loss: 0.1494\n",
      "epoch 10 loss: 0.1469\n",
      "epoch 11 loss: 0.1903\n",
      "epoch 12 loss: 0.1501\n",
      "epoch 13 loss: 0.1185\n",
      "epoch 14 loss: 0.1601\n",
      "epoch 15 loss: 0.1328\n",
      "epoch 16 loss: 0.1700\n",
      "epoch 17 loss: 0.1214\n",
      "epoch 18 loss: 0.1318\n",
      "epoch 19 loss: 0.1311\n",
      "epoch 20 loss: 0.1677\n",
      "epoch 21 loss: 0.1562\n",
      "epoch 22 loss: 0.1242\n",
      "epoch 23 loss: 0.1129\n",
      "epoch 24 loss: 0.1210\n",
      "epoch 25 loss: 0.1287\n",
      "epoch 26 loss: 0.1317\n",
      "epoch 27 loss: 0.1568\n",
      "epoch 28 loss: 0.1323\n",
      "epoch 29 loss: 0.1156\n",
      "epoch 30 loss: 0.1119\n",
      "10\n",
      "epoch 1 loss: 0.9160\n",
      "epoch 2 loss: 0.7550\n",
      "epoch 3 loss: 0.4360\n",
      "epoch 4 loss: 0.3989\n",
      "epoch 5 loss: 0.3376\n",
      "epoch 6 loss: 0.2139\n",
      "epoch 7 loss: 0.2053\n",
      "epoch 8 loss: 0.1865\n",
      "epoch 9 loss: 0.1754\n",
      "epoch 10 loss: 0.1460\n",
      "epoch 11 loss: 0.1760\n",
      "epoch 12 loss: 0.1356\n",
      "epoch 13 loss: 0.1716\n",
      "epoch 14 loss: 0.1619\n",
      "epoch 15 loss: 0.1610\n",
      "epoch 16 loss: 0.1574\n",
      "epoch 17 loss: 0.1011\n",
      "epoch 18 loss: 0.1670\n",
      "epoch 19 loss: 0.1407\n",
      "epoch 20 loss: 0.1100\n",
      "epoch 21 loss: 0.1644\n",
      "epoch 22 loss: 0.1501\n",
      "epoch 23 loss: 0.1331\n",
      "epoch 24 loss: 0.1105\n",
      "epoch 25 loss: 0.1175\n",
      "epoch 26 loss: 0.0753\n",
      "epoch 27 loss: 0.1435\n",
      "epoch 28 loss: 0.1132\n",
      "epoch 29 loss: 0.1083\n",
      "epoch 30 loss: 0.1076\n",
      "11\n",
      "epoch 1 loss: 0.9554\n",
      "epoch 2 loss: 0.4860\n",
      "epoch 3 loss: 0.6086\n",
      "epoch 4 loss: 0.2937\n",
      "epoch 5 loss: 0.2530\n",
      "epoch 6 loss: 0.2119\n",
      "epoch 7 loss: 0.2047\n",
      "epoch 8 loss: 0.1909\n",
      "epoch 9 loss: 0.1616\n",
      "epoch 10 loss: 0.1533\n",
      "epoch 11 loss: 0.1558\n",
      "epoch 12 loss: 0.1664\n",
      "epoch 13 loss: 0.1491\n",
      "epoch 14 loss: 0.1831\n",
      "epoch 15 loss: 0.1479\n",
      "epoch 16 loss: 0.1668\n",
      "epoch 17 loss: 0.1803\n",
      "epoch 18 loss: 0.1810\n",
      "epoch 19 loss: 0.1490\n",
      "epoch 20 loss: 0.1293\n",
      "epoch 21 loss: 0.1580\n",
      "epoch 22 loss: 0.1621\n",
      "epoch 23 loss: 0.1318\n",
      "epoch 24 loss: 0.1113\n",
      "epoch 25 loss: 0.1311\n",
      "epoch 26 loss: 0.2138\n",
      "epoch 27 loss: 0.1604\n",
      "epoch 28 loss: 0.1381\n",
      "epoch 29 loss: 0.1564\n",
      "epoch 30 loss: 0.1263\n",
      "12\n",
      "epoch 1 loss: 0.7840\n",
      "epoch 2 loss: 0.6184\n",
      "epoch 3 loss: 0.4572\n",
      "epoch 4 loss: 0.4253\n",
      "epoch 5 loss: 0.5052\n",
      "epoch 6 loss: 0.3692\n",
      "epoch 7 loss: 0.2145\n",
      "epoch 8 loss: 0.2044\n",
      "epoch 9 loss: 0.1748\n",
      "epoch 10 loss: 0.1317\n",
      "epoch 11 loss: 0.2088\n",
      "epoch 12 loss: 0.1354\n",
      "epoch 13 loss: 0.1306\n",
      "epoch 14 loss: 0.1799\n",
      "epoch 15 loss: 0.1595\n",
      "epoch 16 loss: 0.1560\n",
      "epoch 17 loss: 0.1563\n",
      "epoch 18 loss: 0.1611\n",
      "epoch 19 loss: 0.1241\n",
      "epoch 20 loss: 0.1358\n",
      "epoch 21 loss: 0.1329\n",
      "epoch 22 loss: 0.1115\n",
      "epoch 23 loss: 0.0995\n",
      "epoch 24 loss: 0.2573\n",
      "epoch 25 loss: 0.1539\n",
      "epoch 26 loss: 0.1521\n",
      "epoch 27 loss: 0.2049\n",
      "epoch 28 loss: 0.1443\n",
      "epoch 29 loss: 0.1464\n",
      "epoch 30 loss: 0.1005\n",
      "13\n",
      "epoch 1 loss: 1.0261\n",
      "epoch 2 loss: 0.6244\n",
      "epoch 3 loss: 0.5517\n",
      "epoch 4 loss: 0.3489\n",
      "epoch 5 loss: 0.1722\n",
      "epoch 6 loss: 0.1901\n",
      "epoch 7 loss: 0.1501\n",
      "epoch 8 loss: 0.1616\n",
      "epoch 9 loss: 0.1703\n",
      "epoch 10 loss: 0.1458\n",
      "epoch 11 loss: 0.1533\n",
      "epoch 12 loss: 0.1681\n",
      "epoch 13 loss: 0.1678\n",
      "epoch 14 loss: 0.1757\n",
      "epoch 15 loss: 0.1692\n",
      "epoch 16 loss: 0.1286\n",
      "epoch 17 loss: 0.1470\n",
      "epoch 18 loss: 0.0947\n",
      "epoch 19 loss: 0.1605\n",
      "epoch 20 loss: 0.1181\n",
      "epoch 21 loss: 0.1820\n",
      "epoch 22 loss: 0.1226\n",
      "epoch 23 loss: 0.1430\n",
      "epoch 24 loss: 0.1697\n",
      "epoch 25 loss: 0.1172\n",
      "epoch 26 loss: 0.1205\n",
      "epoch 27 loss: 0.1715\n",
      "epoch 28 loss: 0.1326\n",
      "epoch 29 loss: 0.1340\n",
      "epoch 30 loss: 0.0980\n",
      "14\n",
      "epoch 1 loss: 0.8744\n",
      "epoch 2 loss: 0.4847\n",
      "epoch 3 loss: 0.4119\n",
      "epoch 4 loss: 0.2689\n",
      "epoch 5 loss: 0.2018\n",
      "epoch 6 loss: 0.1549\n",
      "epoch 7 loss: 0.1740\n",
      "epoch 8 loss: 0.1538\n",
      "epoch 9 loss: 0.1502\n",
      "epoch 10 loss: 0.1371\n",
      "epoch 11 loss: 0.1255\n",
      "epoch 12 loss: 0.1446\n",
      "epoch 13 loss: 0.1781\n",
      "epoch 14 loss: 0.1239\n",
      "epoch 15 loss: 0.1778\n",
      "epoch 16 loss: 0.1668\n",
      "epoch 17 loss: 0.1565\n",
      "epoch 18 loss: 0.1466\n",
      "epoch 19 loss: 0.1541\n",
      "epoch 20 loss: 0.1538\n",
      "epoch 21 loss: 0.2071\n",
      "epoch 22 loss: 0.1547\n",
      "epoch 23 loss: 0.1212\n",
      "epoch 24 loss: 0.1588\n",
      "epoch 25 loss: 0.1183\n",
      "epoch 26 loss: 0.1221\n",
      "epoch 27 loss: 0.0943\n",
      "epoch 28 loss: 0.1527\n",
      "epoch 29 loss: 0.1500\n",
      "epoch 30 loss: 0.1176\n",
      "15\n",
      "epoch 1 loss: 0.8422\n",
      "epoch 2 loss: 0.6608\n",
      "epoch 3 loss: 0.4693\n",
      "epoch 4 loss: 0.2816\n",
      "epoch 5 loss: 0.2431\n",
      "epoch 6 loss: 0.1795\n",
      "epoch 7 loss: 0.1422\n",
      "epoch 8 loss: 0.1504\n",
      "epoch 9 loss: 0.1588\n",
      "epoch 10 loss: 0.1709\n",
      "epoch 11 loss: 0.1619\n",
      "epoch 12 loss: 0.1671\n",
      "epoch 13 loss: 0.1421\n",
      "epoch 14 loss: 0.1530\n",
      "epoch 15 loss: 0.1592\n",
      "epoch 16 loss: 0.1224\n",
      "epoch 17 loss: 0.1501\n",
      "epoch 18 loss: 0.1499\n",
      "epoch 19 loss: 0.1507\n",
      "epoch 20 loss: 0.1358\n",
      "epoch 21 loss: 0.1443\n",
      "epoch 22 loss: 0.1440\n",
      "epoch 23 loss: 0.1000\n",
      "epoch 24 loss: 0.1139\n",
      "epoch 25 loss: 0.1293\n",
      "epoch 26 loss: 0.1096\n",
      "epoch 27 loss: 0.1314\n",
      "epoch 28 loss: 0.1291\n",
      "epoch 29 loss: 0.1166\n",
      "epoch 30 loss: 0.0956\n",
      "16\n",
      "epoch 1 loss: 0.8056\n",
      "epoch 2 loss: 0.4445\n",
      "epoch 3 loss: 0.3576\n",
      "epoch 4 loss: 0.2563\n",
      "epoch 5 loss: 0.2203\n",
      "epoch 6 loss: 0.2079\n",
      "epoch 7 loss: 0.1819\n",
      "epoch 8 loss: 0.1675\n",
      "epoch 9 loss: 0.1724\n",
      "epoch 10 loss: 0.1434\n",
      "epoch 11 loss: 0.1752\n",
      "epoch 12 loss: 0.1975\n",
      "epoch 13 loss: 0.1239\n",
      "epoch 14 loss: 0.1861\n",
      "epoch 15 loss: 0.1323\n",
      "epoch 16 loss: 0.1633\n",
      "epoch 17 loss: 0.1732\n",
      "epoch 18 loss: 0.1309\n",
      "epoch 19 loss: 0.1572\n",
      "epoch 20 loss: 0.1587\n",
      "epoch 21 loss: 0.1469\n",
      "epoch 22 loss: 0.1175\n",
      "epoch 23 loss: 0.1645\n",
      "epoch 24 loss: 0.1642\n",
      "epoch 25 loss: 0.1294\n",
      "epoch 26 loss: 0.1421\n",
      "epoch 27 loss: 0.1574\n",
      "epoch 28 loss: 0.1308\n",
      "epoch 29 loss: 0.1014\n",
      "epoch 30 loss: 0.1222\n",
      "17\n",
      "epoch 1 loss: 1.1200\n",
      "epoch 2 loss: 0.6280\n",
      "epoch 3 loss: 0.5844\n",
      "epoch 4 loss: 0.5918\n",
      "epoch 5 loss: 0.3459\n",
      "epoch 6 loss: 0.1766\n",
      "epoch 7 loss: 0.1742\n",
      "epoch 8 loss: 0.2067\n",
      "epoch 9 loss: 0.2181\n",
      "epoch 10 loss: 0.1682\n",
      "epoch 11 loss: 0.1626\n",
      "epoch 12 loss: 0.1338\n",
      "epoch 13 loss: 0.1715\n",
      "epoch 14 loss: 0.1778\n",
      "epoch 15 loss: 0.1952\n",
      "epoch 16 loss: 0.1621\n",
      "epoch 17 loss: 0.1476\n",
      "epoch 18 loss: 0.1709\n",
      "epoch 19 loss: 0.1304\n",
      "epoch 20 loss: 0.1469\n",
      "epoch 21 loss: 0.1728\n",
      "epoch 22 loss: 0.1657\n",
      "epoch 23 loss: 0.1164\n",
      "epoch 24 loss: 0.1552\n",
      "epoch 25 loss: 0.1645\n",
      "epoch 26 loss: 0.1578\n",
      "epoch 27 loss: 0.1223\n",
      "epoch 28 loss: 0.1491\n",
      "epoch 29 loss: 0.1653\n",
      "epoch 30 loss: 0.1577\n",
      "18\n",
      "epoch 1 loss: 0.9798\n",
      "epoch 2 loss: 0.5455\n",
      "epoch 3 loss: 0.4779\n",
      "epoch 4 loss: 0.2247\n",
      "epoch 5 loss: 0.1769\n",
      "epoch 6 loss: 0.1642\n",
      "epoch 7 loss: 0.1454\n",
      "epoch 8 loss: 0.1311\n",
      "epoch 9 loss: 0.1183\n",
      "epoch 10 loss: 0.1688\n",
      "epoch 11 loss: 0.1474\n",
      "epoch 12 loss: 0.1654\n",
      "epoch 13 loss: 0.1542\n",
      "epoch 14 loss: 0.1997\n",
      "epoch 15 loss: 0.1370\n",
      "epoch 16 loss: 0.1862\n",
      "epoch 17 loss: 0.1368\n",
      "epoch 18 loss: 0.1245\n",
      "epoch 19 loss: 0.1606\n",
      "epoch 20 loss: 0.1703\n",
      "epoch 21 loss: 0.1730\n",
      "epoch 22 loss: 0.1286\n",
      "epoch 23 loss: 0.1577\n",
      "epoch 24 loss: 0.1419\n",
      "epoch 25 loss: 0.1399\n",
      "epoch 26 loss: 0.1730\n",
      "epoch 27 loss: 0.1237\n",
      "epoch 28 loss: 0.1440\n",
      "epoch 29 loss: 0.1458\n",
      "epoch 30 loss: 0.1096\n",
      "19\n",
      "epoch 1 loss: 0.9927\n",
      "epoch 2 loss: 0.6790\n",
      "epoch 3 loss: 0.3811\n",
      "epoch 4 loss: 0.2207\n",
      "epoch 5 loss: 0.2099\n",
      "epoch 6 loss: 0.1784\n",
      "epoch 7 loss: 0.1837\n",
      "epoch 8 loss: 0.1680\n",
      "epoch 9 loss: 0.1560\n",
      "epoch 10 loss: 0.1659\n",
      "epoch 11 loss: 0.1883\n",
      "epoch 12 loss: 0.1586\n",
      "epoch 13 loss: 0.1733\n",
      "epoch 14 loss: 0.1600\n",
      "epoch 15 loss: 0.1435\n",
      "epoch 16 loss: 0.2044\n",
      "epoch 17 loss: 0.1415\n",
      "epoch 18 loss: 0.1327\n",
      "epoch 19 loss: 0.1156\n",
      "epoch 20 loss: 0.1356\n",
      "epoch 21 loss: 0.1447\n",
      "epoch 22 loss: 0.1464\n",
      "epoch 23 loss: 0.1933\n",
      "epoch 24 loss: 0.1171\n",
      "epoch 25 loss: 0.1734\n",
      "epoch 26 loss: 0.1231\n",
      "epoch 27 loss: 0.1692\n",
      "epoch 28 loss: 0.1200\n",
      "epoch 29 loss: 0.0853\n",
      "epoch 30 loss: 0.0949\n",
      "20\n",
      "epoch 1 loss: 0.7851\n",
      "epoch 2 loss: 0.5822\n",
      "epoch 3 loss: 0.5774\n",
      "epoch 4 loss: 0.4451\n",
      "epoch 5 loss: 0.4120\n",
      "epoch 6 loss: 0.2555\n",
      "epoch 7 loss: 0.2449\n",
      "epoch 8 loss: 0.1672\n",
      "epoch 9 loss: 0.1715\n",
      "epoch 10 loss: 0.1817\n",
      "epoch 11 loss: 0.1525\n",
      "epoch 12 loss: 0.1410\n",
      "epoch 13 loss: 0.1391\n",
      "epoch 14 loss: 0.1687\n",
      "epoch 15 loss: 0.1571\n",
      "epoch 16 loss: 0.1361\n",
      "epoch 17 loss: 0.1455\n",
      "epoch 18 loss: 0.1703\n",
      "epoch 19 loss: 0.1588\n",
      "epoch 20 loss: 0.1664\n",
      "epoch 21 loss: 0.1591\n",
      "epoch 22 loss: 0.1222\n",
      "epoch 23 loss: 0.1658\n",
      "epoch 24 loss: 0.1347\n",
      "epoch 25 loss: 0.1404\n",
      "epoch 26 loss: 0.1409\n",
      "epoch 27 loss: 0.1794\n",
      "epoch 28 loss: 0.1531\n",
      "epoch 29 loss: 0.1561\n",
      "epoch 30 loss: 0.1383\n",
      "21\n",
      "epoch 1 loss: 0.9888\n",
      "epoch 2 loss: 0.6902\n",
      "epoch 3 loss: 0.4019\n",
      "epoch 4 loss: 0.2420\n",
      "epoch 5 loss: 0.1750\n",
      "epoch 6 loss: 0.1376\n",
      "epoch 7 loss: 0.1568\n",
      "epoch 8 loss: 0.1589\n",
      "epoch 9 loss: 0.1641\n",
      "epoch 10 loss: 0.1664\n",
      "epoch 11 loss: 0.1617\n",
      "epoch 12 loss: 0.1286\n",
      "epoch 13 loss: 0.1171\n",
      "epoch 14 loss: 0.1326\n",
      "epoch 15 loss: 0.1806\n",
      "epoch 16 loss: 0.1748\n",
      "epoch 17 loss: 0.1162\n",
      "epoch 18 loss: 0.1400\n",
      "epoch 19 loss: 0.1156\n",
      "epoch 20 loss: 0.1510\n",
      "epoch 21 loss: 0.1300\n",
      "epoch 22 loss: 0.1108\n",
      "epoch 23 loss: 0.1104\n",
      "epoch 24 loss: 0.1032\n",
      "epoch 25 loss: 0.0865\n",
      "epoch 26 loss: 0.1992\n",
      "epoch 27 loss: 0.1236\n",
      "epoch 28 loss: 0.1375\n",
      "epoch 29 loss: 0.1284\n",
      "epoch 30 loss: 0.0845\n",
      "22\n",
      "epoch 1 loss: 1.0639\n",
      "epoch 2 loss: 0.5475\n",
      "epoch 3 loss: 0.4848\n",
      "epoch 4 loss: 0.2995\n",
      "epoch 5 loss: 0.2139\n",
      "epoch 6 loss: 0.1969\n",
      "epoch 7 loss: 0.1801\n",
      "epoch 8 loss: 0.1692\n",
      "epoch 9 loss: 0.1416\n",
      "epoch 10 loss: 0.2046\n",
      "epoch 11 loss: 0.1615\n",
      "epoch 12 loss: 0.1678\n",
      "epoch 13 loss: 0.1391\n",
      "epoch 14 loss: 0.1613\n",
      "epoch 15 loss: 0.1677\n",
      "epoch 16 loss: 0.1621\n",
      "epoch 17 loss: 0.1129\n",
      "epoch 18 loss: 0.1447\n",
      "epoch 19 loss: 0.1582\n",
      "epoch 20 loss: 0.1299\n",
      "epoch 21 loss: 0.1783\n",
      "epoch 22 loss: 0.1713\n",
      "epoch 23 loss: 0.1252\n",
      "epoch 24 loss: 0.1149\n",
      "epoch 25 loss: 0.1196\n",
      "epoch 26 loss: 0.1139\n",
      "epoch 27 loss: 0.1733\n",
      "epoch 28 loss: 0.1374\n",
      "epoch 29 loss: 0.1136\n",
      "epoch 30 loss: 0.0973\n",
      "23\n",
      "epoch 1 loss: 1.0367\n",
      "epoch 2 loss: 0.5997\n",
      "epoch 3 loss: 0.9551\n",
      "epoch 4 loss: 0.5193\n",
      "epoch 5 loss: 0.4710\n",
      "epoch 6 loss: 0.3901\n",
      "epoch 7 loss: 0.2459\n",
      "epoch 8 loss: 0.1656\n",
      "epoch 9 loss: 0.1560\n",
      "epoch 10 loss: 0.1370\n",
      "epoch 11 loss: 0.1726\n",
      "epoch 12 loss: 0.1558\n",
      "epoch 13 loss: 0.1447\n",
      "epoch 14 loss: 0.1501\n",
      "epoch 15 loss: 0.1902\n",
      "epoch 16 loss: 0.1605\n",
      "epoch 17 loss: 0.1877\n",
      "epoch 18 loss: 0.1586\n",
      "epoch 19 loss: 0.1225\n",
      "epoch 20 loss: 0.1505\n",
      "epoch 21 loss: 0.1824\n",
      "epoch 22 loss: 0.1468\n",
      "epoch 23 loss: 0.1500\n",
      "epoch 24 loss: 0.1204\n",
      "epoch 25 loss: 0.1569\n",
      "epoch 26 loss: 0.1457\n",
      "epoch 27 loss: 0.1577\n",
      "epoch 28 loss: 0.1037\n",
      "epoch 29 loss: 0.1692\n",
      "epoch 30 loss: 0.1892\n",
      "24\n",
      "epoch 1 loss: 0.8480\n",
      "epoch 2 loss: 0.6519\n",
      "epoch 3 loss: 0.7093\n",
      "epoch 4 loss: 0.4226\n",
      "epoch 5 loss: 0.3065\n",
      "epoch 6 loss: 0.2655\n",
      "epoch 7 loss: 0.1723\n",
      "epoch 8 loss: 0.1871\n",
      "epoch 9 loss: 0.1714\n",
      "epoch 10 loss: 0.1665\n",
      "epoch 11 loss: 0.1439\n",
      "epoch 12 loss: 0.1527\n",
      "epoch 13 loss: 0.1592\n",
      "epoch 14 loss: 0.1275\n",
      "epoch 15 loss: 0.1187\n",
      "epoch 16 loss: 0.1520\n",
      "epoch 17 loss: 0.1776\n",
      "epoch 18 loss: 0.1580\n",
      "epoch 19 loss: 0.1243\n",
      "epoch 20 loss: 0.1223\n",
      "epoch 21 loss: 0.1074\n",
      "epoch 22 loss: 0.1160\n",
      "epoch 23 loss: 0.1382\n",
      "epoch 24 loss: 0.1625\n",
      "epoch 25 loss: 0.1269\n",
      "epoch 26 loss: 0.1173\n",
      "epoch 27 loss: 0.0871\n",
      "epoch 28 loss: 0.0845\n",
      "epoch 29 loss: 0.1438\n",
      "epoch 30 loss: 0.0898\n",
      "25\n",
      "epoch 1 loss: 0.8278\n",
      "epoch 2 loss: 0.6251\n",
      "epoch 3 loss: 0.5885\n",
      "epoch 4 loss: 0.2512\n",
      "epoch 5 loss: 0.2256\n",
      "epoch 6 loss: 0.2032\n",
      "epoch 7 loss: 0.1979\n",
      "epoch 8 loss: 0.1741\n",
      "epoch 9 loss: 0.1641\n",
      "epoch 10 loss: 0.1914\n",
      "epoch 11 loss: 0.1473\n",
      "epoch 12 loss: 0.1605\n",
      "epoch 13 loss: 0.1795\n",
      "epoch 14 loss: 0.1446\n",
      "epoch 15 loss: 0.1733\n",
      "epoch 16 loss: 0.1367\n",
      "epoch 17 loss: 0.1397\n",
      "epoch 18 loss: 0.1177\n",
      "epoch 19 loss: 0.1568\n",
      "epoch 20 loss: 0.1379\n",
      "epoch 21 loss: 0.1376\n",
      "epoch 22 loss: 0.1129\n",
      "epoch 23 loss: 0.1744\n",
      "epoch 24 loss: 0.1231\n",
      "epoch 25 loss: 0.1597\n",
      "epoch 26 loss: 0.0905\n",
      "epoch 27 loss: 0.1390\n",
      "epoch 28 loss: 0.2042\n",
      "epoch 29 loss: 0.0984\n",
      "epoch 30 loss: 0.1550\n",
      "26\n",
      "epoch 1 loss: 0.9385\n",
      "epoch 2 loss: 0.8397\n",
      "epoch 3 loss: 0.6889\n",
      "epoch 4 loss: 0.3259\n",
      "epoch 5 loss: 0.2032\n",
      "epoch 6 loss: 0.2227\n",
      "epoch 7 loss: 0.1960\n",
      "epoch 8 loss: 0.1904\n",
      "epoch 9 loss: 0.2005\n",
      "epoch 10 loss: 0.1732\n",
      "epoch 11 loss: 0.1642\n",
      "epoch 12 loss: 0.1808\n",
      "epoch 13 loss: 0.1721\n",
      "epoch 14 loss: 0.1480\n",
      "epoch 15 loss: 0.1486\n",
      "epoch 16 loss: 0.1698\n",
      "epoch 17 loss: 0.1767\n",
      "epoch 18 loss: 0.1654\n",
      "epoch 19 loss: 0.1598\n",
      "epoch 20 loss: 0.1501\n",
      "epoch 21 loss: 0.1794\n",
      "epoch 22 loss: 0.1644\n",
      "epoch 23 loss: 0.1838\n",
      "epoch 24 loss: 0.1356\n",
      "epoch 25 loss: 0.1260\n",
      "epoch 26 loss: 0.1718\n",
      "epoch 27 loss: 0.1295\n",
      "epoch 28 loss: 0.1383\n",
      "epoch 29 loss: 0.1526\n",
      "epoch 30 loss: 0.1220\n",
      "27\n",
      "epoch 1 loss: 0.7893\n",
      "epoch 2 loss: 0.7107\n",
      "epoch 3 loss: 0.4804\n",
      "epoch 4 loss: 0.3526\n",
      "epoch 5 loss: 0.1962\n",
      "epoch 6 loss: 0.1688\n",
      "epoch 7 loss: 0.1768\n",
      "epoch 8 loss: 0.1458\n",
      "epoch 9 loss: 0.1637\n",
      "epoch 10 loss: 0.1495\n",
      "epoch 11 loss: 0.1546\n",
      "epoch 12 loss: 0.1395\n",
      "epoch 13 loss: 0.1357\n",
      "epoch 14 loss: 0.1642\n",
      "epoch 15 loss: 0.1585\n",
      "epoch 16 loss: 0.1484\n",
      "epoch 17 loss: 0.1593\n",
      "epoch 18 loss: 0.1786\n",
      "epoch 19 loss: 0.1375\n",
      "epoch 20 loss: 0.1558\n",
      "epoch 21 loss: 0.1494\n",
      "epoch 22 loss: 0.1449\n",
      "epoch 23 loss: 0.1607\n",
      "epoch 24 loss: 0.1242\n",
      "epoch 25 loss: 0.1507\n",
      "epoch 26 loss: 0.1751\n",
      "epoch 27 loss: 0.1663\n",
      "epoch 28 loss: 0.1698\n",
      "epoch 29 loss: 0.1230\n",
      "epoch 30 loss: 0.1239\n",
      "28\n",
      "epoch 1 loss: 0.7478\n",
      "epoch 2 loss: 0.4792\n",
      "epoch 3 loss: 0.3574\n",
      "epoch 4 loss: 0.2980\n",
      "epoch 5 loss: 0.2103\n",
      "epoch 6 loss: 0.1892\n",
      "epoch 7 loss: 0.1299\n",
      "epoch 8 loss: 0.1709\n",
      "epoch 9 loss: 0.2096\n",
      "epoch 10 loss: 0.1126\n",
      "epoch 11 loss: 0.2033\n",
      "epoch 12 loss: 0.1802\n",
      "epoch 13 loss: 0.1490\n",
      "epoch 14 loss: 0.1639\n",
      "epoch 15 loss: 0.1255\n",
      "epoch 16 loss: 0.1729\n",
      "epoch 17 loss: 0.1444\n",
      "epoch 18 loss: 0.1408\n",
      "epoch 19 loss: 0.1449\n",
      "epoch 20 loss: 0.1476\n",
      "epoch 21 loss: 0.1594\n",
      "epoch 22 loss: 0.1508\n",
      "epoch 23 loss: 0.1287\n",
      "epoch 24 loss: 0.1373\n",
      "epoch 25 loss: 0.1404\n",
      "epoch 26 loss: 0.1481\n",
      "epoch 27 loss: 0.1295\n",
      "epoch 28 loss: 0.1206\n",
      "epoch 29 loss: 0.1446\n",
      "epoch 30 loss: 0.1444\n",
      "29\n",
      "epoch 1 loss: 0.9685\n",
      "epoch 2 loss: 0.5449\n",
      "epoch 3 loss: 0.4003\n",
      "epoch 4 loss: 0.5971\n",
      "epoch 5 loss: 0.6546\n",
      "epoch 6 loss: 0.6203\n",
      "epoch 7 loss: 0.3759\n",
      "epoch 8 loss: 0.2320\n",
      "epoch 9 loss: 0.2617\n",
      "epoch 10 loss: 0.1805\n",
      "epoch 11 loss: 0.1599\n",
      "epoch 12 loss: 0.1981\n",
      "epoch 13 loss: 0.1531\n",
      "epoch 14 loss: 0.1749\n",
      "epoch 15 loss: 0.1702\n",
      "epoch 16 loss: 0.1613\n",
      "epoch 17 loss: 0.1607\n",
      "epoch 18 loss: 0.1454\n",
      "epoch 19 loss: 0.1512\n",
      "epoch 20 loss: 0.1444\n",
      "epoch 21 loss: 0.1781\n",
      "epoch 22 loss: 0.1556\n",
      "epoch 23 loss: 0.1542\n",
      "epoch 24 loss: 0.1213\n",
      "epoch 25 loss: 0.1321\n",
      "epoch 26 loss: 0.1706\n",
      "epoch 27 loss: 0.1364\n",
      "epoch 28 loss: 0.1480\n",
      "epoch 29 loss: 0.1475\n",
      "epoch 30 loss: 0.1667\n",
      "30\n",
      "epoch 1 loss: 0.9298\n",
      "epoch 2 loss: 0.7519\n",
      "epoch 3 loss: 0.5176\n",
      "epoch 4 loss: 0.3900\n",
      "epoch 5 loss: 0.1790\n",
      "epoch 6 loss: 0.2116\n",
      "epoch 7 loss: 0.2083\n",
      "epoch 8 loss: 0.1859\n",
      "epoch 9 loss: 0.1695\n",
      "epoch 10 loss: 0.1614\n",
      "epoch 11 loss: 0.1555\n",
      "epoch 12 loss: 0.1917\n",
      "epoch 13 loss: 0.1750\n",
      "epoch 14 loss: 0.1483\n",
      "epoch 15 loss: 0.1699\n",
      "epoch 16 loss: 0.1731\n",
      "epoch 17 loss: 0.1894\n",
      "epoch 18 loss: 0.1719\n",
      "epoch 19 loss: 0.1445\n",
      "epoch 20 loss: 0.1800\n",
      "epoch 21 loss: 0.1983\n",
      "epoch 22 loss: 0.1252\n",
      "epoch 23 loss: 0.1537\n",
      "epoch 24 loss: 0.1119\n",
      "epoch 25 loss: 0.1579\n",
      "epoch 26 loss: 0.1899\n",
      "epoch 27 loss: 0.1548\n",
      "epoch 28 loss: 0.1995\n",
      "epoch 29 loss: 0.1527\n",
      "epoch 30 loss: 0.1657\n",
      "31\n",
      "epoch 1 loss: 0.9591\n",
      "epoch 2 loss: 0.7087\n",
      "epoch 3 loss: 0.3841\n",
      "epoch 4 loss: 0.1926\n",
      "epoch 5 loss: 0.2093\n",
      "epoch 6 loss: 0.1944\n",
      "epoch 7 loss: 0.2349\n",
      "epoch 8 loss: 0.1650\n",
      "epoch 9 loss: 0.1439\n",
      "epoch 10 loss: 0.1557\n",
      "epoch 11 loss: 0.1895\n",
      "epoch 12 loss: 0.1308\n",
      "epoch 13 loss: 0.1628\n",
      "epoch 14 loss: 0.1728\n",
      "epoch 15 loss: 0.1429\n",
      "epoch 16 loss: 0.1602\n",
      "epoch 17 loss: 0.1563\n",
      "epoch 18 loss: 0.1601\n",
      "epoch 19 loss: 0.1236\n",
      "epoch 20 loss: 0.1314\n",
      "epoch 21 loss: 0.1514\n",
      "epoch 22 loss: 0.1459\n",
      "epoch 23 loss: 0.1327\n",
      "epoch 24 loss: 0.1278\n",
      "epoch 25 loss: 0.1295\n",
      "epoch 26 loss: 0.1674\n",
      "epoch 27 loss: 0.1297\n",
      "epoch 28 loss: 0.1223\n",
      "epoch 29 loss: 0.1343\n",
      "epoch 30 loss: 0.1747\n",
      "32\n",
      "epoch 1 loss: 0.7767\n",
      "epoch 2 loss: 0.8128\n",
      "epoch 3 loss: 0.5314\n",
      "epoch 4 loss: 0.3943\n",
      "epoch 5 loss: 0.2674\n",
      "epoch 6 loss: 0.1747\n",
      "epoch 7 loss: 0.2037\n",
      "epoch 8 loss: 0.1634\n",
      "epoch 9 loss: 0.1524\n",
      "epoch 10 loss: 0.1507\n",
      "epoch 11 loss: 0.1711\n",
      "epoch 12 loss: 0.1361\n",
      "epoch 13 loss: 0.1474\n",
      "epoch 14 loss: 0.1560\n",
      "epoch 15 loss: 0.1879\n",
      "epoch 16 loss: 0.1735\n",
      "epoch 17 loss: 0.1513\n",
      "epoch 18 loss: 0.1679\n",
      "epoch 19 loss: 0.1132\n",
      "epoch 20 loss: 0.1544\n",
      "epoch 21 loss: 0.0995\n",
      "epoch 22 loss: 0.1113\n",
      "epoch 23 loss: 0.1437\n",
      "epoch 24 loss: 0.1415\n",
      "epoch 25 loss: 0.1276\n",
      "epoch 26 loss: 0.1562\n",
      "epoch 27 loss: 0.1261\n",
      "epoch 28 loss: 0.1017\n",
      "epoch 29 loss: 0.1188\n",
      "epoch 30 loss: 0.1276\n",
      "33\n",
      "epoch 1 loss: 0.7928\n",
      "epoch 2 loss: 0.9851\n",
      "epoch 3 loss: 0.6563\n",
      "epoch 4 loss: 0.4679\n",
      "epoch 5 loss: 0.3629\n",
      "epoch 6 loss: 0.2530\n",
      "epoch 7 loss: 0.2406\n",
      "epoch 8 loss: 0.1944\n",
      "epoch 9 loss: 0.1751\n",
      "epoch 10 loss: 0.1637\n",
      "epoch 11 loss: 0.1576\n",
      "epoch 12 loss: 0.1990\n",
      "epoch 13 loss: 0.1656\n",
      "epoch 14 loss: 0.1121\n",
      "epoch 15 loss: 0.1756\n",
      "epoch 16 loss: 0.1645\n",
      "epoch 17 loss: 0.1559\n",
      "epoch 18 loss: 0.1195\n",
      "epoch 19 loss: 0.1916\n",
      "epoch 20 loss: 0.1220\n",
      "epoch 21 loss: 0.1472\n",
      "epoch 22 loss: 0.1064\n",
      "epoch 23 loss: 0.1769\n",
      "epoch 24 loss: 0.1094\n",
      "epoch 25 loss: 0.1472\n",
      "epoch 26 loss: 0.1153\n",
      "epoch 27 loss: 0.1033\n",
      "epoch 28 loss: 0.1376\n",
      "epoch 29 loss: 0.0962\n",
      "epoch 30 loss: 0.1015\n",
      "34\n",
      "epoch 1 loss: 0.9039\n",
      "epoch 2 loss: 0.6693\n",
      "epoch 3 loss: 0.5655\n",
      "epoch 4 loss: 0.3892\n",
      "epoch 5 loss: 0.2085\n",
      "epoch 6 loss: 0.1864\n",
      "epoch 7 loss: 0.1793\n",
      "epoch 8 loss: 0.2015\n",
      "epoch 9 loss: 0.1447\n",
      "epoch 10 loss: 0.1664\n",
      "epoch 11 loss: 0.1733\n",
      "epoch 12 loss: 0.1678\n",
      "epoch 13 loss: 0.1683\n",
      "epoch 14 loss: 0.1714\n",
      "epoch 15 loss: 0.1302\n",
      "epoch 16 loss: 0.1758\n",
      "epoch 17 loss: 0.1657\n",
      "epoch 18 loss: 0.1579\n",
      "epoch 19 loss: 0.1700\n",
      "epoch 20 loss: 0.1207\n",
      "epoch 21 loss: 0.1475\n",
      "epoch 22 loss: 0.1551\n",
      "epoch 23 loss: 0.0969\n",
      "epoch 24 loss: 0.1095\n",
      "epoch 25 loss: 0.1271\n",
      "epoch 26 loss: 0.1217\n",
      "epoch 27 loss: 0.1196\n",
      "epoch 28 loss: 0.0919\n",
      "epoch 29 loss: 0.1070\n",
      "epoch 30 loss: 0.0913\n",
      "35\n",
      "epoch 1 loss: 1.0718\n",
      "epoch 2 loss: 0.7028\n",
      "epoch 3 loss: 0.4604\n",
      "epoch 4 loss: 0.2642\n",
      "epoch 5 loss: 0.2136\n",
      "epoch 6 loss: 0.2119\n",
      "epoch 7 loss: 0.1580\n",
      "epoch 8 loss: 0.2211\n",
      "epoch 9 loss: 0.1937\n",
      "epoch 10 loss: 0.1865\n",
      "epoch 11 loss: 0.1619\n",
      "epoch 12 loss: 0.1570\n",
      "epoch 13 loss: 0.1850\n",
      "epoch 14 loss: 0.1730\n",
      "epoch 15 loss: 0.1790\n",
      "epoch 16 loss: 0.1679\n",
      "epoch 17 loss: 0.1736\n",
      "epoch 18 loss: 0.1292\n",
      "epoch 19 loss: 0.1580\n",
      "epoch 20 loss: 0.1778\n",
      "epoch 21 loss: 0.1959\n",
      "epoch 22 loss: 0.1655\n",
      "epoch 23 loss: 0.1517\n",
      "epoch 24 loss: 0.1945\n",
      "epoch 25 loss: 0.1372\n",
      "epoch 26 loss: 0.1396\n",
      "epoch 27 loss: 0.1344\n",
      "epoch 28 loss: 0.1891\n",
      "epoch 29 loss: 0.1272\n",
      "epoch 30 loss: 0.1525\n",
      "36\n",
      "epoch 1 loss: 0.7698\n",
      "epoch 2 loss: 0.9285\n",
      "epoch 3 loss: 0.5954\n",
      "epoch 4 loss: 0.3449\n",
      "epoch 5 loss: 0.2795\n",
      "epoch 6 loss: 0.1996\n",
      "epoch 7 loss: 0.1978\n",
      "epoch 8 loss: 0.1824\n",
      "epoch 9 loss: 0.1725\n",
      "epoch 10 loss: 0.1876\n",
      "epoch 11 loss: 0.1905\n",
      "epoch 12 loss: 0.1985\n",
      "epoch 13 loss: 0.1427\n",
      "epoch 14 loss: 0.1451\n",
      "epoch 15 loss: 0.1713\n",
      "epoch 16 loss: 0.1200\n",
      "epoch 17 loss: 0.1447\n",
      "epoch 18 loss: 0.1309\n",
      "epoch 19 loss: 0.1632\n",
      "epoch 20 loss: 0.1643\n",
      "epoch 21 loss: 0.1431\n",
      "epoch 22 loss: 0.1539\n",
      "epoch 23 loss: 0.1631\n",
      "epoch 24 loss: 0.1364\n",
      "epoch 25 loss: 0.1250\n",
      "epoch 26 loss: 0.1525\n",
      "epoch 27 loss: 0.1151\n",
      "epoch 28 loss: 0.1329\n",
      "epoch 29 loss: 0.1104\n",
      "epoch 30 loss: 0.1406\n",
      "37\n",
      "epoch 1 loss: 0.8303\n",
      "epoch 2 loss: 0.7225\n",
      "epoch 3 loss: 0.6587\n",
      "epoch 4 loss: 0.5680\n",
      "epoch 5 loss: 0.4419\n",
      "epoch 6 loss: 0.2571\n",
      "epoch 7 loss: 0.2088\n",
      "epoch 8 loss: 0.2317\n",
      "epoch 9 loss: 0.1512\n",
      "epoch 10 loss: 0.1411\n",
      "epoch 11 loss: 0.1328\n",
      "epoch 12 loss: 0.1461\n",
      "epoch 13 loss: 0.1568\n",
      "epoch 14 loss: 0.1428\n",
      "epoch 15 loss: 0.1607\n",
      "epoch 16 loss: 0.1471\n",
      "epoch 17 loss: 0.1636\n",
      "epoch 18 loss: 0.1494\n",
      "epoch 19 loss: 0.1679\n",
      "epoch 20 loss: 0.1517\n",
      "epoch 21 loss: 0.1034\n",
      "epoch 22 loss: 0.1501\n",
      "epoch 23 loss: 0.1372\n",
      "epoch 24 loss: 0.1237\n",
      "epoch 25 loss: 0.1052\n",
      "epoch 26 loss: 0.1069\n",
      "epoch 27 loss: 0.0976\n",
      "epoch 28 loss: 0.1235\n",
      "epoch 29 loss: 0.0987\n",
      "epoch 30 loss: 0.1035\n",
      "38\n",
      "epoch 1 loss: 0.8697\n",
      "epoch 2 loss: 0.7253\n",
      "epoch 3 loss: 0.5005\n",
      "epoch 4 loss: 0.3159\n",
      "epoch 5 loss: 0.2058\n",
      "epoch 6 loss: 0.1936\n",
      "epoch 7 loss: 0.2193\n",
      "epoch 8 loss: 0.1561\n",
      "epoch 9 loss: 0.1972\n",
      "epoch 10 loss: 0.1838\n",
      "epoch 11 loss: 0.1684\n",
      "epoch 12 loss: 0.1958\n",
      "epoch 13 loss: 0.1715\n",
      "epoch 14 loss: 0.1191\n",
      "epoch 15 loss: 0.1648\n",
      "epoch 16 loss: 0.1688\n",
      "epoch 17 loss: 0.1356\n",
      "epoch 18 loss: 0.1692\n",
      "epoch 19 loss: 0.1257\n",
      "epoch 20 loss: 0.1540\n",
      "epoch 21 loss: 0.1413\n",
      "epoch 22 loss: 0.1416\n",
      "epoch 23 loss: 0.1421\n",
      "epoch 24 loss: 0.1327\n",
      "epoch 25 loss: 0.1376\n",
      "epoch 26 loss: 0.1117\n",
      "epoch 27 loss: 0.1240\n",
      "epoch 28 loss: 0.1704\n",
      "epoch 29 loss: 0.1275\n",
      "epoch 30 loss: 0.1428\n",
      "39\n",
      "epoch 1 loss: 0.8228\n",
      "epoch 2 loss: 0.5721\n",
      "epoch 3 loss: 0.5250\n",
      "epoch 4 loss: 0.5875\n",
      "epoch 5 loss: 0.3602\n",
      "epoch 6 loss: 0.2355\n",
      "epoch 7 loss: 0.2322\n",
      "epoch 8 loss: 0.1705\n",
      "epoch 9 loss: 0.1685\n",
      "epoch 10 loss: 0.1839\n",
      "epoch 11 loss: 0.1565\n",
      "epoch 12 loss: 0.2066\n",
      "epoch 13 loss: 0.1998\n",
      "epoch 14 loss: 0.1474\n",
      "epoch 15 loss: 0.2045\n",
      "epoch 16 loss: 0.1563\n",
      "epoch 17 loss: 0.1828\n",
      "epoch 18 loss: 0.1717\n",
      "epoch 19 loss: 0.1759\n",
      "epoch 20 loss: 0.1454\n",
      "epoch 21 loss: 0.1283\n",
      "epoch 22 loss: 0.1587\n",
      "epoch 23 loss: 0.1429\n",
      "epoch 24 loss: 0.1497\n",
      "epoch 25 loss: 0.1798\n",
      "epoch 26 loss: 0.1709\n",
      "epoch 27 loss: 0.1549\n",
      "epoch 28 loss: 0.1531\n",
      "epoch 29 loss: 0.1444\n",
      "epoch 30 loss: 0.1464\n",
      "40\n",
      "epoch 1 loss: 0.9145\n",
      "epoch 2 loss: 0.7667\n",
      "epoch 3 loss: 0.5228\n",
      "epoch 4 loss: 0.5738\n",
      "epoch 5 loss: 0.4045\n",
      "epoch 6 loss: 0.2868\n",
      "epoch 7 loss: 0.1763\n",
      "epoch 8 loss: 0.2232\n",
      "epoch 9 loss: 0.1907\n",
      "epoch 10 loss: 0.1685\n",
      "epoch 11 loss: 0.1606\n",
      "epoch 12 loss: 0.1442\n",
      "epoch 13 loss: 0.1531\n",
      "epoch 14 loss: 0.1574\n",
      "epoch 15 loss: 0.1555\n",
      "epoch 16 loss: 0.1702\n",
      "epoch 17 loss: 0.1952\n",
      "epoch 18 loss: 0.1364\n",
      "epoch 19 loss: 0.1229\n",
      "epoch 20 loss: 0.1475\n",
      "epoch 21 loss: 0.1714\n",
      "epoch 22 loss: 0.1406\n",
      "epoch 23 loss: 0.1605\n",
      "epoch 24 loss: 0.1539\n",
      "epoch 25 loss: 0.1418\n",
      "epoch 26 loss: 0.1532\n",
      "epoch 27 loss: 0.1513\n",
      "epoch 28 loss: 0.1462\n",
      "epoch 29 loss: 0.1532\n",
      "epoch 30 loss: 0.1499\n",
      "41\n",
      "epoch 1 loss: 0.8561\n",
      "epoch 2 loss: 0.5404\n",
      "epoch 3 loss: 0.4635\n",
      "epoch 4 loss: 0.4493\n",
      "epoch 5 loss: 0.2452\n",
      "epoch 6 loss: 0.1772\n",
      "epoch 7 loss: 0.1680\n",
      "epoch 8 loss: 0.1633\n",
      "epoch 9 loss: 0.1926\n",
      "epoch 10 loss: 0.1628\n",
      "epoch 11 loss: 0.1407\n",
      "epoch 12 loss: 0.2197\n",
      "epoch 13 loss: 0.1345\n",
      "epoch 14 loss: 0.1708\n",
      "epoch 15 loss: 0.1888\n",
      "epoch 16 loss: 0.2007\n",
      "epoch 17 loss: 0.1430\n",
      "epoch 18 loss: 0.1551\n",
      "epoch 19 loss: 0.1592\n",
      "epoch 20 loss: 0.1359\n",
      "epoch 21 loss: 0.1389\n",
      "epoch 22 loss: 0.1823\n",
      "epoch 23 loss: 0.1392\n",
      "epoch 24 loss: 0.1222\n",
      "epoch 25 loss: 0.1443\n",
      "epoch 26 loss: 0.1642\n",
      "epoch 27 loss: 0.1211\n",
      "epoch 28 loss: 0.1575\n",
      "epoch 29 loss: 0.1669\n",
      "epoch 30 loss: 0.1573\n",
      "42\n",
      "epoch 1 loss: 1.0199\n",
      "epoch 2 loss: 0.6684\n",
      "epoch 3 loss: 0.5240\n",
      "epoch 4 loss: 0.3201\n",
      "epoch 5 loss: 0.2409\n",
      "epoch 6 loss: 0.2499\n",
      "epoch 7 loss: 0.1757\n",
      "epoch 8 loss: 0.1784\n",
      "epoch 9 loss: 0.1621\n",
      "epoch 10 loss: 0.1466\n",
      "epoch 11 loss: 0.1459\n",
      "epoch 12 loss: 0.1364\n",
      "epoch 13 loss: 0.1288\n",
      "epoch 14 loss: 0.1417\n",
      "epoch 15 loss: 0.1461\n",
      "epoch 16 loss: 0.1580\n",
      "epoch 17 loss: 0.1502\n",
      "epoch 18 loss: 0.1594\n",
      "epoch 19 loss: 0.1886\n",
      "epoch 20 loss: 0.1855\n",
      "epoch 21 loss: 0.1649\n",
      "epoch 22 loss: 0.1471\n",
      "epoch 23 loss: 0.1464\n",
      "epoch 24 loss: 0.0957\n",
      "epoch 25 loss: 0.1439\n",
      "epoch 26 loss: 0.1917\n",
      "epoch 27 loss: 0.1528\n",
      "epoch 28 loss: 0.1206\n",
      "epoch 29 loss: 0.1154\n",
      "epoch 30 loss: 0.0893\n",
      "43\n",
      "epoch 1 loss: 0.9653\n",
      "epoch 2 loss: 0.5263\n",
      "epoch 3 loss: 0.4518\n",
      "epoch 4 loss: 0.4374\n",
      "epoch 5 loss: 0.5275\n",
      "epoch 6 loss: 0.3693\n",
      "epoch 7 loss: 0.2224\n",
      "epoch 8 loss: 0.1488\n",
      "epoch 9 loss: 0.1581\n",
      "epoch 10 loss: 0.1729\n",
      "epoch 11 loss: 0.1621\n",
      "epoch 12 loss: 0.1608\n",
      "epoch 13 loss: 0.1404\n",
      "epoch 14 loss: 0.1419\n",
      "epoch 15 loss: 0.1499\n",
      "epoch 16 loss: 0.1921\n",
      "epoch 17 loss: 0.1344\n",
      "epoch 18 loss: 0.1402\n",
      "epoch 19 loss: 0.1500\n",
      "epoch 20 loss: 0.1671\n",
      "epoch 21 loss: 0.1530\n",
      "epoch 22 loss: 0.1585\n",
      "epoch 23 loss: 0.1484\n",
      "epoch 24 loss: 0.1674\n",
      "epoch 25 loss: 0.1368\n",
      "epoch 26 loss: 0.1453\n",
      "epoch 27 loss: 0.1606\n",
      "epoch 28 loss: 0.1493\n",
      "epoch 29 loss: 0.1103\n",
      "epoch 30 loss: 0.1304\n",
      "44\n",
      "epoch 1 loss: 0.7653\n",
      "epoch 2 loss: 0.6513\n",
      "epoch 3 loss: 0.6816\n",
      "epoch 4 loss: 0.3008\n",
      "epoch 5 loss: 0.2731\n",
      "epoch 6 loss: 0.2035\n",
      "epoch 7 loss: 0.1668\n",
      "epoch 8 loss: 0.2127\n",
      "epoch 9 loss: 0.1883\n",
      "epoch 10 loss: 0.1522\n",
      "epoch 11 loss: 0.1756\n",
      "epoch 12 loss: 0.1683\n",
      "epoch 13 loss: 0.2055\n",
      "epoch 14 loss: 0.1623\n",
      "epoch 15 loss: 0.1858\n",
      "epoch 16 loss: 0.1582\n",
      "epoch 17 loss: 0.1317\n",
      "epoch 18 loss: 0.1765\n",
      "epoch 19 loss: 0.1588\n",
      "epoch 20 loss: 0.1259\n",
      "epoch 21 loss: 0.1221\n",
      "epoch 22 loss: 0.1549\n",
      "epoch 23 loss: 0.1408\n",
      "epoch 24 loss: 0.1682\n",
      "epoch 25 loss: 0.1619\n",
      "epoch 26 loss: 0.1562\n",
      "epoch 27 loss: 0.1558\n",
      "epoch 28 loss: 0.1312\n",
      "epoch 29 loss: 0.1931\n",
      "epoch 30 loss: 0.1788\n",
      "45\n",
      "epoch 1 loss: 1.1262\n",
      "epoch 2 loss: 0.6247\n",
      "epoch 3 loss: 0.5139\n",
      "epoch 4 loss: 0.3521\n",
      "epoch 5 loss: 0.2471\n",
      "epoch 6 loss: 0.1946\n",
      "epoch 7 loss: 0.1693\n",
      "epoch 8 loss: 0.2048\n",
      "epoch 9 loss: 0.1554\n",
      "epoch 10 loss: 0.1497\n",
      "epoch 11 loss: 0.1608\n",
      "epoch 12 loss: 0.1432\n",
      "epoch 13 loss: 0.1494\n",
      "epoch 14 loss: 0.1077\n",
      "epoch 15 loss: 0.1417\n",
      "epoch 16 loss: 0.1665\n",
      "epoch 17 loss: 0.1591\n",
      "epoch 18 loss: 0.1465\n",
      "epoch 19 loss: 0.1487\n",
      "epoch 20 loss: 0.1182\n",
      "epoch 21 loss: 0.1309\n",
      "epoch 22 loss: 0.1231\n",
      "epoch 23 loss: 0.1649\n",
      "epoch 24 loss: 0.1312\n",
      "epoch 25 loss: 0.1534\n",
      "epoch 26 loss: 0.1345\n",
      "epoch 27 loss: 0.1467\n",
      "epoch 28 loss: 0.1704\n",
      "epoch 29 loss: 0.1378\n",
      "epoch 30 loss: 0.1281\n",
      "46\n",
      "epoch 1 loss: 0.8693\n",
      "epoch 2 loss: 0.4987\n",
      "epoch 3 loss: 0.4247\n",
      "epoch 4 loss: 0.2413\n",
      "epoch 5 loss: 0.2199\n",
      "epoch 6 loss: 0.1624\n",
      "epoch 7 loss: 0.1664\n",
      "epoch 8 loss: 0.1309\n",
      "epoch 9 loss: 0.2071\n",
      "epoch 10 loss: 0.1832\n",
      "epoch 11 loss: 0.1400\n",
      "epoch 12 loss: 0.1544\n",
      "epoch 13 loss: 0.1726\n",
      "epoch 14 loss: 0.1553\n",
      "epoch 15 loss: 0.1633\n",
      "epoch 16 loss: 0.1529\n",
      "epoch 17 loss: 0.1665\n",
      "epoch 18 loss: 0.1580\n",
      "epoch 19 loss: 0.1600\n",
      "epoch 20 loss: 0.1626\n",
      "epoch 21 loss: 0.1426\n",
      "epoch 22 loss: 0.1678\n",
      "epoch 23 loss: 0.1681\n",
      "epoch 24 loss: 0.1537\n",
      "epoch 25 loss: 0.1484\n",
      "epoch 26 loss: 0.1125\n",
      "epoch 27 loss: 0.1247\n",
      "epoch 28 loss: 0.1367\n",
      "epoch 29 loss: 0.1101\n",
      "epoch 30 loss: 0.1920\n",
      "47\n",
      "epoch 1 loss: 0.8717\n",
      "epoch 2 loss: 0.7734\n",
      "epoch 3 loss: 0.5990\n",
      "epoch 4 loss: 0.4230\n",
      "epoch 5 loss: 0.2867\n",
      "epoch 6 loss: 0.2436\n",
      "epoch 7 loss: 0.1557\n",
      "epoch 8 loss: 0.1862\n",
      "epoch 9 loss: 0.1353\n",
      "epoch 10 loss: 0.1850\n",
      "epoch 11 loss: 0.1896\n",
      "epoch 12 loss: 0.1277\n",
      "epoch 13 loss: 0.2137\n",
      "epoch 14 loss: 0.1733\n",
      "epoch 15 loss: 0.1808\n",
      "epoch 16 loss: 0.1487\n",
      "epoch 17 loss: 0.1552\n",
      "epoch 18 loss: 0.1798\n",
      "epoch 19 loss: 0.1561\n",
      "epoch 20 loss: 0.1555\n",
      "epoch 21 loss: 0.1403\n",
      "epoch 22 loss: 0.1758\n",
      "epoch 23 loss: 0.1517\n",
      "epoch 24 loss: 0.1713\n",
      "epoch 25 loss: 0.1310\n",
      "epoch 26 loss: 0.1751\n",
      "epoch 27 loss: 0.1618\n",
      "epoch 28 loss: 0.1328\n",
      "epoch 29 loss: 0.1315\n",
      "epoch 30 loss: 0.1354\n",
      "48\n",
      "epoch 1 loss: 0.9382\n",
      "epoch 2 loss: 0.5794\n",
      "epoch 3 loss: 0.4523\n",
      "epoch 4 loss: 0.2618\n",
      "epoch 5 loss: 0.2455\n",
      "epoch 6 loss: 0.1901\n",
      "epoch 7 loss: 0.1757\n",
      "epoch 8 loss: 0.1512\n",
      "epoch 9 loss: 0.1535\n",
      "epoch 10 loss: 0.1458\n",
      "epoch 11 loss: 0.1063\n",
      "epoch 12 loss: 0.1751\n",
      "epoch 13 loss: 0.1649\n",
      "epoch 14 loss: 0.1921\n",
      "epoch 15 loss: 0.1793\n",
      "epoch 16 loss: 0.1523\n",
      "epoch 17 loss: 0.2023\n",
      "epoch 18 loss: 0.1254\n",
      "epoch 19 loss: 0.1365\n",
      "epoch 20 loss: 0.1668\n",
      "epoch 21 loss: 0.1278\n",
      "epoch 22 loss: 0.1092\n",
      "epoch 23 loss: 0.1477\n",
      "epoch 24 loss: 0.1213\n",
      "epoch 25 loss: 0.1671\n",
      "epoch 26 loss: 0.0743\n",
      "epoch 27 loss: 0.1272\n",
      "epoch 28 loss: 0.1088\n",
      "epoch 29 loss: 0.0900\n",
      "epoch 30 loss: 0.0983\n",
      "49\n",
      "epoch 1 loss: 0.9839\n",
      "epoch 2 loss: 0.7290\n",
      "epoch 3 loss: 0.5497\n",
      "epoch 4 loss: 0.8564\n",
      "epoch 5 loss: 0.5359\n",
      "epoch 6 loss: 0.3605\n",
      "epoch 7 loss: 0.2794\n",
      "epoch 8 loss: 0.2475\n",
      "epoch 9 loss: 0.1747\n",
      "epoch 10 loss: 0.1838\n",
      "epoch 11 loss: 0.1896\n",
      "epoch 12 loss: 0.1621\n",
      "epoch 13 loss: 0.1673\n",
      "epoch 14 loss: 0.1473\n",
      "epoch 15 loss: 0.1494\n",
      "epoch 16 loss: 0.1637\n",
      "epoch 17 loss: 0.1586\n",
      "epoch 18 loss: 0.1474\n",
      "epoch 19 loss: 0.1564\n",
      "epoch 20 loss: 0.1758\n",
      "epoch 21 loss: 0.1778\n",
      "epoch 22 loss: 0.3092\n",
      "epoch 23 loss: 0.1522\n",
      "epoch 24 loss: 0.1205\n",
      "epoch 25 loss: 0.1813\n",
      "epoch 26 loss: 0.1733\n",
      "epoch 27 loss: 0.1260\n",
      "epoch 28 loss: 0.1219\n",
      "epoch 29 loss: 0.1608\n",
      "epoch 30 loss: 0.1408\n",
      "50\n",
      "epoch 1 loss: 0.9181\n",
      "epoch 2 loss: 0.7126\n",
      "epoch 3 loss: 0.5845\n",
      "epoch 4 loss: 0.2742\n",
      "epoch 5 loss: 0.2021\n",
      "epoch 6 loss: 0.1946\n",
      "epoch 7 loss: 0.1674\n",
      "epoch 8 loss: 0.1954\n",
      "epoch 9 loss: 0.1935\n",
      "epoch 10 loss: 0.1868\n",
      "epoch 11 loss: 0.1662\n",
      "epoch 12 loss: 0.1485\n",
      "epoch 13 loss: 0.1465\n",
      "epoch 14 loss: 0.1662\n",
      "epoch 15 loss: 0.1489\n",
      "epoch 16 loss: 0.1635\n",
      "epoch 17 loss: 0.1684\n",
      "epoch 18 loss: 0.1638\n",
      "epoch 19 loss: 0.1192\n",
      "epoch 20 loss: 0.1505\n",
      "epoch 21 loss: 0.1201\n",
      "epoch 22 loss: 0.1522\n",
      "epoch 23 loss: 0.1513\n",
      "epoch 24 loss: 0.1177\n",
      "epoch 25 loss: 0.1400\n",
      "epoch 26 loss: 0.1368\n",
      "epoch 27 loss: 0.2096\n",
      "epoch 28 loss: 0.1301\n",
      "epoch 29 loss: 0.1311\n",
      "epoch 30 loss: 0.1620\n",
      "51\n",
      "epoch 1 loss: 0.9557\n",
      "epoch 2 loss: 0.7828\n",
      "epoch 3 loss: 0.4783\n",
      "epoch 4 loss: 0.2543\n",
      "epoch 5 loss: 0.2713\n",
      "epoch 6 loss: 0.1965\n",
      "epoch 7 loss: 0.1686\n",
      "epoch 8 loss: 0.1793\n",
      "epoch 9 loss: 0.1777\n",
      "epoch 10 loss: 0.1703\n",
      "epoch 11 loss: 0.1905\n",
      "epoch 12 loss: 0.1479\n",
      "epoch 13 loss: 0.1520\n",
      "epoch 14 loss: 0.1912\n",
      "epoch 15 loss: 0.1624\n",
      "epoch 16 loss: 0.1663\n",
      "epoch 17 loss: 0.1710\n",
      "epoch 18 loss: 0.1329\n",
      "epoch 19 loss: 0.1463\n",
      "epoch 20 loss: 0.2064\n",
      "epoch 21 loss: 0.1523\n",
      "epoch 22 loss: 0.1531\n",
      "epoch 23 loss: 0.1533\n",
      "epoch 24 loss: 0.1586\n",
      "epoch 25 loss: 0.1486\n",
      "epoch 26 loss: 0.1653\n",
      "epoch 27 loss: 0.1389\n",
      "epoch 28 loss: 0.1310\n",
      "epoch 29 loss: 0.1243\n",
      "epoch 30 loss: 0.2261\n",
      "52\n",
      "epoch 1 loss: 0.8071\n",
      "epoch 2 loss: 0.5605\n",
      "epoch 3 loss: 0.3524\n",
      "epoch 4 loss: 0.2085\n",
      "epoch 5 loss: 0.1976\n",
      "epoch 6 loss: 0.1988\n",
      "epoch 7 loss: 0.1697\n",
      "epoch 8 loss: 0.1493\n",
      "epoch 9 loss: 0.1519\n",
      "epoch 10 loss: 0.1346\n",
      "epoch 11 loss: 0.1642\n",
      "epoch 12 loss: 0.1721\n",
      "epoch 13 loss: 0.1311\n",
      "epoch 14 loss: 0.1585\n",
      "epoch 15 loss: 0.1702\n",
      "epoch 16 loss: 0.1386\n",
      "epoch 17 loss: 0.1621\n",
      "epoch 18 loss: 0.1406\n",
      "epoch 19 loss: 0.1503\n",
      "epoch 20 loss: 0.1782\n",
      "epoch 21 loss: 0.1577\n",
      "epoch 22 loss: 0.1468\n",
      "epoch 23 loss: 0.1453\n",
      "epoch 24 loss: 0.1407\n",
      "epoch 25 loss: 0.1650\n",
      "epoch 26 loss: 0.1150\n",
      "epoch 27 loss: 0.1597\n",
      "epoch 28 loss: 0.1241\n",
      "epoch 29 loss: 0.1397\n",
      "epoch 30 loss: 0.1345\n",
      "53\n",
      "epoch 1 loss: 0.7509\n",
      "epoch 2 loss: 0.6755\n",
      "epoch 3 loss: 0.4697\n",
      "epoch 4 loss: 0.4881\n",
      "epoch 5 loss: 0.2937\n",
      "epoch 6 loss: 0.1953\n",
      "epoch 7 loss: 0.1756\n",
      "epoch 8 loss: 0.1841\n",
      "epoch 9 loss: 0.1611\n",
      "epoch 10 loss: 0.1584\n",
      "epoch 11 loss: 0.1649\n",
      "epoch 12 loss: 0.1393\n",
      "epoch 13 loss: 0.1691\n",
      "epoch 14 loss: 0.1405\n",
      "epoch 15 loss: 0.1515\n",
      "epoch 16 loss: 0.1663\n",
      "epoch 17 loss: 0.1290\n",
      "epoch 18 loss: 0.2282\n",
      "epoch 19 loss: 0.1225\n",
      "epoch 20 loss: 0.1175\n",
      "epoch 21 loss: 0.1258\n",
      "epoch 22 loss: 0.1566\n",
      "epoch 23 loss: 0.1146\n",
      "epoch 24 loss: 0.1323\n",
      "epoch 25 loss: 0.1217\n",
      "epoch 26 loss: 0.1020\n",
      "epoch 27 loss: 0.1141\n",
      "epoch 28 loss: 0.1027\n",
      "epoch 29 loss: 0.1210\n",
      "epoch 30 loss: 0.0887\n",
      "54\n",
      "epoch 1 loss: 0.9789\n",
      "epoch 2 loss: 0.7040\n",
      "epoch 3 loss: 0.6723\n",
      "epoch 4 loss: 0.6871\n",
      "epoch 5 loss: 0.6128\n",
      "epoch 6 loss: 0.2971\n",
      "epoch 7 loss: 0.2350\n",
      "epoch 8 loss: 0.1574\n",
      "epoch 9 loss: 0.1491\n",
      "epoch 10 loss: 0.1656\n",
      "epoch 11 loss: 0.1492\n",
      "epoch 12 loss: 0.1924\n",
      "epoch 13 loss: 0.1553\n",
      "epoch 14 loss: 0.1480\n",
      "epoch 15 loss: 0.1542\n",
      "epoch 16 loss: 0.1201\n",
      "epoch 17 loss: 0.1545\n",
      "epoch 18 loss: 0.1455\n",
      "epoch 19 loss: 0.1476\n",
      "epoch 20 loss: 0.1417\n",
      "epoch 21 loss: 0.1418\n",
      "epoch 22 loss: 0.1580\n",
      "epoch 23 loss: 0.1788\n",
      "epoch 24 loss: 0.1089\n",
      "epoch 25 loss: 0.1609\n",
      "epoch 26 loss: 0.1182\n",
      "epoch 27 loss: 0.0962\n",
      "epoch 28 loss: 0.1585\n",
      "epoch 29 loss: 0.1028\n",
      "epoch 30 loss: 0.1975\n",
      "55\n",
      "epoch 1 loss: 0.8229\n",
      "epoch 2 loss: 0.8490\n",
      "epoch 3 loss: 0.6178\n",
      "epoch 4 loss: 0.4284\n",
      "epoch 5 loss: 0.3629\n",
      "epoch 6 loss: 0.2220\n",
      "epoch 7 loss: 0.1635\n",
      "epoch 8 loss: 0.2128\n",
      "epoch 9 loss: 0.1862\n",
      "epoch 10 loss: 0.1753\n",
      "epoch 11 loss: 0.1372\n",
      "epoch 12 loss: 0.1768\n",
      "epoch 13 loss: 0.1499\n",
      "epoch 14 loss: 0.1228\n",
      "epoch 15 loss: 0.1536\n",
      "epoch 16 loss: 0.1145\n",
      "epoch 17 loss: 0.1602\n",
      "epoch 18 loss: 0.1354\n",
      "epoch 19 loss: 0.1794\n",
      "epoch 20 loss: 0.1457\n",
      "epoch 21 loss: 0.1479\n",
      "epoch 22 loss: 0.1825\n",
      "epoch 23 loss: 0.1405\n",
      "epoch 24 loss: 0.1785\n",
      "epoch 25 loss: 0.1750\n",
      "epoch 26 loss: 0.1632\n",
      "epoch 27 loss: 0.1453\n",
      "epoch 28 loss: 0.1491\n",
      "epoch 29 loss: 0.1308\n",
      "epoch 30 loss: 0.1407\n",
      "56\n",
      "epoch 1 loss: 1.0183\n",
      "epoch 2 loss: 0.6419\n",
      "epoch 3 loss: 0.3580\n",
      "epoch 4 loss: 0.2245\n",
      "epoch 5 loss: 0.1670\n",
      "epoch 6 loss: 0.1525\n",
      "epoch 7 loss: 0.1971\n",
      "epoch 8 loss: 0.1493\n",
      "epoch 9 loss: 0.1274\n",
      "epoch 10 loss: 0.1764\n",
      "epoch 11 loss: 0.1671\n",
      "epoch 12 loss: 0.1548\n",
      "epoch 13 loss: 0.1569\n",
      "epoch 14 loss: 0.1518\n",
      "epoch 15 loss: 0.1617\n",
      "epoch 16 loss: 0.1434\n",
      "epoch 17 loss: 0.1497\n",
      "epoch 18 loss: 0.1407\n",
      "epoch 19 loss: 0.1525\n",
      "epoch 20 loss: 0.1204\n",
      "epoch 21 loss: 0.1720\n",
      "epoch 22 loss: 0.1544\n",
      "epoch 23 loss: 0.1389\n",
      "epoch 24 loss: 0.1708\n",
      "epoch 25 loss: 0.1721\n",
      "epoch 26 loss: 0.1788\n",
      "epoch 27 loss: 0.1371\n",
      "epoch 28 loss: 0.1011\n",
      "epoch 29 loss: 0.1487\n",
      "epoch 30 loss: 0.1136\n",
      "57\n",
      "epoch 1 loss: 1.1691\n",
      "epoch 2 loss: 0.6207\n",
      "epoch 3 loss: 0.6184\n",
      "epoch 4 loss: 0.4505\n",
      "epoch 5 loss: 0.2235\n",
      "epoch 6 loss: 0.1831\n",
      "epoch 7 loss: 0.1878\n",
      "epoch 8 loss: 0.1726\n",
      "epoch 9 loss: 0.1894\n",
      "epoch 10 loss: 0.1569\n",
      "epoch 11 loss: 0.1714\n",
      "epoch 12 loss: 0.1367\n",
      "epoch 13 loss: 0.1518\n",
      "epoch 14 loss: 0.1691\n",
      "epoch 15 loss: 0.1832\n",
      "epoch 16 loss: 0.1694\n",
      "epoch 17 loss: 0.1514\n",
      "epoch 18 loss: 0.1320\n",
      "epoch 19 loss: 0.1890\n",
      "epoch 20 loss: 0.1277\n",
      "epoch 21 loss: 0.1529\n",
      "epoch 22 loss: 0.1331\n",
      "epoch 23 loss: 0.2107\n",
      "epoch 24 loss: 0.1691\n",
      "epoch 25 loss: 0.1294\n",
      "epoch 26 loss: 0.1668\n",
      "epoch 27 loss: 0.1370\n",
      "epoch 28 loss: 0.1267\n",
      "epoch 29 loss: 0.1193\n",
      "epoch 30 loss: 0.1183\n",
      "58\n",
      "epoch 1 loss: 1.0295\n",
      "epoch 2 loss: 0.6706\n",
      "epoch 3 loss: 0.7137\n",
      "epoch 4 loss: 0.3593\n",
      "epoch 5 loss: 0.2494\n",
      "epoch 6 loss: 0.1770\n",
      "epoch 7 loss: 0.1631\n",
      "epoch 8 loss: 0.1886\n",
      "epoch 9 loss: 0.1301\n",
      "epoch 10 loss: 0.1896\n",
      "epoch 11 loss: 0.1405\n",
      "epoch 12 loss: 0.1660\n",
      "epoch 13 loss: 0.1601\n",
      "epoch 14 loss: 0.1518\n",
      "epoch 15 loss: 0.1917\n",
      "epoch 16 loss: 0.1628\n",
      "epoch 17 loss: 0.1283\n",
      "epoch 18 loss: 0.1467\n",
      "epoch 19 loss: 0.1820\n",
      "epoch 20 loss: 0.1419\n",
      "epoch 21 loss: 0.1630\n",
      "epoch 22 loss: 0.1376\n",
      "epoch 23 loss: 0.1025\n",
      "epoch 24 loss: 0.1408\n",
      "epoch 25 loss: 0.1344\n",
      "epoch 26 loss: 0.1118\n",
      "epoch 27 loss: 0.1517\n",
      "epoch 28 loss: 0.1365\n",
      "epoch 29 loss: 0.1097\n",
      "epoch 30 loss: 0.1149\n",
      "59\n",
      "epoch 1 loss: 0.8922\n",
      "epoch 2 loss: 0.6789\n",
      "epoch 3 loss: 0.4488\n",
      "epoch 4 loss: 0.4366\n",
      "epoch 5 loss: 0.2722\n",
      "epoch 6 loss: 0.1951\n",
      "epoch 7 loss: 0.1654\n",
      "epoch 8 loss: 0.1694\n",
      "epoch 9 loss: 0.1858\n",
      "epoch 10 loss: 0.1484\n",
      "epoch 11 loss: 0.1796\n",
      "epoch 12 loss: 0.1909\n",
      "epoch 13 loss: 0.1521\n",
      "epoch 14 loss: 0.1279\n",
      "epoch 15 loss: 0.1110\n",
      "epoch 16 loss: 0.1201\n",
      "epoch 17 loss: 0.1504\n",
      "epoch 18 loss: 0.1584\n",
      "epoch 19 loss: 0.1165\n",
      "epoch 20 loss: 0.1643\n",
      "epoch 21 loss: 0.1803\n",
      "epoch 22 loss: 0.1439\n",
      "epoch 23 loss: 0.1120\n",
      "epoch 24 loss: 0.1234\n",
      "epoch 25 loss: 0.1639\n",
      "epoch 26 loss: 0.1297\n",
      "epoch 27 loss: 0.1347\n",
      "epoch 28 loss: 0.1117\n",
      "epoch 29 loss: 0.1367\n",
      "epoch 30 loss: 0.1084\n",
      "60\n",
      "epoch 1 loss: 0.8791\n",
      "epoch 2 loss: 0.5636\n",
      "epoch 3 loss: 0.4110\n",
      "epoch 4 loss: 0.2845\n",
      "epoch 5 loss: 0.2117\n",
      "epoch 6 loss: 0.1896\n",
      "epoch 7 loss: 0.1793\n",
      "epoch 8 loss: 0.1320\n",
      "epoch 9 loss: 0.1999\n",
      "epoch 10 loss: 0.1467\n",
      "epoch 11 loss: 0.1675\n",
      "epoch 12 loss: 0.1464\n",
      "epoch 13 loss: 0.1400\n",
      "epoch 14 loss: 0.1142\n",
      "epoch 15 loss: 0.1484\n",
      "epoch 16 loss: 0.1833\n",
      "epoch 17 loss: 0.1609\n",
      "epoch 18 loss: 0.1355\n",
      "epoch 19 loss: 0.1352\n",
      "epoch 20 loss: 0.1339\n",
      "epoch 21 loss: 0.1452\n",
      "epoch 22 loss: 0.1523\n",
      "epoch 23 loss: 0.1227\n",
      "epoch 24 loss: 0.1449\n",
      "epoch 25 loss: 0.1177\n",
      "epoch 26 loss: 0.1044\n",
      "epoch 27 loss: 0.1372\n",
      "epoch 28 loss: 0.1048\n",
      "epoch 29 loss: 0.0996\n",
      "epoch 30 loss: 0.1427\n",
      "61\n",
      "epoch 1 loss: 0.7881\n",
      "epoch 2 loss: 1.0303\n",
      "epoch 3 loss: 0.5147\n",
      "epoch 4 loss: 0.3142\n",
      "epoch 5 loss: 0.2557\n",
      "epoch 6 loss: 0.2248\n",
      "epoch 7 loss: 0.2199\n",
      "epoch 8 loss: 0.2454\n",
      "epoch 9 loss: 0.1934\n",
      "epoch 10 loss: 0.1750\n",
      "epoch 11 loss: 0.1805\n",
      "epoch 12 loss: 0.1273\n",
      "epoch 13 loss: 0.1817\n",
      "epoch 14 loss: 0.1710\n",
      "epoch 15 loss: 0.1868\n",
      "epoch 16 loss: 0.1448\n",
      "epoch 17 loss: 0.1190\n",
      "epoch 18 loss: 0.1701\n",
      "epoch 19 loss: 0.1554\n",
      "epoch 20 loss: 0.1652\n",
      "epoch 21 loss: 0.1631\n",
      "epoch 22 loss: 0.1890\n",
      "epoch 23 loss: 0.1962\n",
      "epoch 24 loss: 0.1933\n",
      "epoch 25 loss: 0.1949\n",
      "epoch 26 loss: 0.1528\n",
      "epoch 27 loss: 0.1552\n",
      "epoch 28 loss: 0.1549\n",
      "epoch 29 loss: 0.1568\n",
      "epoch 30 loss: 0.1197\n",
      "62\n",
      "epoch 1 loss: 0.9793\n",
      "epoch 2 loss: 0.6318\n",
      "epoch 3 loss: 0.6107\n",
      "epoch 4 loss: 0.4718\n",
      "epoch 5 loss: 0.3121\n",
      "epoch 6 loss: 0.1953\n",
      "epoch 7 loss: 0.1984\n",
      "epoch 8 loss: 0.1752\n",
      "epoch 9 loss: 0.1661\n",
      "epoch 10 loss: 0.1606\n",
      "epoch 11 loss: 0.1294\n",
      "epoch 12 loss: 0.1561\n",
      "epoch 13 loss: 0.1542\n",
      "epoch 14 loss: 0.1743\n",
      "epoch 15 loss: 0.1244\n",
      "epoch 16 loss: 0.1609\n",
      "epoch 17 loss: 0.1539\n",
      "epoch 18 loss: 0.1883\n",
      "epoch 19 loss: 0.1555\n",
      "epoch 20 loss: 0.1777\n",
      "epoch 21 loss: 0.1524\n",
      "epoch 22 loss: 0.1480\n",
      "epoch 23 loss: 0.1996\n",
      "epoch 24 loss: 0.1345\n",
      "epoch 25 loss: 0.1596\n",
      "epoch 26 loss: 0.1189\n",
      "epoch 27 loss: 0.1043\n",
      "epoch 28 loss: 0.1175\n",
      "epoch 29 loss: 0.1455\n",
      "epoch 30 loss: 0.1456\n",
      "63\n",
      "epoch 1 loss: 0.7555\n",
      "epoch 2 loss: 0.6286\n",
      "epoch 3 loss: 0.5507\n",
      "epoch 4 loss: 0.3614\n",
      "epoch 5 loss: 0.4603\n",
      "epoch 6 loss: 0.4884\n",
      "epoch 7 loss: 0.4324\n",
      "epoch 8 loss: 0.2428\n",
      "epoch 9 loss: 0.2081\n",
      "epoch 10 loss: 0.1622\n",
      "epoch 11 loss: 0.1564\n",
      "epoch 12 loss: 0.1895\n",
      "epoch 13 loss: 0.1869\n",
      "epoch 14 loss: 0.1293\n",
      "epoch 15 loss: 0.1761\n",
      "epoch 16 loss: 0.1405\n",
      "epoch 17 loss: 0.1537\n",
      "epoch 18 loss: 0.1449\n",
      "epoch 19 loss: 0.1534\n",
      "epoch 20 loss: 0.1375\n",
      "epoch 21 loss: 0.1221\n",
      "epoch 22 loss: 0.1545\n",
      "epoch 23 loss: 0.1336\n",
      "epoch 24 loss: 0.1457\n",
      "epoch 25 loss: 0.1861\n",
      "epoch 26 loss: 0.1449\n",
      "epoch 27 loss: 0.1787\n",
      "epoch 28 loss: 0.0998\n",
      "epoch 29 loss: 0.0966\n",
      "epoch 30 loss: 0.1196\n",
      "64\n",
      "epoch 1 loss: 1.1509\n",
      "epoch 2 loss: 0.4347\n",
      "epoch 3 loss: 0.4094\n",
      "epoch 4 loss: 0.2474\n",
      "epoch 5 loss: 0.1629\n",
      "epoch 6 loss: 0.1672\n",
      "epoch 7 loss: 0.1436\n",
      "epoch 8 loss: 0.1770\n",
      "epoch 9 loss: 0.1313\n",
      "epoch 10 loss: 0.1622\n",
      "epoch 11 loss: 0.1757\n",
      "epoch 12 loss: 0.1903\n",
      "epoch 13 loss: 0.1386\n",
      "epoch 14 loss: 0.1551\n",
      "epoch 15 loss: 0.1344\n",
      "epoch 16 loss: 0.1175\n",
      "epoch 17 loss: 0.1549\n",
      "epoch 18 loss: 0.1686\n",
      "epoch 19 loss: 0.1302\n",
      "epoch 20 loss: 0.1188\n",
      "epoch 21 loss: 0.1417\n",
      "epoch 22 loss: 0.1191\n",
      "epoch 23 loss: 0.1094\n",
      "epoch 24 loss: 0.1199\n",
      "epoch 25 loss: 0.1114\n",
      "epoch 26 loss: 0.1314\n",
      "epoch 27 loss: 0.1002\n",
      "epoch 28 loss: 0.1097\n",
      "epoch 29 loss: 0.1141\n",
      "epoch 30 loss: 0.1019\n",
      "65\n",
      "epoch 1 loss: 0.9424\n",
      "epoch 2 loss: 0.7772\n",
      "epoch 3 loss: 0.6138\n",
      "epoch 4 loss: 0.6048\n",
      "epoch 5 loss: 0.4771\n",
      "epoch 6 loss: 0.2939\n",
      "epoch 7 loss: 0.2148\n",
      "epoch 8 loss: 0.1708\n",
      "epoch 9 loss: 0.1876\n",
      "epoch 10 loss: 0.1635\n",
      "epoch 11 loss: 0.1338\n",
      "epoch 12 loss: 0.1626\n",
      "epoch 13 loss: 0.1793\n",
      "epoch 14 loss: 0.1545\n",
      "epoch 15 loss: 0.1175\n",
      "epoch 16 loss: 0.1790\n",
      "epoch 17 loss: 0.1355\n",
      "epoch 18 loss: 0.1583\n",
      "epoch 19 loss: 0.1268\n",
      "epoch 20 loss: 0.1336\n",
      "epoch 21 loss: 0.1554\n",
      "epoch 22 loss: 0.1155\n",
      "epoch 23 loss: 0.1215\n",
      "epoch 24 loss: 0.1670\n",
      "epoch 25 loss: 0.1126\n",
      "epoch 26 loss: 0.1814\n",
      "epoch 27 loss: 0.1375\n",
      "epoch 28 loss: 0.1333\n",
      "epoch 29 loss: 0.1569\n",
      "epoch 30 loss: 0.1325\n",
      "66\n",
      "epoch 1 loss: 0.7462\n",
      "epoch 2 loss: 0.7012\n",
      "epoch 3 loss: 0.4985\n",
      "epoch 4 loss: 0.3316\n",
      "epoch 5 loss: 0.2466\n",
      "epoch 6 loss: 0.1782\n",
      "epoch 7 loss: 0.1608\n",
      "epoch 8 loss: 0.1552\n",
      "epoch 9 loss: 0.1676\n",
      "epoch 10 loss: 0.1992\n",
      "epoch 11 loss: 0.1313\n",
      "epoch 12 loss: 0.1506\n",
      "epoch 13 loss: 0.1581\n",
      "epoch 14 loss: 0.1629\n",
      "epoch 15 loss: 0.1614\n",
      "epoch 16 loss: 0.1611\n",
      "epoch 17 loss: 0.1468\n",
      "epoch 18 loss: 0.1223\n",
      "epoch 19 loss: 0.1241\n",
      "epoch 20 loss: 0.1378\n",
      "epoch 21 loss: 0.1293\n",
      "epoch 22 loss: 0.1236\n",
      "epoch 23 loss: 0.1062\n",
      "epoch 24 loss: 0.1276\n",
      "epoch 25 loss: 0.1857\n",
      "epoch 26 loss: 0.1235\n",
      "epoch 27 loss: 0.1170\n",
      "epoch 28 loss: 0.1821\n",
      "epoch 29 loss: 0.1021\n",
      "epoch 30 loss: 0.1022\n",
      "67\n",
      "epoch 1 loss: 0.8236\n",
      "epoch 2 loss: 0.6294\n",
      "epoch 3 loss: 0.3814\n",
      "epoch 4 loss: 0.4000\n",
      "epoch 5 loss: 0.2283\n",
      "epoch 6 loss: 0.1888\n",
      "epoch 7 loss: 0.1801\n",
      "epoch 8 loss: 0.1580\n",
      "epoch 9 loss: 0.1499\n",
      "epoch 10 loss: 0.1507\n",
      "epoch 11 loss: 0.1901\n",
      "epoch 12 loss: 0.1530\n",
      "epoch 13 loss: 0.1773\n",
      "epoch 14 loss: 0.1383\n",
      "epoch 15 loss: 0.1382\n",
      "epoch 16 loss: 0.1737\n",
      "epoch 17 loss: 0.1377\n",
      "epoch 18 loss: 0.1686\n",
      "epoch 19 loss: 0.1139\n",
      "epoch 20 loss: 0.1607\n",
      "epoch 21 loss: 0.1703\n",
      "epoch 22 loss: 0.1313\n",
      "epoch 23 loss: 0.1293\n",
      "epoch 24 loss: 0.1343\n",
      "epoch 25 loss: 0.1452\n",
      "epoch 26 loss: 0.1471\n",
      "epoch 27 loss: 0.1290\n",
      "epoch 28 loss: 0.0978\n",
      "epoch 29 loss: 0.1024\n",
      "epoch 30 loss: 0.1153\n",
      "68\n",
      "epoch 1 loss: 0.9360\n",
      "epoch 2 loss: 0.7058\n",
      "epoch 3 loss: 0.5703\n",
      "epoch 4 loss: 0.3423\n",
      "epoch 5 loss: 0.2164\n",
      "epoch 6 loss: 0.2154\n",
      "epoch 7 loss: 0.1775\n",
      "epoch 8 loss: 0.1871\n",
      "epoch 9 loss: 0.1546\n",
      "epoch 10 loss: 0.1646\n",
      "epoch 11 loss: 0.1704\n",
      "epoch 12 loss: 0.1804\n",
      "epoch 13 loss: 0.1658\n",
      "epoch 14 loss: 0.1627\n",
      "epoch 15 loss: 0.1405\n",
      "epoch 16 loss: 0.1816\n",
      "epoch 17 loss: 0.1198\n",
      "epoch 18 loss: 0.1696\n",
      "epoch 19 loss: 0.1892\n",
      "epoch 20 loss: 0.1229\n",
      "epoch 21 loss: 0.1420\n",
      "epoch 22 loss: 0.1683\n",
      "epoch 23 loss: 0.1841\n",
      "epoch 24 loss: 0.1587\n",
      "epoch 25 loss: 0.1831\n",
      "epoch 26 loss: 0.1290\n",
      "epoch 27 loss: 0.1326\n",
      "epoch 28 loss: 0.1115\n",
      "epoch 29 loss: 0.1340\n",
      "epoch 30 loss: 0.1437\n",
      "69\n",
      "epoch 1 loss: 0.9474\n",
      "epoch 2 loss: 0.6688\n",
      "epoch 3 loss: 0.5078\n",
      "epoch 4 loss: 0.4429\n",
      "epoch 5 loss: 0.3775\n",
      "epoch 6 loss: 0.2212\n",
      "epoch 7 loss: 0.2357\n",
      "epoch 8 loss: 0.1778\n",
      "epoch 9 loss: 0.2049\n",
      "epoch 10 loss: 0.1368\n",
      "epoch 11 loss: 0.1879\n",
      "epoch 12 loss: 0.1356\n",
      "epoch 13 loss: 0.1542\n",
      "epoch 14 loss: 0.1622\n",
      "epoch 15 loss: 0.1765\n",
      "epoch 16 loss: 0.1798\n",
      "epoch 17 loss: 0.1683\n",
      "epoch 18 loss: 0.1619\n",
      "epoch 19 loss: 0.1493\n",
      "epoch 20 loss: 0.1234\n",
      "epoch 21 loss: 0.1667\n",
      "epoch 22 loss: 0.1540\n",
      "epoch 23 loss: 0.1281\n",
      "epoch 24 loss: 0.1328\n",
      "epoch 25 loss: 0.1586\n",
      "epoch 26 loss: 0.1156\n",
      "epoch 27 loss: 0.1616\n",
      "epoch 28 loss: 0.2390\n",
      "epoch 29 loss: 0.1977\n",
      "epoch 30 loss: 0.1239\n",
      "70\n",
      "epoch 1 loss: 1.0320\n",
      "epoch 2 loss: 0.7207\n",
      "epoch 3 loss: 0.5202\n",
      "epoch 4 loss: 0.3628\n",
      "epoch 5 loss: 0.3141\n",
      "epoch 6 loss: 0.1737\n",
      "epoch 7 loss: 0.1894\n",
      "epoch 8 loss: 0.1536\n",
      "epoch 9 loss: 0.1516\n",
      "epoch 10 loss: 0.1674\n",
      "epoch 11 loss: 0.1411\n",
      "epoch 12 loss: 0.1554\n",
      "epoch 13 loss: 0.1868\n",
      "epoch 14 loss: 0.1715\n",
      "epoch 15 loss: 0.1449\n",
      "epoch 16 loss: 0.1502\n",
      "epoch 17 loss: 0.2046\n",
      "epoch 18 loss: 0.1614\n",
      "epoch 19 loss: 0.1572\n",
      "epoch 20 loss: 0.1382\n",
      "epoch 21 loss: 0.1525\n",
      "epoch 22 loss: 0.1688\n",
      "epoch 23 loss: 0.1557\n",
      "epoch 24 loss: 0.1557\n",
      "epoch 25 loss: 0.1078\n",
      "epoch 26 loss: 0.1603\n",
      "epoch 27 loss: 0.1587\n",
      "epoch 28 loss: 0.1162\n",
      "epoch 29 loss: 0.1668\n",
      "epoch 30 loss: 0.1282\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b0226858dbc63265"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T23:00:16.813174Z",
     "start_time": "2025-10-10T21:53:04.352816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=6, K_yearly=10)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly + fourier_conf.K_yearly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "\n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4,\n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_kw3_km6_ky10_matrix.csv', index=False)"
   ],
   "id": "93729619fb65c27d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zero/Desktop/Downscaling/work_summary_9_26/model_summary.py:1149: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"epoch {ep+1} loss: {float(loss):.4f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6757\n",
      "epoch 2 loss: 0.4850\n",
      "epoch 3 loss: 0.3936\n",
      "epoch 4 loss: 0.3030\n",
      "epoch 5 loss: 0.1951\n",
      "epoch 6 loss: 0.0863\n",
      "epoch 7 loss: 0.0612\n",
      "epoch 8 loss: 0.0564\n",
      "epoch 9 loss: 0.0531\n",
      "epoch 10 loss: 0.0482\n",
      "epoch 11 loss: 0.0427\n",
      "epoch 12 loss: 0.0383\n",
      "epoch 13 loss: 0.0404\n",
      "epoch 14 loss: 0.0404\n",
      "epoch 15 loss: 0.0415\n",
      "epoch 16 loss: 0.0347\n",
      "epoch 17 loss: 0.0378\n",
      "epoch 18 loss: 0.0369\n",
      "epoch 19 loss: 0.0382\n",
      "epoch 20 loss: 0.0322\n",
      "epoch 21 loss: 0.0367\n",
      "epoch 22 loss: 0.0353\n",
      "epoch 23 loss: 0.0301\n",
      "epoch 24 loss: 0.0319\n",
      "epoch 25 loss: 0.0314\n",
      "epoch 26 loss: 0.0318\n",
      "epoch 27 loss: 0.0348\n",
      "epoch 28 loss: 0.0365\n",
      "epoch 29 loss: 0.0353\n",
      "epoch 30 loss: 0.0329\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_37583/3620390467.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7547\n",
      "epoch 2 loss: 0.4642\n",
      "epoch 3 loss: 0.4170\n",
      "epoch 4 loss: 0.2462\n",
      "epoch 5 loss: 0.1129\n",
      "epoch 6 loss: 0.1008\n",
      "epoch 7 loss: 0.0744\n",
      "epoch 8 loss: 0.0710\n",
      "epoch 9 loss: 0.0698\n",
      "epoch 10 loss: 0.0558\n",
      "epoch 11 loss: 0.0656\n",
      "epoch 12 loss: 0.0619\n",
      "epoch 13 loss: 0.0538\n",
      "epoch 14 loss: 0.0502\n",
      "epoch 15 loss: 0.0492\n",
      "epoch 16 loss: 0.0502\n",
      "epoch 17 loss: 0.0499\n",
      "epoch 18 loss: 0.0453\n",
      "epoch 19 loss: 0.0433\n",
      "epoch 20 loss: 0.0397\n",
      "epoch 21 loss: 0.0386\n",
      "epoch 22 loss: 0.0412\n",
      "epoch 23 loss: 0.0397\n",
      "epoch 24 loss: 0.0369\n",
      "epoch 25 loss: 0.0389\n",
      "epoch 26 loss: 0.0368\n",
      "epoch 27 loss: 0.0355\n",
      "epoch 28 loss: 0.0440\n",
      "epoch 29 loss: 0.0371\n",
      "epoch 30 loss: 0.0341\n",
      "3\n",
      "epoch 1 loss: 0.6845\n",
      "epoch 2 loss: 0.5237\n",
      "epoch 3 loss: 0.5536\n",
      "epoch 4 loss: 0.4998\n",
      "epoch 5 loss: 0.3953\n",
      "epoch 6 loss: 0.1984\n",
      "epoch 7 loss: 0.0908\n",
      "epoch 8 loss: 0.0675\n",
      "epoch 9 loss: 0.0576\n",
      "epoch 10 loss: 0.0507\n",
      "epoch 11 loss: 0.0595\n",
      "epoch 12 loss: 0.0564\n",
      "epoch 13 loss: 0.0448\n",
      "epoch 14 loss: 0.0428\n",
      "epoch 15 loss: 0.0486\n",
      "epoch 16 loss: 0.0491\n",
      "epoch 17 loss: 0.0374\n",
      "epoch 18 loss: 0.0370\n",
      "epoch 19 loss: 0.0421\n",
      "epoch 20 loss: 0.0335\n",
      "epoch 21 loss: 0.0349\n",
      "epoch 22 loss: 0.0330\n",
      "epoch 23 loss: 0.0382\n",
      "epoch 24 loss: 0.0344\n",
      "epoch 25 loss: 0.0349\n",
      "epoch 26 loss: 0.0365\n",
      "epoch 27 loss: 0.0342\n",
      "epoch 28 loss: 0.0339\n",
      "epoch 29 loss: 0.0327\n",
      "epoch 30 loss: 0.0342\n",
      "4\n",
      "epoch 1 loss: 0.9414\n",
      "epoch 2 loss: 0.4717\n",
      "epoch 3 loss: 0.4160\n",
      "epoch 4 loss: 0.3823\n",
      "epoch 5 loss: 0.3597\n",
      "epoch 6 loss: 0.1659\n",
      "epoch 7 loss: 0.0842\n",
      "epoch 8 loss: 0.0623\n",
      "epoch 9 loss: 0.0543\n",
      "epoch 10 loss: 0.0514\n",
      "epoch 11 loss: 0.0490\n",
      "epoch 12 loss: 0.0468\n",
      "epoch 13 loss: 0.0468\n",
      "epoch 14 loss: 0.0480\n",
      "epoch 15 loss: 0.0417\n",
      "epoch 16 loss: 0.0425\n",
      "epoch 17 loss: 0.0377\n",
      "epoch 18 loss: 0.0458\n",
      "epoch 19 loss: 0.0358\n",
      "epoch 20 loss: 0.0327\n",
      "epoch 21 loss: 0.0457\n",
      "epoch 22 loss: 0.0384\n",
      "epoch 23 loss: 0.0387\n",
      "epoch 24 loss: 0.0364\n",
      "epoch 25 loss: 0.0367\n",
      "epoch 26 loss: 0.0328\n",
      "epoch 27 loss: 0.0360\n",
      "epoch 28 loss: 0.0372\n",
      "epoch 29 loss: 0.0358\n",
      "epoch 30 loss: 0.0311\n",
      "5\n",
      "epoch 1 loss: 0.7992\n",
      "epoch 2 loss: 0.6748\n",
      "epoch 3 loss: 0.4678\n",
      "epoch 4 loss: 0.5398\n",
      "epoch 5 loss: 0.3749\n",
      "epoch 6 loss: 0.2392\n",
      "epoch 7 loss: 0.1129\n",
      "epoch 8 loss: 0.0836\n",
      "epoch 9 loss: 0.0779\n",
      "epoch 10 loss: 0.0617\n",
      "epoch 11 loss: 0.0847\n",
      "epoch 12 loss: 0.0584\n",
      "epoch 13 loss: 0.0559\n",
      "epoch 14 loss: 0.0633\n",
      "epoch 15 loss: 0.0509\n",
      "epoch 16 loss: 0.0504\n",
      "epoch 17 loss: 0.0530\n",
      "epoch 18 loss: 0.0535\n",
      "epoch 19 loss: 0.0439\n",
      "epoch 20 loss: 0.0515\n",
      "epoch 21 loss: 0.0576\n",
      "epoch 22 loss: 0.0403\n",
      "epoch 23 loss: 0.0522\n",
      "epoch 24 loss: 0.0493\n",
      "epoch 25 loss: 0.0489\n",
      "epoch 26 loss: 0.0526\n",
      "epoch 27 loss: 0.0445\n",
      "epoch 28 loss: 0.0446\n",
      "epoch 29 loss: 0.0459\n",
      "epoch 30 loss: 0.0423\n",
      "6\n",
      "epoch 1 loss: 0.8293\n",
      "epoch 2 loss: 0.5318\n",
      "epoch 3 loss: 0.2830\n",
      "epoch 4 loss: 0.1731\n",
      "epoch 5 loss: 0.1919\n",
      "epoch 6 loss: 0.1290\n",
      "epoch 7 loss: 0.0891\n",
      "epoch 8 loss: 0.0874\n",
      "epoch 9 loss: 0.0810\n",
      "epoch 10 loss: 0.0648\n",
      "epoch 11 loss: 0.0653\n",
      "epoch 12 loss: 0.0560\n",
      "epoch 13 loss: 0.0515\n",
      "epoch 14 loss: 0.0552\n",
      "epoch 15 loss: 0.0517\n",
      "epoch 16 loss: 0.0459\n",
      "epoch 17 loss: 0.0428\n",
      "epoch 18 loss: 0.0461\n",
      "epoch 19 loss: 0.0472\n",
      "epoch 20 loss: 0.0477\n",
      "epoch 21 loss: 0.0344\n",
      "epoch 22 loss: 0.0459\n",
      "epoch 23 loss: 0.0438\n",
      "epoch 24 loss: 0.0435\n",
      "epoch 25 loss: 0.0410\n",
      "epoch 26 loss: 0.0436\n",
      "epoch 27 loss: 0.0381\n",
      "epoch 28 loss: 0.0370\n",
      "epoch 29 loss: 0.0399\n",
      "epoch 30 loss: 0.0320\n",
      "7\n",
      "epoch 1 loss: 1.1179\n",
      "epoch 2 loss: 0.5658\n",
      "epoch 3 loss: 0.4198\n",
      "epoch 4 loss: 0.4304\n",
      "epoch 5 loss: 0.2577\n",
      "epoch 6 loss: 0.1500\n",
      "epoch 7 loss: 0.1295\n",
      "epoch 8 loss: 0.0976\n",
      "epoch 9 loss: 0.0783\n",
      "epoch 10 loss: 0.0704\n",
      "epoch 11 loss: 0.0741\n",
      "epoch 12 loss: 0.0673\n",
      "epoch 13 loss: 0.0586\n",
      "epoch 14 loss: 0.0570\n",
      "epoch 15 loss: 0.0554\n",
      "epoch 16 loss: 0.0583\n",
      "epoch 17 loss: 0.0437\n",
      "epoch 18 loss: 0.0430\n",
      "epoch 19 loss: 0.0441\n",
      "epoch 20 loss: 0.0425\n",
      "epoch 21 loss: 0.0473\n",
      "epoch 22 loss: 0.0413\n",
      "epoch 23 loss: 0.0466\n",
      "epoch 24 loss: 0.0458\n",
      "epoch 25 loss: 0.0505\n",
      "epoch 26 loss: 0.0443\n",
      "epoch 27 loss: 0.0423\n",
      "epoch 28 loss: 0.0454\n",
      "epoch 29 loss: 0.0395\n",
      "epoch 30 loss: 0.0358\n",
      "8\n",
      "epoch 1 loss: 0.6823\n",
      "epoch 2 loss: 0.6404\n",
      "epoch 3 loss: 0.5275\n",
      "epoch 4 loss: 0.5460\n",
      "epoch 5 loss: 0.3611\n",
      "epoch 6 loss: 0.1895\n",
      "epoch 7 loss: 0.1175\n",
      "epoch 8 loss: 0.0772\n",
      "epoch 9 loss: 0.0635\n",
      "epoch 10 loss: 0.0672\n",
      "epoch 11 loss: 0.0623\n",
      "epoch 12 loss: 0.0580\n",
      "epoch 13 loss: 0.0532\n",
      "epoch 14 loss: 0.0510\n",
      "epoch 15 loss: 0.0470\n",
      "epoch 16 loss: 0.0464\n",
      "epoch 17 loss: 0.0486\n",
      "epoch 18 loss: 0.0525\n",
      "epoch 19 loss: 0.0488\n",
      "epoch 20 loss: 0.0479\n",
      "epoch 21 loss: 0.0432\n",
      "epoch 22 loss: 0.0420\n",
      "epoch 23 loss: 0.0389\n",
      "epoch 24 loss: 0.0432\n",
      "epoch 25 loss: 0.0407\n",
      "epoch 26 loss: 0.0362\n",
      "epoch 27 loss: 0.0389\n",
      "epoch 28 loss: 0.0304\n",
      "epoch 29 loss: 0.0393\n",
      "epoch 30 loss: 0.0329\n",
      "9\n",
      "epoch 1 loss: 0.8775\n",
      "epoch 2 loss: 0.7407\n",
      "epoch 3 loss: 0.6183\n",
      "epoch 4 loss: 0.3993\n",
      "epoch 5 loss: 0.2456\n",
      "epoch 6 loss: 0.1121\n",
      "epoch 7 loss: 0.0828\n",
      "epoch 8 loss: 0.0747\n",
      "epoch 9 loss: 0.0660\n",
      "epoch 10 loss: 0.0530\n",
      "epoch 11 loss: 0.0516\n",
      "epoch 12 loss: 0.0491\n",
      "epoch 13 loss: 0.0433\n",
      "epoch 14 loss: 0.0440\n",
      "epoch 15 loss: 0.0449\n",
      "epoch 16 loss: 0.0400\n",
      "epoch 17 loss: 0.0382\n",
      "epoch 18 loss: 0.0375\n",
      "epoch 19 loss: 0.0372\n",
      "epoch 20 loss: 0.0354\n",
      "epoch 21 loss: 0.0384\n",
      "epoch 22 loss: 0.0378\n",
      "epoch 23 loss: 0.0347\n",
      "epoch 24 loss: 0.0392\n",
      "epoch 25 loss: 0.0327\n",
      "epoch 26 loss: 0.0338\n",
      "epoch 27 loss: 0.0371\n",
      "epoch 28 loss: 0.0380\n",
      "epoch 29 loss: 0.0337\n",
      "epoch 30 loss: 0.0292\n",
      "10\n",
      "epoch 1 loss: 0.7588\n",
      "epoch 2 loss: 0.5822\n",
      "epoch 3 loss: 0.4776\n",
      "epoch 4 loss: 0.4518\n",
      "epoch 5 loss: 0.3430\n",
      "epoch 6 loss: 0.1770\n",
      "epoch 7 loss: 0.0917\n",
      "epoch 8 loss: 0.0618\n",
      "epoch 9 loss: 0.0535\n",
      "epoch 10 loss: 0.0450\n",
      "epoch 11 loss: 0.0386\n",
      "epoch 12 loss: 0.0443\n",
      "epoch 13 loss: 0.0378\n",
      "epoch 14 loss: 0.0422\n",
      "epoch 15 loss: 0.0444\n",
      "epoch 16 loss: 0.0373\n",
      "epoch 17 loss: 0.0371\n",
      "epoch 18 loss: 0.0343\n",
      "epoch 19 loss: 0.0371\n",
      "epoch 20 loss: 0.0327\n",
      "epoch 21 loss: 0.0368\n",
      "epoch 22 loss: 0.0390\n",
      "epoch 23 loss: 0.0326\n",
      "epoch 24 loss: 0.0334\n",
      "epoch 25 loss: 0.0326\n",
      "epoch 26 loss: 0.0295\n",
      "epoch 27 loss: 0.0319\n",
      "epoch 28 loss: 0.0343\n",
      "epoch 29 loss: 0.0332\n",
      "epoch 30 loss: 0.0321\n",
      "11\n",
      "epoch 1 loss: 0.6734\n",
      "epoch 2 loss: 0.4866\n",
      "epoch 3 loss: 0.3182\n",
      "epoch 4 loss: 0.2265\n",
      "epoch 5 loss: 0.1272\n",
      "epoch 6 loss: 0.0889\n",
      "epoch 7 loss: 0.0722\n",
      "epoch 8 loss: 0.0614\n",
      "epoch 9 loss: 0.0646\n",
      "epoch 10 loss: 0.0672\n",
      "epoch 11 loss: 0.0492\n",
      "epoch 12 loss: 0.0438\n",
      "epoch 13 loss: 0.0442\n",
      "epoch 14 loss: 0.0423\n",
      "epoch 15 loss: 0.0459\n",
      "epoch 16 loss: 0.0448\n",
      "epoch 17 loss: 0.0424\n",
      "epoch 18 loss: 0.0453\n",
      "epoch 19 loss: 0.0404\n",
      "epoch 20 loss: 0.0375\n",
      "epoch 21 loss: 0.0363\n",
      "epoch 22 loss: 0.0340\n",
      "epoch 23 loss: 0.0393\n",
      "epoch 24 loss: 0.0348\n",
      "epoch 25 loss: 0.0365\n",
      "epoch 26 loss: 0.0326\n",
      "epoch 27 loss: 0.0320\n",
      "epoch 28 loss: 0.0391\n",
      "epoch 29 loss: 0.0318\n",
      "epoch 30 loss: 0.0345\n",
      "12\n",
      "epoch 1 loss: 0.8565\n",
      "epoch 2 loss: 0.6346\n",
      "epoch 3 loss: 0.4493\n",
      "epoch 4 loss: 0.3768\n",
      "epoch 5 loss: 0.2171\n",
      "epoch 6 loss: 0.1719\n",
      "epoch 7 loss: 0.1271\n",
      "epoch 8 loss: 0.0909\n",
      "epoch 9 loss: 0.0671\n",
      "epoch 10 loss: 0.0674\n",
      "epoch 11 loss: 0.0682\n",
      "epoch 12 loss: 0.0484\n",
      "epoch 13 loss: 0.0562\n",
      "epoch 14 loss: 0.0571\n",
      "epoch 15 loss: 0.0486\n",
      "epoch 16 loss: 0.0492\n",
      "epoch 17 loss: 0.0397\n",
      "epoch 18 loss: 0.0476\n",
      "epoch 19 loss: 0.0433\n",
      "epoch 20 loss: 0.0454\n",
      "epoch 21 loss: 0.0455\n",
      "epoch 22 loss: 0.0401\n",
      "epoch 23 loss: 0.0403\n",
      "epoch 24 loss: 0.0406\n",
      "epoch 25 loss: 0.0348\n",
      "epoch 26 loss: 0.0372\n",
      "epoch 27 loss: 0.0365\n",
      "epoch 28 loss: 0.0337\n",
      "epoch 29 loss: 0.0405\n",
      "epoch 30 loss: 0.0391\n",
      "13\n",
      "epoch 1 loss: 0.8972\n",
      "epoch 2 loss: 0.5821\n",
      "epoch 3 loss: 0.4187\n",
      "epoch 4 loss: 0.3201\n",
      "epoch 5 loss: 0.2330\n",
      "epoch 6 loss: 0.1233\n",
      "epoch 7 loss: 0.0687\n",
      "epoch 8 loss: 0.0603\n",
      "epoch 9 loss: 0.0583\n",
      "epoch 10 loss: 0.0501\n",
      "epoch 11 loss: 0.0469\n",
      "epoch 12 loss: 0.0475\n",
      "epoch 13 loss: 0.0423\n",
      "epoch 14 loss: 0.0363\n",
      "epoch 15 loss: 0.0397\n",
      "epoch 16 loss: 0.0353\n",
      "epoch 17 loss: 0.0355\n",
      "epoch 18 loss: 0.0384\n",
      "epoch 19 loss: 0.0333\n",
      "epoch 20 loss: 0.0323\n",
      "epoch 21 loss: 0.0314\n",
      "epoch 22 loss: 0.0359\n",
      "epoch 23 loss: 0.0323\n",
      "epoch 24 loss: 0.0360\n",
      "epoch 25 loss: 0.0322\n",
      "epoch 26 loss: 0.0337\n",
      "epoch 27 loss: 0.0334\n",
      "epoch 28 loss: 0.0330\n",
      "epoch 29 loss: 0.0309\n",
      "epoch 30 loss: 0.0346\n",
      "14\n",
      "epoch 1 loss: 0.7315\n",
      "epoch 2 loss: 0.6160\n",
      "epoch 3 loss: 0.4837\n",
      "epoch 4 loss: 0.6015\n",
      "epoch 5 loss: 0.3817\n",
      "epoch 6 loss: 0.3026\n",
      "epoch 7 loss: 0.1352\n",
      "epoch 8 loss: 0.1006\n",
      "epoch 9 loss: 0.0756\n",
      "epoch 10 loss: 0.0552\n",
      "epoch 11 loss: 0.0489\n",
      "epoch 12 loss: 0.0487\n",
      "epoch 13 loss: 0.0506\n",
      "epoch 14 loss: 0.0397\n",
      "epoch 15 loss: 0.0464\n",
      "epoch 16 loss: 0.0376\n",
      "epoch 17 loss: 0.0414\n",
      "epoch 18 loss: 0.0435\n",
      "epoch 19 loss: 0.0377\n",
      "epoch 20 loss: 0.0386\n",
      "epoch 21 loss: 0.0370\n",
      "epoch 22 loss: 0.0431\n",
      "epoch 23 loss: 0.0385\n",
      "epoch 24 loss: 0.0355\n",
      "epoch 25 loss: 0.0339\n",
      "epoch 26 loss: 0.0381\n",
      "epoch 27 loss: 0.0349\n",
      "epoch 28 loss: 0.0379\n",
      "epoch 29 loss: 0.0370\n",
      "epoch 30 loss: 0.0332\n",
      "15\n",
      "epoch 1 loss: 0.7703\n",
      "epoch 2 loss: 0.5203\n",
      "epoch 3 loss: 0.4647\n",
      "epoch 4 loss: 0.3001\n",
      "epoch 5 loss: 0.2004\n",
      "epoch 6 loss: 0.0839\n",
      "epoch 7 loss: 0.0667\n",
      "epoch 8 loss: 0.0551\n",
      "epoch 9 loss: 0.0560\n",
      "epoch 10 loss: 0.0421\n",
      "epoch 11 loss: 0.0468\n",
      "epoch 12 loss: 0.0446\n",
      "epoch 13 loss: 0.0451\n",
      "epoch 14 loss: 0.0412\n",
      "epoch 15 loss: 0.0414\n",
      "epoch 16 loss: 0.0363\n",
      "epoch 17 loss: 0.0388\n",
      "epoch 18 loss: 0.0400\n",
      "epoch 19 loss: 0.0360\n",
      "epoch 20 loss: 0.0332\n",
      "epoch 21 loss: 0.0399\n",
      "epoch 22 loss: 0.0357\n",
      "epoch 23 loss: 0.0333\n",
      "epoch 24 loss: 0.0297\n",
      "epoch 25 loss: 0.0316\n",
      "epoch 26 loss: 0.0337\n",
      "epoch 27 loss: 0.0299\n",
      "epoch 28 loss: 0.0319\n",
      "epoch 29 loss: 0.0328\n",
      "epoch 30 loss: 0.0331\n",
      "16\n",
      "epoch 1 loss: 0.7418\n",
      "epoch 2 loss: 0.6410\n",
      "epoch 3 loss: 0.6143\n",
      "epoch 4 loss: 0.4234\n",
      "epoch 5 loss: 0.5852\n",
      "epoch 6 loss: 0.5149\n",
      "epoch 7 loss: 0.4233\n",
      "epoch 8 loss: 0.2111\n",
      "epoch 9 loss: 0.0965\n",
      "epoch 10 loss: 0.0635\n",
      "epoch 11 loss: 0.0696\n",
      "epoch 12 loss: 0.0500\n",
      "epoch 13 loss: 0.0584\n",
      "epoch 14 loss: 0.0461\n",
      "epoch 15 loss: 0.0428\n",
      "epoch 16 loss: 0.0511\n",
      "epoch 17 loss: 0.0462\n",
      "epoch 18 loss: 0.0427\n",
      "epoch 19 loss: 0.0422\n",
      "epoch 20 loss: 0.0424\n",
      "epoch 21 loss: 0.0396\n",
      "epoch 22 loss: 0.0441\n",
      "epoch 23 loss: 0.0459\n",
      "epoch 24 loss: 0.0371\n",
      "epoch 25 loss: 0.0407\n",
      "epoch 26 loss: 0.0404\n",
      "epoch 27 loss: 0.0335\n",
      "epoch 28 loss: 0.0423\n",
      "epoch 29 loss: 0.0344\n",
      "epoch 30 loss: 0.0389\n",
      "17\n",
      "epoch 1 loss: 0.9210\n",
      "epoch 2 loss: 0.6982\n",
      "epoch 3 loss: 0.4306\n",
      "epoch 4 loss: 0.4645\n",
      "epoch 5 loss: 0.3194\n",
      "epoch 6 loss: 0.1721\n",
      "epoch 7 loss: 0.0992\n",
      "epoch 8 loss: 0.0644\n",
      "epoch 9 loss: 0.0650\n",
      "epoch 10 loss: 0.0570\n",
      "epoch 11 loss: 0.0537\n",
      "epoch 12 loss: 0.0506\n",
      "epoch 13 loss: 0.0457\n",
      "epoch 14 loss: 0.0432\n",
      "epoch 15 loss: 0.0465\n",
      "epoch 16 loss: 0.0387\n",
      "epoch 17 loss: 0.0376\n",
      "epoch 18 loss: 0.0413\n",
      "epoch 19 loss: 0.0383\n",
      "epoch 20 loss: 0.0409\n",
      "epoch 21 loss: 0.0383\n",
      "epoch 22 loss: 0.0366\n",
      "epoch 23 loss: 0.0333\n",
      "epoch 24 loss: 0.0406\n",
      "epoch 25 loss: 0.0345\n",
      "epoch 26 loss: 0.0359\n",
      "epoch 27 loss: 0.0352\n",
      "epoch 28 loss: 0.0340\n",
      "epoch 29 loss: 0.0313\n",
      "epoch 30 loss: 0.0259\n",
      "18\n",
      "epoch 1 loss: 0.7102\n",
      "epoch 2 loss: 0.4905\n",
      "epoch 3 loss: 0.3613\n",
      "epoch 4 loss: 0.1808\n",
      "epoch 5 loss: 0.1207\n",
      "epoch 6 loss: 0.0831\n",
      "epoch 7 loss: 0.0733\n",
      "epoch 8 loss: 0.0547\n",
      "epoch 9 loss: 0.0683\n",
      "epoch 10 loss: 0.0519\n",
      "epoch 11 loss: 0.0515\n",
      "epoch 12 loss: 0.0524\n",
      "epoch 13 loss: 0.0522\n",
      "epoch 14 loss: 0.0658\n",
      "epoch 15 loss: 0.0440\n",
      "epoch 16 loss: 0.0437\n",
      "epoch 17 loss: 0.0436\n",
      "epoch 18 loss: 0.0330\n",
      "epoch 19 loss: 0.0365\n",
      "epoch 20 loss: 0.0439\n",
      "epoch 21 loss: 0.0402\n",
      "epoch 22 loss: 0.0417\n",
      "epoch 23 loss: 0.0413\n",
      "epoch 24 loss: 0.0381\n",
      "epoch 25 loss: 0.0335\n",
      "epoch 26 loss: 0.0327\n",
      "epoch 27 loss: 0.0368\n",
      "epoch 28 loss: 0.0354\n",
      "epoch 29 loss: 0.0373\n",
      "epoch 30 loss: 0.0376\n",
      "19\n",
      "epoch 1 loss: 0.9993\n",
      "epoch 2 loss: 0.5104\n",
      "epoch 3 loss: 0.4081\n",
      "epoch 4 loss: 0.3884\n",
      "epoch 5 loss: 0.2141\n",
      "epoch 6 loss: 0.1087\n",
      "epoch 7 loss: 0.0689\n",
      "epoch 8 loss: 0.0588\n",
      "epoch 9 loss: 0.0620\n",
      "epoch 10 loss: 0.0528\n",
      "epoch 11 loss: 0.0491\n",
      "epoch 12 loss: 0.0498\n",
      "epoch 13 loss: 0.0489\n",
      "epoch 14 loss: 0.0436\n",
      "epoch 15 loss: 0.0455\n",
      "epoch 16 loss: 0.0410\n",
      "epoch 17 loss: 0.0397\n",
      "epoch 18 loss: 0.0443\n",
      "epoch 19 loss: 0.0436\n",
      "epoch 20 loss: 0.0347\n",
      "epoch 21 loss: 0.0369\n",
      "epoch 22 loss: 0.0400\n",
      "epoch 23 loss: 0.0400\n",
      "epoch 24 loss: 0.0348\n",
      "epoch 25 loss: 0.0342\n",
      "epoch 26 loss: 0.0295\n",
      "epoch 27 loss: 0.0332\n",
      "epoch 28 loss: 0.0322\n",
      "epoch 29 loss: 0.0325\n",
      "epoch 30 loss: 0.0329\n",
      "20\n",
      "epoch 1 loss: 0.7064\n",
      "epoch 2 loss: 0.6180\n",
      "epoch 3 loss: 0.5062\n",
      "epoch 4 loss: 0.3056\n",
      "epoch 5 loss: 0.1585\n",
      "epoch 6 loss: 0.1152\n",
      "epoch 7 loss: 0.0782\n",
      "epoch 8 loss: 0.0608\n",
      "epoch 9 loss: 0.0529\n",
      "epoch 10 loss: 0.0476\n",
      "epoch 11 loss: 0.0449\n",
      "epoch 12 loss: 0.0412\n",
      "epoch 13 loss: 0.0387\n",
      "epoch 14 loss: 0.0415\n",
      "epoch 15 loss: 0.0374\n",
      "epoch 16 loss: 0.0347\n",
      "epoch 17 loss: 0.0405\n",
      "epoch 18 loss: 0.0346\n",
      "epoch 19 loss: 0.0357\n",
      "epoch 20 loss: 0.0278\n",
      "epoch 21 loss: 0.0332\n",
      "epoch 22 loss: 0.0371\n",
      "epoch 23 loss: 0.0303\n",
      "epoch 24 loss: 0.0333\n",
      "epoch 25 loss: 0.0311\n",
      "epoch 26 loss: 0.0326\n",
      "epoch 27 loss: 0.0314\n",
      "epoch 28 loss: 0.0321\n",
      "epoch 29 loss: 0.0273\n",
      "epoch 30 loss: 0.0303\n",
      "21\n",
      "epoch 1 loss: 0.6581\n",
      "epoch 2 loss: 0.5324\n",
      "epoch 3 loss: 0.3967\n",
      "epoch 4 loss: 0.2330\n",
      "epoch 5 loss: 0.1570\n",
      "epoch 6 loss: 0.1114\n",
      "epoch 7 loss: 0.0974\n",
      "epoch 8 loss: 0.0648\n",
      "epoch 9 loss: 0.0573\n",
      "epoch 10 loss: 0.0653\n",
      "epoch 11 loss: 0.0511\n",
      "epoch 12 loss: 0.0483\n",
      "epoch 13 loss: 0.0508\n",
      "epoch 14 loss: 0.0461\n",
      "epoch 15 loss: 0.0466\n",
      "epoch 16 loss: 0.0466\n",
      "epoch 17 loss: 0.0394\n",
      "epoch 18 loss: 0.0475\n",
      "epoch 19 loss: 0.0470\n",
      "epoch 20 loss: 0.0485\n",
      "epoch 21 loss: 0.0396\n",
      "epoch 22 loss: 0.0354\n",
      "epoch 23 loss: 0.0430\n",
      "epoch 24 loss: 0.0399\n",
      "epoch 25 loss: 0.0386\n",
      "epoch 26 loss: 0.0416\n",
      "epoch 27 loss: 0.0409\n",
      "epoch 28 loss: 0.0386\n",
      "epoch 29 loss: 0.0366\n",
      "epoch 30 loss: 0.0364\n",
      "22\n",
      "epoch 1 loss: 1.0643\n",
      "epoch 2 loss: 0.6115\n",
      "epoch 3 loss: 0.4791\n",
      "epoch 4 loss: 0.4624\n",
      "epoch 5 loss: 0.3311\n",
      "epoch 6 loss: 0.1460\n",
      "epoch 7 loss: 0.0861\n",
      "epoch 8 loss: 0.0789\n",
      "epoch 9 loss: 0.0532\n",
      "epoch 10 loss: 0.0528\n",
      "epoch 11 loss: 0.0503\n",
      "epoch 12 loss: 0.0455\n",
      "epoch 13 loss: 0.0464\n",
      "epoch 14 loss: 0.0515\n",
      "epoch 15 loss: 0.0413\n",
      "epoch 16 loss: 0.0446\n",
      "epoch 17 loss: 0.0407\n",
      "epoch 18 loss: 0.0456\n",
      "epoch 19 loss: 0.0401\n",
      "epoch 20 loss: 0.0454\n",
      "epoch 21 loss: 0.0403\n",
      "epoch 22 loss: 0.0399\n",
      "epoch 23 loss: 0.0381\n",
      "epoch 24 loss: 0.0405\n",
      "epoch 25 loss: 0.0390\n",
      "epoch 26 loss: 0.0442\n",
      "epoch 27 loss: 0.0358\n",
      "epoch 28 loss: 0.0419\n",
      "epoch 29 loss: 0.0364\n",
      "epoch 30 loss: 0.0381\n",
      "23\n",
      "epoch 1 loss: 0.6109\n",
      "epoch 2 loss: 0.6382\n",
      "epoch 3 loss: 0.5914\n",
      "epoch 4 loss: 0.3948\n",
      "epoch 5 loss: 0.2771\n",
      "epoch 6 loss: 0.1972\n",
      "epoch 7 loss: 0.1142\n",
      "epoch 8 loss: 0.0589\n",
      "epoch 9 loss: 0.0583\n",
      "epoch 10 loss: 0.0417\n",
      "epoch 11 loss: 0.0444\n",
      "epoch 12 loss: 0.0438\n",
      "epoch 13 loss: 0.0469\n",
      "epoch 14 loss: 0.0373\n",
      "epoch 15 loss: 0.0356\n",
      "epoch 16 loss: 0.0381\n",
      "epoch 17 loss: 0.0369\n",
      "epoch 18 loss: 0.0389\n",
      "epoch 19 loss: 0.0375\n",
      "epoch 20 loss: 0.0364\n",
      "epoch 21 loss: 0.0387\n",
      "epoch 22 loss: 0.0350\n",
      "epoch 23 loss: 0.0337\n",
      "epoch 24 loss: 0.0336\n",
      "epoch 25 loss: 0.0352\n",
      "epoch 26 loss: 0.0327\n",
      "epoch 27 loss: 0.0332\n",
      "epoch 28 loss: 0.0342\n",
      "epoch 29 loss: 0.0299\n",
      "epoch 30 loss: 0.0311\n",
      "24\n",
      "epoch 1 loss: 0.6396\n",
      "epoch 2 loss: 0.4539\n",
      "epoch 3 loss: 0.3155\n",
      "epoch 4 loss: 0.2354\n",
      "epoch 5 loss: 0.1370\n",
      "epoch 6 loss: 0.1013\n",
      "epoch 7 loss: 0.0757\n",
      "epoch 8 loss: 0.0654\n",
      "epoch 9 loss: 0.0593\n",
      "epoch 10 loss: 0.0596\n",
      "epoch 11 loss: 0.0553\n",
      "epoch 12 loss: 0.0544\n",
      "epoch 13 loss: 0.0499\n",
      "epoch 14 loss: 0.0518\n",
      "epoch 15 loss: 0.0407\n",
      "epoch 16 loss: 0.0407\n",
      "epoch 17 loss: 0.0424\n",
      "epoch 18 loss: 0.0423\n",
      "epoch 19 loss: 0.0403\n",
      "epoch 20 loss: 0.0450\n",
      "epoch 21 loss: 0.0389\n",
      "epoch 22 loss: 0.0371\n",
      "epoch 23 loss: 0.0358\n",
      "epoch 24 loss: 0.0323\n",
      "epoch 25 loss: 0.0335\n",
      "epoch 26 loss: 0.0323\n",
      "epoch 27 loss: 0.0346\n",
      "epoch 28 loss: 0.0330\n",
      "epoch 29 loss: 0.0317\n",
      "epoch 30 loss: 0.0330\n",
      "25\n",
      "epoch 1 loss: 0.7485\n",
      "epoch 2 loss: 0.5338\n",
      "epoch 3 loss: 0.3371\n",
      "epoch 4 loss: 0.2909\n",
      "epoch 5 loss: 0.1680\n",
      "epoch 6 loss: 0.0935\n",
      "epoch 7 loss: 0.0738\n",
      "epoch 8 loss: 0.0499\n",
      "epoch 9 loss: 0.0523\n",
      "epoch 10 loss: 0.0443\n",
      "epoch 11 loss: 0.0481\n",
      "epoch 12 loss: 0.0478\n",
      "epoch 13 loss: 0.0441\n",
      "epoch 14 loss: 0.0404\n",
      "epoch 15 loss: 0.0404\n",
      "epoch 16 loss: 0.0394\n",
      "epoch 17 loss: 0.0421\n",
      "epoch 18 loss: 0.0354\n",
      "epoch 19 loss: 0.0395\n",
      "epoch 20 loss: 0.0364\n",
      "epoch 21 loss: 0.0333\n",
      "epoch 22 loss: 0.0315\n",
      "epoch 23 loss: 0.0352\n",
      "epoch 24 loss: 0.0324\n",
      "epoch 25 loss: 0.0311\n",
      "epoch 26 loss: 0.0360\n",
      "epoch 27 loss: 0.0343\n",
      "epoch 28 loss: 0.0333\n",
      "epoch 29 loss: 0.0287\n",
      "epoch 30 loss: 0.0282\n",
      "26\n",
      "epoch 1 loss: 0.9116\n",
      "epoch 2 loss: 0.6204\n",
      "epoch 3 loss: 0.4462\n",
      "epoch 4 loss: 0.4310\n",
      "epoch 5 loss: 0.4823\n",
      "epoch 6 loss: 0.2863\n",
      "epoch 7 loss: 0.1655\n",
      "epoch 8 loss: 0.0942\n",
      "epoch 9 loss: 0.0778\n",
      "epoch 10 loss: 0.0704\n",
      "epoch 11 loss: 0.0631\n",
      "epoch 12 loss: 0.0580\n",
      "epoch 13 loss: 0.0563\n",
      "epoch 14 loss: 0.0530\n",
      "epoch 15 loss: 0.0501\n",
      "epoch 16 loss: 0.0454\n",
      "epoch 17 loss: 0.0455\n",
      "epoch 18 loss: 0.0473\n",
      "epoch 19 loss: 0.0475\n",
      "epoch 20 loss: 0.0421\n",
      "epoch 21 loss: 0.0421\n",
      "epoch 22 loss: 0.0423\n",
      "epoch 23 loss: 0.0390\n",
      "epoch 24 loss: 0.0420\n",
      "epoch 25 loss: 0.0364\n",
      "epoch 26 loss: 0.0424\n",
      "epoch 27 loss: 0.0387\n",
      "epoch 28 loss: 0.0383\n",
      "epoch 29 loss: 0.0371\n",
      "epoch 30 loss: 0.0398\n",
      "27\n",
      "epoch 1 loss: 0.7490\n",
      "epoch 2 loss: 0.6045\n",
      "epoch 3 loss: 0.5323\n",
      "epoch 4 loss: 0.3750\n",
      "epoch 5 loss: 0.4602\n",
      "epoch 6 loss: 0.4062\n",
      "epoch 7 loss: 0.1827\n",
      "epoch 8 loss: 0.0983\n",
      "epoch 9 loss: 0.0721\n",
      "epoch 10 loss: 0.0611\n",
      "epoch 11 loss: 0.0606\n",
      "epoch 12 loss: 0.0465\n",
      "epoch 13 loss: 0.0423\n",
      "epoch 14 loss: 0.0471\n",
      "epoch 15 loss: 0.0437\n",
      "epoch 16 loss: 0.0394\n",
      "epoch 17 loss: 0.0425\n",
      "epoch 18 loss: 0.0353\n",
      "epoch 19 loss: 0.0349\n",
      "epoch 20 loss: 0.0388\n",
      "epoch 21 loss: 0.0361\n",
      "epoch 22 loss: 0.0344\n",
      "epoch 23 loss: 0.0344\n",
      "epoch 24 loss: 0.0340\n",
      "epoch 25 loss: 0.0370\n",
      "epoch 26 loss: 0.0369\n",
      "epoch 27 loss: 0.0337\n",
      "epoch 28 loss: 0.0352\n",
      "epoch 29 loss: 0.0316\n",
      "epoch 30 loss: 0.0326\n",
      "28\n",
      "epoch 1 loss: 0.6462\n",
      "epoch 2 loss: 0.5923\n",
      "epoch 3 loss: 0.4874\n",
      "epoch 4 loss: 0.3505\n",
      "epoch 5 loss: 0.2028\n",
      "epoch 6 loss: 0.1060\n",
      "epoch 7 loss: 0.0905\n",
      "epoch 8 loss: 0.0642\n",
      "epoch 9 loss: 0.0555\n",
      "epoch 10 loss: 0.0495\n",
      "epoch 11 loss: 0.0513\n",
      "epoch 12 loss: 0.0401\n",
      "epoch 13 loss: 0.0468\n",
      "epoch 14 loss: 0.0434\n",
      "epoch 15 loss: 0.0413\n",
      "epoch 16 loss: 0.0371\n",
      "epoch 17 loss: 0.0398\n",
      "epoch 18 loss: 0.0400\n",
      "epoch 19 loss: 0.0395\n",
      "epoch 20 loss: 0.0352\n",
      "epoch 21 loss: 0.0379\n",
      "epoch 22 loss: 0.0342\n",
      "epoch 23 loss: 0.0300\n",
      "epoch 24 loss: 0.0319\n",
      "epoch 25 loss: 0.0290\n",
      "epoch 26 loss: 0.0329\n",
      "epoch 27 loss: 0.0296\n",
      "epoch 28 loss: 0.0295\n",
      "epoch 29 loss: 0.0297\n",
      "epoch 30 loss: 0.0312\n",
      "29\n",
      "epoch 1 loss: 1.0126\n",
      "epoch 2 loss: 0.4706\n",
      "epoch 3 loss: 0.8314\n",
      "epoch 4 loss: 0.3791\n",
      "epoch 5 loss: 0.2918\n",
      "epoch 6 loss: 0.1503\n",
      "epoch 7 loss: 0.0726\n",
      "epoch 8 loss: 0.0631\n",
      "epoch 9 loss: 0.0606\n",
      "epoch 10 loss: 0.0517\n",
      "epoch 11 loss: 0.0512\n",
      "epoch 12 loss: 0.0555\n",
      "epoch 13 loss: 0.0506\n",
      "epoch 14 loss: 0.0533\n",
      "epoch 15 loss: 0.0478\n",
      "epoch 16 loss: 0.0452\n",
      "epoch 17 loss: 0.0425\n",
      "epoch 18 loss: 0.0451\n",
      "epoch 19 loss: 0.0471\n",
      "epoch 20 loss: 0.0385\n",
      "epoch 21 loss: 0.0361\n",
      "epoch 22 loss: 0.0377\n",
      "epoch 23 loss: 0.0352\n",
      "epoch 24 loss: 0.0384\n",
      "epoch 25 loss: 0.0409\n",
      "epoch 26 loss: 0.0396\n",
      "epoch 27 loss: 0.0357\n",
      "epoch 28 loss: 0.0342\n",
      "epoch 29 loss: 0.0411\n",
      "epoch 30 loss: 0.0325\n",
      "30\n",
      "epoch 1 loss: 0.8260\n",
      "epoch 2 loss: 0.6742\n",
      "epoch 3 loss: 0.4646\n",
      "epoch 4 loss: 0.3753\n",
      "epoch 5 loss: 0.3711\n",
      "epoch 6 loss: 0.2077\n",
      "epoch 7 loss: 0.0991\n",
      "epoch 8 loss: 0.0734\n",
      "epoch 9 loss: 0.0618\n",
      "epoch 10 loss: 0.0585\n",
      "epoch 11 loss: 0.0463\n",
      "epoch 12 loss: 0.0466\n",
      "epoch 13 loss: 0.0430\n",
      "epoch 14 loss: 0.0508\n",
      "epoch 15 loss: 0.0372\n",
      "epoch 16 loss: 0.0455\n",
      "epoch 17 loss: 0.0422\n",
      "epoch 18 loss: 0.0365\n",
      "epoch 19 loss: 0.0428\n",
      "epoch 20 loss: 0.0420\n",
      "epoch 21 loss: 0.0390\n",
      "epoch 22 loss: 0.0401\n",
      "epoch 23 loss: 0.0345\n",
      "epoch 24 loss: 0.0393\n",
      "epoch 25 loss: 0.0356\n",
      "epoch 26 loss: 0.0388\n",
      "epoch 27 loss: 0.0360\n",
      "epoch 28 loss: 0.0365\n",
      "epoch 29 loss: 0.0338\n",
      "epoch 30 loss: 0.0344\n",
      "31\n",
      "epoch 1 loss: 0.8358\n",
      "epoch 2 loss: 0.4798\n",
      "epoch 3 loss: 0.3026\n",
      "epoch 4 loss: 0.1418\n",
      "epoch 5 loss: 0.0757\n",
      "epoch 6 loss: 0.0639\n",
      "epoch 7 loss: 0.0577\n",
      "epoch 8 loss: 0.0595\n",
      "epoch 9 loss: 0.0561\n",
      "epoch 10 loss: 0.0531\n",
      "epoch 11 loss: 0.0508\n",
      "epoch 12 loss: 0.0469\n",
      "epoch 13 loss: 0.0494\n",
      "epoch 14 loss: 0.0451\n",
      "epoch 15 loss: 0.0390\n",
      "epoch 16 loss: 0.0399\n",
      "epoch 17 loss: 0.0466\n",
      "epoch 18 loss: 0.0397\n",
      "epoch 19 loss: 0.0381\n",
      "epoch 20 loss: 0.0349\n",
      "epoch 21 loss: 0.0371\n",
      "epoch 22 loss: 0.0331\n",
      "epoch 23 loss: 0.0357\n",
      "epoch 24 loss: 0.0354\n",
      "epoch 25 loss: 0.0283\n",
      "epoch 26 loss: 0.0378\n",
      "epoch 27 loss: 0.0356\n",
      "epoch 28 loss: 0.0322\n",
      "epoch 29 loss: 0.0392\n",
      "epoch 30 loss: 0.0317\n",
      "32\n",
      "epoch 1 loss: 0.7879\n",
      "epoch 2 loss: 0.5165\n",
      "epoch 3 loss: 0.4436\n",
      "epoch 4 loss: 0.2257\n",
      "epoch 5 loss: 0.1540\n",
      "epoch 6 loss: 0.1130\n",
      "epoch 7 loss: 0.0800\n",
      "epoch 8 loss: 0.0714\n",
      "epoch 9 loss: 0.0538\n",
      "epoch 10 loss: 0.0502\n",
      "epoch 11 loss: 0.0435\n",
      "epoch 12 loss: 0.0453\n",
      "epoch 13 loss: 0.0440\n",
      "epoch 14 loss: 0.0487\n",
      "epoch 15 loss: 0.0401\n",
      "epoch 16 loss: 0.0399\n",
      "epoch 17 loss: 0.0363\n",
      "epoch 18 loss: 0.0370\n",
      "epoch 19 loss: 0.0351\n",
      "epoch 20 loss: 0.0375\n",
      "epoch 21 loss: 0.0381\n",
      "epoch 22 loss: 0.0349\n",
      "epoch 23 loss: 0.0333\n",
      "epoch 24 loss: 0.0394\n",
      "epoch 25 loss: 0.0343\n",
      "epoch 26 loss: 0.0357\n",
      "epoch 27 loss: 0.0327\n",
      "epoch 28 loss: 0.0321\n",
      "epoch 29 loss: 0.0359\n",
      "epoch 30 loss: 0.0299\n",
      "33\n",
      "epoch 1 loss: 0.8123\n",
      "epoch 2 loss: 0.5605\n",
      "epoch 3 loss: 0.6226\n",
      "epoch 4 loss: 0.4450\n",
      "epoch 5 loss: 0.2567\n",
      "epoch 6 loss: 0.2194\n",
      "epoch 7 loss: 0.1058\n",
      "epoch 8 loss: 0.0733\n",
      "epoch 9 loss: 0.0620\n",
      "epoch 10 loss: 0.0585\n",
      "epoch 11 loss: 0.0538\n",
      "epoch 12 loss: 0.0579\n",
      "epoch 13 loss: 0.0456\n",
      "epoch 14 loss: 0.0530\n",
      "epoch 15 loss: 0.0406\n",
      "epoch 16 loss: 0.0499\n",
      "epoch 17 loss: 0.0388\n",
      "epoch 18 loss: 0.0389\n",
      "epoch 19 loss: 0.0428\n",
      "epoch 20 loss: 0.0437\n",
      "epoch 21 loss: 0.0434\n",
      "epoch 22 loss: 0.0386\n",
      "epoch 23 loss: 0.0422\n",
      "epoch 24 loss: 0.0361\n",
      "epoch 25 loss: 0.0339\n",
      "epoch 26 loss: 0.0374\n",
      "epoch 27 loss: 0.0349\n",
      "epoch 28 loss: 0.0329\n",
      "epoch 29 loss: 0.0327\n",
      "epoch 30 loss: 0.0328\n",
      "34\n",
      "epoch 1 loss: 0.6873\n",
      "epoch 2 loss: 0.5023\n",
      "epoch 3 loss: 0.4511\n",
      "epoch 4 loss: 0.4195\n",
      "epoch 5 loss: 0.3694\n",
      "epoch 6 loss: 0.3588\n",
      "epoch 7 loss: 0.2586\n",
      "epoch 8 loss: 0.1506\n",
      "epoch 9 loss: 0.0995\n",
      "epoch 10 loss: 0.0690\n",
      "epoch 11 loss: 0.0586\n",
      "epoch 12 loss: 0.0521\n",
      "epoch 13 loss: 0.0482\n",
      "epoch 14 loss: 0.0507\n",
      "epoch 15 loss: 0.0471\n",
      "epoch 16 loss: 0.0414\n",
      "epoch 17 loss: 0.0429\n",
      "epoch 18 loss: 0.0348\n",
      "epoch 19 loss: 0.0367\n",
      "epoch 20 loss: 0.0349\n",
      "epoch 21 loss: 0.0399\n",
      "epoch 22 loss: 0.0334\n",
      "epoch 23 loss: 0.0393\n",
      "epoch 24 loss: 0.0342\n",
      "epoch 25 loss: 0.0375\n",
      "epoch 26 loss: 0.0372\n",
      "epoch 27 loss: 0.0355\n",
      "epoch 28 loss: 0.0304\n",
      "epoch 29 loss: 0.0322\n",
      "epoch 30 loss: 0.0330\n",
      "35\n",
      "epoch 1 loss: 0.9256\n",
      "epoch 2 loss: 0.5380\n",
      "epoch 3 loss: 0.3843\n",
      "epoch 4 loss: 0.2970\n",
      "epoch 5 loss: 0.1856\n",
      "epoch 6 loss: 0.0979\n",
      "epoch 7 loss: 0.0741\n",
      "epoch 8 loss: 0.0616\n",
      "epoch 9 loss: 0.0528\n",
      "epoch 10 loss: 0.0465\n",
      "epoch 11 loss: 0.0451\n",
      "epoch 12 loss: 0.0493\n",
      "epoch 13 loss: 0.0426\n",
      "epoch 14 loss: 0.0395\n",
      "epoch 15 loss: 0.0419\n",
      "epoch 16 loss: 0.0349\n",
      "epoch 17 loss: 0.0379\n",
      "epoch 18 loss: 0.0378\n",
      "epoch 19 loss: 0.0328\n",
      "epoch 20 loss: 0.0375\n",
      "epoch 21 loss: 0.0326\n",
      "epoch 22 loss: 0.0326\n",
      "epoch 23 loss: 0.0343\n",
      "epoch 24 loss: 0.0326\n",
      "epoch 25 loss: 0.0339\n",
      "epoch 26 loss: 0.0316\n",
      "epoch 27 loss: 0.0290\n",
      "epoch 28 loss: 0.0360\n",
      "epoch 29 loss: 0.0307\n",
      "epoch 30 loss: 0.0325\n",
      "36\n",
      "epoch 1 loss: 0.6771\n",
      "epoch 2 loss: 0.5267\n",
      "epoch 3 loss: 0.4385\n",
      "epoch 4 loss: 0.3437\n",
      "epoch 5 loss: 0.1757\n",
      "epoch 6 loss: 0.0886\n",
      "epoch 7 loss: 0.0560\n",
      "epoch 8 loss: 0.0608\n",
      "epoch 9 loss: 0.0558\n",
      "epoch 10 loss: 0.0526\n",
      "epoch 11 loss: 0.0483\n",
      "epoch 12 loss: 0.0414\n",
      "epoch 13 loss: 0.0461\n",
      "epoch 14 loss: 0.0427\n",
      "epoch 15 loss: 0.0448\n",
      "epoch 16 loss: 0.0432\n",
      "epoch 17 loss: 0.0406\n",
      "epoch 18 loss: 0.0429\n",
      "epoch 19 loss: 0.0349\n",
      "epoch 20 loss: 0.0434\n",
      "epoch 21 loss: 0.0387\n",
      "epoch 22 loss: 0.0413\n",
      "epoch 23 loss: 0.0385\n",
      "epoch 24 loss: 0.0355\n",
      "epoch 25 loss: 0.0346\n",
      "epoch 26 loss: 0.0358\n",
      "epoch 27 loss: 0.0350\n",
      "epoch 28 loss: 0.0352\n",
      "epoch 29 loss: 0.0340\n",
      "epoch 30 loss: 0.0301\n",
      "37\n",
      "epoch 1 loss: 0.7847\n",
      "epoch 2 loss: 0.6122\n",
      "epoch 3 loss: 0.4149\n",
      "epoch 4 loss: 0.3217\n",
      "epoch 5 loss: 0.1546\n",
      "epoch 6 loss: 0.0874\n",
      "epoch 7 loss: 0.0685\n",
      "epoch 8 loss: 0.0577\n",
      "epoch 9 loss: 0.0472\n",
      "epoch 10 loss: 0.0467\n",
      "epoch 11 loss: 0.0445\n",
      "epoch 12 loss: 0.0408\n",
      "epoch 13 loss: 0.0391\n",
      "epoch 14 loss: 0.0421\n",
      "epoch 15 loss: 0.0387\n",
      "epoch 16 loss: 0.0463\n",
      "epoch 17 loss: 0.0427\n",
      "epoch 18 loss: 0.0373\n",
      "epoch 19 loss: 0.0381\n",
      "epoch 20 loss: 0.0344\n",
      "epoch 21 loss: 0.0360\n",
      "epoch 22 loss: 0.0365\n",
      "epoch 23 loss: 0.0336\n",
      "epoch 24 loss: 0.0321\n",
      "epoch 25 loss: 0.0340\n",
      "epoch 26 loss: 0.0321\n",
      "epoch 27 loss: 0.0325\n",
      "epoch 28 loss: 0.0383\n",
      "epoch 29 loss: 0.0335\n",
      "epoch 30 loss: 0.0302\n",
      "38\n",
      "epoch 1 loss: 0.6283\n",
      "epoch 2 loss: 0.5672\n",
      "epoch 3 loss: 0.4117\n",
      "epoch 4 loss: 0.3976\n",
      "epoch 5 loss: 0.3041\n",
      "epoch 6 loss: 0.1283\n",
      "epoch 7 loss: 0.0880\n",
      "epoch 8 loss: 0.0578\n",
      "epoch 9 loss: 0.0550\n",
      "epoch 10 loss: 0.0470\n",
      "epoch 11 loss: 0.0496\n",
      "epoch 12 loss: 0.0512\n",
      "epoch 13 loss: 0.0492\n",
      "epoch 14 loss: 0.0364\n",
      "epoch 15 loss: 0.0404\n",
      "epoch 16 loss: 0.0356\n",
      "epoch 17 loss: 0.0389\n",
      "epoch 18 loss: 0.0472\n",
      "epoch 19 loss: 0.0398\n",
      "epoch 20 loss: 0.0344\n",
      "epoch 21 loss: 0.0381\n",
      "epoch 22 loss: 0.0355\n",
      "epoch 23 loss: 0.0320\n",
      "epoch 24 loss: 0.0324\n",
      "epoch 25 loss: 0.0372\n",
      "epoch 26 loss: 0.0325\n",
      "epoch 27 loss: 0.0300\n",
      "epoch 28 loss: 0.0300\n",
      "epoch 29 loss: 0.0331\n",
      "epoch 30 loss: 0.0323\n",
      "39\n",
      "epoch 1 loss: 0.6522\n",
      "epoch 2 loss: 0.5451\n",
      "epoch 3 loss: 0.4025\n",
      "epoch 4 loss: 0.2702\n",
      "epoch 5 loss: 0.1528\n",
      "epoch 6 loss: 0.0955\n",
      "epoch 7 loss: 0.0715\n",
      "epoch 8 loss: 0.0585\n",
      "epoch 9 loss: 0.0532\n",
      "epoch 10 loss: 0.0463\n",
      "epoch 11 loss: 0.0496\n",
      "epoch 12 loss: 0.0479\n",
      "epoch 13 loss: 0.0420\n",
      "epoch 14 loss: 0.0471\n",
      "epoch 15 loss: 0.0530\n",
      "epoch 16 loss: 0.0384\n",
      "epoch 17 loss: 0.0381\n",
      "epoch 18 loss: 0.0404\n",
      "epoch 19 loss: 0.0492\n",
      "epoch 20 loss: 0.0429\n",
      "epoch 21 loss: 0.0368\n",
      "epoch 22 loss: 0.0329\n",
      "epoch 23 loss: 0.0394\n",
      "epoch 24 loss: 0.0392\n",
      "epoch 25 loss: 0.0363\n",
      "epoch 26 loss: 0.0338\n",
      "epoch 27 loss: 0.0332\n",
      "epoch 28 loss: 0.0326\n",
      "epoch 29 loss: 0.0383\n",
      "epoch 30 loss: 0.0329\n",
      "40\n",
      "epoch 1 loss: 0.9297\n",
      "epoch 2 loss: 0.5619\n",
      "epoch 3 loss: 0.4252\n",
      "epoch 4 loss: 0.2157\n",
      "epoch 5 loss: 0.1816\n",
      "epoch 6 loss: 0.1473\n",
      "epoch 7 loss: 0.0954\n",
      "epoch 8 loss: 0.0825\n",
      "epoch 9 loss: 0.0689\n",
      "epoch 10 loss: 0.0559\n",
      "epoch 11 loss: 0.0571\n",
      "epoch 12 loss: 0.0511\n",
      "epoch 13 loss: 0.0590\n",
      "epoch 14 loss: 0.0474\n",
      "epoch 15 loss: 0.0467\n",
      "epoch 16 loss: 0.0456\n",
      "epoch 17 loss: 0.0459\n",
      "epoch 18 loss: 0.0462\n",
      "epoch 19 loss: 0.0444\n",
      "epoch 20 loss: 0.0416\n",
      "epoch 21 loss: 0.0421\n",
      "epoch 22 loss: 0.0380\n",
      "epoch 23 loss: 0.0427\n",
      "epoch 24 loss: 0.0398\n",
      "epoch 25 loss: 0.0514\n",
      "epoch 26 loss: 0.0408\n",
      "epoch 27 loss: 0.0343\n",
      "epoch 28 loss: 0.0329\n",
      "epoch 29 loss: 0.0424\n",
      "epoch 30 loss: 0.0340\n",
      "41\n",
      "epoch 1 loss: 0.6653\n",
      "epoch 2 loss: 0.4638\n",
      "epoch 3 loss: 0.5465\n",
      "epoch 4 loss: 0.3152\n",
      "epoch 5 loss: 0.2311\n",
      "epoch 6 loss: 0.1544\n",
      "epoch 7 loss: 0.0758\n",
      "epoch 8 loss: 0.0614\n",
      "epoch 9 loss: 0.0552\n",
      "epoch 10 loss: 0.0393\n",
      "epoch 11 loss: 0.0481\n",
      "epoch 12 loss: 0.0456\n",
      "epoch 13 loss: 0.0412\n",
      "epoch 14 loss: 0.0412\n",
      "epoch 15 loss: 0.0359\n",
      "epoch 16 loss: 0.0388\n",
      "epoch 17 loss: 0.0357\n",
      "epoch 18 loss: 0.0376\n",
      "epoch 19 loss: 0.0379\n",
      "epoch 20 loss: 0.0356\n",
      "epoch 21 loss: 0.0312\n",
      "epoch 22 loss: 0.0298\n",
      "epoch 23 loss: 0.0344\n",
      "epoch 24 loss: 0.0333\n",
      "epoch 25 loss: 0.0280\n",
      "epoch 26 loss: 0.0321\n",
      "epoch 27 loss: 0.0334\n",
      "epoch 28 loss: 0.0304\n",
      "epoch 29 loss: 0.0321\n",
      "epoch 30 loss: 0.0306\n",
      "42\n",
      "epoch 1 loss: 0.6878\n",
      "epoch 2 loss: 0.4769\n",
      "epoch 3 loss: 0.4994\n",
      "epoch 4 loss: 0.3573\n",
      "epoch 5 loss: 0.3061\n",
      "epoch 6 loss: 0.2556\n",
      "epoch 7 loss: 0.1355\n",
      "epoch 8 loss: 0.0944\n",
      "epoch 9 loss: 0.0620\n",
      "epoch 10 loss: 0.0545\n",
      "epoch 11 loss: 0.0486\n",
      "epoch 12 loss: 0.0455\n",
      "epoch 13 loss: 0.0439\n",
      "epoch 14 loss: 0.0346\n",
      "epoch 15 loss: 0.0426\n",
      "epoch 16 loss: 0.0437\n",
      "epoch 17 loss: 0.0394\n",
      "epoch 18 loss: 0.0385\n",
      "epoch 19 loss: 0.0368\n",
      "epoch 20 loss: 0.0365\n",
      "epoch 21 loss: 0.0329\n",
      "epoch 22 loss: 0.0334\n",
      "epoch 23 loss: 0.0364\n",
      "epoch 24 loss: 0.0350\n",
      "epoch 25 loss: 0.0281\n",
      "epoch 26 loss: 0.0281\n",
      "epoch 27 loss: 0.0342\n",
      "epoch 28 loss: 0.0259\n",
      "epoch 29 loss: 0.0320\n",
      "epoch 30 loss: 0.0297\n",
      "43\n",
      "epoch 1 loss: 0.7424\n",
      "epoch 2 loss: 0.6685\n",
      "epoch 3 loss: 0.7163\n",
      "epoch 4 loss: 0.4882\n",
      "epoch 5 loss: 0.3879\n",
      "epoch 6 loss: 0.2136\n",
      "epoch 7 loss: 0.1198\n",
      "epoch 8 loss: 0.0871\n",
      "epoch 9 loss: 0.0754\n",
      "epoch 10 loss: 0.0529\n",
      "epoch 11 loss: 0.0682\n",
      "epoch 12 loss: 0.0498\n",
      "epoch 13 loss: 0.0547\n",
      "epoch 14 loss: 0.0515\n",
      "epoch 15 loss: 0.0439\n",
      "epoch 16 loss: 0.0441\n",
      "epoch 17 loss: 0.0485\n",
      "epoch 18 loss: 0.0396\n",
      "epoch 19 loss: 0.0400\n",
      "epoch 20 loss: 0.0463\n",
      "epoch 21 loss: 0.0398\n",
      "epoch 22 loss: 0.0394\n",
      "epoch 23 loss: 0.0379\n",
      "epoch 24 loss: 0.0421\n",
      "epoch 25 loss: 0.0373\n",
      "epoch 26 loss: 0.0361\n",
      "epoch 27 loss: 0.0377\n",
      "epoch 28 loss: 0.0373\n",
      "epoch 29 loss: 0.0329\n",
      "epoch 30 loss: 0.0368\n",
      "44\n",
      "epoch 1 loss: 0.9149\n",
      "epoch 2 loss: 0.7798\n",
      "epoch 3 loss: 0.5483\n",
      "epoch 4 loss: 0.3351\n",
      "epoch 5 loss: 0.1888\n",
      "epoch 6 loss: 0.1075\n",
      "epoch 7 loss: 0.0704\n",
      "epoch 8 loss: 0.0691\n",
      "epoch 9 loss: 0.0567\n",
      "epoch 10 loss: 0.0567\n",
      "epoch 11 loss: 0.0505\n",
      "epoch 12 loss: 0.0628\n",
      "epoch 13 loss: 0.0510\n",
      "epoch 14 loss: 0.0491\n",
      "epoch 15 loss: 0.0433\n",
      "epoch 16 loss: 0.0478\n",
      "epoch 17 loss: 0.0426\n",
      "epoch 18 loss: 0.0459\n",
      "epoch 19 loss: 0.0384\n",
      "epoch 20 loss: 0.0415\n",
      "epoch 21 loss: 0.0475\n",
      "epoch 22 loss: 0.0463\n",
      "epoch 23 loss: 0.0359\n",
      "epoch 24 loss: 0.0351\n",
      "epoch 25 loss: 0.0415\n",
      "epoch 26 loss: 0.0370\n",
      "epoch 27 loss: 0.0377\n",
      "epoch 28 loss: 0.0348\n",
      "epoch 29 loss: 0.0358\n",
      "epoch 30 loss: 0.0366\n",
      "45\n",
      "epoch 1 loss: 0.8769\n",
      "epoch 2 loss: 0.4634\n",
      "epoch 3 loss: 0.3143\n",
      "epoch 4 loss: 0.2273\n",
      "epoch 5 loss: 0.1405\n",
      "epoch 6 loss: 0.0743\n",
      "epoch 7 loss: 0.0574\n",
      "epoch 8 loss: 0.0605\n",
      "epoch 9 loss: 0.0436\n",
      "epoch 10 loss: 0.0485\n",
      "epoch 11 loss: 0.0409\n",
      "epoch 12 loss: 0.0457\n",
      "epoch 13 loss: 0.0454\n",
      "epoch 14 loss: 0.0435\n",
      "epoch 15 loss: 0.0349\n",
      "epoch 16 loss: 0.0378\n",
      "epoch 17 loss: 0.0389\n",
      "epoch 18 loss: 0.0365\n",
      "epoch 19 loss: 0.0376\n",
      "epoch 20 loss: 0.0304\n",
      "epoch 21 loss: 0.0365\n",
      "epoch 22 loss: 0.0365\n",
      "epoch 23 loss: 0.0353\n",
      "epoch 24 loss: 0.0295\n",
      "epoch 25 loss: 0.0305\n",
      "epoch 26 loss: 0.0352\n",
      "epoch 27 loss: 0.0320\n",
      "epoch 28 loss: 0.0300\n",
      "epoch 29 loss: 0.0320\n",
      "epoch 30 loss: 0.0347\n",
      "46\n",
      "epoch 1 loss: 0.7960\n",
      "epoch 2 loss: 0.4748\n",
      "epoch 3 loss: 0.4331\n",
      "epoch 4 loss: 0.3287\n",
      "epoch 5 loss: 0.1803\n",
      "epoch 6 loss: 0.1194\n",
      "epoch 7 loss: 0.0883\n",
      "epoch 8 loss: 0.0659\n",
      "epoch 9 loss: 0.0560\n",
      "epoch 10 loss: 0.0574\n",
      "epoch 11 loss: 0.0469\n",
      "epoch 12 loss: 0.0471\n",
      "epoch 13 loss: 0.0428\n",
      "epoch 14 loss: 0.0469\n",
      "epoch 15 loss: 0.0380\n",
      "epoch 16 loss: 0.0450\n",
      "epoch 17 loss: 0.0404\n",
      "epoch 18 loss: 0.0428\n",
      "epoch 19 loss: 0.0407\n",
      "epoch 20 loss: 0.0357\n",
      "epoch 21 loss: 0.0367\n",
      "epoch 22 loss: 0.0401\n",
      "epoch 23 loss: 0.0375\n",
      "epoch 24 loss: 0.0420\n",
      "epoch 25 loss: 0.0383\n",
      "epoch 26 loss: 0.0330\n",
      "epoch 27 loss: 0.0352\n",
      "epoch 28 loss: 0.0363\n",
      "epoch 29 loss: 0.0299\n",
      "epoch 30 loss: 0.0344\n",
      "47\n",
      "epoch 1 loss: 0.9359\n",
      "epoch 2 loss: 0.8085\n",
      "epoch 3 loss: 0.3799\n",
      "epoch 4 loss: 0.2549\n",
      "epoch 5 loss: 0.2026\n",
      "epoch 6 loss: 0.1628\n",
      "epoch 7 loss: 0.1045\n",
      "epoch 8 loss: 0.0806\n",
      "epoch 9 loss: 0.0621\n",
      "epoch 10 loss: 0.0580\n",
      "epoch 11 loss: 0.0639\n",
      "epoch 12 loss: 0.0535\n",
      "epoch 13 loss: 0.0544\n",
      "epoch 14 loss: 0.0503\n",
      "epoch 15 loss: 0.0503\n",
      "epoch 16 loss: 0.0450\n",
      "epoch 17 loss: 0.0527\n",
      "epoch 18 loss: 0.0451\n",
      "epoch 19 loss: 0.0497\n",
      "epoch 20 loss: 0.0402\n",
      "epoch 21 loss: 0.0433\n",
      "epoch 22 loss: 0.0430\n",
      "epoch 23 loss: 0.0405\n",
      "epoch 24 loss: 0.0383\n",
      "epoch 25 loss: 0.0373\n",
      "epoch 26 loss: 0.0405\n",
      "epoch 27 loss: 0.0447\n",
      "epoch 28 loss: 0.0461\n",
      "epoch 29 loss: 0.0388\n",
      "epoch 30 loss: 0.0354\n",
      "48\n",
      "epoch 1 loss: 0.6258\n",
      "epoch 2 loss: 0.4870\n",
      "epoch 3 loss: 0.3044\n",
      "epoch 4 loss: 0.3080\n",
      "epoch 5 loss: 0.1969\n",
      "epoch 6 loss: 0.2038\n",
      "epoch 7 loss: 0.1495\n",
      "epoch 8 loss: 0.1185\n",
      "epoch 9 loss: 0.0926\n",
      "epoch 10 loss: 0.0715\n",
      "epoch 11 loss: 0.0773\n",
      "epoch 12 loss: 0.0650\n",
      "epoch 13 loss: 0.0516\n",
      "epoch 14 loss: 0.0518\n",
      "epoch 15 loss: 0.0498\n",
      "epoch 16 loss: 0.0514\n",
      "epoch 17 loss: 0.0457\n",
      "epoch 18 loss: 0.0390\n",
      "epoch 19 loss: 0.0476\n",
      "epoch 20 loss: 0.0438\n",
      "epoch 21 loss: 0.0464\n",
      "epoch 22 loss: 0.0383\n",
      "epoch 23 loss: 0.0386\n",
      "epoch 24 loss: 0.0366\n",
      "epoch 25 loss: 0.0411\n",
      "epoch 26 loss: 0.0380\n",
      "epoch 27 loss: 0.0366\n",
      "epoch 28 loss: 0.0322\n",
      "epoch 29 loss: 0.0383\n",
      "epoch 30 loss: 0.0311\n",
      "49\n",
      "epoch 1 loss: 0.7257\n",
      "epoch 2 loss: 0.5641\n",
      "epoch 3 loss: 0.4889\n",
      "epoch 4 loss: 0.2993\n",
      "epoch 5 loss: 0.2187\n",
      "epoch 6 loss: 0.0881\n",
      "epoch 7 loss: 0.0628\n",
      "epoch 8 loss: 0.0571\n",
      "epoch 9 loss: 0.0460\n",
      "epoch 10 loss: 0.0472\n",
      "epoch 11 loss: 0.0436\n",
      "epoch 12 loss: 0.0404\n",
      "epoch 13 loss: 0.0431\n",
      "epoch 14 loss: 0.0409\n",
      "epoch 15 loss: 0.0399\n",
      "epoch 16 loss: 0.0385\n",
      "epoch 17 loss: 0.0411\n",
      "epoch 18 loss: 0.0390\n",
      "epoch 19 loss: 0.0473\n",
      "epoch 20 loss: 0.0394\n",
      "epoch 21 loss: 0.0329\n",
      "epoch 22 loss: 0.0355\n",
      "epoch 23 loss: 0.0357\n",
      "epoch 24 loss: 0.0371\n",
      "epoch 25 loss: 0.0346\n",
      "epoch 26 loss: 0.0302\n",
      "epoch 27 loss: 0.0352\n",
      "epoch 28 loss: 0.0316\n",
      "epoch 29 loss: 0.0351\n",
      "epoch 30 loss: 0.0336\n",
      "50\n",
      "epoch 1 loss: 0.8388\n",
      "epoch 2 loss: 0.5880\n",
      "epoch 3 loss: 0.6941\n",
      "epoch 4 loss: 0.4194\n",
      "epoch 5 loss: 0.3529\n",
      "epoch 6 loss: 0.1838\n",
      "epoch 7 loss: 0.1037\n",
      "epoch 8 loss: 0.0648\n",
      "epoch 9 loss: 0.0595\n",
      "epoch 10 loss: 0.0558\n",
      "epoch 11 loss: 0.0468\n",
      "epoch 12 loss: 0.0497\n",
      "epoch 13 loss: 0.0449\n",
      "epoch 14 loss: 0.0514\n",
      "epoch 15 loss: 0.0438\n",
      "epoch 16 loss: 0.0376\n",
      "epoch 17 loss: 0.0395\n",
      "epoch 18 loss: 0.0379\n",
      "epoch 19 loss: 0.0360\n",
      "epoch 20 loss: 0.0386\n",
      "epoch 21 loss: 0.0366\n",
      "epoch 22 loss: 0.0381\n",
      "epoch 23 loss: 0.0362\n",
      "epoch 24 loss: 0.0375\n",
      "epoch 25 loss: 0.0395\n",
      "epoch 26 loss: 0.0354\n",
      "epoch 27 loss: 0.0359\n",
      "epoch 28 loss: 0.0344\n",
      "epoch 29 loss: 0.0344\n",
      "epoch 30 loss: 0.0375\n",
      "51\n",
      "epoch 1 loss: 0.8934\n",
      "epoch 2 loss: 0.6153\n",
      "epoch 3 loss: 0.4147\n",
      "epoch 4 loss: 0.3385\n",
      "epoch 5 loss: 0.2239\n",
      "epoch 6 loss: 0.1615\n",
      "epoch 7 loss: 0.0757\n",
      "epoch 8 loss: 0.0647\n",
      "epoch 9 loss: 0.0569\n",
      "epoch 10 loss: 0.0628\n",
      "epoch 11 loss: 0.0567\n",
      "epoch 12 loss: 0.0533\n",
      "epoch 13 loss: 0.0478\n",
      "epoch 14 loss: 0.0415\n",
      "epoch 15 loss: 0.0473\n",
      "epoch 16 loss: 0.0465\n",
      "epoch 17 loss: 0.0406\n",
      "epoch 18 loss: 0.0404\n",
      "epoch 19 loss: 0.0464\n",
      "epoch 20 loss: 0.0393\n",
      "epoch 21 loss: 0.0400\n",
      "epoch 22 loss: 0.0417\n",
      "epoch 23 loss: 0.0415\n",
      "epoch 24 loss: 0.0363\n",
      "epoch 25 loss: 0.0330\n",
      "epoch 26 loss: 0.0389\n",
      "epoch 27 loss: 0.0382\n",
      "epoch 28 loss: 0.0350\n",
      "epoch 29 loss: 0.0352\n",
      "epoch 30 loss: 0.0311\n",
      "52\n",
      "epoch 1 loss: 0.8545\n",
      "epoch 2 loss: 0.7115\n",
      "epoch 3 loss: 0.6484\n",
      "epoch 4 loss: 0.3438\n",
      "epoch 5 loss: 0.1846\n",
      "epoch 6 loss: 0.2169\n",
      "epoch 7 loss: 0.0830\n",
      "epoch 8 loss: 0.0697\n",
      "epoch 9 loss: 0.0645\n",
      "epoch 10 loss: 0.0527\n",
      "epoch 11 loss: 0.0547\n",
      "epoch 12 loss: 0.0472\n",
      "epoch 13 loss: 0.0432\n",
      "epoch 14 loss: 0.0470\n",
      "epoch 15 loss: 0.0529\n",
      "epoch 16 loss: 0.0501\n",
      "epoch 17 loss: 0.0551\n",
      "epoch 18 loss: 0.0449\n",
      "epoch 19 loss: 0.0489\n",
      "epoch 20 loss: 0.0477\n",
      "epoch 21 loss: 0.0424\n",
      "epoch 22 loss: 0.0426\n",
      "epoch 23 loss: 0.0441\n",
      "epoch 24 loss: 0.0360\n",
      "epoch 25 loss: 0.0396\n",
      "epoch 26 loss: 0.0411\n",
      "epoch 27 loss: 0.0460\n",
      "epoch 28 loss: 0.0360\n",
      "epoch 29 loss: 0.0391\n",
      "epoch 30 loss: 0.0339\n",
      "53\n",
      "epoch 1 loss: 0.6272\n",
      "epoch 2 loss: 0.4842\n",
      "epoch 3 loss: 0.4787\n",
      "epoch 4 loss: 0.3553\n",
      "epoch 5 loss: 0.1708\n",
      "epoch 6 loss: 0.0879\n",
      "epoch 7 loss: 0.0600\n",
      "epoch 8 loss: 0.0542\n",
      "epoch 9 loss: 0.0527\n",
      "epoch 10 loss: 0.0501\n",
      "epoch 11 loss: 0.0410\n",
      "epoch 12 loss: 0.0417\n",
      "epoch 13 loss: 0.0486\n",
      "epoch 14 loss: 0.0427\n",
      "epoch 15 loss: 0.0363\n",
      "epoch 16 loss: 0.0387\n",
      "epoch 17 loss: 0.0337\n",
      "epoch 18 loss: 0.0382\n",
      "epoch 19 loss: 0.0366\n",
      "epoch 20 loss: 0.0382\n",
      "epoch 21 loss: 0.0424\n",
      "epoch 22 loss: 0.0367\n",
      "epoch 23 loss: 0.0321\n",
      "epoch 24 loss: 0.0351\n",
      "epoch 25 loss: 0.0341\n",
      "epoch 26 loss: 0.0314\n",
      "epoch 27 loss: 0.0327\n",
      "epoch 28 loss: 0.0308\n",
      "epoch 29 loss: 0.0315\n",
      "epoch 30 loss: 0.0331\n",
      "54\n",
      "epoch 1 loss: 0.5512\n",
      "epoch 2 loss: 0.5328\n",
      "epoch 3 loss: 0.4990\n",
      "epoch 4 loss: 0.4456\n",
      "epoch 5 loss: 0.2827\n",
      "epoch 6 loss: 0.1308\n",
      "epoch 7 loss: 0.0731\n",
      "epoch 8 loss: 0.0651\n",
      "epoch 9 loss: 0.0535\n",
      "epoch 10 loss: 0.0531\n",
      "epoch 11 loss: 0.0454\n",
      "epoch 12 loss: 0.0474\n",
      "epoch 13 loss: 0.0438\n",
      "epoch 14 loss: 0.0435\n",
      "epoch 15 loss: 0.0410\n",
      "epoch 16 loss: 0.0408\n",
      "epoch 17 loss: 0.0395\n",
      "epoch 18 loss: 0.0411\n",
      "epoch 19 loss: 0.0310\n",
      "epoch 20 loss: 0.0379\n",
      "epoch 21 loss: 0.0411\n",
      "epoch 22 loss: 0.0358\n",
      "epoch 23 loss: 0.0361\n",
      "epoch 24 loss: 0.0352\n",
      "epoch 25 loss: 0.0408\n",
      "epoch 26 loss: 0.0354\n",
      "epoch 27 loss: 0.0360\n",
      "epoch 28 loss: 0.0321\n",
      "epoch 29 loss: 0.0303\n",
      "epoch 30 loss: 0.0323\n",
      "55\n",
      "epoch 1 loss: 0.8243\n",
      "epoch 2 loss: 0.4554\n",
      "epoch 3 loss: 0.4714\n",
      "epoch 4 loss: 0.3508\n",
      "epoch 5 loss: 0.1820\n",
      "epoch 6 loss: 0.1252\n",
      "epoch 7 loss: 0.0713\n",
      "epoch 8 loss: 0.0671\n",
      "epoch 9 loss: 0.0508\n",
      "epoch 10 loss: 0.0519\n",
      "epoch 11 loss: 0.0497\n",
      "epoch 12 loss: 0.0459\n",
      "epoch 13 loss: 0.0430\n",
      "epoch 14 loss: 0.0465\n",
      "epoch 15 loss: 0.0386\n",
      "epoch 16 loss: 0.0370\n",
      "epoch 17 loss: 0.0416\n",
      "epoch 18 loss: 0.0333\n",
      "epoch 19 loss: 0.0397\n",
      "epoch 20 loss: 0.0352\n",
      "epoch 21 loss: 0.0396\n",
      "epoch 22 loss: 0.0355\n",
      "epoch 23 loss: 0.0359\n",
      "epoch 24 loss: 0.0315\n",
      "epoch 25 loss: 0.0275\n",
      "epoch 26 loss: 0.0319\n",
      "epoch 27 loss: 0.0299\n",
      "epoch 28 loss: 0.0329\n",
      "epoch 29 loss: 0.0312\n",
      "epoch 30 loss: 0.0324\n",
      "56\n",
      "epoch 1 loss: 0.9464\n",
      "epoch 2 loss: 0.6823\n",
      "epoch 3 loss: 0.4543\n",
      "epoch 4 loss: 0.4073\n",
      "epoch 5 loss: 0.3472\n",
      "epoch 6 loss: 0.2131\n",
      "epoch 7 loss: 0.1039\n",
      "epoch 8 loss: 0.0713\n",
      "epoch 9 loss: 0.0691\n",
      "epoch 10 loss: 0.0528\n",
      "epoch 11 loss: 0.0482\n",
      "epoch 12 loss: 0.0532\n",
      "epoch 13 loss: 0.0447\n",
      "epoch 14 loss: 0.0435\n",
      "epoch 15 loss: 0.0406\n",
      "epoch 16 loss: 0.0422\n",
      "epoch 17 loss: 0.0440\n",
      "epoch 18 loss: 0.0429\n",
      "epoch 19 loss: 0.0391\n",
      "epoch 20 loss: 0.0386\n",
      "epoch 21 loss: 0.0419\n",
      "epoch 22 loss: 0.0392\n",
      "epoch 23 loss: 0.0373\n",
      "epoch 24 loss: 0.0397\n",
      "epoch 25 loss: 0.0390\n",
      "epoch 26 loss: 0.0352\n",
      "epoch 27 loss: 0.0327\n",
      "epoch 28 loss: 0.0416\n",
      "epoch 29 loss: 0.0320\n",
      "epoch 30 loss: 0.0333\n",
      "57\n",
      "epoch 1 loss: 0.7539\n",
      "epoch 2 loss: 0.5365\n",
      "epoch 3 loss: 0.4209\n",
      "epoch 4 loss: 0.4634\n",
      "epoch 5 loss: 0.3307\n",
      "epoch 6 loss: 0.3153\n",
      "epoch 7 loss: 0.1664\n",
      "epoch 8 loss: 0.1178\n",
      "epoch 9 loss: 0.0822\n",
      "epoch 10 loss: 0.0666\n",
      "epoch 11 loss: 0.0548\n",
      "epoch 12 loss: 0.0555\n",
      "epoch 13 loss: 0.0525\n",
      "epoch 14 loss: 0.0450\n",
      "epoch 15 loss: 0.0441\n",
      "epoch 16 loss: 0.0490\n",
      "epoch 17 loss: 0.0441\n",
      "epoch 18 loss: 0.0375\n",
      "epoch 19 loss: 0.0421\n",
      "epoch 20 loss: 0.0421\n",
      "epoch 21 loss: 0.0378\n",
      "epoch 22 loss: 0.0348\n",
      "epoch 23 loss: 0.0369\n",
      "epoch 24 loss: 0.0371\n",
      "epoch 25 loss: 0.0371\n",
      "epoch 26 loss: 0.0385\n",
      "epoch 27 loss: 0.0354\n",
      "epoch 28 loss: 0.0335\n",
      "epoch 29 loss: 0.0374\n",
      "epoch 30 loss: 0.0329\n",
      "58\n",
      "epoch 1 loss: 0.7798\n",
      "epoch 2 loss: 0.4192\n",
      "epoch 3 loss: 0.2766\n",
      "epoch 4 loss: 0.1628\n",
      "epoch 5 loss: 0.1193\n",
      "epoch 6 loss: 0.0804\n",
      "epoch 7 loss: 0.0649\n",
      "epoch 8 loss: 0.0593\n",
      "epoch 9 loss: 0.0533\n",
      "epoch 10 loss: 0.0540\n",
      "epoch 11 loss: 0.0490\n",
      "epoch 12 loss: 0.0448\n",
      "epoch 13 loss: 0.0460\n",
      "epoch 14 loss: 0.0431\n",
      "epoch 15 loss: 0.0391\n",
      "epoch 16 loss: 0.0359\n",
      "epoch 17 loss: 0.0366\n",
      "epoch 18 loss: 0.0396\n",
      "epoch 19 loss: 0.0373\n",
      "epoch 20 loss: 0.0375\n",
      "epoch 21 loss: 0.0360\n",
      "epoch 22 loss: 0.0375\n",
      "epoch 23 loss: 0.0351\n",
      "epoch 24 loss: 0.0342\n",
      "epoch 25 loss: 0.0337\n",
      "epoch 26 loss: 0.0334\n",
      "epoch 27 loss: 0.0391\n",
      "epoch 28 loss: 0.0331\n",
      "epoch 29 loss: 0.0331\n",
      "epoch 30 loss: 0.0312\n",
      "59\n",
      "epoch 1 loss: 1.0076\n",
      "epoch 2 loss: 0.4351\n",
      "epoch 3 loss: 0.2436\n",
      "epoch 4 loss: 0.1886\n",
      "epoch 5 loss: 0.2158\n",
      "epoch 6 loss: 0.1496\n",
      "epoch 7 loss: 0.1055\n",
      "epoch 8 loss: 0.0787\n",
      "epoch 9 loss: 0.0722\n",
      "epoch 10 loss: 0.0572\n",
      "epoch 11 loss: 0.0516\n",
      "epoch 12 loss: 0.0504\n",
      "epoch 13 loss: 0.0514\n",
      "epoch 14 loss: 0.0449\n",
      "epoch 15 loss: 0.0475\n",
      "epoch 16 loss: 0.0409\n",
      "epoch 17 loss: 0.0464\n",
      "epoch 18 loss: 0.0434\n",
      "epoch 19 loss: 0.0410\n",
      "epoch 20 loss: 0.0517\n",
      "epoch 21 loss: 0.0437\n",
      "epoch 22 loss: 0.0410\n",
      "epoch 23 loss: 0.0379\n",
      "epoch 24 loss: 0.0387\n",
      "epoch 25 loss: 0.0380\n",
      "epoch 26 loss: 0.0342\n",
      "epoch 27 loss: 0.0312\n",
      "epoch 28 loss: 0.0352\n",
      "epoch 29 loss: 0.0388\n",
      "epoch 30 loss: 0.0367\n",
      "60\n",
      "epoch 1 loss: 0.7422\n",
      "epoch 2 loss: 0.4965\n",
      "epoch 3 loss: 0.3953\n",
      "epoch 4 loss: 0.2317\n",
      "epoch 5 loss: 0.1098\n",
      "epoch 6 loss: 0.0947\n",
      "epoch 7 loss: 0.0573\n",
      "epoch 8 loss: 0.0578\n",
      "epoch 9 loss: 0.0562\n",
      "epoch 10 loss: 0.0468\n",
      "epoch 11 loss: 0.0483\n",
      "epoch 12 loss: 0.0429\n",
      "epoch 13 loss: 0.0349\n",
      "epoch 14 loss: 0.0434\n",
      "epoch 15 loss: 0.0413\n",
      "epoch 16 loss: 0.0359\n",
      "epoch 17 loss: 0.0387\n",
      "epoch 18 loss: 0.0374\n",
      "epoch 19 loss: 0.0405\n",
      "epoch 20 loss: 0.0335\n",
      "epoch 21 loss: 0.0360\n",
      "epoch 22 loss: 0.0363\n",
      "epoch 23 loss: 0.0326\n",
      "epoch 24 loss: 0.0303\n",
      "epoch 25 loss: 0.0350\n",
      "epoch 26 loss: 0.0308\n",
      "epoch 27 loss: 0.0333\n",
      "epoch 28 loss: 0.0316\n",
      "epoch 29 loss: 0.0314\n",
      "epoch 30 loss: 0.0295\n",
      "61\n",
      "epoch 1 loss: 0.9182\n",
      "epoch 2 loss: 0.5010\n",
      "epoch 3 loss: 0.3747\n",
      "epoch 4 loss: 0.2979\n",
      "epoch 5 loss: 0.1307\n",
      "epoch 6 loss: 0.0640\n",
      "epoch 7 loss: 0.0666\n",
      "epoch 8 loss: 0.0566\n",
      "epoch 9 loss: 0.0499\n",
      "epoch 10 loss: 0.0559\n",
      "epoch 11 loss: 0.0479\n",
      "epoch 12 loss: 0.0477\n",
      "epoch 13 loss: 0.0442\n",
      "epoch 14 loss: 0.0417\n",
      "epoch 15 loss: 0.0381\n",
      "epoch 16 loss: 0.0473\n",
      "epoch 17 loss: 0.0414\n",
      "epoch 18 loss: 0.0356\n",
      "epoch 19 loss: 0.0425\n",
      "epoch 20 loss: 0.0367\n",
      "epoch 21 loss: 0.0421\n",
      "epoch 22 loss: 0.0378\n",
      "epoch 23 loss: 0.0371\n",
      "epoch 24 loss: 0.0367\n",
      "epoch 25 loss: 0.0364\n",
      "epoch 26 loss: 0.0394\n",
      "epoch 27 loss: 0.0371\n",
      "epoch 28 loss: 0.0346\n",
      "epoch 29 loss: 0.0406\n",
      "epoch 30 loss: 0.0353\n",
      "62\n",
      "epoch 1 loss: 0.9298\n",
      "epoch 2 loss: 0.5979\n",
      "epoch 3 loss: 0.5856\n",
      "epoch 4 loss: 0.4801\n",
      "epoch 5 loss: 0.4666\n",
      "epoch 6 loss: 0.4517\n",
      "epoch 7 loss: 0.2851\n",
      "epoch 8 loss: 0.2120\n",
      "epoch 9 loss: 0.0892\n",
      "epoch 10 loss: 0.0730\n",
      "epoch 11 loss: 0.0593\n",
      "epoch 12 loss: 0.0590\n",
      "epoch 13 loss: 0.0465\n",
      "epoch 14 loss: 0.0436\n",
      "epoch 15 loss: 0.0494\n",
      "epoch 16 loss: 0.0452\n",
      "epoch 17 loss: 0.0448\n",
      "epoch 18 loss: 0.0341\n",
      "epoch 19 loss: 0.0396\n",
      "epoch 20 loss: 0.0391\n",
      "epoch 21 loss: 0.0389\n",
      "epoch 22 loss: 0.0354\n",
      "epoch 23 loss: 0.0382\n",
      "epoch 24 loss: 0.0364\n",
      "epoch 25 loss: 0.0401\n",
      "epoch 26 loss: 0.0341\n",
      "epoch 27 loss: 0.0319\n",
      "epoch 28 loss: 0.0329\n",
      "epoch 29 loss: 0.0334\n",
      "epoch 30 loss: 0.0356\n",
      "63\n",
      "epoch 1 loss: 0.7137\n",
      "epoch 2 loss: 0.5528\n",
      "epoch 3 loss: 0.6718\n",
      "epoch 4 loss: 0.4927\n",
      "epoch 5 loss: 0.4913\n",
      "epoch 6 loss: 0.4710\n",
      "epoch 7 loss: 0.2177\n",
      "epoch 8 loss: 0.1258\n",
      "epoch 9 loss: 0.0941\n",
      "epoch 10 loss: 0.0732\n",
      "epoch 11 loss: 0.0532\n",
      "epoch 12 loss: 0.0551\n",
      "epoch 13 loss: 0.0476\n",
      "epoch 14 loss: 0.0436\n",
      "epoch 15 loss: 0.0420\n",
      "epoch 16 loss: 0.0434\n",
      "epoch 17 loss: 0.0395\n",
      "epoch 18 loss: 0.0414\n",
      "epoch 19 loss: 0.0340\n",
      "epoch 20 loss: 0.0389\n",
      "epoch 21 loss: 0.0421\n",
      "epoch 22 loss: 0.0402\n",
      "epoch 23 loss: 0.0356\n",
      "epoch 24 loss: 0.0368\n",
      "epoch 25 loss: 0.0376\n",
      "epoch 26 loss: 0.0333\n",
      "epoch 27 loss: 0.0413\n",
      "epoch 28 loss: 0.0329\n",
      "epoch 29 loss: 0.0347\n",
      "epoch 30 loss: 0.0365\n",
      "64\n",
      "epoch 1 loss: 0.9870\n",
      "epoch 2 loss: 0.6512\n",
      "epoch 3 loss: 0.3546\n",
      "epoch 4 loss: 0.2639\n",
      "epoch 5 loss: 0.1913\n",
      "epoch 6 loss: 0.2306\n",
      "epoch 7 loss: 0.0961\n",
      "epoch 8 loss: 0.0820\n",
      "epoch 9 loss: 0.0741\n",
      "epoch 10 loss: 0.0595\n",
      "epoch 11 loss: 0.0600\n",
      "epoch 12 loss: 0.0603\n",
      "epoch 13 loss: 0.0573\n",
      "epoch 14 loss: 0.0487\n",
      "epoch 15 loss: 0.0541\n",
      "epoch 16 loss: 0.0484\n",
      "epoch 17 loss: 0.0448\n",
      "epoch 18 loss: 0.0394\n",
      "epoch 19 loss: 0.0466\n",
      "epoch 20 loss: 0.0425\n",
      "epoch 21 loss: 0.0372\n",
      "epoch 22 loss: 0.0425\n",
      "epoch 23 loss: 0.0321\n",
      "epoch 24 loss: 0.0432\n",
      "epoch 25 loss: 0.0412\n",
      "epoch 26 loss: 0.0375\n",
      "epoch 27 loss: 0.0403\n",
      "epoch 28 loss: 0.0395\n",
      "epoch 29 loss: 0.0359\n",
      "epoch 30 loss: 0.0334\n",
      "65\n",
      "epoch 1 loss: 0.8875\n",
      "epoch 2 loss: 0.5515\n",
      "epoch 3 loss: 0.4544\n",
      "epoch 4 loss: 0.3803\n",
      "epoch 5 loss: 0.1871\n",
      "epoch 6 loss: 0.1092\n",
      "epoch 7 loss: 0.0669\n",
      "epoch 8 loss: 0.0609\n",
      "epoch 9 loss: 0.0591\n",
      "epoch 10 loss: 0.0518\n",
      "epoch 11 loss: 0.0499\n",
      "epoch 12 loss: 0.0466\n",
      "epoch 13 loss: 0.0481\n",
      "epoch 14 loss: 0.0462\n",
      "epoch 15 loss: 0.0417\n",
      "epoch 16 loss: 0.0444\n",
      "epoch 17 loss: 0.0409\n",
      "epoch 18 loss: 0.0389\n",
      "epoch 19 loss: 0.0398\n",
      "epoch 20 loss: 0.0364\n",
      "epoch 21 loss: 0.0405\n",
      "epoch 22 loss: 0.0347\n",
      "epoch 23 loss: 0.0346\n",
      "epoch 24 loss: 0.0337\n",
      "epoch 25 loss: 0.0377\n",
      "epoch 26 loss: 0.0288\n",
      "epoch 27 loss: 0.0341\n",
      "epoch 28 loss: 0.0305\n",
      "epoch 29 loss: 0.0310\n",
      "epoch 30 loss: 0.0340\n",
      "66\n",
      "epoch 1 loss: 0.9833\n",
      "epoch 2 loss: 0.5923\n",
      "epoch 3 loss: 0.4347\n",
      "epoch 4 loss: 0.2682\n",
      "epoch 5 loss: 0.1231\n",
      "epoch 6 loss: 0.0863\n",
      "epoch 7 loss: 0.0649\n",
      "epoch 8 loss: 0.0578\n",
      "epoch 9 loss: 0.0607\n",
      "epoch 10 loss: 0.0488\n",
      "epoch 11 loss: 0.0449\n",
      "epoch 12 loss: 0.0446\n",
      "epoch 13 loss: 0.0442\n",
      "epoch 14 loss: 0.0405\n",
      "epoch 15 loss: 0.0430\n",
      "epoch 16 loss: 0.0381\n",
      "epoch 17 loss: 0.0377\n",
      "epoch 18 loss: 0.0362\n",
      "epoch 19 loss: 0.0359\n",
      "epoch 20 loss: 0.0368\n",
      "epoch 21 loss: 0.0312\n",
      "epoch 22 loss: 0.0364\n",
      "epoch 23 loss: 0.0344\n",
      "epoch 24 loss: 0.0330\n",
      "epoch 25 loss: 0.0342\n",
      "epoch 26 loss: 0.0352\n",
      "epoch 27 loss: 0.0315\n",
      "epoch 28 loss: 0.0332\n",
      "epoch 29 loss: 0.0289\n",
      "epoch 30 loss: 0.0326\n",
      "67\n",
      "epoch 1 loss: 0.8913\n",
      "epoch 2 loss: 0.6096\n",
      "epoch 3 loss: 0.5011\n",
      "epoch 4 loss: 0.3655\n",
      "epoch 5 loss: 0.2351\n",
      "epoch 6 loss: 0.1177\n",
      "epoch 7 loss: 0.0815\n",
      "epoch 8 loss: 0.0561\n",
      "epoch 9 loss: 0.0535\n",
      "epoch 10 loss: 0.0549\n",
      "epoch 11 loss: 0.0468\n",
      "epoch 12 loss: 0.0434\n",
      "epoch 13 loss: 0.0442\n",
      "epoch 14 loss: 0.0420\n",
      "epoch 15 loss: 0.0365\n",
      "epoch 16 loss: 0.0381\n",
      "epoch 17 loss: 0.0362\n",
      "epoch 18 loss: 0.0400\n",
      "epoch 19 loss: 0.0356\n",
      "epoch 20 loss: 0.0439\n",
      "epoch 21 loss: 0.0406\n",
      "epoch 22 loss: 0.0355\n",
      "epoch 23 loss: 0.0354\n",
      "epoch 24 loss: 0.0326\n",
      "epoch 25 loss: 0.0391\n",
      "epoch 26 loss: 0.0331\n",
      "epoch 27 loss: 0.0308\n",
      "epoch 28 loss: 0.0364\n",
      "epoch 29 loss: 0.0359\n",
      "epoch 30 loss: 0.0319\n",
      "68\n",
      "epoch 1 loss: 0.8380\n",
      "epoch 2 loss: 0.5628\n",
      "epoch 3 loss: 0.3425\n",
      "epoch 4 loss: 0.2139\n",
      "epoch 5 loss: 0.1248\n",
      "epoch 6 loss: 0.0689\n",
      "epoch 7 loss: 0.0600\n",
      "epoch 8 loss: 0.0519\n",
      "epoch 9 loss: 0.0534\n",
      "epoch 10 loss: 0.0493\n",
      "epoch 11 loss: 0.0458\n",
      "epoch 12 loss: 0.0448\n",
      "epoch 13 loss: 0.0477\n",
      "epoch 14 loss: 0.0470\n",
      "epoch 15 loss: 0.0422\n",
      "epoch 16 loss: 0.0390\n",
      "epoch 17 loss: 0.0392\n",
      "epoch 18 loss: 0.0442\n",
      "epoch 19 loss: 0.0404\n",
      "epoch 20 loss: 0.0375\n",
      "epoch 21 loss: 0.0414\n",
      "epoch 22 loss: 0.0394\n",
      "epoch 23 loss: 0.0329\n",
      "epoch 24 loss: 0.0396\n",
      "epoch 25 loss: 0.0366\n",
      "epoch 26 loss: 0.0322\n",
      "epoch 27 loss: 0.0378\n",
      "epoch 28 loss: 0.0359\n",
      "epoch 29 loss: 0.0320\n",
      "epoch 30 loss: 0.0405\n",
      "69\n",
      "epoch 1 loss: 0.8290\n",
      "epoch 2 loss: 0.4167\n",
      "epoch 3 loss: 0.3452\n",
      "epoch 4 loss: 0.2129\n",
      "epoch 5 loss: 0.1214\n",
      "epoch 6 loss: 0.0746\n",
      "epoch 7 loss: 0.0595\n",
      "epoch 8 loss: 0.0447\n",
      "epoch 9 loss: 0.0482\n",
      "epoch 10 loss: 0.0420\n",
      "epoch 11 loss: 0.0406\n",
      "epoch 12 loss: 0.0430\n",
      "epoch 13 loss: 0.0410\n",
      "epoch 14 loss: 0.0402\n",
      "epoch 15 loss: 0.0374\n",
      "epoch 16 loss: 0.0380\n",
      "epoch 17 loss: 0.0388\n",
      "epoch 18 loss: 0.0376\n",
      "epoch 19 loss: 0.0364\n",
      "epoch 20 loss: 0.0356\n",
      "epoch 21 loss: 0.0354\n",
      "epoch 22 loss: 0.0366\n",
      "epoch 23 loss: 0.0299\n",
      "epoch 24 loss: 0.0351\n",
      "epoch 25 loss: 0.0335\n",
      "epoch 26 loss: 0.0348\n",
      "epoch 27 loss: 0.0302\n",
      "epoch 28 loss: 0.0317\n",
      "epoch 29 loss: 0.0280\n",
      "epoch 30 loss: 0.0330\n",
      "70\n",
      "epoch 1 loss: 0.7442\n",
      "epoch 2 loss: 0.5381\n",
      "epoch 3 loss: 0.3618\n",
      "epoch 4 loss: 0.2834\n",
      "epoch 5 loss: 0.1778\n",
      "epoch 6 loss: 0.0993\n",
      "epoch 7 loss: 0.0758\n",
      "epoch 8 loss: 0.0532\n",
      "epoch 9 loss: 0.0582\n",
      "epoch 10 loss: 0.0454\n",
      "epoch 11 loss: 0.0453\n",
      "epoch 12 loss: 0.0488\n",
      "epoch 13 loss: 0.0481\n",
      "epoch 14 loss: 0.0443\n",
      "epoch 15 loss: 0.0396\n",
      "epoch 16 loss: 0.0460\n",
      "epoch 17 loss: 0.0414\n",
      "epoch 18 loss: 0.0443\n",
      "epoch 19 loss: 0.0345\n",
      "epoch 20 loss: 0.0377\n",
      "epoch 21 loss: 0.0357\n",
      "epoch 22 loss: 0.0406\n",
      "epoch 23 loss: 0.0375\n",
      "epoch 24 loss: 0.0367\n",
      "epoch 25 loss: 0.0360\n",
      "epoch 26 loss: 0.0342\n",
      "epoch 27 loss: 0.0301\n",
      "epoch 28 loss: 0.0318\n",
      "epoch 29 loss: 0.0290\n",
      "epoch 30 loss: 0.0333\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN_based asym",
   "id": "54d537e510ff3d03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_asym_feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_asy_con = pd.concat([results_aep_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_asy_con.to_csv(out_dir + '/results_aep_asy_con.csv', index=False)"
   ],
   "id": "11bc72e4cced646e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN_based ARMA",
   "id": "6a504d406fd2c7bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T23:07:14.885528Z",
     "start_time": "2025-10-05T22:31:20.280932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"cpu\"))\n",
    "results_arma_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2012-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2016-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_dayton.loc[(df_dayton['ds'] >= date_start) & (df_dayton['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_ARMA_Feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_arma_asy_con.to_csv(out_dir + '/results_arma_asy_con.csv', index=False)"
   ],
   "id": "e3e66e64470977a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch 1 loss: 0.9063093662261963\n",
      "epoch 2 loss: 0.7988590002059937\n",
      "epoch 3 loss: 0.5741066336631775\n",
      "epoch 4 loss: 0.2885330021381378\n",
      "epoch 5 loss: 0.21454750001430511\n",
      "epoch 6 loss: 0.20374540984630585\n",
      "epoch 7 loss: 0.1941135674715042\n",
      "epoch 8 loss: 0.17433108389377594\n",
      "epoch 9 loss: 0.14477458596229553\n",
      "epoch 10 loss: 0.17582978308200836\n",
      "epoch 11 loss: 0.17898468673229218\n",
      "epoch 12 loss: 0.21747632324695587\n",
      "epoch 13 loss: 0.1677086353302002\n",
      "epoch 14 loss: 0.13787588477134705\n",
      "epoch 15 loss: 0.1399587094783783\n",
      "epoch 16 loss: 0.17527788877487183\n",
      "epoch 17 loss: 0.16200247406959534\n",
      "epoch 18 loss: 0.1854562908411026\n",
      "epoch 19 loss: 0.15550781786441803\n",
      "epoch 20 loss: 0.14332781732082367\n",
      "epoch 21 loss: 0.14922268688678741\n",
      "epoch 22 loss: 0.1540570706129074\n",
      "epoch 23 loss: 0.17009201645851135\n",
      "epoch 24 loss: 0.20749840140342712\n",
      "epoch 25 loss: 0.13101047277450562\n",
      "epoch 26 loss: 0.15898671746253967\n",
      "epoch 27 loss: 0.16281916201114655\n",
      "epoch 28 loss: 0.16499316692352295\n",
      "epoch 29 loss: 0.1560157835483551\n",
      "epoch 30 loss: 0.19587038457393646\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/5yfj7yqx7lg98t310bfxxr3m0000gn/T/ipykernel_93068/255380348.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.8459588885307312\n",
      "epoch 2 loss: 0.6910005807876587\n",
      "epoch 3 loss: 0.4289501905441284\n",
      "epoch 4 loss: 0.2912578880786896\n",
      "epoch 5 loss: 0.20985087752342224\n",
      "epoch 6 loss: 0.20772825181484222\n",
      "epoch 7 loss: 0.1831783503293991\n",
      "epoch 8 loss: 0.15163955092430115\n",
      "epoch 9 loss: 0.16631698608398438\n",
      "epoch 10 loss: 0.17010140419006348\n",
      "epoch 11 loss: 0.14488977193832397\n",
      "epoch 12 loss: 0.19249531626701355\n",
      "epoch 13 loss: 0.16921448707580566\n",
      "epoch 14 loss: 0.16856977343559265\n",
      "epoch 15 loss: 0.16423960030078888\n",
      "epoch 16 loss: 0.18675602972507477\n",
      "epoch 17 loss: 0.17042726278305054\n",
      "epoch 18 loss: 0.18878597021102905\n",
      "epoch 19 loss: 0.1682056039571762\n",
      "epoch 20 loss: 0.21171049773693085\n",
      "epoch 21 loss: 0.18556520342826843\n",
      "epoch 22 loss: 0.17035695910453796\n",
      "epoch 23 loss: 0.14302076399326324\n",
      "epoch 24 loss: 0.14267580211162567\n",
      "epoch 25 loss: 0.1567109376192093\n",
      "epoch 26 loss: 0.13973349332809448\n",
      "epoch 27 loss: 0.14100608229637146\n",
      "epoch 28 loss: 0.1488053798675537\n",
      "epoch 29 loss: 0.1407739222049713\n",
      "epoch 30 loss: 0.15517722070217133\n",
      "3\n",
      "epoch 1 loss: 0.746414065361023\n",
      "epoch 2 loss: 0.7922227382659912\n",
      "epoch 3 loss: 0.6087497472763062\n",
      "epoch 4 loss: 0.3333801329135895\n",
      "epoch 5 loss: 0.16182473301887512\n",
      "epoch 6 loss: 0.18402551114559174\n",
      "epoch 7 loss: 0.2081947922706604\n",
      "epoch 8 loss: 0.19024302065372467\n",
      "epoch 9 loss: 0.1659356653690338\n",
      "epoch 10 loss: 0.14111438393592834\n",
      "epoch 11 loss: 0.20369067788124084\n",
      "epoch 12 loss: 0.17324568331241608\n",
      "epoch 13 loss: 0.15539664030075073\n",
      "epoch 14 loss: 0.15425030887126923\n",
      "epoch 15 loss: 0.17157621681690216\n",
      "epoch 16 loss: 0.20296965539455414\n",
      "epoch 17 loss: 0.17788295447826385\n",
      "epoch 18 loss: 0.14040100574493408\n",
      "epoch 19 loss: 0.16790372133255005\n",
      "epoch 20 loss: 0.15959008038043976\n",
      "epoch 21 loss: 0.152289018034935\n",
      "epoch 22 loss: 0.14526009559631348\n",
      "epoch 23 loss: 0.15139377117156982\n",
      "epoch 24 loss: 0.16667713224887848\n",
      "epoch 25 loss: 0.20053447782993317\n",
      "epoch 26 loss: 0.1491757333278656\n",
      "epoch 27 loss: 0.16094143688678741\n",
      "epoch 28 loss: 0.16713659465312958\n",
      "epoch 29 loss: 0.16723522543907166\n",
      "epoch 30 loss: 0.17370213568210602\n",
      "4\n",
      "epoch 1 loss: 0.9485737681388855\n",
      "epoch 2 loss: 0.7091113328933716\n",
      "epoch 3 loss: 0.5163787603378296\n",
      "epoch 4 loss: 0.28179654479026794\n",
      "epoch 5 loss: 0.22551533579826355\n",
      "epoch 6 loss: 0.18773695826530457\n",
      "epoch 7 loss: 0.2452610433101654\n",
      "epoch 8 loss: 0.17544014751911163\n",
      "epoch 9 loss: 0.18197347223758698\n",
      "epoch 10 loss: 0.18599504232406616\n",
      "epoch 11 loss: 0.17124854028224945\n",
      "epoch 12 loss: 0.17591802775859833\n",
      "epoch 13 loss: 0.19004452228546143\n",
      "epoch 14 loss: 0.18054035305976868\n",
      "epoch 15 loss: 0.18615905940532684\n",
      "epoch 16 loss: 0.1814853399991989\n",
      "epoch 17 loss: 0.16593784093856812\n",
      "epoch 18 loss: 0.1914641559123993\n",
      "epoch 19 loss: 0.1838797628879547\n",
      "epoch 20 loss: 0.12812720239162445\n",
      "epoch 21 loss: 0.17926304042339325\n",
      "epoch 22 loss: 0.2069520801305771\n",
      "epoch 23 loss: 0.16004841029644012\n",
      "epoch 24 loss: 0.16573689877986908\n",
      "epoch 25 loss: 0.15013718605041504\n",
      "epoch 26 loss: 0.17748507857322693\n",
      "epoch 27 loss: 0.19416162371635437\n",
      "epoch 28 loss: 0.17604337632656097\n",
      "epoch 29 loss: 0.16795854270458221\n",
      "epoch 30 loss: 0.2161693572998047\n",
      "5\n",
      "epoch 1 loss: 0.7650755643844604\n",
      "epoch 2 loss: 0.6780153512954712\n",
      "epoch 3 loss: 0.4876379370689392\n",
      "epoch 4 loss: 0.2869628369808197\n",
      "epoch 5 loss: 0.2065567672252655\n",
      "epoch 6 loss: 0.21221758425235748\n",
      "epoch 7 loss: 0.1467732936143875\n",
      "epoch 8 loss: 0.19440245628356934\n",
      "epoch 9 loss: 0.20630483329296112\n",
      "epoch 10 loss: 0.1851399689912796\n",
      "epoch 11 loss: 0.17771130800247192\n",
      "epoch 12 loss: 0.16097350418567657\n",
      "epoch 13 loss: 0.14541743695735931\n",
      "epoch 14 loss: 0.19688817858695984\n",
      "epoch 15 loss: 0.12657606601715088\n",
      "epoch 16 loss: 0.13011030852794647\n",
      "epoch 17 loss: 0.16609270870685577\n",
      "epoch 18 loss: 0.19532322883605957\n",
      "epoch 19 loss: 0.15683795511722565\n",
      "epoch 20 loss: 0.17693324387073517\n",
      "epoch 21 loss: 0.1607152372598648\n",
      "epoch 22 loss: 0.169397234916687\n",
      "epoch 23 loss: 0.2046061009168625\n",
      "epoch 24 loss: 0.1794186532497406\n",
      "epoch 25 loss: 0.17312492430210114\n",
      "epoch 26 loss: 0.1835668683052063\n",
      "epoch 27 loss: 0.14826005697250366\n",
      "epoch 28 loss: 0.1398768275976181\n",
      "epoch 29 loss: 0.1786622554063797\n",
      "epoch 30 loss: 0.17018356919288635\n",
      "6\n",
      "epoch 1 loss: 0.8639441728591919\n",
      "epoch 2 loss: 0.7271302342414856\n",
      "epoch 3 loss: 0.5786683559417725\n",
      "epoch 4 loss: 0.35172104835510254\n",
      "epoch 5 loss: 0.2600218653678894\n",
      "epoch 6 loss: 0.15206898748874664\n",
      "epoch 7 loss: 0.1493203043937683\n",
      "epoch 8 loss: 0.20548588037490845\n",
      "epoch 9 loss: 0.18875496089458466\n",
      "epoch 10 loss: 0.14999797940254211\n",
      "epoch 11 loss: 0.16256803274154663\n",
      "epoch 12 loss: 0.19796143472194672\n",
      "epoch 13 loss: 0.16582289338111877\n",
      "epoch 14 loss: 0.15453456342220306\n",
      "epoch 15 loss: 0.1561255007982254\n",
      "epoch 16 loss: 0.1597214937210083\n",
      "epoch 17 loss: 0.15074989199638367\n",
      "epoch 18 loss: 0.16641533374786377\n",
      "epoch 19 loss: 0.18039104342460632\n",
      "epoch 20 loss: 0.20200783014297485\n",
      "epoch 21 loss: 0.15782488882541656\n",
      "epoch 22 loss: 0.14808432757854462\n",
      "epoch 23 loss: 0.15000911056995392\n",
      "epoch 24 loss: 0.1527959108352661\n",
      "epoch 25 loss: 0.1796342134475708\n",
      "epoch 26 loss: 0.153904989361763\n",
      "epoch 27 loss: 0.12961897253990173\n",
      "epoch 28 loss: 0.1649954915046692\n",
      "epoch 29 loss: 0.17580698430538177\n",
      "epoch 30 loss: 0.12543494999408722\n",
      "7\n",
      "epoch 1 loss: 0.8726181983947754\n",
      "epoch 2 loss: 0.6502829790115356\n",
      "epoch 3 loss: 0.38822513818740845\n",
      "epoch 4 loss: 0.32824209332466125\n",
      "epoch 5 loss: 0.2565821707248688\n",
      "epoch 6 loss: 0.21715354919433594\n",
      "epoch 7 loss: 0.18291349709033966\n",
      "epoch 8 loss: 0.21558977663516998\n",
      "epoch 9 loss: 0.20217299461364746\n",
      "epoch 10 loss: 0.20358404517173767\n",
      "epoch 11 loss: 0.17581485211849213\n",
      "epoch 12 loss: 0.1739521324634552\n",
      "epoch 13 loss: 0.21896813809871674\n",
      "epoch 14 loss: 0.19950726628303528\n",
      "epoch 15 loss: 0.15746819972991943\n",
      "epoch 16 loss: 0.169734925031662\n",
      "epoch 17 loss: 0.21286460757255554\n",
      "epoch 18 loss: 0.16985705494880676\n",
      "epoch 19 loss: 0.18206363916397095\n",
      "epoch 20 loss: 0.13928665220737457\n",
      "epoch 21 loss: 0.18379060924053192\n",
      "epoch 22 loss: 0.17408110201358795\n",
      "epoch 23 loss: 0.16793832182884216\n",
      "epoch 24 loss: 0.16889458894729614\n",
      "epoch 25 loss: 0.19831933081150055\n",
      "epoch 26 loss: 0.19119621813297272\n",
      "epoch 27 loss: 0.15954242646694183\n",
      "epoch 28 loss: 0.17296548187732697\n",
      "epoch 29 loss: 0.17810216546058655\n",
      "epoch 30 loss: 0.16775427758693695\n",
      "8\n",
      "epoch 1 loss: 0.9332137107849121\n",
      "epoch 2 loss: 0.8472896218299866\n",
      "epoch 3 loss: 0.4781501889228821\n",
      "epoch 4 loss: 0.3791545033454895\n",
      "epoch 5 loss: 0.2013857215642929\n",
      "epoch 6 loss: 0.17562977969646454\n",
      "epoch 7 loss: 0.15462738275527954\n",
      "epoch 8 loss: 0.17378965020179749\n",
      "epoch 9 loss: 0.16414481401443481\n",
      "epoch 10 loss: 0.19123058021068573\n",
      "epoch 11 loss: 0.15261493623256683\n",
      "epoch 12 loss: 0.17041389644145966\n",
      "epoch 13 loss: 0.1615700125694275\n",
      "epoch 14 loss: 0.1657962203025818\n",
      "epoch 15 loss: 0.17085452377796173\n",
      "epoch 16 loss: 0.17644351720809937\n",
      "epoch 17 loss: 0.16003848612308502\n",
      "epoch 18 loss: 0.162411630153656\n",
      "epoch 19 loss: 0.142912358045578\n",
      "epoch 20 loss: 0.1462719589471817\n",
      "epoch 21 loss: 0.202203631401062\n",
      "epoch 22 loss: 0.16350886225700378\n",
      "epoch 23 loss: 0.1557115763425827\n",
      "epoch 24 loss: 0.179729625582695\n",
      "epoch 25 loss: 0.14380839467048645\n",
      "epoch 26 loss: 0.16442763805389404\n",
      "epoch 27 loss: 0.15597794950008392\n",
      "epoch 28 loss: 0.15553638339042664\n",
      "epoch 29 loss: 0.1621035635471344\n",
      "epoch 30 loss: 0.1607663631439209\n",
      "9\n",
      "epoch 1 loss: 0.9046755433082581\n",
      "epoch 2 loss: 0.7398247122764587\n",
      "epoch 3 loss: 0.5944474339485168\n",
      "epoch 4 loss: 0.37410178780555725\n",
      "epoch 5 loss: 0.2285439819097519\n",
      "epoch 6 loss: 0.1773783564567566\n",
      "epoch 7 loss: 0.25588899850845337\n",
      "epoch 8 loss: 0.20974062383174896\n",
      "epoch 9 loss: 0.15466780960559845\n",
      "epoch 10 loss: 0.15734823048114777\n",
      "epoch 11 loss: 0.20473843812942505\n",
      "epoch 12 loss: 0.16443996131420135\n",
      "epoch 13 loss: 0.19743506610393524\n",
      "epoch 14 loss: 0.1823883354663849\n",
      "epoch 15 loss: 0.1543828696012497\n",
      "epoch 16 loss: 0.1713598370552063\n",
      "epoch 17 loss: 0.20465709269046783\n",
      "epoch 18 loss: 0.1536121666431427\n",
      "epoch 19 loss: 0.1706661880016327\n",
      "epoch 20 loss: 0.1858965903520584\n",
      "epoch 21 loss: 0.17446331679821014\n",
      "epoch 22 loss: 0.16646721959114075\n",
      "epoch 23 loss: 0.20341749489307404\n",
      "epoch 24 loss: 0.18566906452178955\n",
      "epoch 25 loss: 0.16405953466892242\n",
      "epoch 26 loss: 0.1534031182527542\n",
      "epoch 27 loss: 0.16606773436069489\n",
      "epoch 28 loss: 0.1742200404405594\n",
      "epoch 29 loss: 0.16269667446613312\n",
      "epoch 30 loss: 0.17273131012916565\n",
      "10\n",
      "epoch 1 loss: 0.8335369825363159\n",
      "epoch 2 loss: 0.7406304478645325\n",
      "epoch 3 loss: 0.6363832950592041\n",
      "epoch 4 loss: 0.37135830521583557\n",
      "epoch 5 loss: 0.33728882670402527\n",
      "epoch 6 loss: 0.23339565098285675\n",
      "epoch 7 loss: 0.2055872678756714\n",
      "epoch 8 loss: 0.16287848353385925\n",
      "epoch 9 loss: 0.20087215304374695\n",
      "epoch 10 loss: 0.17753374576568604\n",
      "epoch 11 loss: 0.16194936633110046\n",
      "epoch 12 loss: 0.1531752645969391\n",
      "epoch 13 loss: 0.15993358194828033\n",
      "epoch 14 loss: 0.16972361505031586\n",
      "epoch 15 loss: 0.1516461968421936\n",
      "epoch 16 loss: 0.1747751086950302\n",
      "epoch 17 loss: 0.1913415640592575\n",
      "epoch 18 loss: 0.1968907117843628\n",
      "epoch 19 loss: 0.15378591418266296\n",
      "epoch 20 loss: 0.11871842294931412\n",
      "epoch 21 loss: 0.14980031549930573\n",
      "epoch 22 loss: 0.1803702712059021\n",
      "epoch 23 loss: 0.14999227225780487\n",
      "epoch 24 loss: 0.17589303851127625\n",
      "epoch 25 loss: 0.15204869210720062\n",
      "epoch 26 loss: 0.16691437363624573\n",
      "epoch 27 loss: 0.178030863404274\n",
      "epoch 28 loss: 0.15709304809570312\n",
      "epoch 29 loss: 0.1627691090106964\n",
      "epoch 30 loss: 0.17693497240543365\n",
      "11\n",
      "epoch 1 loss: 0.943272054195404\n",
      "epoch 2 loss: 0.8298788666725159\n",
      "epoch 3 loss: 0.48446571826934814\n",
      "epoch 4 loss: 0.3918530344963074\n",
      "epoch 5 loss: 0.26494336128234863\n",
      "epoch 6 loss: 0.19486600160598755\n",
      "epoch 7 loss: 0.20186872780323029\n",
      "epoch 8 loss: 0.21813049912452698\n",
      "epoch 9 loss: 0.1825435906648636\n",
      "epoch 10 loss: 0.20120365917682648\n",
      "epoch 11 loss: 0.15647509694099426\n",
      "epoch 12 loss: 0.20366841554641724\n",
      "epoch 13 loss: 0.1585547775030136\n",
      "epoch 14 loss: 0.18118219077587128\n",
      "epoch 15 loss: 0.16939276456832886\n",
      "epoch 16 loss: 0.17188921570777893\n",
      "epoch 17 loss: 0.15252737700939178\n",
      "epoch 18 loss: 0.1450861692428589\n",
      "epoch 19 loss: 0.16822156310081482\n",
      "epoch 20 loss: 0.1775224208831787\n",
      "epoch 21 loss: 0.18185700476169586\n",
      "epoch 22 loss: 0.188890278339386\n",
      "epoch 23 loss: 0.14969542622566223\n",
      "epoch 24 loss: 0.15371882915496826\n",
      "epoch 25 loss: 0.19504280388355255\n",
      "epoch 26 loss: 0.16898906230926514\n",
      "epoch 27 loss: 0.12027829140424728\n",
      "epoch 28 loss: 0.1605970859527588\n",
      "epoch 29 loss: 0.15689904987812042\n",
      "epoch 30 loss: 0.1514648199081421\n",
      "12\n",
      "epoch 1 loss: 0.8827732801437378\n",
      "epoch 2 loss: 0.8183514475822449\n",
      "epoch 3 loss: 0.6084603071212769\n",
      "epoch 4 loss: 0.44074851274490356\n",
      "epoch 5 loss: 0.2839208245277405\n",
      "epoch 6 loss: 0.18550799787044525\n",
      "epoch 7 loss: 0.18260182440280914\n",
      "epoch 8 loss: 0.1723642200231552\n",
      "epoch 9 loss: 0.13774120807647705\n",
      "epoch 10 loss: 0.17543931305408478\n",
      "epoch 11 loss: 0.1362573653459549\n",
      "epoch 12 loss: 0.14156228303909302\n",
      "epoch 13 loss: 0.16431686282157898\n",
      "epoch 14 loss: 0.15649302303791046\n",
      "epoch 15 loss: 0.1966918259859085\n",
      "epoch 16 loss: 0.18937508761882782\n",
      "epoch 17 loss: 0.16846853494644165\n",
      "epoch 18 loss: 0.17043891549110413\n",
      "epoch 19 loss: 0.1724015474319458\n",
      "epoch 20 loss: 0.22050869464874268\n",
      "epoch 21 loss: 0.15438120067119598\n",
      "epoch 22 loss: 0.175718292593956\n",
      "epoch 23 loss: 0.16665153205394745\n",
      "epoch 24 loss: 0.18237772583961487\n",
      "epoch 25 loss: 0.16565734148025513\n",
      "epoch 26 loss: 0.15210169553756714\n",
      "epoch 27 loss: 0.17776158452033997\n",
      "epoch 28 loss: 0.16108816862106323\n",
      "epoch 29 loss: 0.1602826565504074\n",
      "epoch 30 loss: 0.15429054200649261\n",
      "13\n",
      "epoch 1 loss: 0.8780273199081421\n",
      "epoch 2 loss: 0.6383116841316223\n",
      "epoch 3 loss: 0.4498870372772217\n",
      "epoch 4 loss: 0.22850440442562103\n",
      "epoch 5 loss: 0.17012301087379456\n",
      "epoch 6 loss: 0.17820090055465698\n",
      "epoch 7 loss: 0.16942235827445984\n",
      "epoch 8 loss: 0.15466736257076263\n",
      "epoch 9 loss: 0.14986956119537354\n",
      "epoch 10 loss: 0.1938280314207077\n",
      "epoch 11 loss: 0.1910841017961502\n",
      "epoch 12 loss: 0.16445070505142212\n",
      "epoch 13 loss: 0.19758561253547668\n",
      "epoch 14 loss: 0.1459200233221054\n",
      "epoch 15 loss: 0.18170183897018433\n",
      "epoch 16 loss: 0.17614468932151794\n",
      "epoch 17 loss: 0.15757398307323456\n",
      "epoch 18 loss: 0.18122918903827667\n",
      "epoch 19 loss: 0.1475868821144104\n",
      "epoch 20 loss: 0.19380956888198853\n",
      "epoch 21 loss: 0.17231284081935883\n",
      "epoch 22 loss: 0.18040278553962708\n",
      "epoch 23 loss: 0.1595313549041748\n",
      "epoch 24 loss: 0.16948199272155762\n",
      "epoch 25 loss: 0.18749567866325378\n",
      "epoch 26 loss: 0.19072997570037842\n",
      "epoch 27 loss: 0.16620053350925446\n",
      "epoch 28 loss: 0.1792009025812149\n",
      "epoch 29 loss: 0.16153626143932343\n",
      "epoch 30 loss: 0.1805374175310135\n",
      "14\n",
      "epoch 1 loss: 0.963516116142273\n",
      "epoch 2 loss: 0.6683235764503479\n",
      "epoch 3 loss: 0.7651786804199219\n",
      "epoch 4 loss: 0.3848299980163574\n",
      "epoch 5 loss: 0.2628173828125\n",
      "epoch 6 loss: 0.23496904969215393\n",
      "epoch 7 loss: 0.19088034331798553\n",
      "epoch 8 loss: 0.12826219201087952\n",
      "epoch 9 loss: 0.16344329714775085\n",
      "epoch 10 loss: 0.17992500960826874\n",
      "epoch 11 loss: 0.22630953788757324\n",
      "epoch 12 loss: 0.1846536099910736\n",
      "epoch 13 loss: 0.14504610002040863\n",
      "epoch 14 loss: 0.1654359996318817\n",
      "epoch 15 loss: 0.16220282018184662\n",
      "epoch 16 loss: 0.1688644140958786\n",
      "epoch 17 loss: 0.17003771662712097\n",
      "epoch 18 loss: 0.206475168466568\n",
      "epoch 19 loss: 0.15752597153186798\n",
      "epoch 20 loss: 0.18598876893520355\n",
      "epoch 21 loss: 0.19533486664295197\n",
      "epoch 22 loss: 0.16048790514469147\n",
      "epoch 23 loss: 0.20140263438224792\n",
      "epoch 24 loss: 0.1480298489332199\n",
      "epoch 25 loss: 0.1662297397851944\n",
      "epoch 26 loss: 0.21693536639213562\n",
      "epoch 27 loss: 0.18694092333316803\n",
      "epoch 28 loss: 0.1628435254096985\n",
      "epoch 29 loss: 0.17149066925048828\n",
      "epoch 30 loss: 0.13137398660182953\n",
      "15\n",
      "epoch 1 loss: 0.9503175616264343\n",
      "epoch 2 loss: 0.7444363832473755\n",
      "epoch 3 loss: 0.3981620669364929\n",
      "epoch 4 loss: 0.2934055030345917\n",
      "epoch 5 loss: 0.1934940069913864\n",
      "epoch 6 loss: 0.17441312968730927\n",
      "epoch 7 loss: 0.1907617598772049\n",
      "epoch 8 loss: 0.192371666431427\n",
      "epoch 9 loss: 0.21336819231510162\n",
      "epoch 10 loss: 0.18016231060028076\n",
      "epoch 11 loss: 0.1708521693944931\n",
      "epoch 12 loss: 0.19836169481277466\n",
      "epoch 13 loss: 0.18717120587825775\n",
      "epoch 14 loss: 0.168072909116745\n",
      "epoch 15 loss: 0.17404046654701233\n",
      "epoch 16 loss: 0.19525648653507233\n",
      "epoch 17 loss: 0.1879245489835739\n",
      "epoch 18 loss: 0.19291502237319946\n",
      "epoch 19 loss: 0.1426696628332138\n",
      "epoch 20 loss: 0.14823713898658752\n",
      "epoch 21 loss: 0.14950531721115112\n",
      "epoch 22 loss: 0.1551731675863266\n",
      "epoch 23 loss: 0.16205891966819763\n",
      "epoch 24 loss: 0.16483086347579956\n",
      "epoch 25 loss: 0.1375552862882614\n",
      "epoch 26 loss: 0.14940579235553741\n",
      "epoch 27 loss: 0.20362968742847443\n",
      "epoch 28 loss: 0.1557164341211319\n",
      "epoch 29 loss: 0.14069688320159912\n",
      "epoch 30 loss: 0.1906878501176834\n",
      "16\n",
      "epoch 1 loss: 0.8543233275413513\n",
      "epoch 2 loss: 0.735644519329071\n",
      "epoch 3 loss: 0.8114960193634033\n",
      "epoch 4 loss: 0.33204159140586853\n",
      "epoch 5 loss: 0.3135922849178314\n",
      "epoch 6 loss: 0.1905926614999771\n",
      "epoch 7 loss: 0.20948243141174316\n",
      "epoch 8 loss: 0.21390300989151\n",
      "epoch 9 loss: 0.161031574010849\n",
      "epoch 10 loss: 0.1889820694923401\n",
      "epoch 11 loss: 0.16066420078277588\n",
      "epoch 12 loss: 0.16847281157970428\n",
      "epoch 13 loss: 0.16306322813034058\n",
      "epoch 14 loss: 0.16336855292320251\n",
      "epoch 15 loss: 0.14212508499622345\n",
      "epoch 16 loss: 0.175264373421669\n",
      "epoch 17 loss: 0.2054746150970459\n",
      "epoch 18 loss: 0.19019193947315216\n",
      "epoch 19 loss: 0.16885089874267578\n",
      "epoch 20 loss: 0.15420058369636536\n",
      "epoch 21 loss: 0.19066369533538818\n",
      "epoch 22 loss: 0.1635422259569168\n",
      "epoch 23 loss: 0.16406245529651642\n",
      "epoch 24 loss: 0.15909549593925476\n",
      "epoch 25 loss: 0.17656628787517548\n",
      "epoch 26 loss: 0.1850842386484146\n",
      "epoch 27 loss: 0.14269043505191803\n",
      "epoch 28 loss: 0.17269417643547058\n",
      "epoch 29 loss: 0.12547998130321503\n",
      "epoch 30 loss: 0.16562731564044952\n",
      "17\n",
      "epoch 1 loss: 0.8347516059875488\n",
      "epoch 2 loss: 0.6324578523635864\n",
      "epoch 3 loss: 0.4990346431732178\n",
      "epoch 4 loss: 0.2963179051876068\n",
      "epoch 5 loss: 0.25095704197883606\n",
      "epoch 6 loss: 0.24018408358097076\n",
      "epoch 7 loss: 0.19113528728485107\n",
      "epoch 8 loss: 0.13403105735778809\n",
      "epoch 9 loss: 0.1889219582080841\n",
      "epoch 10 loss: 0.17325317859649658\n",
      "epoch 11 loss: 0.15563882887363434\n",
      "epoch 12 loss: 0.19586676359176636\n",
      "epoch 13 loss: 0.1992456316947937\n",
      "epoch 14 loss: 0.1747085005044937\n",
      "epoch 15 loss: 0.18869729340076447\n",
      "epoch 16 loss: 0.2097652405500412\n",
      "epoch 17 loss: 0.17546570301055908\n",
      "epoch 18 loss: 0.1931258589029312\n",
      "epoch 19 loss: 0.14783991873264313\n",
      "epoch 20 loss: 0.20792658627033234\n",
      "epoch 21 loss: 0.16411618888378143\n",
      "epoch 22 loss: 0.15786615014076233\n",
      "epoch 23 loss: 0.17087145149707794\n",
      "epoch 24 loss: 0.15235772728919983\n",
      "epoch 25 loss: 0.17390359938144684\n",
      "epoch 26 loss: 0.13156378269195557\n",
      "epoch 27 loss: 0.14927059412002563\n",
      "epoch 28 loss: 0.1656866818666458\n",
      "epoch 29 loss: 0.14361558854579926\n",
      "epoch 30 loss: 0.1099776178598404\n",
      "18\n",
      "epoch 1 loss: 1.0158358812332153\n",
      "epoch 2 loss: 0.990552544593811\n",
      "epoch 3 loss: 0.4631965756416321\n",
      "epoch 4 loss: 0.34002885222435\n",
      "epoch 5 loss: 0.2458946257829666\n",
      "epoch 6 loss: 0.2114081233739853\n",
      "epoch 7 loss: 0.20106665790081024\n",
      "epoch 8 loss: 0.1825520247220993\n",
      "epoch 9 loss: 0.18233337998390198\n",
      "epoch 10 loss: 0.18136881291866302\n",
      "epoch 11 loss: 0.17579643428325653\n",
      "epoch 12 loss: 0.16358599066734314\n",
      "epoch 13 loss: 0.1827138513326645\n",
      "epoch 14 loss: 0.15376821160316467\n",
      "epoch 15 loss: 0.15264470875263214\n",
      "epoch 16 loss: 0.1529892534017563\n",
      "epoch 17 loss: 0.1997823864221573\n",
      "epoch 18 loss: 0.16838259994983673\n",
      "epoch 19 loss: 0.14724640548229218\n",
      "epoch 20 loss: 0.1764279007911682\n",
      "epoch 21 loss: 0.16042637825012207\n",
      "epoch 22 loss: 0.16440346837043762\n",
      "epoch 23 loss: 0.17038585245609283\n",
      "epoch 24 loss: 0.16774967312812805\n",
      "epoch 25 loss: 0.14652307331562042\n",
      "epoch 26 loss: 0.15030543506145477\n",
      "epoch 27 loss: 0.17947974801063538\n",
      "epoch 28 loss: 0.17021867632865906\n",
      "epoch 29 loss: 0.16065804660320282\n",
      "epoch 30 loss: 0.1682494878768921\n",
      "19\n",
      "epoch 1 loss: 0.8625624179840088\n",
      "epoch 2 loss: 0.7259495854377747\n",
      "epoch 3 loss: 0.4779748320579529\n",
      "epoch 4 loss: 0.3217768669128418\n",
      "epoch 5 loss: 0.25915777683258057\n",
      "epoch 6 loss: 0.21598561108112335\n",
      "epoch 7 loss: 0.1818942427635193\n",
      "epoch 8 loss: 0.16791149973869324\n",
      "epoch 9 loss: 0.17619402706623077\n",
      "epoch 10 loss: 0.175251767039299\n",
      "epoch 11 loss: 0.19963499903678894\n",
      "epoch 12 loss: 0.23978042602539062\n",
      "epoch 13 loss: 0.16987565159797668\n",
      "epoch 14 loss: 0.1702137142419815\n",
      "epoch 15 loss: 0.1702302247285843\n",
      "epoch 16 loss: 0.17835941910743713\n",
      "epoch 17 loss: 0.1792166531085968\n",
      "epoch 18 loss: 0.188607856631279\n",
      "epoch 19 loss: 0.17541436851024628\n",
      "epoch 20 loss: 0.15227669477462769\n",
      "epoch 21 loss: 0.1843794584274292\n",
      "epoch 22 loss: 0.17949825525283813\n",
      "epoch 23 loss: 0.15318147838115692\n",
      "epoch 24 loss: 0.184890016913414\n",
      "epoch 25 loss: 0.21034228801727295\n",
      "epoch 26 loss: 0.14357616007328033\n",
      "epoch 27 loss: 0.15862639248371124\n",
      "epoch 28 loss: 0.13201852142810822\n",
      "epoch 29 loss: 0.17104075849056244\n",
      "epoch 30 loss: 0.15985624492168427\n",
      "20\n",
      "epoch 1 loss: 0.9359117746353149\n",
      "epoch 2 loss: 0.5887588858604431\n",
      "epoch 3 loss: 0.45517122745513916\n",
      "epoch 4 loss: 0.318084180355072\n",
      "epoch 5 loss: 0.21125176548957825\n",
      "epoch 6 loss: 0.1953454166650772\n",
      "epoch 7 loss: 0.21430835127830505\n",
      "epoch 8 loss: 0.18960075080394745\n",
      "epoch 9 loss: 0.15163099765777588\n",
      "epoch 10 loss: 0.1818627119064331\n",
      "epoch 11 loss: 0.1740000694990158\n",
      "epoch 12 loss: 0.15857355296611786\n",
      "epoch 13 loss: 0.13196410238742828\n",
      "epoch 14 loss: 0.16754361987113953\n",
      "epoch 15 loss: 0.1967502236366272\n",
      "epoch 16 loss: 0.16607271134853363\n",
      "epoch 17 loss: 0.14621160924434662\n",
      "epoch 18 loss: 0.16357186436653137\n",
      "epoch 19 loss: 0.19381998479366302\n",
      "epoch 20 loss: 0.15608128905296326\n",
      "epoch 21 loss: 0.146072655916214\n",
      "epoch 22 loss: 0.15829482674598694\n",
      "epoch 23 loss: 0.14533130824565887\n",
      "epoch 24 loss: 0.17232516407966614\n",
      "epoch 25 loss: 0.17987702786922455\n",
      "epoch 26 loss: 0.21288350224494934\n",
      "epoch 27 loss: 0.12422488629817963\n",
      "epoch 28 loss: 0.1882695108652115\n",
      "epoch 29 loss: 0.18414604663848877\n",
      "epoch 30 loss: 0.15286116302013397\n",
      "21\n",
      "epoch 1 loss: 1.090886116027832\n",
      "epoch 2 loss: 0.6199123859405518\n",
      "epoch 3 loss: 0.44251322746276855\n",
      "epoch 4 loss: 0.2770441472530365\n",
      "epoch 5 loss: 0.2615732252597809\n",
      "epoch 6 loss: 0.1793634593486786\n",
      "epoch 7 loss: 0.18786174058914185\n",
      "epoch 8 loss: 0.17642901837825775\n",
      "epoch 9 loss: 0.1802331507205963\n",
      "epoch 10 loss: 0.19392620027065277\n",
      "epoch 11 loss: 0.1614791303873062\n",
      "epoch 12 loss: 0.15671460330486298\n",
      "epoch 13 loss: 0.14754270017147064\n",
      "epoch 14 loss: 0.1571546345949173\n",
      "epoch 15 loss: 0.20002782344818115\n",
      "epoch 16 loss: 0.1690666675567627\n",
      "epoch 17 loss: 0.15990756452083588\n",
      "epoch 18 loss: 0.18314789235591888\n",
      "epoch 19 loss: 0.15725260972976685\n",
      "epoch 20 loss: 0.1504935920238495\n",
      "epoch 21 loss: 0.12786737084388733\n",
      "epoch 22 loss: 0.19136151671409607\n",
      "epoch 23 loss: 0.17062444984912872\n",
      "epoch 24 loss: 0.17742697894573212\n",
      "epoch 25 loss: 0.18078789114952087\n",
      "epoch 26 loss: 0.18726351857185364\n",
      "epoch 27 loss: 0.22038239240646362\n",
      "epoch 28 loss: 0.17374686896800995\n",
      "epoch 29 loss: 0.16072936356067657\n",
      "epoch 30 loss: 0.1830882430076599\n",
      "22\n",
      "epoch 1 loss: 0.949225902557373\n",
      "epoch 2 loss: 0.7771602869033813\n",
      "epoch 3 loss: 0.6241446733474731\n",
      "epoch 4 loss: 0.3536180853843689\n",
      "epoch 5 loss: 0.24885426461696625\n",
      "epoch 6 loss: 0.211342915892601\n",
      "epoch 7 loss: 0.17944875359535217\n",
      "epoch 8 loss: 0.19699795544147491\n",
      "epoch 9 loss: 0.16941222548484802\n",
      "epoch 10 loss: 0.2053140252828598\n",
      "epoch 11 loss: 0.15562844276428223\n",
      "epoch 12 loss: 0.18625223636627197\n",
      "epoch 13 loss: 0.18232232332229614\n",
      "epoch 14 loss: 0.12706799805164337\n",
      "epoch 15 loss: 0.17052526772022247\n",
      "epoch 16 loss: 0.1499135047197342\n",
      "epoch 17 loss: 0.18233586847782135\n",
      "epoch 18 loss: 0.13633882999420166\n",
      "epoch 19 loss: 0.15319406986236572\n",
      "epoch 20 loss: 0.16964617371559143\n",
      "epoch 21 loss: 0.1922938972711563\n",
      "epoch 22 loss: 0.1441725194454193\n",
      "epoch 23 loss: 0.11902311444282532\n",
      "epoch 24 loss: 0.17612677812576294\n",
      "epoch 25 loss: 0.14521445333957672\n",
      "epoch 26 loss: 0.15826140344142914\n",
      "epoch 27 loss: 0.15499433875083923\n",
      "epoch 28 loss: 0.17791275680065155\n",
      "epoch 29 loss: 0.16844144463539124\n",
      "epoch 30 loss: 0.1412915587425232\n",
      "23\n",
      "epoch 1 loss: 1.075769305229187\n",
      "epoch 2 loss: 0.6914546489715576\n",
      "epoch 3 loss: 0.6512011885643005\n",
      "epoch 4 loss: 0.25896522402763367\n",
      "epoch 5 loss: 0.2180570513010025\n",
      "epoch 6 loss: 0.23177167773246765\n",
      "epoch 7 loss: 0.14934617280960083\n",
      "epoch 8 loss: 0.16963019967079163\n",
      "epoch 9 loss: 0.20546357333660126\n",
      "epoch 10 loss: 0.19098366796970367\n",
      "epoch 11 loss: 0.14330151677131653\n",
      "epoch 12 loss: 0.20089852809906006\n",
      "epoch 13 loss: 0.1608545482158661\n",
      "epoch 14 loss: 0.1695198267698288\n",
      "epoch 15 loss: 0.1609746515750885\n",
      "epoch 16 loss: 0.1726200133562088\n",
      "epoch 17 loss: 0.16542963683605194\n",
      "epoch 18 loss: 0.18167546391487122\n",
      "epoch 19 loss: 0.16766822338104248\n",
      "epoch 20 loss: 0.17092980444431305\n",
      "epoch 21 loss: 0.1374417245388031\n",
      "epoch 22 loss: 0.1399264931678772\n",
      "epoch 23 loss: 0.1259494572877884\n",
      "epoch 24 loss: 0.19273696839809418\n",
      "epoch 25 loss: 0.1556597501039505\n",
      "epoch 26 loss: 0.1421075314283371\n",
      "epoch 27 loss: 0.17380060255527496\n",
      "epoch 28 loss: 0.14640231430530548\n",
      "epoch 29 loss: 0.14794667065143585\n",
      "epoch 30 loss: 0.15188229084014893\n",
      "24\n",
      "epoch 1 loss: 1.084567904472351\n",
      "epoch 2 loss: 0.6183754801750183\n",
      "epoch 3 loss: 0.4104142189025879\n",
      "epoch 4 loss: 0.19978532195091248\n",
      "epoch 5 loss: 0.1665446013212204\n",
      "epoch 6 loss: 0.17776507139205933\n",
      "epoch 7 loss: 0.20102494955062866\n",
      "epoch 8 loss: 0.20386584103107452\n",
      "epoch 9 loss: 0.15054170787334442\n",
      "epoch 10 loss: 0.182188481092453\n",
      "epoch 11 loss: 0.18917398154735565\n",
      "epoch 12 loss: 0.1656043380498886\n",
      "epoch 13 loss: 0.16588886082172394\n",
      "epoch 14 loss: 0.2037680298089981\n",
      "epoch 15 loss: 0.14843705296516418\n",
      "epoch 16 loss: 0.19803951680660248\n",
      "epoch 17 loss: 0.15550461411476135\n",
      "epoch 18 loss: 0.1483893096446991\n",
      "epoch 19 loss: 0.18133671581745148\n",
      "epoch 20 loss: 0.15685386955738068\n",
      "epoch 21 loss: 0.14127802848815918\n",
      "epoch 22 loss: 0.20159123837947845\n",
      "epoch 23 loss: 0.1760869175195694\n",
      "epoch 24 loss: 0.1357947140932083\n",
      "epoch 25 loss: 0.16166900098323822\n",
      "epoch 26 loss: 0.18628573417663574\n",
      "epoch 27 loss: 0.1672896146774292\n",
      "epoch 28 loss: 0.1651451140642166\n",
      "epoch 29 loss: 0.18560242652893066\n",
      "epoch 30 loss: 0.15340982377529144\n",
      "25\n",
      "epoch 1 loss: 0.9496744871139526\n",
      "epoch 2 loss: 0.6345568895339966\n",
      "epoch 3 loss: 0.488567054271698\n",
      "epoch 4 loss: 0.29633453488349915\n",
      "epoch 5 loss: 0.19877326488494873\n",
      "epoch 6 loss: 0.2050035446882248\n",
      "epoch 7 loss: 0.19366709887981415\n",
      "epoch 8 loss: 0.16471625864505768\n",
      "epoch 9 loss: 0.14932893216609955\n",
      "epoch 10 loss: 0.1815624237060547\n",
      "epoch 11 loss: 0.16782993078231812\n",
      "epoch 12 loss: 0.20926636457443237\n",
      "epoch 13 loss: 0.17314493656158447\n",
      "epoch 14 loss: 0.1611999273300171\n",
      "epoch 15 loss: 0.2003128081560135\n",
      "epoch 16 loss: 0.15357783436775208\n",
      "epoch 17 loss: 0.157760351896286\n",
      "epoch 18 loss: 0.18773327767848969\n",
      "epoch 19 loss: 0.1639595925807953\n",
      "epoch 20 loss: 0.15136489272117615\n",
      "epoch 21 loss: 0.18125669658184052\n",
      "epoch 22 loss: 0.1427915096282959\n",
      "epoch 23 loss: 0.1825142800807953\n",
      "epoch 24 loss: 0.18666334450244904\n",
      "epoch 25 loss: 0.22042369842529297\n",
      "epoch 26 loss: 0.1658940464258194\n",
      "epoch 27 loss: 0.17447936534881592\n",
      "epoch 28 loss: 0.1413573920726776\n",
      "epoch 29 loss: 0.17373067140579224\n",
      "epoch 30 loss: 0.12731921672821045\n",
      "26\n",
      "epoch 1 loss: 1.0811278820037842\n",
      "epoch 2 loss: 0.7990289330482483\n",
      "epoch 3 loss: 0.5502832531929016\n",
      "epoch 4 loss: 0.31332695484161377\n",
      "epoch 5 loss: 0.2596869170665741\n",
      "epoch 6 loss: 0.20986999571323395\n",
      "epoch 7 loss: 0.1784636229276657\n",
      "epoch 8 loss: 0.16569402813911438\n",
      "epoch 9 loss: 0.19121208786964417\n",
      "epoch 10 loss: 0.14275005459785461\n",
      "epoch 11 loss: 0.19934281706809998\n",
      "epoch 12 loss: 0.16433878242969513\n",
      "epoch 13 loss: 0.17601828277111053\n",
      "epoch 14 loss: 0.13758258521556854\n",
      "epoch 15 loss: 0.1778467893600464\n",
      "epoch 16 loss: 0.1460980325937271\n",
      "epoch 17 loss: 0.1816338151693344\n",
      "epoch 18 loss: 0.15290114283561707\n",
      "epoch 19 loss: 0.14511029422283173\n",
      "epoch 20 loss: 0.1625394970178604\n",
      "epoch 21 loss: 0.16221357882022858\n",
      "epoch 22 loss: 0.20019449293613434\n",
      "epoch 23 loss: 0.16545437276363373\n",
      "epoch 24 loss: 0.15012235939502716\n",
      "epoch 25 loss: 0.15727773308753967\n",
      "epoch 26 loss: 0.18430866301059723\n",
      "epoch 27 loss: 0.17123524844646454\n",
      "epoch 28 loss: 0.18402482569217682\n",
      "epoch 29 loss: 0.1687866747379303\n",
      "epoch 30 loss: 0.1557120680809021\n",
      "27\n",
      "epoch 1 loss: 0.7684524655342102\n",
      "epoch 2 loss: 0.6875949501991272\n",
      "epoch 3 loss: 0.567327618598938\n",
      "epoch 4 loss: 0.3319714367389679\n",
      "epoch 5 loss: 0.2587279677391052\n",
      "epoch 6 loss: 0.2202707678079605\n",
      "epoch 7 loss: 0.19939124584197998\n",
      "epoch 8 loss: 0.2267647087574005\n",
      "epoch 9 loss: 0.18101178109645844\n",
      "epoch 10 loss: 0.20505502820014954\n",
      "epoch 11 loss: 0.16738386452198029\n",
      "epoch 12 loss: 0.20169299840927124\n",
      "epoch 13 loss: 0.20857389271259308\n",
      "epoch 14 loss: 0.14832442998886108\n",
      "epoch 15 loss: 0.20662806928157806\n",
      "epoch 16 loss: 0.17597700655460358\n",
      "epoch 17 loss: 0.1630256623029709\n",
      "epoch 18 loss: 0.16337764263153076\n",
      "epoch 19 loss: 0.1859339475631714\n",
      "epoch 20 loss: 0.12627248466014862\n",
      "epoch 21 loss: 0.1958385705947876\n",
      "epoch 22 loss: 0.18898966908454895\n",
      "epoch 23 loss: 0.1697118878364563\n",
      "epoch 24 loss: 0.1565990298986435\n",
      "epoch 25 loss: 0.17806734144687653\n",
      "epoch 26 loss: 0.16059190034866333\n",
      "epoch 27 loss: 0.1437940150499344\n",
      "epoch 28 loss: 0.15800796449184418\n",
      "epoch 29 loss: 0.1563299596309662\n",
      "epoch 30 loss: 0.1552494317293167\n",
      "28\n",
      "epoch 1 loss: 1.0002467632293701\n",
      "epoch 2 loss: 0.7349660992622375\n",
      "epoch 3 loss: 0.5915200710296631\n",
      "epoch 4 loss: 0.19147905707359314\n",
      "epoch 5 loss: 0.21467940509319305\n",
      "epoch 6 loss: 0.21741612255573273\n",
      "epoch 7 loss: 0.17105357348918915\n",
      "epoch 8 loss: 0.18828625977039337\n",
      "epoch 9 loss: 0.1593906134366989\n",
      "epoch 10 loss: 0.1854437291622162\n",
      "epoch 11 loss: 0.1610676795244217\n",
      "epoch 12 loss: 0.14088785648345947\n",
      "epoch 13 loss: 0.16176538169384003\n",
      "epoch 14 loss: 0.16056057810783386\n",
      "epoch 15 loss: 0.1886630356311798\n",
      "epoch 16 loss: 0.1094822958111763\n",
      "epoch 17 loss: 0.15805089473724365\n",
      "epoch 18 loss: 0.16173037886619568\n",
      "epoch 19 loss: 0.14588716626167297\n",
      "epoch 20 loss: 0.16501937806606293\n",
      "epoch 21 loss: 0.16747884452342987\n",
      "epoch 22 loss: 0.1938285231590271\n",
      "epoch 23 loss: 0.16891948878765106\n",
      "epoch 24 loss: 0.198626309633255\n",
      "epoch 25 loss: 0.1344236433506012\n",
      "epoch 26 loss: 0.13740380108356476\n",
      "epoch 27 loss: 0.14153923094272614\n",
      "epoch 28 loss: 0.18467125296592712\n",
      "epoch 29 loss: 0.1926489621400833\n",
      "epoch 30 loss: 0.1880367249250412\n",
      "29\n",
      "epoch 1 loss: 0.6919063329696655\n",
      "epoch 2 loss: 0.6889693140983582\n",
      "epoch 3 loss: 0.4478655755519867\n",
      "epoch 4 loss: 0.31696805357933044\n",
      "epoch 5 loss: 0.19491244852542877\n",
      "epoch 6 loss: 0.18599246442317963\n",
      "epoch 7 loss: 0.20071929693222046\n",
      "epoch 8 loss: 0.1592978686094284\n",
      "epoch 9 loss: 0.2051135152578354\n",
      "epoch 10 loss: 0.1612960547208786\n",
      "epoch 11 loss: 0.1820157766342163\n",
      "epoch 12 loss: 0.16560256481170654\n",
      "epoch 13 loss: 0.2058352380990982\n",
      "epoch 14 loss: 0.17691153287887573\n",
      "epoch 15 loss: 0.1746392548084259\n",
      "epoch 16 loss: 0.18939335644245148\n",
      "epoch 17 loss: 0.19571512937545776\n",
      "epoch 18 loss: 0.17462415993213654\n",
      "epoch 19 loss: 0.19813235104084015\n",
      "epoch 20 loss: 0.16507788002490997\n",
      "epoch 21 loss: 0.12729492783546448\n",
      "epoch 22 loss: 0.15864627063274384\n",
      "epoch 23 loss: 0.18279998004436493\n",
      "epoch 24 loss: 0.17400796711444855\n",
      "epoch 25 loss: 0.14919601380825043\n",
      "epoch 26 loss: 0.17842987179756165\n",
      "epoch 27 loss: 0.16746549308300018\n",
      "epoch 28 loss: 0.18447734415531158\n",
      "epoch 29 loss: 0.1507125049829483\n",
      "epoch 30 loss: 0.1800759881734848\n",
      "30\n",
      "epoch 1 loss: 1.0634493827819824\n",
      "epoch 2 loss: 0.7316738367080688\n",
      "epoch 3 loss: 0.5358626842498779\n",
      "epoch 4 loss: 0.36541497707366943\n",
      "epoch 5 loss: 0.26423007249832153\n",
      "epoch 6 loss: 0.18345798552036285\n",
      "epoch 7 loss: 0.18955639004707336\n",
      "epoch 8 loss: 0.16078031063079834\n",
      "epoch 9 loss: 0.15580706298351288\n",
      "epoch 10 loss: 0.19787101447582245\n",
      "epoch 11 loss: 0.1454584300518036\n",
      "epoch 12 loss: 0.18541324138641357\n",
      "epoch 13 loss: 0.2026461958885193\n",
      "epoch 14 loss: 0.1606748104095459\n",
      "epoch 15 loss: 0.17553509771823883\n",
      "epoch 16 loss: 0.19364464282989502\n",
      "epoch 17 loss: 0.17086440324783325\n",
      "epoch 18 loss: 0.18588940799236298\n",
      "epoch 19 loss: 0.18707948923110962\n",
      "epoch 20 loss: 0.15535463392734528\n",
      "epoch 21 loss: 0.17876531183719635\n",
      "epoch 22 loss: 0.16097798943519592\n",
      "epoch 23 loss: 0.14323177933692932\n",
      "epoch 24 loss: 0.16595838963985443\n",
      "epoch 25 loss: 0.1429661363363266\n",
      "epoch 26 loss: 0.14425213634967804\n",
      "epoch 27 loss: 0.197846457362175\n",
      "epoch 28 loss: 0.20371690392494202\n",
      "epoch 29 loss: 0.14556102454662323\n",
      "epoch 30 loss: 0.17923206090927124\n",
      "31\n",
      "epoch 1 loss: 0.8815926909446716\n",
      "epoch 2 loss: 0.8360605239868164\n",
      "epoch 3 loss: 0.47396907210350037\n",
      "epoch 4 loss: 0.3623654246330261\n",
      "epoch 5 loss: 0.20549827814102173\n",
      "epoch 6 loss: 0.2215680032968521\n",
      "epoch 7 loss: 0.17265360057353973\n",
      "epoch 8 loss: 0.17781931161880493\n",
      "epoch 9 loss: 0.21876633167266846\n",
      "epoch 10 loss: 0.16280348598957062\n",
      "epoch 11 loss: 0.1666046679019928\n",
      "epoch 12 loss: 0.1869996190071106\n",
      "epoch 13 loss: 0.16870789229869843\n",
      "epoch 14 loss: 0.2039296180009842\n",
      "epoch 15 loss: 0.19009768962860107\n",
      "epoch 16 loss: 0.15087902545928955\n",
      "epoch 17 loss: 0.19177213311195374\n",
      "epoch 18 loss: 0.1665266454219818\n",
      "epoch 19 loss: 0.17289888858795166\n",
      "epoch 20 loss: 0.15631623566150665\n",
      "epoch 21 loss: 0.16525448858737946\n",
      "epoch 22 loss: 0.1721104383468628\n",
      "epoch 23 loss: 0.15707799792289734\n",
      "epoch 24 loss: 0.1593863070011139\n",
      "epoch 25 loss: 0.1546960026025772\n",
      "epoch 26 loss: 0.16587001085281372\n",
      "epoch 27 loss: 0.1690278798341751\n",
      "epoch 28 loss: 0.191072478890419\n",
      "epoch 29 loss: 0.19902688264846802\n",
      "epoch 30 loss: 0.1733325719833374\n",
      "32\n",
      "epoch 1 loss: 0.9334836006164551\n",
      "epoch 2 loss: 0.5918551087379456\n",
      "epoch 3 loss: 0.5021753311157227\n",
      "epoch 4 loss: 0.26107490062713623\n",
      "epoch 5 loss: 0.18440137803554535\n",
      "epoch 6 loss: 0.17569072544574738\n",
      "epoch 7 loss: 0.1747884601354599\n",
      "epoch 8 loss: 0.15177153050899506\n",
      "epoch 9 loss: 0.2159716635942459\n",
      "epoch 10 loss: 0.14010989665985107\n",
      "epoch 11 loss: 0.16761399805545807\n",
      "epoch 12 loss: 0.21923094987869263\n",
      "epoch 13 loss: 0.17386949062347412\n",
      "epoch 14 loss: 0.17864525318145752\n",
      "epoch 15 loss: 0.14518524706363678\n",
      "epoch 16 loss: 0.1974020153284073\n",
      "epoch 17 loss: 0.17148883640766144\n",
      "epoch 18 loss: 0.1784607470035553\n",
      "epoch 19 loss: 0.18508471548557281\n",
      "epoch 20 loss: 0.14283409714698792\n",
      "epoch 21 loss: 0.15917770564556122\n",
      "epoch 22 loss: 0.1798326075077057\n",
      "epoch 23 loss: 0.19972804188728333\n",
      "epoch 24 loss: 0.14309203624725342\n",
      "epoch 25 loss: 0.15660303831100464\n",
      "epoch 26 loss: 0.1440962851047516\n",
      "epoch 27 loss: 0.17465969920158386\n",
      "epoch 28 loss: 0.16032251715660095\n",
      "epoch 29 loss: 0.1526930332183838\n",
      "epoch 30 loss: 0.14994755387306213\n",
      "33\n",
      "epoch 1 loss: 0.8841755986213684\n",
      "epoch 2 loss: 0.8180249929428101\n",
      "epoch 3 loss: 0.6056281328201294\n",
      "epoch 4 loss: 0.35961034893989563\n",
      "epoch 5 loss: 0.22448407113552094\n",
      "epoch 6 loss: 0.19824782013893127\n",
      "epoch 7 loss: 0.17422033846378326\n",
      "epoch 8 loss: 0.2119242250919342\n",
      "epoch 9 loss: 0.1671898514032364\n",
      "epoch 10 loss: 0.18179528415203094\n",
      "epoch 11 loss: 0.18316002190113068\n",
      "epoch 12 loss: 0.16395436227321625\n",
      "epoch 13 loss: 0.190110981464386\n",
      "epoch 14 loss: 0.19005684554576874\n",
      "epoch 15 loss: 0.1661236733198166\n",
      "epoch 16 loss: 0.17100143432617188\n",
      "epoch 17 loss: 0.16496804356575012\n",
      "epoch 18 loss: 0.15748968720436096\n",
      "epoch 19 loss: 0.20293334126472473\n",
      "epoch 20 loss: 0.17087604105472565\n",
      "epoch 21 loss: 0.15105588734149933\n",
      "epoch 22 loss: 0.1463070511817932\n",
      "epoch 23 loss: 0.12591423094272614\n",
      "epoch 24 loss: 0.14229543507099152\n",
      "epoch 25 loss: 0.2079923152923584\n",
      "epoch 26 loss: 0.1532101333141327\n",
      "epoch 27 loss: 0.17988994717597961\n",
      "epoch 28 loss: 0.1459321826696396\n",
      "epoch 29 loss: 0.1724511981010437\n",
      "epoch 30 loss: 0.17662739753723145\n",
      "34\n",
      "epoch 1 loss: 0.7554082274436951\n",
      "epoch 2 loss: 0.6768472790718079\n",
      "epoch 3 loss: 0.5382567048072815\n",
      "epoch 4 loss: 0.2705709636211395\n",
      "epoch 5 loss: 0.25367411971092224\n",
      "epoch 6 loss: 0.2123163342475891\n",
      "epoch 7 loss: 0.1486462503671646\n",
      "epoch 8 loss: 0.1483476161956787\n",
      "epoch 9 loss: 0.16357026994228363\n",
      "epoch 10 loss: 0.16566304862499237\n",
      "epoch 11 loss: 0.1711532324552536\n",
      "epoch 12 loss: 0.1688622385263443\n",
      "epoch 13 loss: 0.15430425107479095\n",
      "epoch 14 loss: 0.15225915610790253\n",
      "epoch 15 loss: 0.20709455013275146\n",
      "epoch 16 loss: 0.14773018658161163\n",
      "epoch 17 loss: 0.1349334567785263\n",
      "epoch 18 loss: 0.18902587890625\n",
      "epoch 19 loss: 0.17183616757392883\n",
      "epoch 20 loss: 0.15804791450500488\n",
      "epoch 21 loss: 0.1761285811662674\n",
      "epoch 22 loss: 0.16047172248363495\n",
      "epoch 23 loss: 0.17699778079986572\n",
      "epoch 24 loss: 0.1728062480688095\n",
      "epoch 25 loss: 0.19147376716136932\n",
      "epoch 26 loss: 0.1637338250875473\n",
      "epoch 27 loss: 0.1601017564535141\n",
      "epoch 28 loss: 0.1486629843711853\n",
      "epoch 29 loss: 0.13330206274986267\n",
      "epoch 30 loss: 0.1774941384792328\n",
      "35\n",
      "epoch 1 loss: 0.8959154486656189\n",
      "epoch 2 loss: 0.9471129179000854\n",
      "epoch 3 loss: 0.566453218460083\n",
      "epoch 4 loss: 0.3276468813419342\n",
      "epoch 5 loss: 0.248455211520195\n",
      "epoch 6 loss: 0.1596008539199829\n",
      "epoch 7 loss: 0.18080702424049377\n",
      "epoch 8 loss: 0.17383986711502075\n",
      "epoch 9 loss: 0.2090655267238617\n",
      "epoch 10 loss: 0.17221981287002563\n",
      "epoch 11 loss: 0.1582387089729309\n",
      "epoch 12 loss: 0.2003554105758667\n",
      "epoch 13 loss: 0.14696116745471954\n",
      "epoch 14 loss: 0.17914649844169617\n",
      "epoch 15 loss: 0.17338593304157257\n",
      "epoch 16 loss: 0.17829765379428864\n",
      "epoch 17 loss: 0.14199529588222504\n",
      "epoch 18 loss: 0.16890931129455566\n",
      "epoch 19 loss: 0.16484248638153076\n",
      "epoch 20 loss: 0.19354040920734406\n",
      "epoch 21 loss: 0.17882564663887024\n",
      "epoch 22 loss: 0.2032167911529541\n",
      "epoch 23 loss: 0.17485573887825012\n",
      "epoch 24 loss: 0.1699082851409912\n",
      "epoch 25 loss: 0.17806407809257507\n",
      "epoch 26 loss: 0.1977781057357788\n",
      "epoch 27 loss: 0.17323212325572968\n",
      "epoch 28 loss: 0.15808622539043427\n",
      "epoch 29 loss: 0.1798890233039856\n",
      "epoch 30 loss: 0.1866246461868286\n",
      "36\n",
      "epoch 1 loss: 1.017225980758667\n",
      "epoch 2 loss: 0.7224771976470947\n",
      "epoch 3 loss: 0.38167282938957214\n",
      "epoch 4 loss: 0.3092571496963501\n",
      "epoch 5 loss: 0.2638387084007263\n",
      "epoch 6 loss: 0.2253148853778839\n",
      "epoch 7 loss: 0.14606988430023193\n",
      "epoch 8 loss: 0.15297630429267883\n",
      "epoch 9 loss: 0.19324982166290283\n",
      "epoch 10 loss: 0.17009972035884857\n",
      "epoch 11 loss: 0.16178788244724274\n",
      "epoch 12 loss: 0.14408187568187714\n",
      "epoch 13 loss: 0.17352037131786346\n",
      "epoch 14 loss: 0.18809767067432404\n",
      "epoch 15 loss: 0.16527479887008667\n",
      "epoch 16 loss: 0.1457756757736206\n",
      "epoch 17 loss: 0.17635281383991241\n",
      "epoch 18 loss: 0.13920298218727112\n",
      "epoch 19 loss: 0.1816454380750656\n",
      "epoch 20 loss: 0.17922651767730713\n",
      "epoch 21 loss: 0.21041132509708405\n",
      "epoch 22 loss: 0.16975246369838715\n",
      "epoch 23 loss: 0.17708902060985565\n",
      "epoch 24 loss: 0.19958031177520752\n",
      "epoch 25 loss: 0.17056943476200104\n",
      "epoch 26 loss: 0.1506592482328415\n",
      "epoch 27 loss: 0.1551516354084015\n",
      "epoch 28 loss: 0.16108164191246033\n",
      "epoch 29 loss: 0.16589407622814178\n",
      "epoch 30 loss: 0.17223520576953888\n",
      "37\n",
      "epoch 1 loss: 1.1227738857269287\n",
      "epoch 2 loss: 0.6976152658462524\n",
      "epoch 3 loss: 0.3891022205352783\n",
      "epoch 4 loss: 0.25485068559646606\n",
      "epoch 5 loss: 0.22994190454483032\n",
      "epoch 6 loss: 0.221903458237648\n",
      "epoch 7 loss: 0.2096419781446457\n",
      "epoch 8 loss: 0.15667060017585754\n",
      "epoch 9 loss: 0.19484065473079681\n",
      "epoch 10 loss: 0.18832585215568542\n",
      "epoch 11 loss: 0.2128501534461975\n",
      "epoch 12 loss: 0.20285581052303314\n",
      "epoch 13 loss: 0.13294526934623718\n",
      "epoch 14 loss: 0.13494575023651123\n",
      "epoch 15 loss: 0.15648527443408966\n",
      "epoch 16 loss: 0.18634627759456635\n",
      "epoch 17 loss: 0.16502758860588074\n",
      "epoch 18 loss: 0.16751226782798767\n",
      "epoch 19 loss: 0.11288636922836304\n",
      "epoch 20 loss: 0.16151605546474457\n",
      "epoch 21 loss: 0.16517630219459534\n",
      "epoch 22 loss: 0.1665857583284378\n",
      "epoch 23 loss: 0.14117775857448578\n",
      "epoch 24 loss: 0.1958228200674057\n",
      "epoch 25 loss: 0.15633267164230347\n",
      "epoch 26 loss: 0.16731084883213043\n",
      "epoch 27 loss: 0.16308371722698212\n",
      "epoch 28 loss: 0.1598329097032547\n",
      "epoch 29 loss: 0.14278294146060944\n",
      "epoch 30 loss: 0.17368552088737488\n",
      "38\n",
      "epoch 1 loss: 0.9316405653953552\n",
      "epoch 2 loss: 0.8511250615119934\n",
      "epoch 3 loss: 0.46473777294158936\n",
      "epoch 4 loss: 0.29789549112319946\n",
      "epoch 5 loss: 0.2265559583902359\n",
      "epoch 6 loss: 0.18324731290340424\n",
      "epoch 7 loss: 0.17922662198543549\n",
      "epoch 8 loss: 0.20535530149936676\n",
      "epoch 9 loss: 0.22759076952934265\n",
      "epoch 10 loss: 0.15227264165878296\n",
      "epoch 11 loss: 0.1645745187997818\n",
      "epoch 12 loss: 0.19095483422279358\n",
      "epoch 13 loss: 0.1442827582359314\n",
      "epoch 14 loss: 0.1708100587129593\n",
      "epoch 15 loss: 0.1765344738960266\n",
      "epoch 16 loss: 0.17658844590187073\n",
      "epoch 17 loss: 0.18495379388332367\n",
      "epoch 18 loss: 0.11899233609437943\n",
      "epoch 19 loss: 0.16412928700447083\n",
      "epoch 20 loss: 0.17080503702163696\n",
      "epoch 21 loss: 0.1273869425058365\n",
      "epoch 22 loss: 0.15518225729465485\n",
      "epoch 23 loss: 0.18671393394470215\n",
      "epoch 24 loss: 0.1368432193994522\n",
      "epoch 25 loss: 0.17151176929473877\n",
      "epoch 26 loss: 0.17136867344379425\n",
      "epoch 27 loss: 0.18492965400218964\n",
      "epoch 28 loss: 0.1718318611383438\n",
      "epoch 29 loss: 0.16827434301376343\n",
      "epoch 30 loss: 0.18511717021465302\n",
      "39\n",
      "epoch 1 loss: 0.9333722591400146\n",
      "epoch 2 loss: 0.6509295701980591\n",
      "epoch 3 loss: 0.5683677196502686\n",
      "epoch 4 loss: 0.3321465849876404\n",
      "epoch 5 loss: 0.23096759617328644\n",
      "epoch 6 loss: 0.14098775386810303\n",
      "epoch 7 loss: 0.1683170050382614\n",
      "epoch 8 loss: 0.19221405684947968\n",
      "epoch 9 loss: 0.155795156955719\n",
      "epoch 10 loss: 0.15282797813415527\n",
      "epoch 11 loss: 0.13684727251529694\n",
      "epoch 12 loss: 0.20079880952835083\n",
      "epoch 13 loss: 0.16549783945083618\n",
      "epoch 14 loss: 0.18720944225788116\n",
      "epoch 15 loss: 0.17723259329795837\n",
      "epoch 16 loss: 0.16505004465579987\n",
      "epoch 17 loss: 0.1493106335401535\n",
      "epoch 18 loss: 0.1692209392786026\n",
      "epoch 19 loss: 0.17658057808876038\n",
      "epoch 20 loss: 0.15680871903896332\n",
      "epoch 21 loss: 0.14106211066246033\n",
      "epoch 22 loss: 0.11357229202985764\n",
      "epoch 23 loss: 0.17828987538814545\n",
      "epoch 24 loss: 0.17167282104492188\n",
      "epoch 25 loss: 0.17346155643463135\n",
      "epoch 26 loss: 0.16382287442684174\n",
      "epoch 27 loss: 0.17606480419635773\n",
      "epoch 28 loss: 0.1801852434873581\n",
      "epoch 29 loss: 0.16590020060539246\n",
      "epoch 30 loss: 0.13213840126991272\n",
      "40\n",
      "epoch 1 loss: 0.8713799715042114\n",
      "epoch 2 loss: 0.6815592646598816\n",
      "epoch 3 loss: 0.4873509407043457\n",
      "epoch 4 loss: 0.4081821143627167\n",
      "epoch 5 loss: 0.29376062750816345\n",
      "epoch 6 loss: 0.1576387584209442\n",
      "epoch 7 loss: 0.18914104998111725\n",
      "epoch 8 loss: 0.1802361160516739\n",
      "epoch 9 loss: 0.18667590618133545\n",
      "epoch 10 loss: 0.19528231024742126\n",
      "epoch 11 loss: 0.2058839052915573\n",
      "epoch 12 loss: 0.15970219671726227\n",
      "epoch 13 loss: 0.1884109228849411\n",
      "epoch 14 loss: 0.16214506328105927\n",
      "epoch 15 loss: 0.19274096190929413\n",
      "epoch 16 loss: 0.1745612621307373\n",
      "epoch 17 loss: 0.1816467046737671\n",
      "epoch 18 loss: 0.17402376234531403\n",
      "epoch 19 loss: 0.14988012611865997\n",
      "epoch 20 loss: 0.15884698927402496\n",
      "epoch 21 loss: 0.17531172931194305\n",
      "epoch 22 loss: 0.15496960282325745\n",
      "epoch 23 loss: 0.18850865960121155\n",
      "epoch 24 loss: 0.17125490307807922\n",
      "epoch 25 loss: 0.16307827830314636\n",
      "epoch 26 loss: 0.1905139684677124\n",
      "epoch 27 loss: 0.16803428530693054\n",
      "epoch 28 loss: 0.18133707344532013\n",
      "epoch 29 loss: 0.17993634939193726\n",
      "epoch 30 loss: 0.18831866979599\n",
      "41\n",
      "epoch 1 loss: 0.7404817938804626\n",
      "epoch 2 loss: 0.7751375436782837\n",
      "epoch 3 loss: 0.5609688758850098\n",
      "epoch 4 loss: 0.3314417898654938\n",
      "epoch 5 loss: 0.22516633570194244\n",
      "epoch 6 loss: 0.2480652779340744\n",
      "epoch 7 loss: 0.20961955189704895\n",
      "epoch 8 loss: 0.1355295479297638\n",
      "epoch 9 loss: 0.16039124131202698\n",
      "epoch 10 loss: 0.18173128366470337\n",
      "epoch 11 loss: 0.15818333625793457\n",
      "epoch 12 loss: 0.1567041575908661\n",
      "epoch 13 loss: 0.1698201298713684\n",
      "epoch 14 loss: 0.1822022646665573\n",
      "epoch 15 loss: 0.10575848817825317\n",
      "epoch 16 loss: 0.21609032154083252\n",
      "epoch 17 loss: 0.19432669878005981\n",
      "epoch 18 loss: 0.15203683078289032\n",
      "epoch 19 loss: 0.15960201621055603\n",
      "epoch 20 loss: 0.16635359823703766\n",
      "epoch 21 loss: 0.17357321083545685\n",
      "epoch 22 loss: 0.1684192419052124\n",
      "epoch 23 loss: 0.17573730647563934\n",
      "epoch 24 loss: 0.13354723155498505\n",
      "epoch 25 loss: 0.18100512027740479\n",
      "epoch 26 loss: 0.17183294892311096\n",
      "epoch 27 loss: 0.15861405432224274\n",
      "epoch 28 loss: 0.16760486364364624\n",
      "epoch 29 loss: 0.16789878904819489\n",
      "epoch 30 loss: 0.18581320345401764\n",
      "42\n",
      "epoch 1 loss: 0.8452593088150024\n",
      "epoch 2 loss: 0.7403455376625061\n",
      "epoch 3 loss: 0.4899124801158905\n",
      "epoch 4 loss: 0.2671336829662323\n",
      "epoch 5 loss: 0.27504265308380127\n",
      "epoch 6 loss: 0.16533777117729187\n",
      "epoch 7 loss: 0.16067685186862946\n",
      "epoch 8 loss: 0.22311419248580933\n",
      "epoch 9 loss: 0.1151261255145073\n",
      "epoch 10 loss: 0.1466280072927475\n",
      "epoch 11 loss: 0.20784638822078705\n",
      "epoch 12 loss: 0.18531052768230438\n",
      "epoch 13 loss: 0.13508878648281097\n",
      "epoch 14 loss: 0.17920725047588348\n",
      "epoch 15 loss: 0.15682029724121094\n",
      "epoch 16 loss: 0.17349040508270264\n",
      "epoch 17 loss: 0.21192650496959686\n",
      "epoch 18 loss: 0.18312494456768036\n",
      "epoch 19 loss: 0.17696048319339752\n",
      "epoch 20 loss: 0.20108100771903992\n",
      "epoch 21 loss: 0.14006851613521576\n",
      "epoch 22 loss: 0.17864654958248138\n",
      "epoch 23 loss: 0.1688292920589447\n",
      "epoch 24 loss: 0.2121608555316925\n",
      "epoch 25 loss: 0.16716179251670837\n",
      "epoch 26 loss: 0.14601387083530426\n",
      "epoch 27 loss: 0.164173424243927\n",
      "epoch 28 loss: 0.18036602437496185\n",
      "epoch 29 loss: 0.18371547758579254\n",
      "epoch 30 loss: 0.18451090157032013\n",
      "43\n",
      "epoch 1 loss: 0.8312097191810608\n",
      "epoch 2 loss: 0.7332877516746521\n",
      "epoch 3 loss: 0.4143703281879425\n",
      "epoch 4 loss: 0.22246335446834564\n",
      "epoch 5 loss: 0.23168636858463287\n",
      "epoch 6 loss: 0.23538856208324432\n",
      "epoch 7 loss: 0.1642780303955078\n",
      "epoch 8 loss: 0.1626942902803421\n",
      "epoch 9 loss: 0.1638094186782837\n",
      "epoch 10 loss: 0.16345295310020447\n",
      "epoch 11 loss: 0.20104797184467316\n",
      "epoch 12 loss: 0.1546250879764557\n",
      "epoch 13 loss: 0.1493653804063797\n",
      "epoch 14 loss: 0.15606524050235748\n",
      "epoch 15 loss: 0.2117919921875\n",
      "epoch 16 loss: 0.16400794684886932\n",
      "epoch 17 loss: 0.15917210280895233\n",
      "epoch 18 loss: 0.17429035902023315\n",
      "epoch 19 loss: 0.19284853339195251\n",
      "epoch 20 loss: 0.1935928910970688\n",
      "epoch 21 loss: 0.15925028920173645\n",
      "epoch 22 loss: 0.1653059422969818\n",
      "epoch 23 loss: 0.187148779630661\n",
      "epoch 24 loss: 0.14941588044166565\n",
      "epoch 25 loss: 0.16896651685237885\n",
      "epoch 26 loss: 0.16523022949695587\n",
      "epoch 27 loss: 0.1779295802116394\n",
      "epoch 28 loss: 0.17909322679042816\n",
      "epoch 29 loss: 0.14618167281150818\n",
      "epoch 30 loss: 0.16773802042007446\n",
      "44\n",
      "epoch 1 loss: 0.8478168845176697\n",
      "epoch 2 loss: 0.7874204516410828\n",
      "epoch 3 loss: 0.6377298831939697\n",
      "epoch 4 loss: 0.36922770738601685\n",
      "epoch 5 loss: 0.2401183545589447\n",
      "epoch 6 loss: 0.1705532670021057\n",
      "epoch 7 loss: 0.19982683658599854\n",
      "epoch 8 loss: 0.20161622762680054\n",
      "epoch 9 loss: 0.17511209845542908\n",
      "epoch 10 loss: 0.14842204749584198\n",
      "epoch 11 loss: 0.16089418530464172\n",
      "epoch 12 loss: 0.13353948295116425\n",
      "epoch 13 loss: 0.1407272070646286\n",
      "epoch 14 loss: 0.1679186373949051\n",
      "epoch 15 loss: 0.15856115520000458\n",
      "epoch 16 loss: 0.19075056910514832\n",
      "epoch 17 loss: 0.1459578424692154\n",
      "epoch 18 loss: 0.1976960450410843\n",
      "epoch 19 loss: 0.16968092322349548\n",
      "epoch 20 loss: 0.15424534678459167\n",
      "epoch 21 loss: 0.1522914469242096\n",
      "epoch 22 loss: 0.1507510542869568\n",
      "epoch 23 loss: 0.1580457240343094\n",
      "epoch 24 loss: 0.19260771572589874\n",
      "epoch 25 loss: 0.17882303893566132\n",
      "epoch 26 loss: 0.16465280950069427\n",
      "epoch 27 loss: 0.15382781624794006\n",
      "epoch 28 loss: 0.1662205457687378\n",
      "epoch 29 loss: 0.1650426685810089\n",
      "epoch 30 loss: 0.15448454022407532\n",
      "45\n",
      "epoch 1 loss: 1.082605242729187\n",
      "epoch 2 loss: 0.7685522437095642\n",
      "epoch 3 loss: 0.5250676274299622\n",
      "epoch 4 loss: 0.3157062828540802\n",
      "epoch 5 loss: 0.2642152011394501\n",
      "epoch 6 loss: 0.17768876254558563\n",
      "epoch 7 loss: 0.19059544801712036\n",
      "epoch 8 loss: 0.18715044856071472\n",
      "epoch 9 loss: 0.14567533135414124\n",
      "epoch 10 loss: 0.1731080263853073\n",
      "epoch 11 loss: 0.15409445762634277\n",
      "epoch 12 loss: 0.17915596067905426\n",
      "epoch 13 loss: 0.16619887948036194\n",
      "epoch 14 loss: 0.16560539603233337\n",
      "epoch 15 loss: 0.17501094937324524\n",
      "epoch 16 loss: 0.15186628699302673\n",
      "epoch 17 loss: 0.1559515744447708\n",
      "epoch 18 loss: 0.1526210606098175\n",
      "epoch 19 loss: 0.17360050976276398\n",
      "epoch 20 loss: 0.21590808033943176\n",
      "epoch 21 loss: 0.1450929492712021\n",
      "epoch 22 loss: 0.18922069668769836\n",
      "epoch 23 loss: 0.17442010343074799\n",
      "epoch 24 loss: 0.15755262970924377\n",
      "epoch 25 loss: 0.18462245166301727\n",
      "epoch 26 loss: 0.13940872251987457\n",
      "epoch 27 loss: 0.1739635467529297\n",
      "epoch 28 loss: 0.18392886221408844\n",
      "epoch 29 loss: 0.18535971641540527\n",
      "epoch 30 loss: 0.18672825396060944\n",
      "46\n",
      "epoch 1 loss: 0.9981973767280579\n",
      "epoch 2 loss: 0.717797577381134\n",
      "epoch 3 loss: 0.4440418481826782\n",
      "epoch 4 loss: 0.36429813504219055\n",
      "epoch 5 loss: 0.23743081092834473\n",
      "epoch 6 loss: 0.2286304533481598\n",
      "epoch 7 loss: 0.17066623270511627\n",
      "epoch 8 loss: 0.19004911184310913\n",
      "epoch 9 loss: 0.22828559577465057\n",
      "epoch 10 loss: 0.14229056239128113\n",
      "epoch 11 loss: 0.15611772239208221\n",
      "epoch 12 loss: 0.14634011685848236\n",
      "epoch 13 loss: 0.17707765102386475\n",
      "epoch 14 loss: 0.17368976771831512\n",
      "epoch 15 loss: 0.1596985161304474\n",
      "epoch 16 loss: 0.1595669388771057\n",
      "epoch 17 loss: 0.1695277839899063\n",
      "epoch 18 loss: 0.17138715088367462\n",
      "epoch 19 loss: 0.1585216224193573\n",
      "epoch 20 loss: 0.1617937833070755\n",
      "epoch 21 loss: 0.18786945939064026\n",
      "epoch 22 loss: 0.16804154217243195\n",
      "epoch 23 loss: 0.1691637486219406\n",
      "epoch 24 loss: 0.1834665983915329\n",
      "epoch 25 loss: 0.16420748829841614\n",
      "epoch 26 loss: 0.16386917233467102\n",
      "epoch 27 loss: 0.11416666954755783\n",
      "epoch 28 loss: 0.1330643892288208\n",
      "epoch 29 loss: 0.1878192275762558\n",
      "epoch 30 loss: 0.1907992660999298\n",
      "47\n",
      "epoch 1 loss: 0.9661176204681396\n",
      "epoch 2 loss: 0.732554018497467\n",
      "epoch 3 loss: 0.5037543773651123\n",
      "epoch 4 loss: 0.33132168650627136\n",
      "epoch 5 loss: 0.23061875998973846\n",
      "epoch 6 loss: 0.21972665190696716\n",
      "epoch 7 loss: 0.15243011713027954\n",
      "epoch 8 loss: 0.20891594886779785\n",
      "epoch 9 loss: 0.17665553092956543\n",
      "epoch 10 loss: 0.17820049822330475\n",
      "epoch 11 loss: 0.16117694973945618\n",
      "epoch 12 loss: 0.17015017569065094\n",
      "epoch 13 loss: 0.16602693498134613\n",
      "epoch 14 loss: 0.19214408099651337\n",
      "epoch 15 loss: 0.19184455275535583\n",
      "epoch 16 loss: 0.1877690851688385\n",
      "epoch 17 loss: 0.17922943830490112\n",
      "epoch 18 loss: 0.14238600432872772\n",
      "epoch 19 loss: 0.15418517589569092\n",
      "epoch 20 loss: 0.16826170682907104\n",
      "epoch 21 loss: 0.167872816324234\n",
      "epoch 22 loss: 0.1699478030204773\n",
      "epoch 23 loss: 0.1790054738521576\n",
      "epoch 24 loss: 0.17121273279190063\n",
      "epoch 25 loss: 0.17946797609329224\n",
      "epoch 26 loss: 0.16497227549552917\n",
      "epoch 27 loss: 0.1630527228116989\n",
      "epoch 28 loss: 0.19122840464115143\n",
      "epoch 29 loss: 0.15261194109916687\n",
      "epoch 30 loss: 0.20690469443798065\n",
      "48\n",
      "epoch 1 loss: 1.048906683921814\n",
      "epoch 2 loss: 0.687360405921936\n",
      "epoch 3 loss: 0.5282443761825562\n",
      "epoch 4 loss: 0.2720056474208832\n",
      "epoch 5 loss: 0.15375064313411713\n",
      "epoch 6 loss: 0.20369252562522888\n",
      "epoch 7 loss: 0.14888112246990204\n",
      "epoch 8 loss: 0.19746707379817963\n",
      "epoch 9 loss: 0.2350337952375412\n",
      "epoch 10 loss: 0.21478141844272614\n",
      "epoch 11 loss: 0.16331100463867188\n",
      "epoch 12 loss: 0.2016630619764328\n",
      "epoch 13 loss: 0.16122783720493317\n",
      "epoch 14 loss: 0.15651893615722656\n",
      "epoch 15 loss: 0.1708991527557373\n",
      "epoch 16 loss: 0.20155052840709686\n",
      "epoch 17 loss: 0.17952843010425568\n",
      "epoch 18 loss: 0.16285490989685059\n",
      "epoch 19 loss: 0.18269358575344086\n",
      "epoch 20 loss: 0.15176039934158325\n",
      "epoch 21 loss: 0.15202394127845764\n",
      "epoch 22 loss: 0.21768373250961304\n",
      "epoch 23 loss: 0.15781129896640778\n",
      "epoch 24 loss: 0.1820269227027893\n",
      "epoch 25 loss: 0.14562362432479858\n",
      "epoch 26 loss: 0.1436796933412552\n",
      "epoch 27 loss: 0.16795963048934937\n",
      "epoch 28 loss: 0.1647448092699051\n",
      "epoch 29 loss: 0.16295717656612396\n",
      "epoch 30 loss: 0.14406490325927734\n",
      "49\n",
      "epoch 1 loss: 0.92063307762146\n",
      "epoch 2 loss: 0.6881250143051147\n",
      "epoch 3 loss: 0.43161752820014954\n",
      "epoch 4 loss: 0.3466598391532898\n",
      "epoch 5 loss: 0.1786288321018219\n",
      "epoch 6 loss: 0.19500838220119476\n",
      "epoch 7 loss: 0.1927095204591751\n",
      "epoch 8 loss: 0.22506830096244812\n",
      "epoch 9 loss: 0.19107146561145782\n",
      "epoch 10 loss: 0.16319820284843445\n",
      "epoch 11 loss: 0.18537303805351257\n",
      "epoch 12 loss: 0.18067151308059692\n",
      "epoch 13 loss: 0.15831252932548523\n",
      "epoch 14 loss: 0.18225428462028503\n",
      "epoch 15 loss: 0.18735025823116302\n",
      "epoch 16 loss: 0.12580227851867676\n",
      "epoch 17 loss: 0.16744862496852875\n",
      "epoch 18 loss: 0.19314469397068024\n",
      "epoch 19 loss: 0.1764327436685562\n",
      "epoch 20 loss: 0.17718802392482758\n",
      "epoch 21 loss: 0.16322605311870575\n",
      "epoch 22 loss: 0.13841238617897034\n",
      "epoch 23 loss: 0.1464635729789734\n",
      "epoch 24 loss: 0.15552973747253418\n",
      "epoch 25 loss: 0.2081630676984787\n",
      "epoch 26 loss: 0.14810970425605774\n",
      "epoch 27 loss: 0.1560986191034317\n",
      "epoch 28 loss: 0.18011559545993805\n",
      "epoch 29 loss: 0.12571921944618225\n",
      "epoch 30 loss: 0.13930469751358032\n",
      "50\n",
      "epoch 1 loss: 0.902559757232666\n",
      "epoch 2 loss: 0.7601596713066101\n",
      "epoch 3 loss: 0.502118706703186\n",
      "epoch 4 loss: 0.3740179240703583\n",
      "epoch 5 loss: 0.1908186376094818\n",
      "epoch 6 loss: 0.19314931333065033\n",
      "epoch 7 loss: 0.1446331888437271\n",
      "epoch 8 loss: 0.21420986950397491\n",
      "epoch 9 loss: 0.17640650272369385\n",
      "epoch 10 loss: 0.15799592435359955\n",
      "epoch 11 loss: 0.15826857089996338\n",
      "epoch 12 loss: 0.17229139804840088\n",
      "epoch 13 loss: 0.14758743345737457\n",
      "epoch 14 loss: 0.14834201335906982\n",
      "epoch 15 loss: 0.17001797258853912\n",
      "epoch 16 loss: 0.15468385815620422\n",
      "epoch 17 loss: 0.161995530128479\n",
      "epoch 18 loss: 0.1461745947599411\n",
      "epoch 19 loss: 0.16140638291835785\n",
      "epoch 20 loss: 0.14590218663215637\n",
      "epoch 21 loss: 0.17998287081718445\n",
      "epoch 22 loss: 0.14688852429389954\n",
      "epoch 23 loss: 0.17368298768997192\n",
      "epoch 24 loss: 0.16589783132076263\n",
      "epoch 25 loss: 0.15974804759025574\n",
      "epoch 26 loss: 0.18972139060497284\n",
      "epoch 27 loss: 0.11936171352863312\n",
      "epoch 28 loss: 0.16126024723052979\n",
      "epoch 29 loss: 0.17768479883670807\n",
      "epoch 30 loss: 0.1683797389268875\n",
      "51\n",
      "epoch 1 loss: 0.8474169373512268\n",
      "epoch 2 loss: 0.6202479600906372\n",
      "epoch 3 loss: 0.4139745831489563\n",
      "epoch 4 loss: 0.2375255674123764\n",
      "epoch 5 loss: 0.17946501076221466\n",
      "epoch 6 loss: 0.1692250818014145\n",
      "epoch 7 loss: 0.17066875100135803\n",
      "epoch 8 loss: 0.20066098868846893\n",
      "epoch 9 loss: 0.19570469856262207\n",
      "epoch 10 loss: 0.1728316992521286\n",
      "epoch 11 loss: 0.17090733349323273\n",
      "epoch 12 loss: 0.1916746199131012\n",
      "epoch 13 loss: 0.19957689940929413\n",
      "epoch 14 loss: 0.18659117817878723\n",
      "epoch 15 loss: 0.18259714543819427\n",
      "epoch 16 loss: 0.18908755481243134\n",
      "epoch 17 loss: 0.1772031933069229\n",
      "epoch 18 loss: 0.2244865894317627\n",
      "epoch 19 loss: 0.1396111100912094\n",
      "epoch 20 loss: 0.16116680204868317\n",
      "epoch 21 loss: 0.1645110547542572\n",
      "epoch 22 loss: 0.15784363448619843\n",
      "epoch 23 loss: 0.17900581657886505\n",
      "epoch 24 loss: 0.17882825434207916\n",
      "epoch 25 loss: 0.1490073800086975\n",
      "epoch 26 loss: 0.16096238791942596\n",
      "epoch 27 loss: 0.12813891470432281\n",
      "epoch 28 loss: 0.17655245959758759\n",
      "epoch 29 loss: 0.1762811839580536\n",
      "epoch 30 loss: 0.1759384423494339\n",
      "52\n",
      "epoch 1 loss: 0.8289163708686829\n",
      "epoch 2 loss: 0.8601481318473816\n",
      "epoch 3 loss: 0.45761117339134216\n",
      "epoch 4 loss: 0.2698063850402832\n",
      "epoch 5 loss: 0.2111780345439911\n",
      "epoch 6 loss: 0.1654597967863083\n",
      "epoch 7 loss: 0.1950903683900833\n",
      "epoch 8 loss: 0.1499260663986206\n",
      "epoch 9 loss: 0.18667100369930267\n",
      "epoch 10 loss: 0.15694302320480347\n",
      "epoch 11 loss: 0.1876816600561142\n",
      "epoch 12 loss: 0.2001744508743286\n",
      "epoch 13 loss: 0.1583097130060196\n",
      "epoch 14 loss: 0.17794567346572876\n",
      "epoch 15 loss: 0.187977597117424\n",
      "epoch 16 loss: 0.16772030293941498\n",
      "epoch 17 loss: 0.19548776745796204\n",
      "epoch 18 loss: 0.17684240639209747\n",
      "epoch 19 loss: 0.16939206421375275\n",
      "epoch 20 loss: 0.18617293238639832\n",
      "epoch 21 loss: 0.15941224992275238\n",
      "epoch 22 loss: 0.1698502004146576\n",
      "epoch 23 loss: 0.16841819882392883\n",
      "epoch 24 loss: 0.1564752161502838\n",
      "epoch 25 loss: 0.1654096096754074\n",
      "epoch 26 loss: 0.15289191901683807\n",
      "epoch 27 loss: 0.1429012566804886\n",
      "epoch 28 loss: 0.1371331363916397\n",
      "epoch 29 loss: 0.14317163825035095\n",
      "epoch 30 loss: 0.17622429132461548\n",
      "53\n",
      "epoch 1 loss: 0.7987226247787476\n",
      "epoch 2 loss: 0.7822988629341125\n",
      "epoch 3 loss: 0.40536919236183167\n",
      "epoch 4 loss: 0.2675037086009979\n",
      "epoch 5 loss: 0.208898663520813\n",
      "epoch 6 loss: 0.23891231417655945\n",
      "epoch 7 loss: 0.19578413665294647\n",
      "epoch 8 loss: 0.17046645283699036\n",
      "epoch 9 loss: 0.19257694482803345\n",
      "epoch 10 loss: 0.15748481452465057\n",
      "epoch 11 loss: 0.17639827728271484\n",
      "epoch 12 loss: 0.17377357184886932\n",
      "epoch 13 loss: 0.18906563520431519\n",
      "epoch 14 loss: 0.19299475848674774\n",
      "epoch 15 loss: 0.17381909489631653\n",
      "epoch 16 loss: 0.18678753077983856\n",
      "epoch 17 loss: 0.14401820302009583\n",
      "epoch 18 loss: 0.14772357046604156\n",
      "epoch 19 loss: 0.18937860429286957\n",
      "epoch 20 loss: 0.15846951305866241\n",
      "epoch 21 loss: 0.18038062751293182\n",
      "epoch 22 loss: 0.20005552470684052\n",
      "epoch 23 loss: 0.15715627372264862\n",
      "epoch 24 loss: 0.18410201370716095\n",
      "epoch 25 loss: 0.1627867966890335\n",
      "epoch 26 loss: 0.1586330533027649\n",
      "epoch 27 loss: 0.1926138699054718\n",
      "epoch 28 loss: 0.14436686038970947\n",
      "epoch 29 loss: 0.1682264804840088\n",
      "epoch 30 loss: 0.18077746033668518\n",
      "54\n",
      "epoch 1 loss: 0.984832763671875\n",
      "epoch 2 loss: 0.7397506237030029\n",
      "epoch 3 loss: 0.4840928614139557\n",
      "epoch 4 loss: 0.35164758563041687\n",
      "epoch 5 loss: 0.1728915572166443\n",
      "epoch 6 loss: 0.18053337931632996\n",
      "epoch 7 loss: 0.17993658781051636\n",
      "epoch 8 loss: 0.20508605241775513\n",
      "epoch 9 loss: 0.13545280694961548\n",
      "epoch 10 loss: 0.17172273993492126\n",
      "epoch 11 loss: 0.1687188297510147\n",
      "epoch 12 loss: 0.21319207549095154\n",
      "epoch 13 loss: 0.19361013174057007\n",
      "epoch 14 loss: 0.15477928519248962\n",
      "epoch 15 loss: 0.18863829970359802\n",
      "epoch 16 loss: 0.17663992941379547\n",
      "epoch 17 loss: 0.1514417976140976\n",
      "epoch 18 loss: 0.17774423956871033\n",
      "epoch 19 loss: 0.18914736807346344\n",
      "epoch 20 loss: 0.1629212349653244\n",
      "epoch 21 loss: 0.1639721691608429\n",
      "epoch 22 loss: 0.18344174325466156\n",
      "epoch 23 loss: 0.15010735392570496\n",
      "epoch 24 loss: 0.16406013071537018\n",
      "epoch 25 loss: 0.13751523196697235\n",
      "epoch 26 loss: 0.17551103234291077\n",
      "epoch 27 loss: 0.14162194728851318\n",
      "epoch 28 loss: 0.1547960489988327\n",
      "epoch 29 loss: 0.14172498881816864\n",
      "epoch 30 loss: 0.18343733251094818\n",
      "55\n",
      "epoch 1 loss: 1.0151166915893555\n",
      "epoch 2 loss: 0.8131949305534363\n",
      "epoch 3 loss: 0.5762943029403687\n",
      "epoch 4 loss: 0.3382672965526581\n",
      "epoch 5 loss: 0.25490838289260864\n",
      "epoch 6 loss: 0.20064139366149902\n",
      "epoch 7 loss: 0.20417429506778717\n",
      "epoch 8 loss: 0.1953311711549759\n",
      "epoch 9 loss: 0.17153197526931763\n",
      "epoch 10 loss: 0.1848514825105667\n",
      "epoch 11 loss: 0.16688419878482819\n",
      "epoch 12 loss: 0.18574362993240356\n",
      "epoch 13 loss: 0.18562102317810059\n",
      "epoch 14 loss: 0.19417676329612732\n",
      "epoch 15 loss: 0.16529728472232819\n",
      "epoch 16 loss: 0.2045251876115799\n",
      "epoch 17 loss: 0.17890803515911102\n",
      "epoch 18 loss: 0.19030192494392395\n",
      "epoch 19 loss: 0.1445489078760147\n",
      "epoch 20 loss: 0.15009896457195282\n",
      "epoch 21 loss: 0.20351222157478333\n",
      "epoch 22 loss: 0.1841796636581421\n",
      "epoch 23 loss: 0.16766028106212616\n",
      "epoch 24 loss: 0.18913735449314117\n",
      "epoch 25 loss: 0.19748085737228394\n",
      "epoch 26 loss: 0.1506277173757553\n",
      "epoch 27 loss: 0.1908026933670044\n",
      "epoch 28 loss: 0.18201249837875366\n",
      "epoch 29 loss: 0.1547224372625351\n",
      "epoch 30 loss: 0.1543748378753662\n",
      "56\n",
      "epoch 1 loss: 0.8598823547363281\n",
      "epoch 2 loss: 0.7358065247535706\n",
      "epoch 3 loss: 0.5673890113830566\n",
      "epoch 4 loss: 0.4473930299282074\n",
      "epoch 5 loss: 0.1969078630208969\n",
      "epoch 6 loss: 0.200516015291214\n",
      "epoch 7 loss: 0.19699405133724213\n",
      "epoch 8 loss: 0.1947299987077713\n",
      "epoch 9 loss: 0.15569476783275604\n",
      "epoch 10 loss: 0.17305836081504822\n",
      "epoch 11 loss: 0.207442969083786\n",
      "epoch 12 loss: 0.19906258583068848\n",
      "epoch 13 loss: 0.18724597990512848\n",
      "epoch 14 loss: 0.15868903696537018\n",
      "epoch 15 loss: 0.16874480247497559\n",
      "epoch 16 loss: 0.2075033336877823\n",
      "epoch 17 loss: 0.17275185883045197\n",
      "epoch 18 loss: 0.1825263500213623\n",
      "epoch 19 loss: 0.2028374969959259\n",
      "epoch 20 loss: 0.16503658890724182\n",
      "epoch 21 loss: 0.17307014763355255\n",
      "epoch 22 loss: 0.1501425802707672\n",
      "epoch 23 loss: 0.17216800153255463\n",
      "epoch 24 loss: 0.15523286163806915\n",
      "epoch 25 loss: 0.1888103187084198\n",
      "epoch 26 loss: 0.15619288384914398\n",
      "epoch 27 loss: 0.16777634620666504\n",
      "epoch 28 loss: 0.18870213627815247\n",
      "epoch 29 loss: 0.1309150755405426\n",
      "epoch 30 loss: 0.16382482647895813\n",
      "57\n",
      "epoch 1 loss: 1.139115810394287\n",
      "epoch 2 loss: 0.9098609685897827\n",
      "epoch 3 loss: 0.6934434175491333\n",
      "epoch 4 loss: 0.31206896901130676\n",
      "epoch 5 loss: 0.1960531324148178\n",
      "epoch 6 loss: 0.20529888570308685\n",
      "epoch 7 loss: 0.16720084846019745\n",
      "epoch 8 loss: 0.1876848042011261\n",
      "epoch 9 loss: 0.1962839514017105\n",
      "epoch 10 loss: 0.14631570875644684\n",
      "epoch 11 loss: 0.15065214037895203\n",
      "epoch 12 loss: 0.16504454612731934\n",
      "epoch 13 loss: 0.1884130984544754\n",
      "epoch 14 loss: 0.15649503469467163\n",
      "epoch 15 loss: 0.15108801424503326\n",
      "epoch 16 loss: 0.19723622500896454\n",
      "epoch 17 loss: 0.1658141165971756\n",
      "epoch 18 loss: 0.18839532136917114\n",
      "epoch 19 loss: 0.14372065663337708\n",
      "epoch 20 loss: 0.1505320817232132\n",
      "epoch 21 loss: 0.13419562578201294\n",
      "epoch 22 loss: 0.19779835641384125\n",
      "epoch 23 loss: 0.1413436084985733\n",
      "epoch 24 loss: 0.17600496113300323\n",
      "epoch 25 loss: 0.15344379842281342\n",
      "epoch 26 loss: 0.19770954549312592\n",
      "epoch 27 loss: 0.1853327602148056\n",
      "epoch 28 loss: 0.13635286688804626\n",
      "epoch 29 loss: 0.1747792810201645\n",
      "epoch 30 loss: 0.1826377809047699\n",
      "58\n",
      "epoch 1 loss: 1.0800096988677979\n",
      "epoch 2 loss: 0.6930527091026306\n",
      "epoch 3 loss: 0.5881403088569641\n",
      "epoch 4 loss: 0.39053109288215637\n",
      "epoch 5 loss: 0.21282754838466644\n",
      "epoch 6 loss: 0.21629652380943298\n",
      "epoch 7 loss: 0.22379329800605774\n",
      "epoch 8 loss: 0.17097218334674835\n",
      "epoch 9 loss: 0.20337635278701782\n",
      "epoch 10 loss: 0.1546909064054489\n",
      "epoch 11 loss: 0.18280208110809326\n",
      "epoch 12 loss: 0.19577831029891968\n",
      "epoch 13 loss: 0.14172068238258362\n",
      "epoch 14 loss: 0.16584710776805878\n",
      "epoch 15 loss: 0.16079570353031158\n",
      "epoch 16 loss: 0.18150630593299866\n",
      "epoch 17 loss: 0.16952483355998993\n",
      "epoch 18 loss: 0.20122572779655457\n",
      "epoch 19 loss: 0.1366276890039444\n",
      "epoch 20 loss: 0.18623469769954681\n",
      "epoch 21 loss: 0.17602963745594025\n",
      "epoch 22 loss: 0.12146814167499542\n",
      "epoch 23 loss: 0.1262436807155609\n",
      "epoch 24 loss: 0.1586114764213562\n",
      "epoch 25 loss: 0.16083818674087524\n",
      "epoch 26 loss: 0.14665953814983368\n",
      "epoch 27 loss: 0.14513616263866425\n",
      "epoch 28 loss: 0.1590052992105484\n",
      "epoch 29 loss: 0.18508993089199066\n",
      "epoch 30 loss: 0.20010806620121002\n",
      "59\n",
      "epoch 1 loss: 0.8572293519973755\n",
      "epoch 2 loss: 0.8539208173751831\n",
      "epoch 3 loss: 0.4561348259449005\n",
      "epoch 4 loss: 0.2908670902252197\n",
      "epoch 5 loss: 0.21663156151771545\n",
      "epoch 6 loss: 0.2269497811794281\n",
      "epoch 7 loss: 0.19074521958827972\n",
      "epoch 8 loss: 0.17462606728076935\n",
      "epoch 9 loss: 0.2320934683084488\n",
      "epoch 10 loss: 0.16622957587242126\n",
      "epoch 11 loss: 0.18613016605377197\n",
      "epoch 12 loss: 0.1643097847700119\n",
      "epoch 13 loss: 0.16955384612083435\n",
      "epoch 14 loss: 0.2151683121919632\n",
      "epoch 15 loss: 0.15695929527282715\n",
      "epoch 16 loss: 0.21383720636367798\n",
      "epoch 17 loss: 0.1564439982175827\n",
      "epoch 18 loss: 0.18377989530563354\n",
      "epoch 19 loss: 0.17271403968334198\n",
      "epoch 20 loss: 0.1609598845243454\n",
      "epoch 21 loss: 0.15415872633457184\n",
      "epoch 22 loss: 0.1583198606967926\n",
      "epoch 23 loss: 0.18975001573562622\n",
      "epoch 24 loss: 0.2020697146654129\n",
      "epoch 25 loss: 0.19829359650611877\n",
      "epoch 26 loss: 0.17433756589889526\n",
      "epoch 27 loss: 0.15855427086353302\n",
      "epoch 28 loss: 0.16781044006347656\n",
      "epoch 29 loss: 0.16642597317695618\n",
      "epoch 30 loss: 0.15384314954280853\n",
      "60\n",
      "epoch 1 loss: 1.041157841682434\n",
      "epoch 2 loss: 0.7828338146209717\n",
      "epoch 3 loss: 0.48881620168685913\n",
      "epoch 4 loss: 0.2799670398235321\n",
      "epoch 5 loss: 0.21727731823921204\n",
      "epoch 6 loss: 0.2435922920703888\n",
      "epoch 7 loss: 0.1691167652606964\n",
      "epoch 8 loss: 0.23314033448696136\n",
      "epoch 9 loss: 0.16900138556957245\n",
      "epoch 10 loss: 0.2071782946586609\n",
      "epoch 11 loss: 0.22825393080711365\n",
      "epoch 12 loss: 0.19270332157611847\n",
      "epoch 13 loss: 0.155715212225914\n",
      "epoch 14 loss: 0.16269278526306152\n",
      "epoch 15 loss: 0.1750013828277588\n",
      "epoch 16 loss: 0.15514613687992096\n",
      "epoch 17 loss: 0.175424262881279\n",
      "epoch 18 loss: 0.17934925854206085\n",
      "epoch 19 loss: 0.19407013058662415\n",
      "epoch 20 loss: 0.17853544652462006\n",
      "epoch 21 loss: 0.1917857974767685\n",
      "epoch 22 loss: 0.1769540011882782\n",
      "epoch 23 loss: 0.17565491795539856\n",
      "epoch 24 loss: 0.17729808390140533\n",
      "epoch 25 loss: 0.13918602466583252\n",
      "epoch 26 loss: 0.15624594688415527\n",
      "epoch 27 loss: 0.16159914433956146\n",
      "epoch 28 loss: 0.19092494249343872\n",
      "epoch 29 loss: 0.1680261492729187\n",
      "epoch 30 loss: 0.1465781033039093\n",
      "61\n",
      "epoch 1 loss: 0.7939950227737427\n",
      "epoch 2 loss: 0.6680611371994019\n",
      "epoch 3 loss: 0.5448525547981262\n",
      "epoch 4 loss: 0.2665265202522278\n",
      "epoch 5 loss: 0.2623170018196106\n",
      "epoch 6 loss: 0.19917194545269012\n",
      "epoch 7 loss: 0.1713586002588272\n",
      "epoch 8 loss: 0.18419300019741058\n",
      "epoch 9 loss: 0.24442484974861145\n",
      "epoch 10 loss: 0.1946115344762802\n",
      "epoch 11 loss: 0.17207567393779755\n",
      "epoch 12 loss: 0.18771418929100037\n",
      "epoch 13 loss: 0.23205339908599854\n",
      "epoch 14 loss: 0.1642608344554901\n",
      "epoch 15 loss: 0.18170307576656342\n",
      "epoch 16 loss: 0.18176814913749695\n",
      "epoch 17 loss: 0.18094371259212494\n",
      "epoch 18 loss: 0.19117501378059387\n",
      "epoch 19 loss: 0.1984698325395584\n",
      "epoch 20 loss: 0.16101309657096863\n",
      "epoch 21 loss: 0.17029955983161926\n",
      "epoch 22 loss: 0.20345988869667053\n",
      "epoch 23 loss: 0.15200559794902802\n",
      "epoch 24 loss: 0.1651143729686737\n",
      "epoch 25 loss: 0.20072531700134277\n",
      "epoch 26 loss: 0.21674728393554688\n",
      "epoch 27 loss: 0.1506175696849823\n",
      "epoch 28 loss: 0.18745888769626617\n",
      "epoch 29 loss: 0.13746710121631622\n",
      "epoch 30 loss: 0.16804388165473938\n",
      "62\n",
      "epoch 1 loss: 0.7868064045906067\n",
      "epoch 2 loss: 0.7332586646080017\n",
      "epoch 3 loss: 0.3959945738315582\n",
      "epoch 4 loss: 0.3061707019805908\n",
      "epoch 5 loss: 0.1880805790424347\n",
      "epoch 6 loss: 0.21457171440124512\n",
      "epoch 7 loss: 0.16455300152301788\n",
      "epoch 8 loss: 0.16008110344409943\n",
      "epoch 9 loss: 0.20078177750110626\n",
      "epoch 10 loss: 0.16758565604686737\n",
      "epoch 11 loss: 0.20299461483955383\n",
      "epoch 12 loss: 0.18589095771312714\n",
      "epoch 13 loss: 0.1551651805639267\n",
      "epoch 14 loss: 0.13628780841827393\n",
      "epoch 15 loss: 0.18300680816173553\n",
      "epoch 16 loss: 0.1802188754081726\n",
      "epoch 17 loss: 0.1678132563829422\n",
      "epoch 18 loss: 0.1769256591796875\n",
      "epoch 19 loss: 0.14823752641677856\n",
      "epoch 20 loss: 0.19012680649757385\n",
      "epoch 21 loss: 0.13449551165103912\n",
      "epoch 22 loss: 0.13789276778697968\n",
      "epoch 23 loss: 0.15782752633094788\n",
      "epoch 24 loss: 0.16947992146015167\n",
      "epoch 25 loss: 0.14634041488170624\n",
      "epoch 26 loss: 0.17304587364196777\n",
      "epoch 27 loss: 0.1575004607439041\n",
      "epoch 28 loss: 0.19405241310596466\n",
      "epoch 29 loss: 0.15328443050384521\n",
      "epoch 30 loss: 0.20945622026920319\n",
      "63\n",
      "epoch 1 loss: 1.072143793106079\n",
      "epoch 2 loss: 0.8802798986434937\n",
      "epoch 3 loss: 0.6937215924263\n",
      "epoch 4 loss: 0.3617700934410095\n",
      "epoch 5 loss: 0.289857417345047\n",
      "epoch 6 loss: 0.21914727985858917\n",
      "epoch 7 loss: 0.19518110156059265\n",
      "epoch 8 loss: 0.2162400484085083\n",
      "epoch 9 loss: 0.1751643717288971\n",
      "epoch 10 loss: 0.14066384732723236\n",
      "epoch 11 loss: 0.18998485803604126\n",
      "epoch 12 loss: 0.16722597181797028\n",
      "epoch 13 loss: 0.1427200436592102\n",
      "epoch 14 loss: 0.1934283822774887\n",
      "epoch 15 loss: 0.19804644584655762\n",
      "epoch 16 loss: 0.20728692412376404\n",
      "epoch 17 loss: 0.16865099966526031\n",
      "epoch 18 loss: 0.20227691531181335\n",
      "epoch 19 loss: 0.17550694942474365\n",
      "epoch 20 loss: 0.17030315101146698\n",
      "epoch 21 loss: 0.1773584485054016\n",
      "epoch 22 loss: 0.1735900640487671\n",
      "epoch 23 loss: 0.1544259637594223\n",
      "epoch 24 loss: 0.15487471222877502\n",
      "epoch 25 loss: 0.156351238489151\n",
      "epoch 26 loss: 0.1846005916595459\n",
      "epoch 27 loss: 0.15579856932163239\n",
      "epoch 28 loss: 0.18025638163089752\n",
      "epoch 29 loss: 0.15384447574615479\n",
      "epoch 30 loss: 0.1617373824119568\n",
      "64\n",
      "epoch 1 loss: 0.9539250135421753\n",
      "epoch 2 loss: 0.9831323623657227\n",
      "epoch 3 loss: 0.4698382318019867\n",
      "epoch 4 loss: 0.36271145939826965\n",
      "epoch 5 loss: 0.2682203948497772\n",
      "epoch 6 loss: 0.18414746224880219\n",
      "epoch 7 loss: 0.2097044438123703\n",
      "epoch 8 loss: 0.20286329090595245\n",
      "epoch 9 loss: 0.2032029777765274\n",
      "epoch 10 loss: 0.1996127963066101\n",
      "epoch 11 loss: 0.18973614275455475\n",
      "epoch 12 loss: 0.1927228718996048\n",
      "epoch 13 loss: 0.1487899124622345\n",
      "epoch 14 loss: 0.16530176997184753\n",
      "epoch 15 loss: 0.13560767471790314\n",
      "epoch 16 loss: 0.1742183268070221\n",
      "epoch 17 loss: 0.16469107568264008\n",
      "epoch 18 loss: 0.1534121185541153\n",
      "epoch 19 loss: 0.1822570562362671\n",
      "epoch 20 loss: 0.15579736232757568\n",
      "epoch 21 loss: 0.18745321035385132\n",
      "epoch 22 loss: 0.1910317838191986\n",
      "epoch 23 loss: 0.16269856691360474\n",
      "epoch 24 loss: 0.20476499199867249\n",
      "epoch 25 loss: 0.2085929960012436\n",
      "epoch 26 loss: 0.2031630277633667\n",
      "epoch 27 loss: 0.1839611530303955\n",
      "epoch 28 loss: 0.1861535608768463\n",
      "epoch 29 loss: 0.19567924737930298\n",
      "epoch 30 loss: 0.17949147522449493\n",
      "65\n",
      "epoch 1 loss: 0.801507294178009\n",
      "epoch 2 loss: 0.6985565423965454\n",
      "epoch 3 loss: 0.40899428725242615\n",
      "epoch 4 loss: 0.2833618223667145\n",
      "epoch 5 loss: 0.22609955072402954\n",
      "epoch 6 loss: 0.18510672450065613\n",
      "epoch 7 loss: 0.1714734137058258\n",
      "epoch 8 loss: 0.1421135812997818\n",
      "epoch 9 loss: 0.19797292351722717\n",
      "epoch 10 loss: 0.15959402918815613\n",
      "epoch 11 loss: 0.17169241607189178\n",
      "epoch 12 loss: 0.18121370673179626\n",
      "epoch 13 loss: 0.18006548285484314\n",
      "epoch 14 loss: 0.15998142957687378\n",
      "epoch 15 loss: 0.15511678159236908\n",
      "epoch 16 loss: 0.15894927084445953\n",
      "epoch 17 loss: 0.20719507336616516\n",
      "epoch 18 loss: 0.1498100906610489\n",
      "epoch 19 loss: 0.1584671586751938\n",
      "epoch 20 loss: 0.15018711984157562\n",
      "epoch 21 loss: 0.18407069146633148\n",
      "epoch 22 loss: 0.19548901915550232\n",
      "epoch 23 loss: 0.15392771363258362\n",
      "epoch 24 loss: 0.18933065235614777\n",
      "epoch 25 loss: 0.193070188164711\n",
      "epoch 26 loss: 0.21417178213596344\n",
      "epoch 27 loss: 0.14583051204681396\n",
      "epoch 28 loss: 0.1593908667564392\n",
      "epoch 29 loss: 0.1307775378227234\n",
      "epoch 30 loss: 0.17705805599689484\n",
      "66\n",
      "epoch 1 loss: 0.8726754784584045\n",
      "epoch 2 loss: 0.7847506403923035\n",
      "epoch 3 loss: 0.51470947265625\n",
      "epoch 4 loss: 0.3424626588821411\n",
      "epoch 5 loss: 0.202851802110672\n",
      "epoch 6 loss: 0.1745453029870987\n",
      "epoch 7 loss: 0.1675887554883957\n",
      "epoch 8 loss: 0.18522441387176514\n",
      "epoch 9 loss: 0.18064041435718536\n",
      "epoch 10 loss: 0.18210862576961517\n",
      "epoch 11 loss: 0.15727020800113678\n",
      "epoch 12 loss: 0.1723005473613739\n",
      "epoch 13 loss: 0.1565312296152115\n",
      "epoch 14 loss: 0.17712551355361938\n",
      "epoch 15 loss: 0.20092307031154633\n",
      "epoch 16 loss: 0.22857949137687683\n",
      "epoch 17 loss: 0.18322819471359253\n",
      "epoch 18 loss: 0.19521820545196533\n",
      "epoch 19 loss: 0.16219626367092133\n",
      "epoch 20 loss: 0.10148187726736069\n",
      "epoch 21 loss: 0.2075371891260147\n",
      "epoch 22 loss: 0.15280161798000336\n",
      "epoch 23 loss: 0.16080811619758606\n",
      "epoch 24 loss: 0.12239336222410202\n",
      "epoch 25 loss: 0.16688989102840424\n",
      "epoch 26 loss: 0.18961697816848755\n",
      "epoch 27 loss: 0.1394282430410385\n",
      "epoch 28 loss: 0.14652234315872192\n",
      "epoch 29 loss: 0.13450570404529572\n",
      "epoch 30 loss: 0.1552630066871643\n",
      "67\n",
      "epoch 1 loss: 0.85799640417099\n",
      "epoch 2 loss: 0.760966956615448\n",
      "epoch 3 loss: 0.5218709111213684\n",
      "epoch 4 loss: 0.29126212000846863\n",
      "epoch 5 loss: 0.19548927247524261\n",
      "epoch 6 loss: 0.228012815117836\n",
      "epoch 7 loss: 0.1876571923494339\n",
      "epoch 8 loss: 0.18105991184711456\n",
      "epoch 9 loss: 0.17665325105190277\n",
      "epoch 10 loss: 0.17036931216716766\n",
      "epoch 11 loss: 0.1657704859972\n",
      "epoch 12 loss: 0.15293274819850922\n",
      "epoch 13 loss: 0.16294045746326447\n",
      "epoch 14 loss: 0.1426856964826584\n",
      "epoch 15 loss: 0.1756933331489563\n",
      "epoch 16 loss: 0.16224786639213562\n",
      "epoch 17 loss: 0.18032515048980713\n",
      "epoch 18 loss: 0.17074130475521088\n",
      "epoch 19 loss: 0.1408890336751938\n",
      "epoch 20 loss: 0.18435503542423248\n",
      "epoch 21 loss: 0.17001973092556\n",
      "epoch 22 loss: 0.1453796923160553\n",
      "epoch 23 loss: 0.1224089115858078\n",
      "epoch 24 loss: 0.17020690441131592\n",
      "epoch 25 loss: 0.17213620245456696\n",
      "epoch 26 loss: 0.12350335717201233\n",
      "epoch 27 loss: 0.15508463978767395\n",
      "epoch 28 loss: 0.12265635281801224\n",
      "epoch 29 loss: 0.13046663999557495\n",
      "epoch 30 loss: 0.14276844263076782\n",
      "68\n",
      "epoch 1 loss: 0.9467760324478149\n",
      "epoch 2 loss: 0.8084927201271057\n",
      "epoch 3 loss: 0.4210284352302551\n",
      "epoch 4 loss: 0.28353458642959595\n",
      "epoch 5 loss: 0.2324550449848175\n",
      "epoch 6 loss: 0.24604667723178864\n",
      "epoch 7 loss: 0.18050223588943481\n",
      "epoch 8 loss: 0.19018474221229553\n",
      "epoch 9 loss: 0.1757247895002365\n",
      "epoch 10 loss: 0.1941954493522644\n",
      "epoch 11 loss: 0.18109868466854095\n",
      "epoch 12 loss: 0.21073681116104126\n",
      "epoch 13 loss: 0.15252478420734406\n",
      "epoch 14 loss: 0.17861026525497437\n",
      "epoch 15 loss: 0.2092604786157608\n",
      "epoch 16 loss: 0.16095289587974548\n",
      "epoch 17 loss: 0.15010526776313782\n",
      "epoch 18 loss: 0.1357908397912979\n",
      "epoch 19 loss: 0.14936374127864838\n",
      "epoch 20 loss: 0.14971472322940826\n",
      "epoch 21 loss: 0.1827966421842575\n",
      "epoch 22 loss: 0.16401197016239166\n",
      "epoch 23 loss: 0.17617610096931458\n",
      "epoch 24 loss: 0.1796940118074417\n",
      "epoch 25 loss: 0.17286916077136993\n",
      "epoch 26 loss: 0.1746646761894226\n",
      "epoch 27 loss: 0.16143086552619934\n",
      "epoch 28 loss: 0.1604701280593872\n",
      "epoch 29 loss: 0.16588334739208221\n",
      "epoch 30 loss: 0.16051363945007324\n",
      "69\n",
      "epoch 1 loss: 0.8203852772712708\n",
      "epoch 2 loss: 0.5480477213859558\n",
      "epoch 3 loss: 0.49117419123649597\n",
      "epoch 4 loss: 0.5093300342559814\n",
      "epoch 5 loss: 0.2010292112827301\n",
      "epoch 6 loss: 0.17919547855854034\n",
      "epoch 7 loss: 0.1585436910390854\n",
      "epoch 8 loss: 0.16660305857658386\n",
      "epoch 9 loss: 0.1754177361726761\n",
      "epoch 10 loss: 0.23516802489757538\n",
      "epoch 11 loss: 0.16576336324214935\n",
      "epoch 12 loss: 0.16085213422775269\n",
      "epoch 13 loss: 0.1872979998588562\n",
      "epoch 14 loss: 0.18940676748752594\n",
      "epoch 15 loss: 0.1746351718902588\n",
      "epoch 16 loss: 0.1626710444688797\n",
      "epoch 17 loss: 0.18705931305885315\n",
      "epoch 18 loss: 0.1585894078016281\n",
      "epoch 19 loss: 0.14954252541065216\n",
      "epoch 20 loss: 0.17252983152866364\n",
      "epoch 21 loss: 0.18140505254268646\n",
      "epoch 22 loss: 0.1654568910598755\n",
      "epoch 23 loss: 0.13641035556793213\n",
      "epoch 24 loss: 0.17125838994979858\n",
      "epoch 25 loss: 0.16064035892486572\n",
      "epoch 26 loss: 0.15894781053066254\n",
      "epoch 27 loss: 0.1803869754076004\n",
      "epoch 28 loss: 0.16835784912109375\n",
      "epoch 29 loss: 0.14340616762638092\n",
      "epoch 30 loss: 0.1467209756374359\n",
      "70\n",
      "epoch 1 loss: 0.9387560486793518\n",
      "epoch 2 loss: 0.6662671566009521\n",
      "epoch 3 loss: 0.3999192416667938\n",
      "epoch 4 loss: 0.24793027341365814\n",
      "epoch 5 loss: 0.20117223262786865\n",
      "epoch 6 loss: 0.16618919372558594\n",
      "epoch 7 loss: 0.16404415667057037\n",
      "epoch 8 loss: 0.16976779699325562\n",
      "epoch 9 loss: 0.17385545372962952\n",
      "epoch 10 loss: 0.1731649935245514\n",
      "epoch 11 loss: 0.177626833319664\n",
      "epoch 12 loss: 0.17824479937553406\n",
      "epoch 13 loss: 0.15079240500926971\n",
      "epoch 14 loss: 0.17387568950653076\n",
      "epoch 15 loss: 0.1504993438720703\n",
      "epoch 16 loss: 0.1678147166967392\n",
      "epoch 17 loss: 0.1576438844203949\n",
      "epoch 18 loss: 0.18670783936977386\n",
      "epoch 19 loss: 0.1576012223958969\n",
      "epoch 20 loss: 0.18376390635967255\n",
      "epoch 21 loss: 0.15518821775913239\n",
      "epoch 22 loss: 0.18660296499729156\n",
      "epoch 23 loss: 0.14810416102409363\n",
      "epoch 24 loss: 0.1378706395626068\n",
      "epoch 25 loss: 0.15349030494689941\n",
      "epoch 26 loss: 0.14257586002349854\n",
      "epoch 27 loss: 0.15407073497772217\n",
      "epoch 28 loss: 0.1690942645072937\n",
      "epoch 29 loss: 0.1620764285326004\n",
      "epoch 30 loss: 0.16345995664596558\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "d27cf356-2ff4-4378-b703-2f448c5feb51",
   "metadata": {},
   "source": [
    "## DEOK"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a3a7744-611e-43a6-af04-b599caa3f0f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T01:35:32.333224Z",
     "start_time": "2025-10-04T01:35:30.483262Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import model_summary as model_class\n",
    "import prophet_linear_adjust as prophet_based\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "58e77d59-04d2-4325-ba43-49365711bf25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T01:35:34.671128Z",
     "start_time": "2025-10-04T01:35:34.601647Z"
    }
   },
   "source": [
    "df_deok = pd.read_csv(\"DEOK_hourly.csv\")\n",
    "df_deok.rename(columns={'Datetime': 'ds', 'DEOK_MW': 'y'}, inplace=True)\n",
    "df_deok['ds'] = pd.to_datetime(df_deok['ds'], format='%Y-%m-%d %H:%M:%S')\n",
    "out_dir = 'Deok_results'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based without seasonality",
   "id": "9c511e80846b31ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T01:44:30.058185Z",
     "start_time": "2025-10-04T01:35:36.894738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_demand_deok = df_deok.groupby(df_deok['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "results_prophet = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_deok, date_start, date_end, daily_demand_deok, manual = False, daily = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet = pd.concat(results_prophet, ignore_index=True)\n",
    "\n",
    "results_prophet.to_csv(out_dir + '/results_prophet.csv', index=False)"
   ],
   "id": "2851f131cd7e7d1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:35:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:35:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:35:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:35:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:35:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:36:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:36:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:36:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:36:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:36:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:36:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:36:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:36:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:38:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:38:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:38:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:38:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:38:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:38:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:38:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:38:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:38:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:38:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:38:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:38:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:38:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:38:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:38:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:38:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:38:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:38:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:39:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:39:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:39:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:39:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:39:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:39:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:39:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:39:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:39:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:39:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:39:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:39:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:39:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:39:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:40:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:40:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:40:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:40:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:40:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:40:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:40:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:40:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:40:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:40:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:40:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:40:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:40:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:40:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:40:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:41:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:41:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:41:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:41:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:41:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:41:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:41:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:41:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:41:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:41:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:41:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:41:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:41:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:41:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:42:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:42:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:42:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:42:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:42:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:42:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:42:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:42:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:42:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:42:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:42:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:42:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:42:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:42:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:42:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:42:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:43:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:43:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:43:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:43:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:43:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:43:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:43:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:43:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:44:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:44:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:44:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:44:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:44:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:44:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:44:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test prophet based with weekly seasonality",
   "id": "bc68866fe05682cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T01:54:26.100039Z",
     "start_time": "2025-10-04T01:44:30.083996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_demand_deok = df_deok.groupby(df_deok['ds'].dt.date)['y'].sum().reset_index()\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "results_prophet_w = []\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(f\"fit model {date_end + pd.Timedelta(days=1)}\")\n",
    "    result = prophet_based.forecast_next_day_hourly(df_deok, date_start, date_end, daily_demand_deok, manual = False, daily = True, weekly = True)\n",
    "    result['h_ahead'] = pd.to_datetime(result['ds']).dt.hour\n",
    "    results_prophet_w.append(result)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "\n",
    "    if i == 70:\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_prophet_w = pd.concat(results_prophet_w, ignore_index=True)\n",
    "\n",
    "results_prophet_w.to_csv(out_dir + '/results_prophet_w.csv', index=False)"
   ],
   "id": "237529760dfba1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:44:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:44:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:44:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:44:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:44:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:44:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:44:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:45:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:45:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:45:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:45:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:45:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:45:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:45:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:45:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:45:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:45:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:45:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:45:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:45:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:45:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:46:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:46:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:46:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:46:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:46:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:46:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:46:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:46:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:47:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:47:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:47:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:47:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:47:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:47:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:47:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:47:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:47:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:47:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:47:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:47:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:47:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:48:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:48:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:48:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:48:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:48:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:48:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:48:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:48:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-10-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:48:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:48:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:48:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:48:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:48:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:48:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:48:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:49:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:49:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:49:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:49:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:49:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:49:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:49:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:49:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:49:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:49:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:49:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:49:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:49:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:50:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:50:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:50:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:50:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:50:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:50:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:50:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:50:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-14 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:50:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:50:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:50:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:50:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:50:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:51:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-17 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:51:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:51:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:51:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:51:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:51:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:51:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-20 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:51:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:51:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-21 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:51:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:51:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:51:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:51:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-23 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:51:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:52:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-24 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:52:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:52:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:52:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:52:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:52:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:52:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-27 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:52:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:52:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-28 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:52:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:52:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:52:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:52:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-11-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:52:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:53:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:53:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:53:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:53:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:53:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-03 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:53:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:53:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:53:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:53:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:53:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-06 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:53:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:53:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-07 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:53:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:54:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:54:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:54:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:54:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:54:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit model 2017-12-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:54:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:54:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "9c39d431-2b1f-4c1a-beb4-7419b9743eff",
   "metadata": {},
   "source": [
    "### test RNN+self convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56191aed-b3f0-4310-844e-7a7cb33859c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con = pd.concat([results_aep_self_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con.to_csv(out_dir + '/results_aep_self_con.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ad29d-c1ce-42e4-b531-c18995aee2a5",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + numerical weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a634a6-8595-4e14-9211-321c96e3952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wn = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wn()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wn = pd.concat([results_aep_self_con_wn, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_self_con_wn.to_csv(out_dir + '/results_aep_self_con_wn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d279f1e3-814f-4e92-a728-a69b8d9edaa7",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + categorical weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c37ad-3a27-4288-9e33-e4fd6762084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_self_con_wc = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_FeatureAttention_wc()\n",
    "    trainer = model_class.RNN_train_2(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_self_con_wc = pd.concat([results_aep_self_con_wc, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "results_aep_self_con_wc.to_csv(out_dir + '/results_aep_self_con_wc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f52c4-720d-43c7-bdf7-6feff3156197",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier vector (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06fe62-65ac-4279-8eaf-af83e1993db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"vector\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w = pd.concat([results_aep_fourier_w, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w.to_csv(out_dir + '/results_aep_fourier_w.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8eb99c-9fd8-4e1f-bde8-d828c435296c",
   "metadata": {},
   "source": [
    "### test RNN+self convolution + fourier matrix (only weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17cb594-359d-4712-b704-71b7e293481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "fourier_conf = model_class.fourier_config(mode=\"matrix\", K_weekly=3, K_monthly=0)\n",
    "F_pairs = 2*(fourier_conf.K_weekly + fourier_conf.K_monthly)\n",
    "if fourier_conf.mode == \"vector\":\n",
    "    cont_dim = 1 + F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "else:\n",
    "    cont_dim = 1 + 24*F_pairs\n",
    "    fourier_dim = F_pairs\n",
    "            \n",
    "results_aep_fourier_w_matrix = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_fourier(cont_dim=cont_dim, fourier_dim=fourier_dim,\n",
    "                                    xf_mode=fourier_conf.mode, d_model=128, nhead=4, \n",
    "                                    activation=\"relu\", learn_z0=True, dropout=0.0,\n",
    "                                    H=24, use_gate=True, nonneg_U0=False)\n",
    "    trainer = model_class.RNN_train_fourier(model, train_config, fourier_conf)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    \n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_fourier_w_matrix = pd.concat([results_aep_fourier_w_matrix, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_fourier_w_matrix.to_csv(out_dir + '/results_aep_fourier_w_matrix.csv', index=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test RNN_based asym",
   "id": "961ea56b8e152fde"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8d677-64cd-46f4-beec-91da417b3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"mps\"))\n",
    "results_aep_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_asym_feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_aep_asy_con = pd.concat([results_aep_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_aep_asy_con.to_csv(out_dir + '/results_aep_asy_con.csv', index=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test RNN_based ARMA",
   "id": "dbbcaa33b4e564a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c23a4c-b0d3-487f-9550-c71b8b5d9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = model_class.training_config(n_epochs = 30, device = torch.device(\"cpu\"))\n",
    "results_arma_asy_con = pd.DataFrame({'day': [], 'hour': [], 'y_hat': [], 'y':[]})\n",
    "date_start = pd.to_datetime('2013-10-01 00:00:00')\n",
    "date_end = pd.to_datetime('2017-10-01 00:00:00')\n",
    "\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    print(i)\n",
    "    df_reduced = df_deok.loc[(df_deok['ds'] >= date_start) & (df_deok['ds'] < date_end)].copy()\n",
    "    model = model_class.RNN_ARMA_Feature()\n",
    "    trainer = model_class.RNN_train_1(model, train_config)\n",
    "    forcast, true = trainer(df_reduced)\n",
    "    result = pd.DataFrame({'day': df_reduced['ds'].dt.date.max(), 'hour': list(range(24)), 'y_hat': forcast, 'y': true})\n",
    "\n",
    "    results_arma_asy_con = pd.concat([results_arma_asy_con, result]).reset_index(drop=True)\n",
    "\n",
    "    date_start += pd.Timedelta(days=1)\n",
    "    date_end += pd.Timedelta(days=1)\n",
    "    if i == 70:\n",
    "        print('finish')\n",
    "        break\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "results_arma_asy_con.to_csv(out_dir + '/results_arma_asy_con.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01b47f-ab24-4859-8e8c-c1697ed2e61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1664e3b4-3076-40f6-9971-fde328252947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fb538-8d01-444d-b722-99e2547467c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269cf35-b68b-4c0f-81dc-eb4cf3b80359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41807dc5-6529-47ea-857e-483dacaca4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b79ce5-fbc3-4ea9-9c8d-804118a32c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3181d-41c4-4e29-a7e4-622ffe9eaa62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6266e9ec-31c0-434f-87d9-74fa9156e69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f8595-bad6-4254-97d7-c473ef63525a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4418937a-a255-464f-8efb-7c01372490d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
